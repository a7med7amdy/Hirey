{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from matplotlib import image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import numpy  as np\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import data\n",
    "import matplotlib.pyplot as plt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Network architecture.\n",
    "class Deep_Emotion(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Deep_Emotion class contains the network architecture.\n",
    "        '''\n",
    "        super(Deep_Emotion,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,5)\n",
    "        self.conv2 = nn.Conv2d(10,10,5)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(10,10,5)\n",
    "        self.conv4 = nn.Conv2d(10,10,5)\n",
    "        self.pool4 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.norm = nn.BatchNorm2d(10)\n",
    "\n",
    "        self.fc1 = nn.Linear(320,50)\n",
    "        self.fc2 = nn.Linear(50,8)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 3 * 3, 32),    #//////640\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "        \n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 10 * 3 * 3)      #//////640///10*3*3\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        \n",
    "        print(x.size(),\"SIZE\")\n",
    "        print(theta.size(),\"SIZE\")\n",
    "        \n",
    "        grid = F.affine_grid(theta, x.size(),align_corners=True)\n",
    "        x = F.grid_sample(x, grid)\n",
    "        return x\n",
    "#         return grid\n",
    "\n",
    "    def forward(self,input):\n",
    "#         grid = self.stn(input)\n",
    "        out = self.stn(input)\n",
    "        \n",
    "#         out = F.relu(self.conv1(input))\n",
    "        out = F.relu(self.conv1(out))\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(self.pool2(out))\n",
    "        \n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = self.norm(self.conv4(out))\n",
    "        out = F.relu(self.pool4(out))\n",
    "\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = out.view(-1, 320)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deep_Emotion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Deep_Emotion, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 8)\n",
    "\n",
    "        # Spatial transformer localization-network\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 3 * 3, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 10 * 3 * 3)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        # Perform the usual forward pass\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sec_Deep_Emotion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Deep_Emotion, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3)\n",
    "        self.cnn2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n",
    "        self.cnn3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "        self.cnn4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.cnn5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.cnn6 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3)\n",
    "        self.cnn7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2, 1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.cnn1_bn = nn.BatchNorm2d(8)\n",
    "        self.cnn2_bn = nn.BatchNorm2d(16)\n",
    "        self.cnn3_bn = nn.BatchNorm2d(32)\n",
    "        self.cnn4_bn = nn.BatchNorm2d(64)\n",
    "        self.cnn5_bn = nn.BatchNorm2d(128)\n",
    "        self.cnn6_bn = nn.BatchNorm2d(256)\n",
    "        self.cnn7_bn = nn.BatchNorm2d(256)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 7)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "#         self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.pool1(self.cnn1_bn(self.cnn1(x))))\n",
    "        x = self.relu(self.pool1(self.cnn2_bn(self.dropout(self.cnn2(x)))))\n",
    "        x = self.relu(self.pool1(self.cnn3_bn(self.cnn3(x))))\n",
    "        x = self.relu(self.pool1(self.cnn4_bn(self.dropout(self.cnn4(x)))))\n",
    "        x = self.relu(self.pool2(self.cnn5_bn(self.cnn5(x))))\n",
    "        x = self.relu(self.pool2(self.cnn6_bn(self.dropout(self.cnn6(x)))))\n",
    "        x = self.relu(self.pool2(self.cnn7_bn(self.dropout(self.cnn7(x)))))\n",
    "    \n",
    "        x = x.view(x.size(0), -1)\n",
    "    \n",
    "        x = self.relu(self.dropout(self.fc1(x)))\n",
    "        x = self.relu(self.dropout(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "#         x = self.log_softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "def Train(epochs,train_loader,val_loader,criterion,optmizer,device):\n",
    "    '''\n",
    "    Training Loop\n",
    "    '''\n",
    "    print(\"===================================Start Training===================================\")\n",
    "#     validation_dataset = 0\n",
    "#     test_dataset = 0\n",
    "    traini_loss = list()\n",
    "    vali_loss = list()\n",
    "    \n",
    "    traini_acc = list()\n",
    "    vali_acc = list()\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        train_loss = 0\n",
    "        validation_loss = 0\n",
    "        train_correct = 0\n",
    "        val_correct = 0\n",
    "        \n",
    "        # Train the model  #\n",
    "        net.train()\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optmizer.zero_grad()\n",
    "            outputs = net(data)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optmizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs,1)\n",
    "            train_correct += torch.sum(preds == labels.data)  #----------------------->\n",
    "#             train_dataset = train_dataset+1\n",
    "#         scheduler.step()\n",
    "\n",
    "        #validate the model#\n",
    "        net.eval()\n",
    "        for data,labels in val_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            val_outputs = net(data)\n",
    "            val_loss = criterion(val_outputs, labels)\n",
    "            validation_loss += val_loss.item()\n",
    "            _, val_preds = torch.max(val_outputs,1)\n",
    "            val_correct += torch.sum(val_preds == labels.data) #----------------------->\n",
    "#             validation_dataset = validation_dataset+1\n",
    "\n",
    "#         print(len(train_dataset))\n",
    "    \n",
    "        train_loss = train_loss/len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        validation_loss =  validation_loss / len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        \n",
    "        traini_loss.append(train_loss)\n",
    "        vali_loss.append(validation_loss)\n",
    "        \n",
    "        traini_acc.append(train_acc)\n",
    "        vali_acc.append(val_acc)\n",
    "        \n",
    "        print('Epoch: {} \\tTraining Loss: {:.8f} \\tValidation Loss {:.8f} \\tTraining Acuuarcy {:.3f}% \\tValidation Acuuarcy {:.3f}%'\n",
    "                                                           .format(e+1, train_loss,val_loss,train_acc * 100, val_acc*100))\n",
    "\n",
    "    torch.save(net.state_dict(),'deep_emotion_CK+neutral-30.30-{}-{}-{}.pt'.format(epochs,batchsize,lr))\n",
    "    #-------------------------------------------->\n",
    "#     f, (ax1, ax2) = plt.subplots(1, 2, figsize = (6, 6))\n",
    "    plt.plot(range(0,len(traini_loss)),traini_loss, color='Blue', label='train')\n",
    "    plt.plot(range(0,len(vali_loss)),vali_loss, color='Red', label='validation')\n",
    "#     plt.plot(range(0,len(traini_acc)),traini_loss, color='cyan', label='train')\n",
    "#     plt.plot(range(0,len(vali_acc)),vali_loss, color='yellow', label='validation')\n",
    "    plt.legend() \n",
    "    plt.show() \n",
    "    print(\"===================================Training Finished===================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1097\n",
      "[767, 111, 219]\n",
      "===================================Start Training===================================\n",
      "Epoch: 1 \tTraining Loss: 0.03249955 \tValidation Loss 2.07652545 \tTraining Acuuarcy 11.213% \tValidation Acuuarcy 18.018%\n",
      "Epoch: 2 \tTraining Loss: 0.03191719 \tValidation Loss 2.03460860 \tTraining Acuuarcy 19.817% \tValidation Acuuarcy 19.820%\n",
      "Epoch: 3 \tTraining Loss: 0.03141781 \tValidation Loss 1.98827815 \tTraining Acuuarcy 22.425% \tValidation Acuuarcy 21.622%\n",
      "Epoch: 4 \tTraining Loss: 0.03121353 \tValidation Loss 2.05647969 \tTraining Acuuarcy 22.555% \tValidation Acuuarcy 20.721%\n",
      "Epoch: 5 \tTraining Loss: 0.03092183 \tValidation Loss 1.97100711 \tTraining Acuuarcy 24.772% \tValidation Acuuarcy 20.721%\n",
      "Epoch: 6 \tTraining Loss: 0.03073991 \tValidation Loss 1.98886108 \tTraining Acuuarcy 22.295% \tValidation Acuuarcy 20.721%\n",
      "Epoch: 7 \tTraining Loss: 0.03049238 \tValidation Loss 1.96601772 \tTraining Acuuarcy 23.859% \tValidation Acuuarcy 20.721%\n",
      "Epoch: 8 \tTraining Loss: 0.03039889 \tValidation Loss 2.00250006 \tTraining Acuuarcy 26.336% \tValidation Acuuarcy 20.721%\n",
      "Epoch: 9 \tTraining Loss: 0.03047272 \tValidation Loss 2.03119349 \tTraining Acuuarcy 23.990% \tValidation Acuuarcy 21.622%\n",
      "Epoch: 10 \tTraining Loss: 0.03028455 \tValidation Loss 2.00244069 \tTraining Acuuarcy 25.684% \tValidation Acuuarcy 20.721%\n",
      "Epoch: 11 \tTraining Loss: 0.03023145 \tValidation Loss 1.93718731 \tTraining Acuuarcy 26.728% \tValidation Acuuarcy 21.622%\n",
      "Epoch: 12 \tTraining Loss: 0.03001453 \tValidation Loss 1.95299339 \tTraining Acuuarcy 28.162% \tValidation Acuuarcy 31.532%\n",
      "Epoch: 13 \tTraining Loss: 0.02999795 \tValidation Loss 1.81496894 \tTraining Acuuarcy 30.639% \tValidation Acuuarcy 37.838%\n",
      "Epoch: 14 \tTraining Loss: 0.02961493 \tValidation Loss 1.99467814 \tTraining Acuuarcy 31.682% \tValidation Acuuarcy 36.036%\n",
      "Epoch: 15 \tTraining Loss: 0.02904887 \tValidation Loss 1.94862986 \tTraining Acuuarcy 33.116% \tValidation Acuuarcy 38.739%\n",
      "Epoch: 16 \tTraining Loss: 0.02879774 \tValidation Loss 1.79198873 \tTraining Acuuarcy 36.115% \tValidation Acuuarcy 37.838%\n",
      "Epoch: 17 \tTraining Loss: 0.02822706 \tValidation Loss 1.93880224 \tTraining Acuuarcy 36.506% \tValidation Acuuarcy 38.739%\n",
      "Epoch: 18 \tTraining Loss: 0.02728164 \tValidation Loss 1.53099239 \tTraining Acuuarcy 39.374% \tValidation Acuuarcy 42.342%\n",
      "Epoch: 19 \tTraining Loss: 0.02635685 \tValidation Loss 1.64937997 \tTraining Acuuarcy 40.939% \tValidation Acuuarcy 44.144%\n",
      "Epoch: 20 \tTraining Loss: 0.02509803 \tValidation Loss 1.42693055 \tTraining Acuuarcy 43.025% \tValidation Acuuarcy 43.243%\n",
      "Epoch: 21 \tTraining Loss: 0.02428200 \tValidation Loss 1.40225005 \tTraining Acuuarcy 46.154% \tValidation Acuuarcy 49.550%\n",
      "Epoch: 22 \tTraining Loss: 0.02307849 \tValidation Loss 1.37039053 \tTraining Acuuarcy 49.153% \tValidation Acuuarcy 48.649%\n",
      "Epoch: 23 \tTraining Loss: 0.02256064 \tValidation Loss 1.46211994 \tTraining Acuuarcy 50.065% \tValidation Acuuarcy 51.351%\n",
      "Epoch: 24 \tTraining Loss: 0.02107822 \tValidation Loss 1.21316719 \tTraining Acuuarcy 52.542% \tValidation Acuuarcy 54.955%\n",
      "Epoch: 25 \tTraining Loss: 0.02068691 \tValidation Loss 1.29884171 \tTraining Acuuarcy 51.108% \tValidation Acuuarcy 55.856%\n",
      "Epoch: 26 \tTraining Loss: 0.02023872 \tValidation Loss 1.11305273 \tTraining Acuuarcy 54.889% \tValidation Acuuarcy 58.559%\n",
      "Epoch: 27 \tTraining Loss: 0.01901092 \tValidation Loss 1.28582180 \tTraining Acuuarcy 57.366% \tValidation Acuuarcy 57.658%\n",
      "Epoch: 28 \tTraining Loss: 0.01883914 \tValidation Loss 1.30247378 \tTraining Acuuarcy 56.193% \tValidation Acuuarcy 53.153%\n",
      "Epoch: 29 \tTraining Loss: 0.01877420 \tValidation Loss 1.07822382 \tTraining Acuuarcy 58.279% \tValidation Acuuarcy 57.658%\n",
      "Epoch: 30 \tTraining Loss: 0.01794411 \tValidation Loss 1.28719723 \tTraining Acuuarcy 58.409% \tValidation Acuuarcy 56.757%\n",
      "Epoch: 31 \tTraining Loss: 0.01781482 \tValidation Loss 0.82655060 \tTraining Acuuarcy 60.235% \tValidation Acuuarcy 59.459%\n",
      "Epoch: 32 \tTraining Loss: 0.01739847 \tValidation Loss 0.97748458 \tTraining Acuuarcy 61.408% \tValidation Acuuarcy 60.360%\n",
      "Epoch: 33 \tTraining Loss: 0.01750137 \tValidation Loss 1.00332284 \tTraining Acuuarcy 61.408% \tValidation Acuuarcy 58.559%\n",
      "Epoch: 34 \tTraining Loss: 0.01648037 \tValidation Loss 0.99878228 \tTraining Acuuarcy 64.928% \tValidation Acuuarcy 60.360%\n",
      "Epoch: 35 \tTraining Loss: 0.01616275 \tValidation Loss 1.00482452 \tTraining Acuuarcy 63.364% \tValidation Acuuarcy 65.766%\n",
      "Epoch: 36 \tTraining Loss: 0.01602067 \tValidation Loss 0.81246656 \tTraining Acuuarcy 63.625% \tValidation Acuuarcy 68.468%\n",
      "Epoch: 37 \tTraining Loss: 0.01519210 \tValidation Loss 1.08508849 \tTraining Acuuarcy 68.579% \tValidation Acuuarcy 68.468%\n",
      "Epoch: 38 \tTraining Loss: 0.01419069 \tValidation Loss 0.69550955 \tTraining Acuuarcy 67.666% \tValidation Acuuarcy 64.865%\n",
      "Epoch: 39 \tTraining Loss: 0.01629451 \tValidation Loss 0.89003307 \tTraining Acuuarcy 64.537% \tValidation Acuuarcy 62.162%\n",
      "Epoch: 40 \tTraining Loss: 0.01861388 \tValidation Loss 0.93201202 \tTraining Acuuarcy 58.801% \tValidation Acuuarcy 64.865%\n",
      "Epoch: 41 \tTraining Loss: 0.01683647 \tValidation Loss 0.88220191 \tTraining Acuuarcy 64.537% \tValidation Acuuarcy 66.667%\n",
      "Epoch: 42 \tTraining Loss: 0.01485984 \tValidation Loss 0.95275742 \tTraining Acuuarcy 66.102% \tValidation Acuuarcy 65.766%\n",
      "Epoch: 43 \tTraining Loss: 0.01470315 \tValidation Loss 0.85682273 \tTraining Acuuarcy 70.013% \tValidation Acuuarcy 69.369%\n",
      "Epoch: 44 \tTraining Loss: 0.01358202 \tValidation Loss 0.82599837 \tTraining Acuuarcy 70.535% \tValidation Acuuarcy 70.270%\n",
      "Epoch: 45 \tTraining Loss: 0.01385800 \tValidation Loss 0.76702344 \tTraining Acuuarcy 69.492% \tValidation Acuuarcy 73.874%\n",
      "Epoch: 46 \tTraining Loss: 0.01320624 \tValidation Loss 0.77726901 \tTraining Acuuarcy 72.621% \tValidation Acuuarcy 72.973%\n",
      "Epoch: 47 \tTraining Loss: 0.01300574 \tValidation Loss 0.60504401 \tTraining Acuuarcy 70.665% \tValidation Acuuarcy 70.270%\n",
      "Epoch: 48 \tTraining Loss: 0.01336757 \tValidation Loss 0.45712975 \tTraining Acuuarcy 69.492% \tValidation Acuuarcy 73.874%\n",
      "Epoch: 49 \tTraining Loss: 0.01309761 \tValidation Loss 0.61992460 \tTraining Acuuarcy 71.317% \tValidation Acuuarcy 70.270%\n",
      "Epoch: 50 \tTraining Loss: 0.01275034 \tValidation Loss 0.79177856 \tTraining Acuuarcy 74.185% \tValidation Acuuarcy 72.973%\n",
      "Epoch: 51 \tTraining Loss: 0.01273076 \tValidation Loss 1.13043976 \tTraining Acuuarcy 72.229% \tValidation Acuuarcy 72.973%\n",
      "Epoch: 52 \tTraining Loss: 0.01228835 \tValidation Loss 0.72361892 \tTraining Acuuarcy 71.838% \tValidation Acuuarcy 73.874%\n",
      "Epoch: 53 \tTraining Loss: 0.01280932 \tValidation Loss 0.84141964 \tTraining Acuuarcy 71.969% \tValidation Acuuarcy 74.775%\n",
      "Epoch: 54 \tTraining Loss: 0.01420858 \tValidation Loss 0.73935944 \tTraining Acuuarcy 69.100% \tValidation Acuuarcy 71.171%\n",
      "Epoch: 55 \tTraining Loss: 0.01304636 \tValidation Loss 0.67249763 \tTraining Acuuarcy 71.578% \tValidation Acuuarcy 77.477%\n",
      "Epoch: 56 \tTraining Loss: 0.01170005 \tValidation Loss 0.61826265 \tTraining Acuuarcy 74.185% \tValidation Acuuarcy 76.577%\n",
      "Epoch: 57 \tTraining Loss: 0.01140820 \tValidation Loss 0.71785295 \tTraining Acuuarcy 73.794% \tValidation Acuuarcy 75.676%\n",
      "Epoch: 58 \tTraining Loss: 0.01080652 \tValidation Loss 0.74042422 \tTraining Acuuarcy 75.750% \tValidation Acuuarcy 79.279%\n",
      "Epoch: 59 \tTraining Loss: 0.01064926 \tValidation Loss 0.52954727 \tTraining Acuuarcy 74.576% \tValidation Acuuarcy 82.883%\n",
      "Epoch: 60 \tTraining Loss: 0.01030466 \tValidation Loss 0.71923941 \tTraining Acuuarcy 77.314% \tValidation Acuuarcy 81.081%\n",
      "Epoch: 61 \tTraining Loss: 0.00961206 \tValidation Loss 0.58098429 \tTraining Acuuarcy 76.923% \tValidation Acuuarcy 81.982%\n",
      "Epoch: 62 \tTraining Loss: 0.00952666 \tValidation Loss 0.51652360 \tTraining Acuuarcy 77.966% \tValidation Acuuarcy 83.784%\n",
      "Epoch: 63 \tTraining Loss: 0.00916808 \tValidation Loss 0.52723640 \tTraining Acuuarcy 77.445% \tValidation Acuuarcy 78.378%\n",
      "Epoch: 64 \tTraining Loss: 0.00907708 \tValidation Loss 0.54523885 \tTraining Acuuarcy 77.314% \tValidation Acuuarcy 84.685%\n",
      "Epoch: 65 \tTraining Loss: 0.00959124 \tValidation Loss 0.77983296 \tTraining Acuuarcy 78.488% \tValidation Acuuarcy 71.171%\n",
      "Epoch: 66 \tTraining Loss: 0.01005166 \tValidation Loss 0.65835786 \tTraining Acuuarcy 78.227% \tValidation Acuuarcy 81.982%\n",
      "Epoch: 67 \tTraining Loss: 0.00988458 \tValidation Loss 0.53289139 \tTraining Acuuarcy 78.488% \tValidation Acuuarcy 80.180%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68 \tTraining Loss: 0.00915619 \tValidation Loss 0.64239573 \tTraining Acuuarcy 79.400% \tValidation Acuuarcy 81.982%\n",
      "Epoch: 69 \tTraining Loss: 0.00889052 \tValidation Loss 0.47392729 \tTraining Acuuarcy 79.531% \tValidation Acuuarcy 86.486%\n",
      "Epoch: 70 \tTraining Loss: 0.00957250 \tValidation Loss 0.44826487 \tTraining Acuuarcy 77.705% \tValidation Acuuarcy 87.387%\n",
      "Epoch: 71 \tTraining Loss: 0.00892692 \tValidation Loss 0.55429792 \tTraining Acuuarcy 80.052% \tValidation Acuuarcy 81.081%\n",
      "Epoch: 72 \tTraining Loss: 0.00809686 \tValidation Loss 0.41085970 \tTraining Acuuarcy 80.574% \tValidation Acuuarcy 83.784%\n",
      "Epoch: 73 \tTraining Loss: 0.00780596 \tValidation Loss 0.30097437 \tTraining Acuuarcy 81.486% \tValidation Acuuarcy 87.387%\n",
      "Epoch: 74 \tTraining Loss: 0.00857739 \tValidation Loss 0.39742416 \tTraining Acuuarcy 80.313% \tValidation Acuuarcy 86.486%\n",
      "Epoch: 75 \tTraining Loss: 0.00749831 \tValidation Loss 0.33639270 \tTraining Acuuarcy 83.051% \tValidation Acuuarcy 85.586%\n",
      "Epoch: 76 \tTraining Loss: 0.00713401 \tValidation Loss 0.31623843 \tTraining Acuuarcy 82.790% \tValidation Acuuarcy 81.982%\n",
      "Epoch: 77 \tTraining Loss: 0.00779615 \tValidation Loss 0.38423133 \tTraining Acuuarcy 81.095% \tValidation Acuuarcy 81.081%\n",
      "Epoch: 78 \tTraining Loss: 0.00763136 \tValidation Loss 0.42265621 \tTraining Acuuarcy 83.703% \tValidation Acuuarcy 84.685%\n",
      "Epoch: 79 \tTraining Loss: 0.00693886 \tValidation Loss 0.66259265 \tTraining Acuuarcy 84.355% \tValidation Acuuarcy 85.586%\n",
      "Epoch: 80 \tTraining Loss: 0.00742243 \tValidation Loss 0.46082139 \tTraining Acuuarcy 84.485% \tValidation Acuuarcy 80.180%\n",
      "Epoch: 81 \tTraining Loss: 0.00896566 \tValidation Loss 0.46812597 \tTraining Acuuarcy 81.877% \tValidation Acuuarcy 75.676%\n",
      "Epoch: 82 \tTraining Loss: 0.00787891 \tValidation Loss 0.41010395 \tTraining Acuuarcy 82.790% \tValidation Acuuarcy 86.486%\n",
      "Epoch: 83 \tTraining Loss: 0.00653005 \tValidation Loss 0.53796446 \tTraining Acuuarcy 86.050% \tValidation Acuuarcy 83.784%\n",
      "Epoch: 84 \tTraining Loss: 0.00632646 \tValidation Loss 0.39350018 \tTraining Acuuarcy 85.398% \tValidation Acuuarcy 84.685%\n",
      "Epoch: 85 \tTraining Loss: 0.00717571 \tValidation Loss 0.53828651 \tTraining Acuuarcy 82.790% \tValidation Acuuarcy 76.577%\n",
      "Epoch: 86 \tTraining Loss: 0.00826623 \tValidation Loss 0.47397858 \tTraining Acuuarcy 80.574% \tValidation Acuuarcy 86.486%\n",
      "Epoch: 87 \tTraining Loss: 0.00753707 \tValidation Loss 0.49175811 \tTraining Acuuarcy 82.269% \tValidation Acuuarcy 79.279%\n",
      "Epoch: 88 \tTraining Loss: 0.00664196 \tValidation Loss 0.37439764 \tTraining Acuuarcy 85.007% \tValidation Acuuarcy 87.387%\n",
      "Epoch: 89 \tTraining Loss: 0.00612321 \tValidation Loss 0.53987014 \tTraining Acuuarcy 85.658% \tValidation Acuuarcy 87.387%\n",
      "Epoch: 90 \tTraining Loss: 0.00591640 \tValidation Loss 0.43935481 \tTraining Acuuarcy 86.310% \tValidation Acuuarcy 85.586%\n",
      "Epoch: 91 \tTraining Loss: 0.00576077 \tValidation Loss 0.40854385 \tTraining Acuuarcy 86.701% \tValidation Acuuarcy 86.486%\n",
      "Epoch: 92 \tTraining Loss: 0.00593935 \tValidation Loss 0.24992596 \tTraining Acuuarcy 85.658% \tValidation Acuuarcy 89.189%\n",
      "Epoch: 93 \tTraining Loss: 0.00555159 \tValidation Loss 0.47094426 \tTraining Acuuarcy 87.614% \tValidation Acuuarcy 85.586%\n",
      "Epoch: 94 \tTraining Loss: 0.00546471 \tValidation Loss 0.27179754 \tTraining Acuuarcy 86.701% \tValidation Acuuarcy 88.288%\n",
      "Epoch: 95 \tTraining Loss: 0.00520208 \tValidation Loss 0.56699628 \tTraining Acuuarcy 87.484% \tValidation Acuuarcy 86.486%\n",
      "Epoch: 96 \tTraining Loss: 0.00761000 \tValidation Loss 0.38830721 \tTraining Acuuarcy 83.312% \tValidation Acuuarcy 89.189%\n",
      "Epoch: 97 \tTraining Loss: 0.00696838 \tValidation Loss 0.41084832 \tTraining Acuuarcy 82.138% \tValidation Acuuarcy 85.586%\n",
      "Epoch: 98 \tTraining Loss: 0.00585253 \tValidation Loss 0.46195984 \tTraining Acuuarcy 87.614% \tValidation Acuuarcy 86.486%\n",
      "Epoch: 99 \tTraining Loss: 0.00596924 \tValidation Loss 0.36301154 \tTraining Acuuarcy 86.441% \tValidation Acuuarcy 88.288%\n",
      "Epoch: 100 \tTraining Loss: 0.00628057 \tValidation Loss 0.22685005 \tTraining Acuuarcy 85.267% \tValidation Acuuarcy 88.288%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================Training Finished===================================\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "lr = 0.005 #1-e3\n",
    "batchsize = 64 #----------------------->\n",
    "net = Deep_Emotion()\n",
    "net.to(device)\n",
    "# print(\"Model archticture: \", net)\n",
    "\n",
    "transformation= transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,)),\n",
    "                                    transforms.Grayscale(1),transforms.Resize((28,28))])\n",
    "        \n",
    "dataset = datasets.ImageFolder('C:/Users/nourg/Desktop/4th Year/GP/archive/CK+48', transform=transformation)\n",
    "# Val_dataset = datasets.ImageFolder('C:/Users/nourg/Desktop/4th Year/GP/archive/ck+', transform=transformation)\n",
    "# test_set = datasets.ImageFolder('C:/Users/nourg/Desktop/4th Year/GP/fer/data/test', transform=transformation)\n",
    "\n",
    "lengths = [int(len(dataset)*0.7), int(len(dataset) - (int(len(dataset)*0.7)+int(len(dataset)*0.2))),int(len(dataset)*0.2)]\n",
    "# lengths = [int(len(dataset)*0.8), int(len(dataset) - int(len(dataset)*0.8))]\n",
    "print(len(dataset))\n",
    "print(lengths)\n",
    "\n",
    "train_set, Val_set, test_set = random_split(dataset, lengths, generator=torch.Generator().manual_seed(42))\n",
    "# train_loader, Val_dataset= random_split(dataset, lengths, generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "train_loader = DataLoader(train_set, batch_size=batchsize,shuffle = True,num_workers=0)\n",
    "val_loader = DataLoader(Val_set, batch_size=batchsize,shuffle = True,num_workers=0)\n",
    "        \n",
    "criterion= nn.CrossEntropyLoss()\n",
    "# optmizer= optim.Adam(net.parameters(),lr= lr)\n",
    "\n",
    "optmizer = optim.SGD(net.parameters(), lr = lr, momentum=0.9,weight_decay = 1e-3)\n",
    "\n",
    "        # Decay LR by a factor of 0.1 every 7 epochs\n",
    "#         exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "        \n",
    "Train(epochs, train_loader, val_loader, criterion, optmizer, device)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 91 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transformation= transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,)), transforms.Grayscale(1), \n",
    "                                            transforms.Resize((48,48))])\n",
    "# test_dataset = datasets.ImageFolder('C:/Users/nourg/Desktop/4th Year/GP/testr', transform=transformation)\n",
    "test_loader =  DataLoader(test_set,shuffle = True,num_workers=0)\n",
    "\n",
    "# import cv2\n",
    "# import os\n",
    "\n",
    "# folder = 'C:/Users/nourg/Desktop/4th Year/GP/testr/anger'\n",
    "\n",
    "\n",
    "# images = []\n",
    "# for filename in os.listdir(folder):\n",
    "#     img = cv2.imread(os.path.join(folder,filename))\n",
    "#     if img is not None:\n",
    "#         images.append(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "\n",
    "net = Deep_Emotion()\n",
    "# print(\"Deep Emotion:-\", net)\n",
    "net.load_state_dict(torch.load('C:/Users/nourg/deep_emotion_CK+neutral-30.30-100-64-0.005.pt'))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "#Model Evaluation on test data\n",
    "classes = ('Angry','contempt' ,'Disgust', 'Fear', 'Happy', 'neutral','Sad', 'Surprise')\n",
    "# total = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "#     for data in torch.tensor(images):\n",
    "        data,labels = data.to(device), labels.to(device)\n",
    "        outputs = net(data)\n",
    "        pred = F.softmax(outputs,dim=1)\n",
    "        classs = torch.argmax(pred,1)\n",
    "#         wrong = torch.where(classs != labels,torch.tensor([1.]).to(\"cpu\").data,torch.tensor([0.]).to(\"cpu\").data)\n",
    "        correct += (classs == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "#         acc = torch.sum(correct)\n",
    "#         total.append(correct)\n",
    "#         print(\"acc\",acc)\n",
    "#         imshow(torchvision.utils.make_grid(data))\n",
    "#         print('GroundTruth: ', ' '.join('%7s' % classes[labels[j]] for j in range(7)))\n",
    "        \n",
    "#         print('Predicted: ', ' '.join('%7s' % classes[classs]))\n",
    "#         total += labels.size(0)\n",
    "#             total.append(acc.item())\n",
    "                    \n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * (correct / total)) )\n",
    "# print('Accuracy of the network on the test images: %d %%' % (100 * np.mean(total/ len(test_loader.dataset))))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 5., 0., 5., 7., 5., 5., 5., 1., 5., 1., 5., 5., 6., 7., 5., 6., 5., 7., 7., 7., 3., 4., 3., 6., 3., 3., 1.,\n",
      "        6., 5., 3., 7., 5., 7., 5., 6., 3., 0., 4., 4., 4., 0., 5., 5., 4., 3., 3., 1., 1., 4., 3., 7., 1., 5., 7., 6.,\n",
      "        6., 7., 5., 3., 0., 7., 5., 3., 6., 5., 6., 4., 3., 1., 7., 1., 3., 0., 7., 3., 6., 1., 4., 5., 7., 3., 4., 3.,\n",
      "        0., 2., 7., 3., 6., 7., 4., 5., 5., 2., 7., 4., 4., 7., 5., 0., 5., 7., 7., 5., 7., 5., 7., 2., 1., 7., 7., 0.,\n",
      "        0., 4., 7., 0., 3., 7., 5., 7., 7., 7., 5., 7., 3., 5., 7., 1., 7., 5., 4., 1., 7., 2., 0., 6., 3., 3., 7., 3.,\n",
      "        7., 4., 7., 0., 3., 3., 2., 7., 3., 4., 7., 3., 1., 1., 2., 5., 3., 3., 5., 7., 4., 0., 3., 5., 7., 7., 7., 1.,\n",
      "        3., 7., 1., 5., 7., 0., 3., 1., 5., 3., 4., 7., 0., 6., 7., 1., 3., 1., 0., 7., 5., 0., 0., 5., 0., 3., 5., 2.,\n",
      "        4., 0., 1., 7., 7., 3., 5., 1., 7., 6., 6., 5., 0., 3., 5., 5., 7., 5., 6., 6., 7., 1., 3.])\n",
      "Confusion matrix, without normalization\n",
      "[[18  2  1  0  0  0  0  0]\n",
      " [ 0 22  0  0  0  0  0  0]\n",
      " [ 0  1  2  0  1  1  2  0]\n",
      " [ 0  3  0 34  0  0  0  1]\n",
      " [ 0  1  0  0 18  0  0  0]\n",
      " [ 0  0  0  0  0 43  0  0]\n",
      " [ 0  3  0  0  0  0 14  0]\n",
      " [ 0  0  2  0  0  0  1 49]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x3600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "########################################################################################################\n",
    "########################################CONFUSION MATRIX################################################\n",
    "########################################################################################################\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "torch.set_printoptions(linewidth = 120)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# classes = ('Angry','contempt' ,'Disgust', 'Fear', 'Happy','Sad', 'Surprise')\n",
    "classes = ('Angry','contempt' ,'Disgust', 'Fear', 'Happy', 'neutral','Sad', 'Surprise')\n",
    "# classes = ('Angry' ,'Disgust', 'Fear', 'Happy', 'neutral' , 'Sad', 'Surprise')\n",
    "# dataset = datasets.ImageFolder('C:/Users/nourg/Desktop/4th Year/GP/archive2/images/train', transform=transformation)\n",
    "\n",
    "net = Deep_Emotion()\n",
    "# print(\"Deep Emotion:-\", net)\n",
    "net.load_state_dict(torch.load('C:/Users/nourg/deep_emotion_CK+neutral-30.30-100-64-0.005.pt'))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "# print(dataset.targets)\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_all_prediction(model, loader):\n",
    "    preds = torch.tensor([])\n",
    "    label = torch.tensor([])\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "        batch_predictions = model(images)\n",
    "        preds = torch.cat((preds, batch_predictions), dim = 0)\n",
    "        label = torch.cat((label, labels), dim = 0)\n",
    "    return preds,label\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=batchsize,shuffle = True,num_workers=0)\n",
    "train_preds,label = get_all_prediction(net, test_loader)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "# img , labels = test_loader\n",
    "# train_features, train_labels = next(iter(test_loader))\n",
    "# preds = torch.tensor([])\n",
    "# for batch in loader:\n",
    "#     images, labels = batch    \n",
    "print(label)\n",
    "\n",
    "plt.figure(figsize=(50,50))\n",
    "plot_confusion_matrix(label, train_preds.argmax(dim=1), classes=classes,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nourg\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:132: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  img = torch.from_numpy(np.array(pic, np.float32, copy=False))\n",
      "C:\\Users\\nourg\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3825: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "emotion_dict = ('Angry','contempt' ,'Disgust', 'Fear', 'Happy','Sad', 'Surprise')\n",
    "\n",
    "device = \"cpu\"\n",
    "val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))])\n",
    "net = Deep_Emotion()\n",
    "net.load_state_dict(torch.load('C:/Users/nourg/Desktop/4th Year/GP/archive/deep_emotion_ck+-100-64-0.005-97%.pt'))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    count +=1\n",
    "    if True:\n",
    "        face_cascade = cv2.CascadeClassifier('C:/Users/nourg/anaconda3/Library/etc/haarcascades/haarcascade_frontalface_default.xml')\n",
    "        faces = face_cascade.detectMultiScale(frame)\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "            resize_frame = cv2.resize(gray[y:y + h, x:x + w], (48, 48))\n",
    "            X = resize_frame/256\n",
    "#         cv2.imwrite(\"roi.jpg\", X)\n",
    "#         plt.imshow(X,'gray')\n",
    "#         plt.show()\n",
    "            X = Image.fromarray((X))\n",
    "            X = val_transform(X).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                out = net(X)\n",
    "                pred = F.softmax(out,dim=1)\n",
    "                classs = torch.argmax(pred,1)\n",
    "                pred = emotion_dict[classs.item()]\n",
    "            cv2.putText(frame, pred, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1)\n",
    "            count = 0\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotcm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-2c803e18b870>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mplotcm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_all_preds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotcm'"
     ]
    }
   ],
   "source": [
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "##############################################TRAAAAAAAAAAAASH########################################################\n",
    "######################################################################################################################\n",
    "######################################################################################################################\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from plotcm import plot_confusion_matrix\n",
    "@torch.no_grad()\n",
    "def get_all_preds(model, loader):\n",
    "    all_preds = torch.tensor([])\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "\n",
    "        preds = model(images)\n",
    "        all_preds = torch.cat(\n",
    "            (all_preds, preds)\n",
    "            ,dim=0\n",
    "        )\n",
    "    return all_preds\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction_loader = torch.utils.data.DataLoader(train_loader, batch_size=64)\n",
    "    train_preds = get_all_preds(net, prediction_loader)\n",
    "train_set.targets\n",
    "train_preds.argmax(dim=1)\n",
    "\n",
    "stacked = torch.stack(\n",
    "    (\n",
    "        train_set.targets\n",
    "        ,train_preds.argmax(dim=1)\n",
    "    )\n",
    "    ,dim=1\n",
    ")\n",
    "cmt = torch.zeros(10,10, dtype=torch.int64)\n",
    "\n",
    "for p in stacked:\n",
    "    tl, pl = p.tolist()\n",
    "    cmt[tl, pl] = cmt[tl, pl] + 1\n",
    "    \n",
    "cm = confusion_matrix(train_set.targets, train_preds.argmax(dim=1))\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cm, train_set.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show images and labels in test set.\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nourg\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:132: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  img = torch.from_numpy(np.array(pic, np.float32, copy=False))\n",
      "C:\\Users\\nourg\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3825: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "1\n",
      "1\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "6\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Let us import the Libraries required.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from model import FacialExpressionModel\n",
    "\n",
    "device = \"cpu\"\n",
    "transformation= transforms.Compose([transforms.ToTensor()])\n",
    "face_cascade = cv2.CascadeClassifier('C:/Users/nourg/anaconda3/Library/etc/haarcascades/haarcascade_frontalface_default.xml')\n",
    "# To capture video from webcam.\n",
    "cap = cv2.VideoCapture(0)\n",
    "val_transform = transforms.Compose([\n",
    "        transforms.ToTensor()])\n",
    "net = Deep_Emotion()\n",
    "net.load_state_dict(torch.load('C:/Users/nourg/Desktop/4th Year/GP/archive/deep_emotion_ck+-100-64-0.005-97%.pt'))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "#Model Evaluation on test data\n",
    "classes = ('Angry', 'contempt' ,'Disgust', 'Fear', 'Happy','Sad', 'Surprise')\n",
    "while True:\n",
    "    # Read the frame\n",
    "    _, img = cap.read()\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect the faces\n",
    "    faces = face_cascade.detectMultiScale(img, 1.1, 4)\n",
    "    # Draw the rectangle around each face\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "        resize_frame = cv2.resize(gray[y:y + h, x:x + w], (48, 48))\n",
    "        \n",
    "        X = resize_frame/256\n",
    "        X = Image.fromarray((X))\n",
    "        X = transformation(X).unsqueeze(0)\n",
    "        \n",
    "#         imge = torch.autograd.Variable(X,requires_grad = True)\n",
    "#         plt.imshow('img', img)\n",
    "#         plt.show()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            imj = X.to(device)\n",
    "            out = net(imj)\n",
    "            pred = F.softmax(out,dim=1)\n",
    "            classs = torch.argmax(pred,1)\n",
    "#     wrong = torch.where(classs != 3,torch.tensor([1.]).cuda(),torch.tensor([0.]).cuda())\n",
    "#     classs = torch.argmax(pred,1)\n",
    "            prediction = classes[classs.item()]\n",
    "            print(classs.item())\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            org = (50, 50)\n",
    "            fontScale = 1\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 2\n",
    "            img = cv2.putText(img, prediction, org, font,\n",
    "                       fontScale, color, thickness, cv2.LINE_AA)\n",
    "#         cv2.putText(img, pred, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1)\n",
    "        \n",
    "#     imgg = load_img(\"C:/Users/nourg/roi.jpg\")\n",
    "    \n",
    "\n",
    "    \n",
    "    cv2.imshow('img', img)\n",
    "    \n",
    "    # Finding the Probability of each Emotion\n",
    "#     preds = net.return_probabs(roi[np.newaxis, :, :, np.newaxis])\n",
    "\n",
    "#         # Converting the array into list\n",
    "#     data = preds.tolist()[0]\n",
    "\n",
    "#         # Initializing the Figure for Bar Graph\n",
    "#     fig = plt.figure(figsize=(8, 5))\n",
    "\n",
    "#         # Creating the bar plot\n",
    "#     plt.bar(EMOTIONS, data, color='green',\n",
    "#                 width=0.4)\n",
    "\n",
    "#         # Labelling the axes and title\n",
    "#     plt.xlabel(\"Types of Emotions\")\n",
    "#     plt.ylabel(\"Probability\")\n",
    "#     plt.title(\"Facial Emotion Recognition\")\n",
    "\n",
    "#         # Saving the Bar Plot\n",
    "#     path = \"static/\" + \"bar_plot\" + str(img)\n",
    "#     plt.savefig(path)\n",
    "        # Stop if (Q) key is pressed\n",
    "        \n",
    "    k = cv2.waitKey(30)\n",
    "    if k==ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    # Release the VideoCapture object\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us import the Libraries required.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import FacialExpressionModel\n",
    "\n",
    "# Creating an instance of the class with the parameters as model and its weights.\n",
    "test_model = FacialExpressionModel(\"model.json\", \"model_weights.h5\")\n",
    "\n",
    "# Loading the classifier from the file.\n",
    "facec = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "def Emotion_Analysis(img):\n",
    "    \"\"\" It does prediction of Emotions found in the Image provided, does the \n",
    "    Graphical visualisation, saves as Images and returns them \"\"\"\n",
    "\n",
    "    # Read the Image through OpenCv's imread()\n",
    "    path = \"static/\" + str(img)\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    # Convert the Image into Gray Scale\n",
    "    gray_frame = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Image size is reduced by 30% at each image scale.\n",
    "    scaleFactor = 1.3\n",
    "\n",
    "    # 5 neighbors should be present for each rectangle to be retained.\n",
    "    minNeighbors = 5\n",
    "\n",
    "    # Detect the Faces in the given Image and store it in faces.\n",
    "    faces = facec.detectMultiScale(gray_frame, scaleFactor, minNeighbors)\n",
    "\n",
    "    # When Classifier could not detect any Face.\n",
    "    if len(faces) == 0:\n",
    "        return [img]\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "\n",
    "        # Taking the Face part in the Image as Region of Interest.\n",
    "        roi = gray_frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Let us resize the Image accordingly to use pretrained model.\n",
    "        roi = cv2.resize(roi, (48, 48))\n",
    "\n",
    "        # Let us make the Prediction of Emotion present in the Image\n",
    "        prediction = test_model.predict_emotion(\n",
    "            roi[np.newaxis, :, :, np.newaxis])\n",
    "\n",
    "        # Custom Symbols to print with text of emotion.\n",
    "        Symbols = {\"Happy\": \":)\", \"Sad\": \":}\", \"Surprise\": \"!!\",\n",
    "                   \"Angry\": \"?\", \"Disgust\": \"#\", \"Neutral\": \".\", \"Fear\": \"~\"}\n",
    "    \n",
    "\n",
    "        ## based on the prediction recommend music\n",
    "\n",
    "\n",
    "        # Defining the Parameters for putting Text on Image\n",
    "        Text = str(prediction) + Symbols[str(prediction)]\n",
    "        Text_Color = (180, 105, 255)\n",
    "\n",
    "        Thickness = 2\n",
    "        Font_Scale = 1\n",
    "        Font_Type = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "        # Inserting the Text on Image\n",
    "        cv2.putText(image, Text, (x, y), Font_Type,\n",
    "                    Font_Scale, Text_Color, Thickness)\n",
    "\n",
    "        # Finding the Coordinates and Radius of Circle\n",
    "        xc = int((x + x+w)/2)\n",
    "        yc = int((y + y+h)/2)\n",
    "        radius = int(w/2)\n",
    "\n",
    "        # Drawing the Circle on the Image\n",
    "        cv2.circle(image, (xc, yc), radius, (0, 255, 0), Thickness)\n",
    "\n",
    "        # Saving the Predicted Image\n",
    "        path = \"static/\" + \"pred\" + str(img)\n",
    "        cv2.imwrite(path, image)\n",
    "\n",
    "        # List of Emotions\n",
    "        EMOTIONS = [\"Angry\", \"Disgust\",\n",
    "                    \"Fear\", \"Happy\",\n",
    "                    \"Neutral\", \"Sad\",\n",
    "                    \"Surprise\"]\n",
    "\n",
    "        # Finding the Probability of each Emotion\n",
    "        preds = test_model.return_probabs(roi[np.newaxis, :, :, np.newaxis])\n",
    "\n",
    "        # Converting the array into list\n",
    "        data = preds.tolist()[0]\n",
    "\n",
    "        # Initializing the Figure for Bar Graph\n",
    "        fig = plt.figure(figsize=(8, 5))\n",
    "\n",
    "        # Creating the bar plot\n",
    "        plt.bar(EMOTIONS, data, color='green',\n",
    "                width=0.4)\n",
    "\n",
    "        # Labelling the axes and title\n",
    "        plt.xlabel(\"Types of Emotions\")\n",
    "        plt.ylabel(\"Probability\")\n",
    "        plt.title(\"Facial Emotion Recognition\")\n",
    "\n",
    "        # Saving the Bar Plot\n",
    "        path = \"static/\" + \"bar_plot\" + str(img)\n",
    "        plt.savefig(path)\n",
    "        \n",
    "    # Returns a list containing the names of Original, Predicted, Bar Plot Images\n",
    "    return ([img, \"pred\" + img, \"bar_plot\" + img, prediction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
