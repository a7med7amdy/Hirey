{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Deploy_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7043921d9b8e4a01864a04a5d7f5bd21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fe18cbc8e7cc4dee9b48c56b11b5c255",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8b3263bef55540f5a5e4ac19799c4407",
              "IPY_MODEL_04f1be9d7a2a4be5a60799dac92ea579"
            ]
          }
        },
        "fe18cbc8e7cc4dee9b48c56b11b5c255": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b3263bef55540f5a5e4ac19799c4407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_68c75511c2ed4fe79ceaffbd8c04d1de",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 89843225,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 89843225,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e782c94371944a5818e541cb0e197d6"
          }
        },
        "04f1be9d7a2a4be5a60799dac92ea579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_45ef63cda1a243cba65996e85f72f89d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 85.7M/85.7M [00:32&lt;00:00, 2.75MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_333d097bf684469bad48102a4608221b"
          }
        },
        "68c75511c2ed4fe79ceaffbd8c04d1de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e782c94371944a5818e541cb0e197d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45ef63cda1a243cba65996e85f72f89d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "333d097bf684469bad48102a4608221b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "205a592920ff42e1b37765aaf7b4b0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7b5eccc5da0c49088e8ba649e003622e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_70718d46ba3a41c4ab25af26c94fa7f5",
              "IPY_MODEL_e881cf3a84d4422891d046d09dec96ad"
            ]
          }
        },
        "7b5eccc5da0c49088e8ba649e003622e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70718d46ba3a41c4ab25af26c94fa7f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3f89489c688c4d7a86b372f841cfdfb4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 96316515,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 96316515,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_50796d3089f6422b99b14cc6f98e6d40"
          }
        },
        "e881cf3a84d4422891d046d09dec96ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fcc787dd39334979a8e3c9535d8cc173",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 91.9M/91.9M [00:10&lt;00:00, 8.91MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f494c9448caa4276b2aba09c24055503"
          }
        },
        "3f89489c688c4d7a86b372f841cfdfb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "50796d3089f6422b99b14cc6f98e6d40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fcc787dd39334979a8e3c9535d8cc173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f494c9448caa4276b2aba09c24055503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b7b71a7caed440eacf94c2ade8b9ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b9228df733c54e2e83959460489f0ad8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c7bc507e3a2341398c214585e9d2423e",
              "IPY_MODEL_8630bb9d166244ffa768cdbd02ec94ce"
            ]
          }
        },
        "b9228df733c54e2e83959460489f0ad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7bc507e3a2341398c214585e9d2423e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b22007593d734a9db29483e5f5c366a0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_020e8b659db04616924aa6337cf65a76"
          }
        },
        "8630bb9d166244ffa768cdbd02ec94ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_488e33292a7344eeb4c97d1d409db9a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:01&lt;00:00, 18.8B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41ff8c2a91184f8caf70bad7fad26c56"
          }
        },
        "b22007593d734a9db29483e5f5c366a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "020e8b659db04616924aa6337cf65a76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "488e33292a7344eeb4c97d1d409db9a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41ff8c2a91184f8caf70bad7fad26c56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74feafc9345b4c4dbba192b500742dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a9b7e4d200ff4ffe9256d07439859359",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_109b6fdc5d7242d4835d723c124c7dac",
              "IPY_MODEL_afe20436911045aaa866be54a1fe18f2"
            ]
          }
        },
        "a9b7e4d200ff4ffe9256d07439859359": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "109b6fdc5d7242d4835d723c124c7dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_33f9e8222c394c87b635fc873bdac6a4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddfbd64b6cc349519a1d3d6a868ea9af"
          }
        },
        "afe20436911045aaa866be54a1fe18f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d03ac5bc0956461eb4e7920dea12d86b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [01:31&lt;00:00, 6.26B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0db2cb286a2a4c1989a7643c8dc9fe91"
          }
        },
        "33f9e8222c394c87b635fc873bdac6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddfbd64b6cc349519a1d3d6a868ea9af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d03ac5bc0956461eb4e7920dea12d86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0db2cb286a2a4c1989a7643c8dc9fe91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "487b4125d25a43db9e2d4b2427b1bc25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ab8c3b5201db46e2b76180d63805d67b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1e37946eede946668e2c51f4a0d28d1e",
              "IPY_MODEL_3138cc9312434caeac584f640312b2fb"
            ]
          }
        },
        "ab8c3b5201db46e2b76180d63805d67b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e37946eede946668e2c51f4a0d28d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4665b1b320304411935b93c958b87159",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_216b3625424f402ca1679511af9c715f"
          }
        },
        "3138cc9312434caeac584f640312b2fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b4cbc031b88449199c1a393af297cb32",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:05&lt;00:00, 43.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf79cf42333c4b7da00393b0e35ebf29"
          }
        },
        "4665b1b320304411935b93c958b87159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "216b3625424f402ca1679511af9c715f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4cbc031b88449199c1a393af297cb32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf79cf42333c4b7da00393b0e35ebf29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91a79d8d777f455f8a69781cb41b6870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4aeaa7ba5e994b83a5072359daf464c3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_58a0a758a190409191b094604b9aba7d",
              "IPY_MODEL_65846bb3ae664fa5845ee761a699cf95"
            ]
          }
        },
        "4aeaa7ba5e994b83a5072359daf464c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58a0a758a190409191b094604b9aba7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0f114df1c16c4183b697e0d4ad39a94a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d34f3985249542e1931fa55710e9ec74"
          }
        },
        "65846bb3ae664fa5845ee761a699cf95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9645f6a551bf4349b77ed745b83f0e27",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:03&lt;00:00, 131kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6140148cec8422f8b447120be2684cd"
          }
        },
        "0f114df1c16c4183b697e0d4ad39a94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d34f3985249542e1931fa55710e9ec74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9645f6a551bf4349b77ed745b83f0e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6140148cec8422f8b447120be2684cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weM74AKrwwj3"
      },
      "source": [
        "# **Importing and Installation**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqPr-_zXw7sG",
        "outputId": "f758e62f-66d9-4326-e423-4ca10ff7d180"
      },
      "source": [
        "!pip install google-cloud-texttospeech\n",
        "!pip install google-cloud\n",
        "!pip install google-cloud-speech"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-cloud-texttospeech in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.26.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-texttospeech) (1.26.3)\n",
            "Requirement already satisfied: proto-plus>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-texttospeech) (1.19.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-texttospeech) (21.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (1.32.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (1.53.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (57.2.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (2018.9)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (1.34.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (0.2.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-cloud-texttospeech) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-texttospeech) (1.24.3)\n",
            "Requirement already satisfied: google-cloud in /usr/local/lib/python3.7/dist-packages (0.34.0)\n",
            "Requirement already satisfied: google-cloud-speech in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: libcst>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from google-cloud-speech) (0.3.19)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-speech) (21.0)\n",
            "Requirement already satisfied: proto-plus>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-speech) (1.19.0)\n",
            "Requirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.26.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-speech) (1.26.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (1.15.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (1.32.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (1.53.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (2018.9)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (57.2.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (1.34.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (4.7.2)\n",
            "Requirement already satisfied: pyyaml>=5.2 in /usr/local/lib/python3.7/dist-packages (from libcst>=0.2.5->google-cloud-speech) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.2 in /usr/local/lib/python3.7/dist-packages (from libcst>=0.2.5->google-cloud-speech) (3.7.4.3)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from libcst>=0.2.5->google-cloud-speech) (0.7.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-cloud-speech) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-speech) (1.24.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from typing-inspect>=0.4.0->libcst>=0.2.5->google-cloud-speech) (0.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrQmVgfVw-L6",
        "outputId": "6a106ea3-ae68-47e2-b2fd-9351d368bc9b"
      },
      "source": [
        "!pip install face-alignment\n",
        "!pip install flask-ngrok\n",
        "!pip install -U flask-cors\n",
        "!pip install pydub\n",
        "!pip install transformers\n",
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face-alignment\n",
            "  Downloading face_alignment-1.3.4.tar.gz (26 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from face-alignment) (1.9.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face-alignment) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from face-alignment) (1.4.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from face-alignment) (0.16.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from face-alignment) (4.1.2.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from face-alignment) (4.41.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from face-alignment) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->face-alignment) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->face-alignment) (57.2.0)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment) (2.5.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.15.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->face-alignment) (4.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->face-alignment) (3.7.4.3)\n",
            "Building wheels for collected packages: face-alignment\n",
            "  Building wheel for face-alignment (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-alignment: filename=face_alignment-1.3.4-py2.py3-none-any.whl size=27859 sha256=34301c674b8b6a96b4f4ae31cc6323e6d30b7f80049646876d8207ee33fca071\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/f8/8f/617fca0e22aa1dc6b5fbfad78b07fa7626707b49167eea901c\n",
            "Successfully built face-alignment\n",
            "Installing collected packages: face-alignment\n",
            "Successfully installed face-alignment-1.3.4\n",
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "Collecting flask-cors\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.7/dist-packages (from flask-cors) (1.1.4)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors) (1.15.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask-cors) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask-cors) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask-cors) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask-cors) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.9->flask-cors) (2.0.1)\n",
            "Installing collected packages: flask-cors\n",
            "Successfully installed flask-cors-3.0.10\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.9.0-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 39.7 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 45.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.0\n",
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.18.4-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.9.0+cu102)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting botocore<1.22.0,>=1.21.4\n",
            "  Downloading botocore-1.21.4-py3-none-any.whl (7.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.7 MB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.4->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 48.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.4->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 45.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.5.30)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.18.4 botocore-1.21.4 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.5.0 urllib3-1.25.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx_k8dq7xBEG"
      },
      "source": [
        "%matplotlib inline\n",
        "import face_alignment\n",
        "import os\n",
        "from os import listdir\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import image\n",
        "from PIL import Image\n",
        "\n",
        "from skimage import transform,data,color,feature\n",
        "import skimage.io as ios\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import cross_val_score , GridSearchCV, train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from numba import jit, cuda\n",
        "import pickle\n",
        "import timeit\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.nn.modules.activation import ReLU\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import re\n",
        "import string\n",
        "import spacy\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "\n",
        "\n",
        "from imutils.face_utils import FaceAligner\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import sys\n",
        "from transformers import AutoTokenizer\n",
        "from pytorch_pretrained_bert import BertModel\n",
        "import scipy.io.wavfile as wav\n",
        "import io as ar\n",
        "from google.cloud import speech\n",
        "from flask import Flask, request, jsonify, render_template,send_file,Response\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask_cors import CORS\n",
        "\n",
        "from google.cloud import texttospeech\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "\n",
        "import librosa\n",
        "import soundfile\n",
        "import glob\n",
        "import shutil\n",
        "import wave\n",
        "import contextlib\n",
        "\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'avian-tract-283207-f1553ac44767.json'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P09dBindyVtg"
      },
      "source": [
        "# **Face detection and Emotion Recognition**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271,
          "referenced_widgets": [
            "7043921d9b8e4a01864a04a5d7f5bd21",
            "fe18cbc8e7cc4dee9b48c56b11b5c255",
            "8b3263bef55540f5a5e4ac19799c4407",
            "04f1be9d7a2a4be5a60799dac92ea579",
            "68c75511c2ed4fe79ceaffbd8c04d1de",
            "9e782c94371944a5818e541cb0e197d6",
            "45ef63cda1a243cba65996e85f72f89d",
            "333d097bf684469bad48102a4608221b",
            "205a592920ff42e1b37765aaf7b4b0ce",
            "7b5eccc5da0c49088e8ba649e003622e",
            "70718d46ba3a41c4ab25af26c94fa7f5",
            "e881cf3a84d4422891d046d09dec96ad",
            "3f89489c688c4d7a86b372f841cfdfb4",
            "50796d3089f6422b99b14cc6f98e6d40",
            "fcc787dd39334979a8e3c9535d8cc173",
            "f494c9448caa4276b2aba09c24055503"
          ]
        },
        "id": "yiaE2E06yRen",
        "outputId": "a7988fcf-8c6d-4127-aca9-870adb788725"
      },
      "source": [
        "model = pickle.load(open(\"faceDetection2.sav\", 'rb'))\n",
        "print(model)\n",
        "fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, flip_input=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.23.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" to /root/.cache/torch/hub/checkpoints/s3fd-619a316812.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "          verbose=0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7043921d9b8e4a01864a04a5d7f5bd21",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=89843225.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/2DFAN4-cd938726ad.zip\" to /root/.cache/torch/hub/checkpoints/2DFAN4-cd938726ad.zip\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "205a592920ff42e1b37765aaf7b4b0ce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=96316515.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-Vmmt_mybEa"
      },
      "source": [
        "def getFaceAlign(img):\n",
        "  ios.imsave('testt.jpg',img)\n",
        "  preds = fa.get_landmarks(img)\n",
        "  if preds == None:\n",
        "    #print('Warning: No faces were detected.')\n",
        "    return None,0\n",
        "  if preds!=None:\n",
        "    mnXY= np.min(np.min(preds, axis=1), axis=0)\n",
        "    mxXY= np.max(np.max(preds, axis=1), axis=0)\n",
        "    mxY=int(mxXY[0]+2)\n",
        "    mnX=int(mnXY[1])-8\n",
        "    mxX=int(mxXY[1])\n",
        "    if mnX < 0:\n",
        "       mnX=0\n",
        "    if int(mxXY[0]+2) >= img.shape[1]:\n",
        "      mxY=img.shape[1]-1\n",
        "    if (img.shape[0]-2-mnX) <= 40:\n",
        "      return img[mnX:img.shape[0]-2,int(mnXY[0])-2:mxY],1\n",
        "    else:\n",
        "      return img[mnX:mnX+40,int(mnXY[0])-2:mxY],1   # were 40 instead of 50\n",
        "    ####################################\n",
        "    # im_pil = Image.fromarray(img[mnX:mxX,int(mnXY[0]):mxY])\n",
        "    # im_pil=im_pil.resize((100, 100), Image.ANTIALIAS)\n",
        "    # io.imshow(np.array(im_pil))\n",
        "    # io.imsave('testtt.jpg',np.array(im_pil))\n",
        "    # return np.array(im_pil),1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOnm_rvWyfZx"
      },
      "source": [
        "def non_max_suppression_fast(boxes, overlapThresh):\n",
        "\tif len(boxes) == 0:\n",
        "\t\treturn []\n",
        "\tif boxes.dtype.kind == \"i\":\n",
        "\t\tboxes = boxes.astype(\"float\")\n",
        "\tpick = []\n",
        "\tx1 = boxes[:,2]\n",
        "\ty1 = boxes[:,0]\n",
        "\tx2 = boxes[:,3]\n",
        "\ty2 = boxes[:,1]\n",
        "\tarea = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "\tidxs = np.argsort(y2)\n",
        "\twhile len(idxs) > 0:\n",
        "\t\tlast = len(idxs) - 1\n",
        "\t\ti = idxs[last]\n",
        "\t\tpick.append(i)\n",
        "\t\txx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
        "\t\tyy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
        "\t\txx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
        "\t\tyy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
        "\t\tw = np.maximum(0, xx2 - xx1 + 1)\n",
        "\t\th = np.maximum(0, yy2 - yy1 + 1)\n",
        "\t\toverlap = (w * h) / area[idxs[:last]]\n",
        "\t\tidxs = np.delete(idxs, np.concatenate(([last],\n",
        "\t\t\tnp.where(overlap > overlapThresh)[0])))\n",
        "\treturn boxes[pick].astype(\"int\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO6GN716yhmW"
      },
      "source": [
        "def find(image):\n",
        "    boxes=[[i,i+k,j,int(j+k)] for k in [35,45,55] for i in range(0,image.shape[0]-k,5) for j in range(0,image.shape[1]-k,5) if (model.predict([feature.hog(transform.resize(image[i:i+k,j:int(j+k)],(48,48)))])[0] == 1)]\n",
        "    #boxes=[[i,i+k,j,int(j+k)] for k in [35,40,45,50] for i in range(0,image.shape[0]-k,10) for j in range(0,image.shape[1]-k,10) if (model.predict([feature.hog(transform.resize(image[i:i+k,j:int(j+k)],(48,48)))])[0] == 1)]\n",
        "    #boxes=[[i,i+k,j,int(j+k)] for k in [150,160,170,180,250,260,270,280,350,360,370,400,420,450] for i in range(0,image.shape[0]-k,50) for j in range(0,image.shape[1]-k,50) if (model.predict([feature.hog(transform.resize(image[i:i+k,j:int(j+k)],(48,48)))])[0] == 1)]\n",
        "    return boxes"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_bCgr_dyj7A"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def conv_bn_relu(in_channels, out_channels, kernel_size=3, stride=1, padding=0):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "def SeparableConv2D(in_channels, out_channels, kernel=3):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, in_channels, kernel_size=kernel, stride=1, groups=in_channels,padding=1, bias=False),\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
        "    )\n",
        "\n",
        "class ResidualXceptionBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel=3):\n",
        "        super(ResidualXceptionBlock, self).__init__()\n",
        "        global device\n",
        "\n",
        "        self.depthwise_conv1 = SeparableConv2D(in_channels, out_channels, kernel).to(device)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.depthwise_conv2 = SeparableConv2D(out_channels, out_channels, kernel).to(device)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # self.padd = nn.ZeroPad2d(22)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        # self.residual_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2, padding=22, bias=False)\n",
        "        self.residual_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.residual_bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # residual branch\n",
        "        residual = self.residual_conv(x)\n",
        "        residual = self.residual_bn(residual)\n",
        "        \n",
        "        # print('input',x.shape)\n",
        "        # feature extraction branch\n",
        "        x = self.depthwise_conv1(x)\n",
        "        # print('conv1',x.shape)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        x = self.depthwise_conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        # print('conv2',x.shape)\n",
        "\n",
        "        # x = self.padd(x)\n",
        "        x = self.maxpool(x)\n",
        "        # print(x[:,:, 11:22, 11:22])\n",
        "        # print('max_pooling',x.shape)\n",
        "        # print('res',residual.shape)\n",
        "        return x + residual\n",
        "\n",
        "class Mini_Xception(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Mini_Xception, self).__init__()\n",
        "        self.conv1 = conv_bn_relu(1, 8, kernel_size=3, stride=1, padding=0)\n",
        "        self.conv2 = conv_bn_relu(8, 8, kernel_size=3, stride=1, padding=0)\n",
        "        self.residual_blocks = nn.ModuleList([\n",
        "            ResidualXceptionBlock(8 , 16).to(device),\n",
        "            ResidualXceptionBlock(16, 32).to(device),\n",
        "            ResidualXceptionBlock(32, 64).to(device),\n",
        "            ResidualXceptionBlock(64, 128).to(device)            \n",
        "        ])\n",
        "        self.conv3 = nn.Conv2d(128, 7, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        for block in self.residual_blocks:\n",
        "            x = block(x)\n",
        "            # print('ith block', x.shape, block.device)\n",
        "\n",
        "        # print('blocks:',x.shape)\n",
        "        x = self.conv3(x)\n",
        "        # print('conv3',x.shape)\n",
        "        x = self.global_avg_pool(x)\n",
        "        # # x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def get_label_emotion(label : int) -> str:\n",
        "    label_emotion_map = { \n",
        "        0: 'Angry',\n",
        "        1: 'Disgust', \n",
        "        2: 'Fear', \n",
        "        3: 'Happy', \n",
        "        4: 'Sad', \n",
        "        5: 'Surprise', \n",
        "        6: 'Neutral'        \n",
        "    }\n",
        "    return label_emotion_map[label]\n",
        "\n",
        "\n",
        "def pr(img):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  mini_xception = Mini_Xception().to(device)\n",
        "  mini_xception.eval()\n",
        "\n",
        "  # Load model\n",
        "  checkpoint = torch.load('weights_epoch_75.pth.tar')\n",
        "  mini_xception.load_state_dict(checkpoint['mini_xception'])\n",
        "\n",
        "    \n",
        "  input_face = cv2.resize(img, (48,48))\n",
        "  input_face = cv2.equalizeHist(input_face)\n",
        "  input_face = transforms.ToTensor()(input_face).to(device)\n",
        "  input_face = torch.unsqueeze(input_face, 0)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      input_face = input_face.to(device)\n",
        "      emotion = mini_xception(input_face)\n",
        "      # print(f'\\ntime={(time.time()-t) * 1000 } ms')\n",
        "\n",
        "      torch.set_printoptions(precision=6)\n",
        "      softmax = torch.nn.Softmax()\n",
        "      emotions_soft = softmax(emotion.squeeze()).reshape(-1,1).cpu().detach().numpy()\n",
        "      emotions_soft = np.round(emotions_soft, 3)\n",
        "      for i, em in enumerate(emotions_soft):\n",
        "          em = round(em.item(),3)\n",
        "          # print(f'{get_label_emotion(i)} : {em}')\n",
        "\n",
        "      emotion = torch.argmax(emotion)                \n",
        "      percentage = round(emotions_soft[emotion].item(), 2)\n",
        "      emotion = emotion.squeeze().cpu().detach().item()\n",
        "      emotion = get_label_emotion(emotion)\n",
        "      return emotion"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK3HJ9Zxzgxp"
      },
      "source": [
        "# **Voice analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t85espCZ66vJ",
        "outputId": "a774dfd0-fb93-4d54-da4c-b35337f5491e"
      },
      "source": [
        "voice_model = pickle.load(open('voice_model.pkl', 'rb'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neural_network.multilayer_perceptron module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neural_network. Anything that cannot be imported from sklearn.neural_network is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.label module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.21.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.21.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZcFJlPvzm1W"
      },
      "source": [
        "#DataFlair - Extract features (mfcc, chroma, mel) from a sound file\n",
        "def extract_feature(X, mfcc, chroma, mel,sample_rate):   \n",
        "    result=np.array([])\n",
        "    if mfcc:\n",
        "        mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "        result=np.hstack((result, mfccs))\n",
        "    if chroma:\n",
        "        stft=np.abs(librosa.stft(X))\n",
        "        chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "        result=np.hstack((result, chroma))\n",
        "    if mel:\n",
        "        mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "        result=np.hstack((result, mel))\n",
        "    return result"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DA7syofzqF5"
      },
      "source": [
        "def predict_voice(file):\n",
        "    x=[]\n",
        "    y=[]\n",
        "    y, s = librosa.load(file) # Downsample 44.1kHz to 8kHz\n",
        "    feature=extract_feature(X=y, mfcc=True, chroma=True, mel=True,sample_rate=s)\n",
        "    x.append(feature)\n",
        "    y_pred=voice_model.predict(x)\n",
        "    emotion = y_pred[0]\n",
        "    return emotion"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-T796Y8zsMy"
      },
      "source": [
        "def get_duration(fname):\n",
        "    with contextlib.closing(wave.open(fname,'r')) as f:\n",
        "        frames = f.getnframes()\n",
        "        rate = f.getframerate()\n",
        "        duration = frames / float(rate)\n",
        "        return duration"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9ajKcMNzvM0"
      },
      "source": [
        "def get_emotion_dic(fname):\n",
        "  duration = get_duration(fname) \n",
        "  \n",
        "  # frames/ is the directory to stores audio frames\n",
        "  dir='frames'\n",
        "  if not os.path.exists(dir):\n",
        "    os.makedirs(dir)\n",
        "  else:\n",
        "    shutil.rmtree(dir)           \n",
        "    os.makedirs(dir)  \n",
        "  emotion_dic={'bad':0,'medium':0,'good':0}\n",
        "  originalAudio = AudioSegment.from_wav(fname)\n",
        "  for i in range(0,int(duration),3):\n",
        "      #newAudio = AudioSegment.from_wav(\"ted2.wav\")\n",
        "      newAudio = originalAudio[i*1000:(i+3)*1000]\n",
        "      newAudio.export('frames/'+str(i)+'.wav', format=\"wav\") #Exports to a wav file in the current path.\n",
        "      emotion = predict_voice('frames/'+str(i)+'.wav') \n",
        "      emotion_dic[emotion]+=1\n",
        "  return emotion_dic"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCNDbgYd0CfV"
      },
      "source": [
        "# **Speech Recognition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZu1Aqe-0ELR"
      },
      "source": [
        "client = speech.SpeechClient()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPrZ3mAM0L5K"
      },
      "source": [
        "def SpeechRecognition(audiof, audiofile):\n",
        "  x, s = librosa.load(audiof)\n",
        "  soundfile.write(audiofile, x, s)\n",
        "  with ar.open(audiof,'rb') as audio_file:\n",
        "    content = audio_file.read()\n",
        "  audio = speech.RecognitionAudio(content=content)\n",
        "  config = speech.RecognitionConfig(\n",
        "      encoding = speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
        "      language_code = 'en-US')\n",
        "  operation = client.long_running_recognize(config=config, audio=audio)\n",
        "  print(\"Waiting for operation to complete...\")\n",
        "  response = operation.result(timeout=90)\n",
        "  answer = \"\"\n",
        "  for result in response.results:\n",
        "      # print('Transcript: {}'.format(result.alternatives[0].transcript))\n",
        "      answer += result.alternatives[0].transcript\n",
        "  return answer "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxpEOpjZyrwx"
      },
      "source": [
        "# **Answer Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxAe7KiCym1F"
      },
      "source": [
        "def clean_text(text):\n",
        "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation and remove words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text\n",
        "\n",
        "def clean2_text(text):\n",
        "  #remove some of stopwords as 'a, an, the'\n",
        "  txt = clean_text(text)\n",
        "  words = txt.split(' ')\n",
        "  aft_remove = [w for w in words if w not in ['a', 'an', 'the', 'of', 'that', 'which']]\n",
        "  return ' '.join(aft_remove)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JScYrN4SzDJW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "7b7b71a7caed440eacf94c2ade8b9ede",
            "b9228df733c54e2e83959460489f0ad8",
            "c7bc507e3a2341398c214585e9d2423e",
            "8630bb9d166244ffa768cdbd02ec94ce",
            "b22007593d734a9db29483e5f5c366a0",
            "020e8b659db04616924aa6337cf65a76",
            "488e33292a7344eeb4c97d1d409db9a1",
            "41ff8c2a91184f8caf70bad7fad26c56",
            "74feafc9345b4c4dbba192b500742dea",
            "a9b7e4d200ff4ffe9256d07439859359",
            "109b6fdc5d7242d4835d723c124c7dac",
            "afe20436911045aaa866be54a1fe18f2",
            "33f9e8222c394c87b635fc873bdac6a4",
            "ddfbd64b6cc349519a1d3d6a868ea9af",
            "d03ac5bc0956461eb4e7920dea12d86b",
            "0db2cb286a2a4c1989a7643c8dc9fe91",
            "487b4125d25a43db9e2d4b2427b1bc25",
            "ab8c3b5201db46e2b76180d63805d67b",
            "1e37946eede946668e2c51f4a0d28d1e",
            "3138cc9312434caeac584f640312b2fb",
            "4665b1b320304411935b93c958b87159",
            "216b3625424f402ca1679511af9c715f",
            "b4cbc031b88449199c1a393af297cb32",
            "cf79cf42333c4b7da00393b0e35ebf29",
            "91a79d8d777f455f8a69781cb41b6870",
            "4aeaa7ba5e994b83a5072359daf464c3",
            "58a0a758a190409191b094604b9aba7d",
            "65846bb3ae664fa5845ee761a699cf95",
            "0f114df1c16c4183b697e0d4ad39a94a",
            "d34f3985249542e1931fa55710e9ec74",
            "9645f6a551bf4349b77ed745b83f0e27",
            "a6140148cec8422f8b447120be2684cd"
          ]
        },
        "outputId": "bd63714e-7dcb-4eaa-86bc-fc62ec32f37b"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b7b71a7caed440eacf94c2ade8b9ede",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74feafc9345b4c4dbba192b500742dea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "487b4125d25a43db9e2d4b2427b1bc25",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91a79d8d777f455f8a69781cb41b6870",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwxVk13XzEKI"
      },
      "source": [
        "class Similarity_Model(nn.Module):\n",
        "    def __init__(self, output_dim, n_layers, hidden_dim, freeze_bert):\n",
        "        super(Similarity_Model,self).__init__()\n",
        " \n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.no_layers = no_layers\n",
        "        \n",
        "        #bert Model and Freeze the BERT model\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "        if freeze_bert:\n",
        "            for p in self.bert_model.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        #LSTM layers\n",
        "        # self.lstm = nn.LSTM(768, hidden_dim, n_layers, batch_first=True)\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        # linear layer\n",
        "        self.fc = nn.Linear(768, output_dim)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input_ids, attention_masks, token_type_ids, hidden):\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        sequence_output, pooled_output = self.bert_model(input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids) \n",
        "        # print(\"seq  \" , len(sequence_output))\n",
        "        \n",
        "        # lstm_out, hidden = self.lstm(sequence_output[0], hidden)\n",
        "\n",
        "        # lstm_out = lstm_out.permute(0,2,1)\n",
        "        \n",
        "        # out_max = F.max_pool1d(lstm_out, kernel_size=lstm_out.shape[2])\n",
        "        # out_avg = F.avg_pool1d(lstm_out, kernel_size=lstm_out.shape[2])\n",
        "        \n",
        "        # out = torch.cat((out_avg, out_max), dim=1)\n",
        "        # out = out.permute(0,2,1)\n",
        "\n",
        "        # dropout and fully connected layer\n",
        "        out = self.dropout(pooled_output)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        out = sig_out.view(batch_size, -1)\n",
        "\n",
        "        out = out[:, -1]\n",
        "\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # initialize hidden states with sizes n_layers x batch_size x hidden_dim\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        hidden = (h0,c0)\n",
        "        return hidden"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sSe6XdCz7Ah",
        "outputId": "261c5c1f-5bdb-4476-e35c-5f46169c0ce3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Dx3yzYIy-Jf",
        "outputId": "a3c2e9d4-c10f-4927-8aa2-85c3e4feb324"
      },
      "source": [
        "no_layers = 1\n",
        "output_dim = 1\n",
        "hidden_dim = 128\n",
        "Freeze_bert = False\n",
        "Similar_Model = Similarity_Model(output_dim, no_layers, hidden_dim, Freeze_bert)\n",
        "#moving to gpu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "Similar_Model.to(device)\n",
        "Similar_Model.eval()\n",
        "\n",
        "Similar_Model.load_state_dict(torch.load(\"/content/drive/MyDrive/Snli_TechSimilarity.pt\"))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:28<00:00, 14065115.51B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DdRHRBwzcVK"
      },
      "source": [
        "def predict_similarity(ans1, ans2):\n",
        "  sentence1 = clean2_text(ans1)\n",
        "  sentence2 = clean2_text(ans2)\n",
        "  # print(sentence1, sentence2)\n",
        "  encoded_pair = tokenizer(  sentence1, sentence2, \n",
        "      add_special_tokens=True,\n",
        "      truncation=True,\n",
        "      max_length = 500,\n",
        "      return_tensors='pt'  # Return torch.Tensor objects\n",
        "  )\n",
        "  # print(encoded_pair['input_ids'].shape)\n",
        "  text, attention, token_ids = encoded_pair['input_ids'].expand(1,-1), encoded_pair['attention_mask'].expand(1,-1), encoded_pair['token_type_ids'].expand(1,-1)\n",
        "  inputs, attention, token_ids = text.to(device), attention.to(device), token_ids.to(device)\n",
        "  h = Similar_Model.init_hidden(1)\n",
        "  h = tuple([each.data for each in h])\n",
        "  output, _ = Similar_Model(inputs, attention, token_ids, h)\n",
        "  return str(output.item())"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNlDUZXMqjsf"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_text(sentence):\n",
        "  doc = nlp(sentence)\n",
        "  # Analyze syntax\n",
        "  nouns = [chunk.text for chunk in doc.noun_chunks]\n",
        "  # print(\"Noun phrases:\", nouns)\n",
        "\n",
        "  #remove the nouns from sentence\n",
        "  tmp = sentence\n",
        "  for x in nouns:\n",
        "    tmp = tmp.replace(x, '')\n",
        "  # print(tmp)\n",
        "\n",
        "  #analyze the verbs\n",
        "  doc2 = nlp(tmp)\n",
        "  verbs = [token.text for token in doc2 if token.dep_ == \"VERB\" or token.dep_ == \"ROOT\" or token.dep_ == \"auxpass\"]\n",
        "  # print(\"Verbs:\", verbs)\n",
        "  # objects = [token.text for token in doc if token.dep_ == \"iobj\" or token.dep_ == \"dobj\" or token.dep_ == \"obj\" or token.dep_ == \"nsubj\"]\n",
        "\n",
        "  tmp2 = tmp\n",
        "  for x in verbs:\n",
        "    # print(x)\n",
        "    tmp2 = tmp2.replace(x, '')\n",
        "  # print(tmp2)\n",
        "\n",
        "  # print(len((' '.join(nouns)).split(' ')))\n",
        "  if ( len( (' '.join(nouns)).split(' ') ) + len( (' '.join(tmp2)).split(' ') ) ) >= 2 and len(verbs) >= 1 :\n",
        "    return True\n",
        "  else:  \n",
        "    return False\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksh_HALrKFwd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "772b1a2c-af3e-4bd9-fd7a-01858669d9c8"
      },
      "source": [
        "# ans1 = \"Linear regression is a supervised Machine Learning algorithm. It is used to find the linear relationship between the dependent and the independent variables for predictive analysis.\"\n",
        "# # ans1 = \"It's are powerful yet flexible supervised machine learning algorithms which are used both for classification and regression. But generally, they are used in classification problems\"\n",
        "# # ans1 = \"Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.\"\n",
        "# # ans1 = \"machine learning is a form of AI that enables a system to learn from data rather than through explicit programming. However, machine learning is not a simple process. As the algorithms ingest training data, it is then possible to produce more precise models based on that data. A machine-learning model is the output generated when you train your machine-learning algorithm with data. After training, when you provide a model with an input, you will be given an output. For example, a predictive algorithm will create a predictive model. Then, when you provide the predictive model with data, you will receive a prediction based on the data that trained the model.\"\n",
        "# ans2 = \"Linear regression Linear regression Linear regression Linear regression like a ball\"\n",
        "# print(len(ans2.split()))\n",
        "# if len(ans2.split()) >= 0 and len(ans2.split()) <= 2 :\n",
        "#   prob1 = 0.0\n",
        "# else:\n",
        "#   prob1 = predict_similarity(ans1, ans2)\n",
        "# print(prob1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11\n",
            "0.053810447454452515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9c7riT601Nb"
      },
      "source": [
        "# **Routes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0CBZC5SrqTB"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6qJaZIe02Ed",
        "outputId": "76e70543-d6de-4cba-dde1-f7727bc62e47"
      },
      "source": [
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "#this contains the path of folder that to store the images in\n",
        "app.config[\"IMAGE_UPLOADS\"] = \"/content\"\n",
        "app.config[\"AUDIO_UPLOADS\"]=\"/content\"\n",
        "run_with_ngrok(app)  # Start ngrok when app is run\n",
        "\n",
        "@app.route(\"/predict\", methods=['post'])\n",
        "def predict():\n",
        "    image_bytes = b64decode(request.form[\"image\"].split(',')[1])\n",
        "    # convert bytes to numpy array\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    # decode numpy array into OpenCV BGR image\n",
        "    image = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "    url = request.method\n",
        "    frameTemp = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    frameTemp = cv2.resize(frameTemp, (100, 100))\n",
        "    try:\n",
        "      rects = find(frameTemp)\n",
        "      rects = np.array(rects)\n",
        "      rects = non_max_suppression_fast(rects, 0.2)\n",
        "\n",
        "      output=\"\"\n",
        "      ans = \"\"\n",
        "      for rect in rects: \n",
        "          res,ret=getFaceAlign(frameTemp[rect[0]:rect[1],rect[2]:rect[3]])\n",
        "          if ret==1:\n",
        "            pred = pr(res)\n",
        "            print(pred)\n",
        "            if pred in ['Disgust','Fear','Sad','Angry']:\n",
        "              ans = 'bad'\n",
        "            elif pred in ['Surprise' , 'Neutral']:\n",
        "              ans = 'medium'\n",
        "            elif pred == 'Happy':\n",
        "              ans = 'good'             \n",
        "            output+= ans+\" \"\n",
        "            print(ans)\n",
        "      #return the emotion of the face's image to the html\n",
        "      if output!=\"\":\n",
        "        return jsonify(output)\n",
        "      return jsonify(\"medium\")\n",
        "    \n",
        "    except:\n",
        "        return jsonify(\"medium\")\n",
        "\n",
        "@app.route('/predictVoice',methods=['POST'])\n",
        "def predictVoice():\n",
        "    audio = request.files[\"file\"]\n",
        "    audiofile=audio.filename\n",
        "    #save the audio in colab directory /content \n",
        "    audio.save(os.path.join(app.config[\"AUDIO_UPLOADS\"], audiofile))\n",
        "    #dir of audio is in the current directory \n",
        "    #convert audio to correct wav file\n",
        "    newAudio = AudioSegment.from_file(audiofile)\n",
        "    #overwrite corrupted audio with the corrected audio \n",
        "    newAudio.export(audiofile, format=\"wav\")\n",
        "    emotion_dic=get_emotion_dic(\"/content/\"+audiofile)\n",
        "    print(emotion_dic)\n",
        "    return jsonify(emotion_dic)\n",
        "\n",
        "\n",
        "@app.route('/predictSimilarity', methods=['POST'])\n",
        "def predictSimilarity():\n",
        "    audio = request.files[\"file\"]\n",
        "    audiofile=audio.filename\n",
        "    audio.save(os.path.join(app.config[\"AUDIO_UPLOADS\"], audio.filename))\n",
        "\n",
        "    User_answer = SpeechRecognition(\"/content/\"+audiofile, audiofile)\n",
        "    print(\"User answer from API: \" , User_answer)\n",
        "\n",
        "    # os.remove(\"/content/\"+audiofile)\n",
        "    # !rm audiofile\n",
        "    question=request.form['question']\n",
        "\n",
        "    answer1 = request.form['ans1']\n",
        "    answer2 = request.form['ans2']\n",
        "    answer3 = request.form['ans3']\n",
        "    print(\"Model Answer 1:  \" , answer1)\n",
        "    \n",
        "    if len(User_answer.split()) >= 0 and len(User_answer.split()) <= 2 :\n",
        "      prob = 0.0\n",
        "    elif parse_text(User_answer) == False:\n",
        "      prob = 0.0\n",
        "    else:\n",
        "      prob1 = predict_similarity(answer1, User_answer)\n",
        "      prob2 = predict_similarity(answer2, User_answer)\n",
        "      prob3 = predict_similarity(answer3, User_answer)\n",
        "\n",
        "      prob = max(prob1, prob2, prob3)\n",
        "      \n",
        "    print(\"probability = \", prob)\n",
        "    dic=[question, answer1,prob]\n",
        "\n",
        "    # response = jsonify(dic)\n",
        "    # response.headers.add('Access-Control-Allow-Origin', '*')\n",
        "    # return  response\n",
        "    return jsonify(dic)    \n",
        "\n",
        "app.run()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://67c9b845ebb3.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n",
            "Waiting for operation to complete...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Jul/2021 14:43:38] \"\u001b[37mPOST /predictSimilarity HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "User answer from API:  computer software computer software computer software\n",
            "Model Answer 1:   Software is a collection of data or computer instructions that tell the computer how to work.\n",
            "probability =  0.0\n",
            "Sad\n",
            "bad\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Jul/2021 14:43:43] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [22/Jul/2021 14:43:48] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Neutral\n",
            "medium\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Jul/2021 14:43:51] \"\u001b[37mOPTIONS /predictVoice HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [22/Jul/2021 14:43:55] \"\u001b[37mPOST /predictVoice HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bad': 2, 'medium': 0, 'good': 2}\n",
            "Waiting for operation to complete...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Jul/2021 14:44:08] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Sad\n",
            "bad\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Jul/2021 14:44:14] \"\u001b[37mPOST /predictSimilarity HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "User answer from API:  acquirements can range from high-level abstract statements or services or system constraints to detail the mathematical functional specification\n",
            "Model Answer 1:   Software requirements are a functional description of a proposed software system. It is assumed to be the description of the target system, its functionalities, and features.\n",
            "probability =  0.9342197775840759\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Jul/2021 14:44:18] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Sad\n",
            "bad\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Jul/2021 14:44:21] \"\u001b[37mOPTIONS /predictVoice HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [22/Jul/2021 14:44:26] \"\u001b[37mPOST /predictVoice HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bad': 4, 'medium': 0, 'good': 2}\n",
            "Waiting for operation to complete...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Jul/2021 14:44:33] \"\u001b[37mPOST /predictSimilarity HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "User answer from API:  software development life cycle is a framework that is defined as the steps involved in the development of software interface it covers is a detailed plan for building the blowing and maintaining the software\n",
            "Model Answer 1:   SDLC is a process for planning, creating, testing, and deploying an information system. It consists of Planning and Requirement Analysis, Defining Requirements, Designing the Product Architecture, Building or Developing the Product, Testing the Product and finally Deployment in the Market and Maintenance\n",
            "probability =  0.9970294237136841\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Jul/2021 14:44:38] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fear\n",
            "bad\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Jul/2021 14:44:48] \"\u001b[37mOPTIONS /predictVoice HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [22/Jul/2021 14:44:48] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Sad\n",
            "bad\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Jul/2021 14:44:51] \"\u001b[37mPOST /predictVoice HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bad': 5, 'medium': 0, 'good': 1}\n",
            "Waiting for operation to complete...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Jul/2021 14:45:02] \"\u001b[37mOPTIONS /predictVoice HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [22/Jul/2021 14:45:04] \"\u001b[37mPOST /predictVoice HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bad': 1, 'medium': 0, 'good': 0}\n",
            "Waiting for operation to complete...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Jul/2021 14:45:06] \"\u001b[37mPOST /predictSimilarity HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "User answer from API:  functional and non-functional requirements\n",
            "Model Answer 1:   Functional Requirements: These are the requirements that the end user specifically demands as basic facilities that the system should offer. And Non-functional requirements: These are basically the quality constraints that the system must satisfy according to the project contract as Security,Maintainability,Reliability,Scalability,Performance,Reusability,Flexibility\n",
            "probability =  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Jul/2021 14:45:23] \"\u001b[37mPOST /predictSimilarity HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "User answer from API:  it's a process to systematically manage organize and control the changes in the documents codes and the other entities during the software development life cycle\n",
            "Model Answer 1:   Software configuration management is a process of tracking and controlling changes that happen in the software.Change control is a function which ensures that all changes made into the software system are consistent and created using organizational rules and regulations.\n",
            "probability =  0.9965230226516724\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}