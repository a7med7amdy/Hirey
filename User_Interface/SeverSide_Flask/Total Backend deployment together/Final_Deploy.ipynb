{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Deploy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weM74AKrwwj3"
      },
      "source": [
        "# **Importing and Installation**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqPr-_zXw7sG",
        "outputId": "975df4e3-c2aa-4dc6-8aa3-1b425d49c0e8"
      },
      "source": [
        "!pip install google-cloud-texttospeech\n",
        "!pip install google-cloud\n",
        "!pip install google-cloud-speech"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-cloud-texttospeech in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-texttospeech) (21.0)\n",
            "Requirement already satisfied: proto-plus>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-texttospeech) (1.19.0)\n",
            "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.26.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-texttospeech) (1.26.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-texttospeech) (1.53.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-texttospeech) (1.32.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-texttospeech) (57.2.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-texttospeech) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-texttospeech) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-texttospeech) (3.17.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-texttospeech) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-texttospeech) (1.34.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-texttospeech) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-texttospeech) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-texttospeech) (4.2.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-cloud-texttospeech) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-texttospeech) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-texttospeech) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-texttospeech) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-texttospeech) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-texttospeech) (3.0.4)\n",
            "Requirement already satisfied: google-cloud in /usr/local/lib/python3.7/dist-packages (0.34.0)\n",
            "Requirement already satisfied: google-cloud-speech in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: proto-plus>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-speech) (1.19.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-speech) (21.0)\n",
            "Requirement already satisfied: libcst>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from google-cloud-speech) (0.3.19)\n",
            "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.26.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-speech) (1.26.3)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-speech) (1.32.1)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-speech) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-speech) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-speech) (57.2.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-speech) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-speech) (1.53.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-speech) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-speech) (1.34.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-speech) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-speech) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-speech) (0.2.8)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from libcst>=0.2.5->google-cloud-speech) (0.7.1)\n",
            "Requirement already satisfied: pyyaml>=5.2 in /usr/local/lib/python3.7/dist-packages (from libcst>=0.2.5->google-cloud-speech) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.2 in /usr/local/lib/python3.7/dist-packages (from libcst>=0.2.5->google-cloud-speech) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-cloud-speech) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-speech) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-speech) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-speech) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-speech) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.26.0->google-cloud-speech) (3.0.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from typing-inspect>=0.4.0->libcst>=0.2.5->google-cloud-speech) (0.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrQmVgfVw-L6",
        "outputId": "9a3cb2a4-298f-4dd0-abd5-6b13db651228"
      },
      "source": [
        "!pip install face-alignment\n",
        "!pip install flask-ngrok\n",
        "!pip install -U flask-cors\n",
        "!pip install pydub\n",
        "!pip install transformers\n",
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: face-alignment in /usr/local/lib/python3.7/dist-packages (1.3.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from face-alignment) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from face-alignment) (4.41.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from face-alignment) (0.16.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from face-alignment) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face-alignment) (1.19.5)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from face-alignment) (0.51.2)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from face-alignment) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->face-alignment) (57.2.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->face-alignment) (0.34.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment) (2.5.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment) (7.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.15.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->face-alignment) (4.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->face-alignment) (3.7.4.3)\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.7/dist-packages (3.0.10)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors) (1.15.0)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.7/dist-packages (from flask-cors) (1.1.4)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask-cors) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask-cors) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask-cors) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.9->flask-cors) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.9->flask-cors) (2.0.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.18.3)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.9.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.5.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.3 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.21.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.3->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.3->boto3->pytorch-pretrained-bert) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.3->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx_k8dq7xBEG"
      },
      "source": [
        "%matplotlib inline\n",
        "import face_alignment\n",
        "import os\n",
        "from os import listdir\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import image\n",
        "from PIL import Image\n",
        "\n",
        "from skimage import transform,data,color,feature\n",
        "import skimage.io as ios\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import cross_val_score , GridSearchCV, train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "from numba import jit, cuda\n",
        "import pickle\n",
        "import timeit\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.nn.modules.activation import ReLU\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import re\n",
        "import string\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "\n",
        "\n",
        "from imutils.face_utils import FaceAligner\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import sys\n",
        "from transformers import AutoTokenizer\n",
        "from pytorch_pretrained_bert import BertModel\n",
        "import scipy.io.wavfile as wav\n",
        "import io as ar\n",
        "from google.cloud import speech\n",
        "from flask import Flask, request, jsonify, render_template,send_file,Response\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask_cors import CORS\n",
        "\n",
        "from google.cloud import texttospeech\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "\n",
        "import librosa\n",
        "import soundfile\n",
        "import glob\n",
        "import shutil\n",
        "import wave\n",
        "import contextlib\n",
        "\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'avian-tract-283207-f1553ac44767.json'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P09dBindyVtg"
      },
      "source": [
        "# **Face detection and Emotion Recognition**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiaE2E06yRen",
        "outputId": "e9b5ae01-4d38-428c-fcbe-b124c0c11c8c"
      },
      "source": [
        "model = pickle.load(open(\"faceDetection2.sav\", 'rb'))\n",
        "print(model)\n",
        "fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, flip_input=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.23.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "          verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-Vmmt_mybEa"
      },
      "source": [
        "def getFaceAlign(img):\n",
        "  ios.imsave('testt.jpg',img)\n",
        "  preds = fa.get_landmarks(img)\n",
        "  if preds == None:\n",
        "    #print('Warning: No faces were detected.')\n",
        "    return None,0\n",
        "  if preds!=None:\n",
        "    mnXY= np.min(np.min(preds, axis=1), axis=0)\n",
        "    mxXY= np.max(np.max(preds, axis=1), axis=0)\n",
        "    mxY=int(mxXY[0]+2)\n",
        "    mnX=int(mnXY[1])-8\n",
        "    mxX=int(mxXY[1])\n",
        "    if mnX < 0:\n",
        "       mnX=0\n",
        "    if int(mxXY[0]+2) >= img.shape[1]:\n",
        "      mxY=img.shape[1]-1\n",
        "    if (img.shape[0]-2-mnX) <= 40:\n",
        "      return img[mnX:img.shape[0]-2,int(mnXY[0])-2:mxY],1\n",
        "    else:\n",
        "      return img[mnX:mnX+40,int(mnXY[0])-2:mxY],1   # were 40 instead of 50\n",
        "    ####################################\n",
        "    # im_pil = Image.fromarray(img[mnX:mxX,int(mnXY[0]):mxY])\n",
        "    # im_pil=im_pil.resize((100, 100), Image.ANTIALIAS)\n",
        "    # io.imshow(np.array(im_pil))\n",
        "    # io.imsave('testtt.jpg',np.array(im_pil))\n",
        "    # return np.array(im_pil),1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOnm_rvWyfZx"
      },
      "source": [
        "def non_max_suppression_fast(boxes, overlapThresh):\n",
        "\tif len(boxes) == 0:\n",
        "\t\treturn []\n",
        "\tif boxes.dtype.kind == \"i\":\n",
        "\t\tboxes = boxes.astype(\"float\")\n",
        "\tpick = []\n",
        "\tx1 = boxes[:,2]\n",
        "\ty1 = boxes[:,0]\n",
        "\tx2 = boxes[:,3]\n",
        "\ty2 = boxes[:,1]\n",
        "\tarea = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "\tidxs = np.argsort(y2)\n",
        "\twhile len(idxs) > 0:\n",
        "\t\tlast = len(idxs) - 1\n",
        "\t\ti = idxs[last]\n",
        "\t\tpick.append(i)\n",
        "\t\txx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
        "\t\tyy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
        "\t\txx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
        "\t\tyy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
        "\t\tw = np.maximum(0, xx2 - xx1 + 1)\n",
        "\t\th = np.maximum(0, yy2 - yy1 + 1)\n",
        "\t\toverlap = (w * h) / area[idxs[:last]]\n",
        "\t\tidxs = np.delete(idxs, np.concatenate(([last],\n",
        "\t\t\tnp.where(overlap > overlapThresh)[0])))\n",
        "\treturn boxes[pick].astype(\"int\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO6GN716yhmW"
      },
      "source": [
        "def find(image):\n",
        "    boxes=[[i,i+k,j,int(j+k)] for k in [35,45,55] for i in range(0,image.shape[0]-k,5) for j in range(0,image.shape[1]-k,5) if (model.predict([feature.hog(transform.resize(image[i:i+k,j:int(j+k)],(48,48)))])[0] == 1)]\n",
        "    #boxes=[[i,i+k,j,int(j+k)] for k in [35,40,45,50] for i in range(0,image.shape[0]-k,10) for j in range(0,image.shape[1]-k,10) if (model.predict([feature.hog(transform.resize(image[i:i+k,j:int(j+k)],(48,48)))])[0] == 1)]\n",
        "    #boxes=[[i,i+k,j,int(j+k)] for k in [150,160,170,180,250,260,270,280,350,360,370,400,420,450] for i in range(0,image.shape[0]-k,50) for j in range(0,image.shape[1]-k,50) if (model.predict([feature.hog(transform.resize(image[i:i+k,j:int(j+k)],(48,48)))])[0] == 1)]\n",
        "    return boxes"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_bCgr_dyj7A"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def conv_bn_relu(in_channels, out_channels, kernel_size=3, stride=1, padding=0):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "\n",
        "def SeparableConv2D(in_channels, out_channels, kernel=3):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, in_channels, kernel_size=kernel, stride=1, groups=in_channels,padding=1, bias=False),\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
        "    )\n",
        "\n",
        "class ResidualXceptionBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel=3):\n",
        "        super(ResidualXceptionBlock, self).__init__()\n",
        "        global device\n",
        "\n",
        "        self.depthwise_conv1 = SeparableConv2D(in_channels, out_channels, kernel).to(device)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.depthwise_conv2 = SeparableConv2D(out_channels, out_channels, kernel).to(device)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # self.padd = nn.ZeroPad2d(22)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        # self.residual_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2, padding=22, bias=False)\n",
        "        self.residual_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.residual_bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # residual branch\n",
        "        residual = self.residual_conv(x)\n",
        "        residual = self.residual_bn(residual)\n",
        "        \n",
        "        # print('input',x.shape)\n",
        "        # feature extraction branch\n",
        "        x = self.depthwise_conv1(x)\n",
        "        # print('conv1',x.shape)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        x = self.depthwise_conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        # print('conv2',x.shape)\n",
        "\n",
        "        # x = self.padd(x)\n",
        "        x = self.maxpool(x)\n",
        "        # print(x[:,:, 11:22, 11:22])\n",
        "        # print('max_pooling',x.shape)\n",
        "        # print('res',residual.shape)\n",
        "        return x + residual\n",
        "\n",
        "class Mini_Xception(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Mini_Xception, self).__init__()\n",
        "        self.conv1 = conv_bn_relu(1, 8, kernel_size=3, stride=1, padding=0)\n",
        "        self.conv2 = conv_bn_relu(8, 8, kernel_size=3, stride=1, padding=0)\n",
        "        self.residual_blocks = nn.ModuleList([\n",
        "            ResidualXceptionBlock(8 , 16).to(device),\n",
        "            ResidualXceptionBlock(16, 32).to(device),\n",
        "            ResidualXceptionBlock(32, 64).to(device),\n",
        "            ResidualXceptionBlock(64, 128).to(device)            \n",
        "        ])\n",
        "        self.conv3 = nn.Conv2d(128, 7, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        for block in self.residual_blocks:\n",
        "            x = block(x)\n",
        "            # print('ith block', x.shape, block.device)\n",
        "\n",
        "        # print('blocks:',x.shape)\n",
        "        x = self.conv3(x)\n",
        "        # print('conv3',x.shape)\n",
        "        x = self.global_avg_pool(x)\n",
        "        # # x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def get_label_emotion(label : int) -> str:\n",
        "    label_emotion_map = { \n",
        "        0: 'Angry',\n",
        "        1: 'Disgust', \n",
        "        2: 'Fear', \n",
        "        3: 'Happy', \n",
        "        4: 'Sad', \n",
        "        5: 'Surprise', \n",
        "        6: 'Neutral'        \n",
        "    }\n",
        "    return label_emotion_map[label]\n",
        "\n",
        "\n",
        "def pr(img):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  mini_xception = Mini_Xception().to(device)\n",
        "  mini_xception.eval()\n",
        "\n",
        "  # Load model\n",
        "  checkpoint = torch.load('weights_epoch_75.pth.tar')\n",
        "  mini_xception.load_state_dict(checkpoint['mini_xception'])\n",
        "\n",
        "    \n",
        "  input_face = cv2.resize(img, (48,48))\n",
        "  input_face = cv2.equalizeHist(input_face)\n",
        "  input_face = transforms.ToTensor()(input_face).to(device)\n",
        "  input_face = torch.unsqueeze(input_face, 0)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      input_face = input_face.to(device)\n",
        "      emotion = mini_xception(input_face)\n",
        "      # print(f'\\ntime={(time.time()-t) * 1000 } ms')\n",
        "\n",
        "      torch.set_printoptions(precision=6)\n",
        "      softmax = torch.nn.Softmax()\n",
        "      emotions_soft = softmax(emotion.squeeze()).reshape(-1,1).cpu().detach().numpy()\n",
        "      emotions_soft = np.round(emotions_soft, 3)\n",
        "      for i, em in enumerate(emotions_soft):\n",
        "          em = round(em.item(),3)\n",
        "          # print(f'{get_label_emotion(i)} : {em}')\n",
        "\n",
        "      emotion = torch.argmax(emotion)                \n",
        "      percentage = round(emotions_soft[emotion].item(), 2)\n",
        "      emotion = emotion.squeeze().cpu().detach().item()\n",
        "      emotion = get_label_emotion(emotion)\n",
        "      return emotion"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK3HJ9Zxzgxp"
      },
      "source": [
        "# **Voice analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t85espCZ66vJ",
        "outputId": "9a2e90e2-6199-4694-b9ce-d38e4db37b54"
      },
      "source": [
        "voice_model = pickle.load(open('voice_model.pkl', 'rb'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neural_network.multilayer_perceptron module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neural_network. Anything that cannot be imported from sklearn.neural_network is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.label module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.21.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.21.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZcFJlPvzm1W"
      },
      "source": [
        "#DataFlair - Extract features (mfcc, chroma, mel) from a sound file\n",
        "def extract_feature(X, mfcc, chroma, mel,sample_rate):   \n",
        "    result=np.array([])\n",
        "    if mfcc:\n",
        "        mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "        result=np.hstack((result, mfccs))\n",
        "    if chroma:\n",
        "        stft=np.abs(librosa.stft(X))\n",
        "        chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "        result=np.hstack((result, chroma))\n",
        "    if mel:\n",
        "        mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "        result=np.hstack((result, mel))\n",
        "    return result"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DA7syofzqF5"
      },
      "source": [
        "def predict_voice(file):\n",
        "    x=[]\n",
        "    y=[]\n",
        "    y, s = librosa.load(file) # Downsample 44.1kHz to 8kHz\n",
        "    feature=extract_feature(X=y, mfcc=True, chroma=True, mel=True,sample_rate=s)\n",
        "    x.append(feature)\n",
        "    y_pred=voice_model.predict(x)\n",
        "    emotion = y_pred[0]\n",
        "    return emotion"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-T796Y8zsMy"
      },
      "source": [
        "def get_duration(fname):\n",
        "    with contextlib.closing(wave.open(fname,'r')) as f:\n",
        "        frames = f.getnframes()\n",
        "        rate = f.getframerate()\n",
        "        duration = frames / float(rate)\n",
        "        return duration"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9ajKcMNzvM0"
      },
      "source": [
        "def get_emotion_dic(fname):\n",
        "  duration = get_duration(fname) \n",
        "  \n",
        "  # frames/ is the directory to stores audio frames\n",
        "  dir='frames'\n",
        "  if not os.path.exists(dir):\n",
        "    os.makedirs(dir)\n",
        "  else:\n",
        "    shutil.rmtree(dir)           \n",
        "    os.makedirs(dir)  \n",
        "  emotion_dic={'bad':0,'medium':0,'good':0}\n",
        "  originalAudio = AudioSegment.from_wav(fname)\n",
        "  for i in range(0,int(duration),3):\n",
        "      #newAudio = AudioSegment.from_wav(\"ted2.wav\")\n",
        "      newAudio = originalAudio[i*1000:(i+3)*1000]\n",
        "      newAudio.export('frames/'+str(i)+'.wav', format=\"wav\") #Exports to a wav file in the current path.\n",
        "      emotion = predict_voice('frames/'+str(i)+'.wav') \n",
        "      emotion_dic[emotion]+=1\n",
        "  return emotion_dic"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCNDbgYd0CfV"
      },
      "source": [
        "# **Speech Recognition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZu1Aqe-0ELR"
      },
      "source": [
        "client = speech.SpeechClient()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPrZ3mAM0L5K"
      },
      "source": [
        "def SpeechRecognition(audiof, audiofile):\n",
        "  x, s = librosa.load(audiof)\n",
        "  soundfile.write(audiofile, x, s)\n",
        "  with ar.open(audiof,'rb') as audio_file:\n",
        "    content = audio_file.read()\n",
        "  audio = speech.RecognitionAudio(content=content)\n",
        "  config = speech.RecognitionConfig(\n",
        "      encoding = speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
        "      language_code = 'en-US')\n",
        "  operation = client.long_running_recognize(config=config, audio=audio)\n",
        "  print(\"Waiting for operation to complete...\")\n",
        "  response = operation.result(timeout=90)\n",
        "  answer = \"\"\n",
        "  for result in response.results:\n",
        "      # print('Transcript: {}'.format(result.alternatives[0].transcript))\n",
        "      answer += result.alternatives[0].transcript\n",
        "  return answer "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxpEOpjZyrwx"
      },
      "source": [
        "# **Answer Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxAe7KiCym1F"
      },
      "source": [
        "def clean_text(text):\n",
        "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation and remove words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text\n",
        "\n",
        "def clean2_text(text):\n",
        "  #remove some of stopwords as 'a, an, the'\n",
        "  txt = clean_text(text)\n",
        "  words = txt.split(' ')\n",
        "  aft_remove = [w for w in words if w not in ['a', 'an', 'the', 'of', 'that', 'which']]\n",
        "  return ' '.join(aft_remove)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JScYrN4SzDJW"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwxVk13XzEKI"
      },
      "source": [
        "class Similarity_Model(nn.Module):\n",
        "    def __init__(self, output_dim, n_layers, hidden_dim, freeze_bert):\n",
        "        super(Similarity_Model,self).__init__()\n",
        " \n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.no_layers = no_layers\n",
        "        \n",
        "        #bert Model and Freeze the BERT model\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "        if freeze_bert:\n",
        "            for p in self.bert_model.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        #LSTM layers\n",
        "        # self.lstm = nn.LSTM(768, hidden_dim, n_layers, batch_first=True)\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        # linear layer\n",
        "        self.fc = nn.Linear(768, output_dim)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input_ids, attention_masks, token_type_ids, hidden):\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        sequence_output, pooled_output = self.bert_model(input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids) \n",
        "        # print(\"seq  \" , len(sequence_output))\n",
        "        \n",
        "        # lstm_out, hidden = self.lstm(sequence_output[0], hidden)\n",
        "\n",
        "        # lstm_out = lstm_out.permute(0,2,1)\n",
        "        \n",
        "        # out_max = F.max_pool1d(lstm_out, kernel_size=lstm_out.shape[2])\n",
        "        # out_avg = F.avg_pool1d(lstm_out, kernel_size=lstm_out.shape[2])\n",
        "        \n",
        "        # out = torch.cat((out_avg, out_max), dim=1)\n",
        "        # out = out.permute(0,2,1)\n",
        "\n",
        "        # dropout and fully connected layer\n",
        "        out = self.dropout(pooled_output)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        out = sig_out.view(batch_size, -1)\n",
        "\n",
        "        out = out[:, -1]\n",
        "\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # initialize hidden states with sizes n_layers x batch_size x hidden_dim\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        hidden = (h0,c0)\n",
        "        return hidden"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sSe6XdCz7Ah",
        "outputId": "1f3240a1-5625-4f23-ebb7-805d68587e1c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Dx3yzYIy-Jf",
        "outputId": "0d371ece-b032-4d94-d10a-750be8dc7e5c"
      },
      "source": [
        "no_layers = 1\n",
        "output_dim = 1\n",
        "hidden_dim = 128\n",
        "Freeze_bert = False\n",
        "Similar_Model = Similarity_Model(output_dim, no_layers, hidden_dim, Freeze_bert)\n",
        "#moving to gpu\n",
        "Similar_Model.to(device)\n",
        "Similar_Model.eval()\n",
        "\n",
        "Similar_Model.load_state_dict(torch.load(\"/content/drive/MyDrive/Snli_TechSimilarity.pt\"))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DdRHRBwzcVK"
      },
      "source": [
        "def predict_similarity(ans1, ans2):\n",
        "  sentence1 = clean2_text(ans1)\n",
        "  sentence2 = clean2_text(ans2)\n",
        "  # print(sentence1, sentence2)\n",
        "  encoded_pair = tokenizer(  sentence1, sentence2, \n",
        "      add_special_tokens=True,\n",
        "      truncation=True,\n",
        "      max_length = 500,\n",
        "      return_tensors='pt'  # Return torch.Tensor objects\n",
        "  )\n",
        "  # print(encoded_pair['input_ids'].shape)\n",
        "  text, attention, token_ids = encoded_pair['input_ids'].expand(1,-1), encoded_pair['attention_mask'].expand(1,-1), encoded_pair['token_type_ids'].expand(1,-1)\n",
        "  inputs, attention, token_ids = text.to(device), attention.to(device), token_ids.to(device)\n",
        "  h = Similar_Model.init_hidden(1)\n",
        "  h = tuple([each.data for each in h])\n",
        "  output, _ = Similar_Model(inputs, attention, token_ids, h)\n",
        "  return str(output.item())"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ksh_HALrKFwd",
        "outputId": "1b136d9b-f7d7-4fd7-fb60-18702cf49f53"
      },
      "source": [
        "ans1 = \"Linear Regression is a supervised Machine Learning algorithm. It is used to find the linear relationship between the dependent and the independent variables for predictive analysis.\"\n",
        "# ans1 = \"It's are powerful yet flexible supervised machine learning algorithms which are used both for classification and regression. But generally, they are used in classification problems\"\n",
        "ans2 = \"Linear Regression\"\n",
        "print(len(ans2.split()))\n",
        "if len(ans2.split()) >= 0 and len(ans2.split()) <= 2 :\n",
        "  prob1 = 0.0\n",
        "else:\n",
        "  prob1 = predict_similarity(ans1, ans2)\n",
        "print(prob1)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9c7riT601Nb"
      },
      "source": [
        "# **Routes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0CBZC5SrqTB"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6qJaZIe02Ed",
        "outputId": "c6c84569-deea-4b88-bed4-37cb550552db"
      },
      "source": [
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "#this contains the path of folder that to store the images in\n",
        "app.config[\"IMAGE_UPLOADS\"] = \"/content\"\n",
        "app.config[\"AUDIO_UPLOADS\"]=\"/content\"\n",
        "run_with_ngrok(app)  # Start ngrok when app is run\n",
        "\n",
        "@app.route(\"/predict\", methods=['post'])\n",
        "def predict():\n",
        "    image_bytes = b64decode(request.form[\"image\"].split(',')[1])\n",
        "    # convert bytes to numpy array\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    # decode numpy array into OpenCV BGR image\n",
        "    image = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "    url = request.method\n",
        "    frameTemp = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    frameTemp = cv2.resize(frameTemp, (100, 100))\n",
        "    try:\n",
        "      rects = find(frameTemp)\n",
        "      rects = np.array(rects)\n",
        "      rects = non_max_suppression_fast(rects, 0.2)\n",
        "\n",
        "      output=\"\"\n",
        "      ans = \"\"\n",
        "      for rect in rects: \n",
        "          res,ret=getFaceAlign(frameTemp[rect[0]:rect[1],rect[2]:rect[3]])\n",
        "          if ret==1:\n",
        "            pred = pr(res)\n",
        "            print(pred)\n",
        "            if pred in ['Disgust','Fear','Sad','Angry']:\n",
        "              ans = 'bad'\n",
        "            elif pred in ['Surprise' , 'Neutral']:\n",
        "              ans = 'medium'\n",
        "            elif pred == 'Happy':\n",
        "              ans = 'good'             \n",
        "            output+= ans+\" \"\n",
        "            print(ans)\n",
        "      #return the emotion of the face's image to the html\n",
        "      if output!=\"\":\n",
        "        return jsonify(output)\n",
        "      return jsonify(\"medium\")\n",
        "    \n",
        "    except:\n",
        "        return jsonify(\"medium\")\n",
        "\n",
        "@app.route('/predictVoice',methods=['POST'])\n",
        "def predictVoice():\n",
        "    audio = request.files[\"file\"]\n",
        "    audiofile=audio.filename\n",
        "    #save the audio in colab directory /content \n",
        "    audio.save(os.path.join(app.config[\"AUDIO_UPLOADS\"], audiofile))\n",
        "    #dir of audio is in the current directory \n",
        "    #convert audio to correct wav file\n",
        "    newAudio = AudioSegment.from_file(audiofile)\n",
        "    #overwrite corrupted audio with the corrected audio \n",
        "    newAudio.export(audiofile, format=\"wav\")\n",
        "    emotion_dic=get_emotion_dic(\"/content/\"+audiofile)\n",
        "    print(emotion_dic)\n",
        "    return jsonify(emotion_dic)\n",
        "\n",
        "\n",
        "@app.route('/predictSimilarity', methods=['POST'])\n",
        "def predictSimilarity():\n",
        "    audio = request.files[\"file\"]\n",
        "    audiofile=audio.filename\n",
        "    audio.save(os.path.join(app.config[\"AUDIO_UPLOADS\"], audio.filename))\n",
        "\n",
        "    User_answer = SpeechRecognition(\"/content/\"+audiofile, audiofile)\n",
        "    print(\"User answer from API: \" , User_answer)\n",
        "\n",
        "    # os.remove(\"/content/\"+audiofile)\n",
        "    # !rm audiofile\n",
        "    question=request.form['question']\n",
        "\n",
        "    answer1 = request.form['ans1']\n",
        "    answer2 = request.form['ans2']\n",
        "    answer3 = request.form['ans3']\n",
        "    print(\"Model Answer 1:  \" , answer1)\n",
        "    \n",
        "    if len(User_answer.split()) >= 0 and len(User_answer.split()) <= 2 :\n",
        "      prob = 0.0\n",
        "    else:\n",
        "      prob1 = predict_similarity(answer1, User_answer)\n",
        "      prob2 = predict_similarity(answer2, User_answer)\n",
        "      prob3 = predict_similarity(answer3, User_answer)\n",
        "\n",
        "      prob = max(prob1, prob2, prob3)\n",
        "      \n",
        "    print(\"probability = \", prob)\n",
        "    dic=[question, answer1,prob]\n",
        "    return jsonify(dic)    \n",
        "\n",
        "app.run()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://e48130db9698.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:32:25] \"\u001b[37mPOST /predictVoice HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bad': 0, 'medium': 1, 'good': 0}\n",
            "Waiting for operation to complete...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:32:28] \"\u001b[37mPOST /predictSimilarity HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "User answer from API:  Goodwin\n",
            "Model Answer 1:   AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making. anyone to heaven, I wish I could get my mother-in-law to eat it!\n",
            "probability =  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:32:37] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fear\n",
            "bad\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:32:38] \"\u001b[37mPOST /predictVoice HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bad': 1, 'medium': 0, 'good': 0}\n",
            "Waiting for operation to complete...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:32:41] \"\u001b[37mPOST /predictSimilarity HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "User answer from API:  bad one\n",
            "Model Answer 1:   Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.\n",
            "probability =  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:32:52] \"\u001b[37mPOST /predictVoice HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bad': 1, 'medium': 0, 'good': 0}\n",
            "Waiting for operation to complete...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:32:55] \"\u001b[37mPOST /predictSimilarity HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "User answer from API:  sad one\n",
            "Model Answer 1:   A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.\n",
            "probability =  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:33:06] \"\u001b[37mPOST /predictVoice HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bad': 0, 'medium': 0, 'good': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:33:07] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Neutral\n",
            "medium\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:33:19] \"\u001b[37mPOST /predictVoice HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bad': 1, 'medium': 0, 'good': 0}\n",
            "Waiting for operation to complete...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:33:22] \"\u001b[37mPOST /predictSimilarity HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "User answer from API:  try you on\n",
            "Model Answer 1:   Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.\n",
            "probability =  0.07245948910713196\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:33:25] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:33:36] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:33:45] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:33:55] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:34:05] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:34:15] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:34:25] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:34:35] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:34:45] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:34:55] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:35:05] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:35:15] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:35:25] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:35:35] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:35:45] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:35:55] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:36:05] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:36:15] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:36:25] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:36:35] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:36:45] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:36:56] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:37:05] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:37:15] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:37:25] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:37:35] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:37:45] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:37:55] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:38:05] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:38:15] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:38:25] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:38:35] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:38:45] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:38:55] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:39:05] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:39:15] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:39:25] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:39:35] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:39:45] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:39:55] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:40:21] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:40:27] \"\u001b[37mPOST /predictVoice HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bad': 1, 'medium': 0, 'good': 3}\n",
            "Waiting for operation to complete...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:40:32] \"\u001b[37mPOST /predictSimilarity HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "User answer from API:  \n",
            "Model Answer 1:   Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.\n",
            "probability =  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:40:38] \"\u001b[37mPOST /predictVoice HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bad': 0, 'medium': 0, 'good': 1}\n",
            "Waiting for operation to complete...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:40:40] \"\u001b[37mPOST /predictSimilarity HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "User answer from API:  \n",
            "Model Answer 1:   AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making. anyone to heaven, I wish I could get my mother-in-law to eat it!\n",
            "probability =  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:40:49] \"\u001b[37mPOST /predictVoice HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bad': 0, 'medium': 0, 'good': 0}\n",
            "Waiting for operation to complete...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:40:51] \"\u001b[37mPOST /predictSimilarity HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "User answer from API:  \n",
            "Model Answer 1:   Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.\n",
            "probability =  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:41:00] \"\u001b[37mPOST /predictVoice HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bad': 0, 'medium': 0, 'good': 0}\n",
            "Waiting for operation to complete...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:41:02] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fear\n",
            "bad\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:41:03] \"\u001b[37mPOST /predictSimilarity HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "User answer from API:  \n",
            "Model Answer 1:   A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.\n",
            "probability =  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:41:11] \"\u001b[37mPOST /predictVoice HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'bad': 0, 'medium': 0, 'good': 0}\n",
            "Waiting for operation to complete...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:41:12] \"\u001b[37mPOST /predictSimilarity HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "User answer from API:  \n",
            "Model Answer 1:   Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.\n",
            "probability =  0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Jul/2021 23:41:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:41:29] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:41:40] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:41:50] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:41:59] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:42:10] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:42:19] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:42:29] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:42:40] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:42:50] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:43:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:43:10] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:43:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:43:30] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:43:40] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:43:50] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:44:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:44:10] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:44:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:44:30] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:44:40] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:44:50] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:45:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:45:10] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:45:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:45:30] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:45:40] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:45:50] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:46:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:46:10] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:46:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:46:30] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:46:40] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:46:50] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:47:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:47:10] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:47:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:47:30] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:47:40] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:47:50] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:48:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:48:10] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:48:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:48:30] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:48:40] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:48:50] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:49:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:49:10] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:49:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:49:30] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:49:40] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:49:50] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:50:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:50:10] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:50:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:50:30] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:50:40] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:50:50] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:51:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:51:10] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:51:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:51:30] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:51:40] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:51:50] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:52:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:52:10] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:52:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:52:30] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:52:40] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:52:50] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:53:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:53:10] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:53:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:53:30] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:53:40] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:53:50] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:54:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:54:10] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:54:20] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:54:30] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:54:40] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:54:50] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:55:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [20/Jul/2021 23:55:10] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYKiyOvSItfc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}