{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51137d49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51137d49",
    "outputId": "8d5057d9-6df1-4d1b-a68b-6acee6eee619"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face-alignment\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/be/f4cbc7b2191e73415d869462178dce7e9b6c31fd7d8faec9594ce93f7d3b/face_alignment-1.3.4.tar.gz\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from face-alignment) (1.9.0+cu102)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face-alignment) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from face-alignment) (1.4.1)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from face-alignment) (0.16.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from face-alignment) (4.1.2.30)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from face-alignment) (4.41.1)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from face-alignment) (0.51.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->face-alignment) (3.7.4.3)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment) (2.5.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment) (3.2.2)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment) (2.4.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->face-alignment) (7.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->face-alignment) (57.0.0)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->face-alignment) (0.34.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->face-alignment) (4.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image->face-alignment) (1.15.0)\n",
      "Building wheels for collected packages: face-alignment\n",
      "  Building wheel for face-alignment (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for face-alignment: filename=face_alignment-1.3.4-py2.py3-none-any.whl size=27859 sha256=9d6536c635595e6b0badecc496ffb670929a41e6c036d3202902c144465e03fe\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/4d/d9/fa80a2341395ce73765c09eef97b262a048b2a763c9b689c2c\n",
      "Successfully built face-alignment\n",
      "Installing collected packages: face-alignment\n",
      "Successfully installed face-alignment-1.3.4\n"
     ]
    }
   ],
   "source": [
    "!pip install face-alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11f7c43d",
   "metadata": {
    "id": "11f7c43d"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import face_alignment\n",
    "from skimage import io,transform,data,color,feature\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import os\n",
    "import skimage.io as io\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score , GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "from numba import jit, cuda\n",
    "import pickle\n",
    "import timeit\n",
    "from os import listdir\n",
    "from matplotlib import image\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import dlib\n",
    "from imutils.face_utils import FaceAligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8481d410",
   "metadata": {
    "id": "8481d410"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be2c7d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272,
     "referenced_widgets": [
      "2f56f9a672084eaebfe5992c7864d5a8",
      "daf41710368744d7981d95283ef00613",
      "ee6e72c944a745a8bbcf504513a3f708",
      "eb8662ba4838454bb48bc981dcfc7a42",
      "1f6d117e178742c58741ba43d94c74ee",
      "5350f4286089491b937e5ac696af33c7",
      "daa9c57d397f4abcba3602c96035f73a",
      "ecdb648e03dc49dcb2d12896ccd9ded3",
      "2b48dc5be328478383bddf96b736e347",
      "895b6c12c2a7493c83547428a6034a8a",
      "7c7c868e6d554e939d0336450f7d8151",
      "47e48199398a4830b47c34061ab0a256",
      "8d348cc730f54a5297ec3eeae65fd212",
      "c2c7e690c951430880cb2f8faca6e68e",
      "62558e0edf8a46d8ad13132ccb294a71",
      "9ad6e040e24548c6912f42c3a57c962a"
     ]
    },
    "id": "4be2c7d4",
    "outputId": "2741ef4e-7ba7-464f-ef99-f299c7e9869b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LinearSVC from version 0.23.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" to /root/.cache/torch/hub/checkpoints/s3fd-619a316812.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f56f9a672084eaebfe5992c7864d5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=89843225.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/2DFAN4-cd938726ad.zip\" to /root/.cache/torch/hub/checkpoints/2DFAN4-cd938726ad.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b48dc5be328478383bddf96b736e347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=96316515.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# put here the path to the mode\n",
    "model = pickle.load(open(\"faceDetection2.sav\", 'rb'))\n",
    "print(model)\n",
    "fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, flip_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d650428",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d650428",
    "outputId": "8d20528c-23c1-486a-9b43-bfee1a9a6773"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neural_network.multilayer_perceptron module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neural_network. Anything that cannot be imported from sklearn.neural_network is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.label module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.21.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.21.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#load the model \n",
    "voice_model = pickle.load(open('voice_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5499f54",
   "metadata": {
    "id": "d5499f54"
   },
   "outputs": [],
   "source": [
    "def getFaceAlign(img):\n",
    "  io.imsave('testt.jpg',img)\n",
    "  preds = fa.get_landmarks(img)\n",
    "  if preds == None:\n",
    "    print('Warning: No faces were detected.')\n",
    "    return None,0\n",
    "  if preds!=None:\n",
    "    mnXY= np.min(np.min(preds, axis=1), axis=0)\n",
    "    mxXY= np.max(np.max(preds, axis=1), axis=0)\n",
    "    mxY=int(mxXY[0]+2)\n",
    "    mnX=int(mnXY[1])-8\n",
    "    mxX=int(mxXY[1])\n",
    "    if mnX < 0:\n",
    "       mnX=0\n",
    "    if int(mxXY[0]+2) >= img.shape[1]:\n",
    "      mxY=img.shape[1]-1\n",
    "    if (img.shape[0]-2-mnX) <= 40:\n",
    "      return img[mnX:img.shape[0]-2,int(mnXY[0])-2:mxY],1\n",
    "    else:\n",
    "      return img[mnX:mnX+40,int(mnXY[0])-2:mxY],1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba7a7d03",
   "metadata": {
    "id": "ba7a7d03"
   },
   "outputs": [],
   "source": [
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    pick = []\n",
    "    x1 = boxes[:,2]\n",
    "    y1 = boxes[:,0]\n",
    "    x2 = boxes[:,3]\n",
    "    y2 = boxes[:,1]\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    return boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ec24f65",
   "metadata": {
    "id": "7ec24f65"
   },
   "outputs": [],
   "source": [
    "def find(image):\n",
    "    boxes=[[i,i+k,j,int(j+k)] for k in [35,45,55] for i in range(0,image.shape[0]-k,5) for j in range(0,image.shape[1]-k,5) if (model.predict([feature.hog(transform.resize(image[i:i+k,j:int(j+k)],(48,48)))])[0] == 1)]\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9476384",
   "metadata": {
    "id": "e9476384"
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "from torch.nn.modules.activation import ReLU\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def conv_bn_relu(in_channels, out_channels, kernel_size=3, stride=1, padding=0):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def SeparableConv2D(in_channels, out_channels, kernel=3):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, in_channels, kernel_size=kernel, stride=1, groups=in_channels,padding=1, bias=False),\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "    )\n",
    "\n",
    "class ResidualXceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel=3):\n",
    "        super(ResidualXceptionBlock, self).__init__()\n",
    "        global device\n",
    "\n",
    "        self.depthwise_conv1 = SeparableConv2D(in_channels, out_channels, kernel).to(device)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.depthwise_conv2 = SeparableConv2D(out_channels, out_channels, kernel).to(device)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # self.padd = nn.ZeroPad2d(22)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        # self.residual_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2, padding=22, bias=False)\n",
    "        self.residual_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.residual_bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # residual branch\n",
    "        residual = self.residual_conv(x)\n",
    "        residual = self.residual_bn(residual)\n",
    "        \n",
    "        # print('input',x.shape)\n",
    "        # feature extraction branch\n",
    "        x = self.depthwise_conv1(x)\n",
    "        # print('conv1',x.shape)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.depthwise_conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        # print('conv2',x.shape)\n",
    "\n",
    "        # x = self.padd(x)\n",
    "        x = self.maxpool(x)\n",
    "        # print(x[:,:, 11:22, 11:22])\n",
    "        # print('max_pooling',x.shape)\n",
    "        # print('res',residual.shape)\n",
    "        return x + residual\n",
    "\n",
    "class Mini_Xception(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mini_Xception, self).__init__()\n",
    "        self.conv1 = conv_bn_relu(1, 8, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv2 = conv_bn_relu(8, 8, kernel_size=3, stride=1, padding=0)\n",
    "        self.residual_blocks = nn.ModuleList([\n",
    "            ResidualXceptionBlock(8 , 16).to(device),\n",
    "            ResidualXceptionBlock(16, 32).to(device),\n",
    "            ResidualXceptionBlock(32, 64).to(device),\n",
    "            ResidualXceptionBlock(64, 128).to(device)            \n",
    "        ])\n",
    "        self.conv3 = nn.Conv2d(128, 7, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        for block in self.residual_blocks:\n",
    "            x = block(x)\n",
    "            # print('ith block', x.shape, block.device)\n",
    "\n",
    "        # print('blocks:',x.shape)\n",
    "        x = self.conv3(x)\n",
    "        # print('conv3',x.shape)\n",
    "        x = self.global_avg_pool(x)\n",
    "        # # x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def get_label_emotion(label : int) -> str:\n",
    "    label_emotion_map = { \n",
    "        0: 'Angry',\n",
    "        1: 'Disgust', \n",
    "        2: 'Fear', \n",
    "        3: 'Happy', \n",
    "        4: 'Sad', \n",
    "        5: 'Surprise', \n",
    "        6: 'Neutral'        \n",
    "    }\n",
    "    return label_emotion_map[label]\n",
    "\n",
    "\n",
    "def pr(img):\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "  mini_xception = Mini_Xception().to(device)\n",
    "  mini_xception.eval()\n",
    "\n",
    "  # Load model\n",
    "  # put here the path to the model\n",
    "  checkpoint = torch.load('/content/drive/MyDrive/Colab Notebooks/weights_epoch_75.pth.tar')\n",
    "  mini_xception.load_state_dict(checkpoint['mini_xception'])\n",
    "\n",
    "    \n",
    "  input_face = cv2.resize(img, (48,48))\n",
    "  input_face = cv2.equalizeHist(input_face)\n",
    "  input_face = transforms.ToTensor()(input_face).to(device)\n",
    "  input_face = torch.unsqueeze(input_face, 0)\n",
    "\n",
    "  with torch.no_grad():\n",
    "      input_face = input_face.to(device)\n",
    "      emotion = mini_xception(input_face)\n",
    "      # print(f'\\ntime={(time.time()-t) * 1000 } ms')\n",
    "\n",
    "      torch.set_printoptions(precision=6)\n",
    "      softmax = torch.nn.Softmax()\n",
    "      emotions_soft = softmax(emotion.squeeze()).reshape(-1,1).cpu().detach().numpy()\n",
    "      emotions_soft = np.round(emotions_soft, 3)\n",
    "      for i, em in enumerate(emotions_soft):\n",
    "          em = round(em.item(),3)\n",
    "          # print(f'{get_label_emotion(i)} : {em}')\n",
    "\n",
    "      emotion = torch.argmax(emotion)                \n",
    "      percentage = round(emotions_soft[emotion].item(), 2)\n",
    "      emotion = emotion.squeeze().cpu().detach().item()\n",
    "      emotion = get_label_emotion(emotion)\n",
    "      return emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2921901",
   "metadata": {
    "id": "c2921901"
   },
   "source": [
    "# Voice analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e98c0aeb",
   "metadata": {
    "id": "e98c0aeb"
   },
   "outputs": [],
   "source": [
    "#DataFlair - Extract features (mfcc, chroma, mel) from a sound file\n",
    "def extract_feature(X, mfcc, chroma, mel,sample_rate):   \n",
    "    result=np.array([])\n",
    "    if mfcc:\n",
    "        mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        result=np.hstack((result, mfccs))\n",
    "    if chroma:\n",
    "        stft=np.abs(librosa.stft(X))\n",
    "        chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result=np.hstack((result, chroma))\n",
    "    if mel:\n",
    "        mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "        result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaa92cd3",
   "metadata": {
    "id": "eaa92cd3"
   },
   "outputs": [],
   "source": [
    "def predict_voice(file):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    y, s = librosa.load(file) # Downsample 44.1kHz to 8kHz\n",
    "    feature=extract_feature(X=y, mfcc=True, chroma=True, mel=True,sample_rate=s)\n",
    "    x.append(feature)\n",
    "    y_pred=voice_model.predict(x)\n",
    "    emotion = y_pred[0]\n",
    "    return emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8720c670",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8720c670",
    "outputId": "4817f27e-8ab5-473b-ea5f-4da6ed2338af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask-ngrok\n",
      "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
      "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
      "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
      "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
      "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
      "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
      "Installing collected packages: flask-ngrok\n",
      "Successfully installed flask-ngrok-0.0.25\n"
     ]
    }
   ],
   "source": [
    "!pip install flask-ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50beadcd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "50beadcd",
    "outputId": "6009d169-3297-4426-d36d-22840b81765d"
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "from flask_ngrok import run_with_ngrok\n",
    "\n",
    "app = Flask(__name__)\n",
    "#this contains the path of folder that to store the images in\n",
    "app.config[\"IMAGE_UPLOADS\"] = \"/content\"\n",
    "app.config[\"AUDIO_UPLOADS\"]=\"/content\"\n",
    "run_with_ngrok(app)  # Start ngrok when app is run\n",
    "\n",
    "@app.route('/') \n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route(\"/predict\", methods=['POST'])\n",
    "def predict():\n",
    "    url = request.method\n",
    "    image = request.files[\"image\"]\n",
    "    \n",
    "    #the name of image file\n",
    "    imgName = image.filename\n",
    "    #save the image in colab directory /content \n",
    "    image.save(os.path.join(app.config[\"IMAGE_UPLOADS\"], image.filename))\n",
    "    frameTemp = cv2.imread(imgName,0)\n",
    "    frameTemp = cv2.resize(frameTemp, (100, 100))\n",
    "    rects = find(frameTemp)\n",
    "    rects = np.array(rects)\n",
    "    rects = non_max_suppression_fast(rects, 0.2)\n",
    "    output=\"\"\n",
    "    for rect in rects:\n",
    "        res,ret=getFaceAlign(frameTemp[rect[0]:rect[1],rect[2]:rect[3]])\n",
    "        if ret==1:\n",
    "          print(rect)\n",
    "          io.imshow(res)\n",
    "          print(pr(res))\n",
    "          output+= pr(res)+\" \"\n",
    "    \n",
    "    #return the emotion of the face's image to the html \n",
    "    return output\n",
    "\n",
    "@app.route('/predictVoice',methods=['POST'])\n",
    "def predictVoice():\n",
    "    audio = request.files[\"audio\"]\n",
    "    print(audio)\n",
    "    audiofile=audio.filename\n",
    "    #save the audio in colab directory /content \n",
    "    audio.save(os.path.join(app.config[\"AUDIO_UPLOADS\"], audio.filename))\n",
    "    #dir of audio is in the current directory \n",
    "    emotion = predict_voice(\"/content/\"+audiofile)\n",
    "    return emotion\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VmBoTBVge-s0",
   "metadata": {
    "id": "VmBoTBVge-s0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Deploy2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1f6d117e178742c58741ba43d94c74ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2b48dc5be328478383bddf96b736e347": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7c7c868e6d554e939d0336450f7d8151",
       "IPY_MODEL_47e48199398a4830b47c34061ab0a256"
      ],
      "layout": "IPY_MODEL_895b6c12c2a7493c83547428a6034a8a"
     }
    },
    "2f56f9a672084eaebfe5992c7864d5a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee6e72c944a745a8bbcf504513a3f708",
       "IPY_MODEL_eb8662ba4838454bb48bc981dcfc7a42"
      ],
      "layout": "IPY_MODEL_daf41710368744d7981d95283ef00613"
     }
    },
    "47e48199398a4830b47c34061ab0a256": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ad6e040e24548c6912f42c3a57c962a",
      "placeholder": "​",
      "style": "IPY_MODEL_62558e0edf8a46d8ad13132ccb294a71",
      "value": " 91.9M/91.9M [02:59&lt;00:00, 536kB/s]"
     }
    },
    "5350f4286089491b937e5ac696af33c7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62558e0edf8a46d8ad13132ccb294a71": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7c7c868e6d554e939d0336450f7d8151": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2c7e690c951430880cb2f8faca6e68e",
      "max": 96316515,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8d348cc730f54a5297ec3eeae65fd212",
      "value": 96316515
     }
    },
    "895b6c12c2a7493c83547428a6034a8a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d348cc730f54a5297ec3eeae65fd212": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9ad6e040e24548c6912f42c3a57c962a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2c7e690c951430880cb2f8faca6e68e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daa9c57d397f4abcba3602c96035f73a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "daf41710368744d7981d95283ef00613": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb8662ba4838454bb48bc981dcfc7a42": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecdb648e03dc49dcb2d12896ccd9ded3",
      "placeholder": "​",
      "style": "IPY_MODEL_daa9c57d397f4abcba3602c96035f73a",
      "value": " 85.7M/85.7M [00:16&lt;00:00, 5.52MB/s]"
     }
    },
    "ecdb648e03dc49dcb2d12896ccd9ded3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee6e72c944a745a8bbcf504513a3f708": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5350f4286089491b937e5ac696af33c7",
      "max": 89843225,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1f6d117e178742c58741ba43d94c74ee",
      "value": 89843225
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
