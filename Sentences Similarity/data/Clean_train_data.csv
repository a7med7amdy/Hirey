Questions,ans1,ans2,class
What is deep learning?,"Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.",Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,1
What is deep learning?,"Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.",The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,0
what do you know about input layer?,Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,"Input Layer: Input variables, sometimes called the visible layer.",0
What is deep learning?,"Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.","Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data.",1
What is deep learning?,"Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.",Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,0
"What do you mean by ""overfitting""?","Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data.","Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.",0
What is deep learning?,"Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.",Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,1
What is deep learning?,"Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.",Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,0
What do you understand by Autoencoder?,Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,"Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.",0
What is deep learning?,"Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.","Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.",1
What is deep learning?,"Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.",initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,0
What is the meaning of term weight initialization in neural networks?,"Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.","initializing weights with too-small values will lead to divergence, too-large values will lead to exploding.",0
What is deep learning?,"Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.","Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.",1
What is deep learning?,"Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.",Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,0
Explain the following variant of Gradient Descent Stochastic?,"Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.","Instead of going through all examples, the gradient based on a single training sample.",0
What is deep learning?,"Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.","Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.",1
What do you understand by Autoencoder?,"Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.","Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.",0
What is deep learning?,Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,"Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data.",1
What is deep learning?,Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,0
Explain the layer of CNN: pooling,"Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data.",pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,0
What is deep learning?,Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,1
What is deep learning?,Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,The data is made available at the output layer.,0
what do you know about output layer?,Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,"The output layer is the simplest, usually consisting of a single output for classification problems.",0
What is deep learning?,Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,"Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.",1
What is deep learning?,Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,"Instead of going through all examples, Stochastic Gradient Descent (SGD) performs the parameters update on each example.",0
Explain the following variant of Gradient Descent Stochastic?,"Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.","the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.",0
What is deep learning?,Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,"Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.",1
What is deep learning?,Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,"layer will compute the class scores, resulting a class probability distribution.",0
Explain the layer of CNN: Full Collectedness,"Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.",aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,0
What is deep learning?,Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,"Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.",1
What is deep learning?,Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Autoencoder?,"Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.","Autoencoders are neural networks. Neural networks are composed of multiple layers, and the defining aspect of an autoencoder is that the input layers contain exactly as much information as the output layer.",0
What is deep learning?,"Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data.",Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,1
What is deep learning?,"Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data.","The input layer contains input neurons, sometimes called the visible layer.",0
what do you know about input layer?,Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,The input layer is contains your raw data. which send information to the hidden layer.,0
What is deep learning?,"Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data.","Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.",1
What is deep learning?,"Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data.",A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,0
What do you understand by Perceptron?,"Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.","A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",0
What is deep learning?,"Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data.","Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.",1
What is deep learning?,"Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data.",Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,0
What do you understand by Boltzmann Machine?,"Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.",The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,0
What is deep learning?,"Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data.","Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.",1
What is deep learning?,"Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data.","The output layer is the simplest, usually consisting of a single output for classification problems.",0
what do you know about output layer?,"Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.",The data is made available the output variables.,0
What is deep learning?,Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,"Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.",1
What is deep learning?,Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,"Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.",0
What do you understand by Tensors?,"Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.","Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.",0
What is deep learning?,Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,"Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.",1
What is deep learning?,Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,"This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network",0
What is the use of decoder layers in Autoencoders?,"Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.",Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,0
What is deep learning?,Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,"Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.",1
What is deep learning?,Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,"Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).",0
What is the use of leaky ReLU function?,"Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.","Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",0
What is deep learning?,"Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.","Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.",1
What is deep learning?,"Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.","Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.",0
Explain the layer of CNN: ReLU,"Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.","the most commonly deployed activation function, such as the max(0,x) thresholding at zero.",0
What is deep learning?,"Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.","Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.",1
What is deep learning?,"Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.",A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.,0
What do you understand by Tensors?,"Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.",A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,0
What is deep learning?,"Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.","Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.",1
What is deep learning?,"Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.",Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,0
Explain the following variant of Gradient Descent Stochastic?,"Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.","the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.","Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.",The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,0
What is the use of leaky ReLU function?,"Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,0
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.",This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,0
Explain the layer of CNN: convolution,"Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",This layer computes the convolutions between the neurons of an input that results in an activation.,0
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.","AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.","a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",0
What is the use of leaky ReLU function?,"AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems","the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.",most important feature in an activation function is its ability to add non-linearity into a neural network.,0
What is the use of the Activation function?,"AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",The basic purpose of the activation function its ability to add non-linearity into a neural network.,0
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.","can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",0
What is a binary step function?,"Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.","is one of the most common activation function in neural networks. if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.","AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.","Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.",0
Explain the following variant of Gradient Descent mini-batch?,"AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.","Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.","The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.",0
What is Tanh function?,"Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.","rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.","AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,0
What is Tanh function?,"AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems","tanh produces output ranges from -1 and 1, and used as activation function.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",A convolution is the simple application of a filter to an input that results in an activation.,0
Explain the layer of CNN: convolution,"AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",This layer computes the convolutions between the neurons of an input that results in an activation.,0
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",The data is made available the output variables.,0
what do you know about output layer?,"Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",Output Layer: A layer of nodes that usually consisting of a single output for classification problems.,0
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.","AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.","In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
Differentiate supervised and unsupervised deep learning procedures.,"AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.","supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.","AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.","The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.","The hidden layer is used to send data, There may be one or more of these layers.",0
what do you know about hidden layer?,"AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.","Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.","Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.",0
Explain the layer of CNN: ReLU,"Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.","the most commonly deployed activation function, such as the max(0,x) thresholding at zero.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.","AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.","n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.",0
What is the meaning of term weight initialization in neural networks?,"AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,0
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems",multiplies arrays A and B of same dimension by multiplying corresponding elements.,0
What is matrix element-wise multiplication?,"AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.","takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems",has the same structure of a single layer perceptron with one or more hidden layers.,0
what is a multilayer percepton?,"Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,0
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems","AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems",The basic purpose of the activation function its ability to add non-linearity into a neural network.,0
What is the use of the Activation function?,"AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,0
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,0
What is matrix element-wise multiplication?,"Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.","We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.","AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.","When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.",0
What is the function of the Fourier Transform in Deep Learning?,"AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.","processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.","AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",1
"What are the main differences between AI, Machine Learning, and Deep Learning?","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.","Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.",0
Explain the layer of CNN: Full Collectedness,"AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",fully connected neural network structure that drives the final classification decision.,0
Differentiate supervised and unsupervised deep learning procedures.,"Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.","In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",1
Differentiate supervised and unsupervised deep learning procedures.,"Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.","Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",0
Explain gradient descent?,"In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,0
Differentiate supervised and unsupervised deep learning procedures.,"Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.",supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,1
Differentiate supervised and unsupervised deep learning procedures.,"Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.","An optimization algorithm that is used to minimize some function by repeatedly moving in the direction of steepest descent as specified by the negative of the gradient is known as gradient descent. It's an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameter of the function",0
Explain gradient descent?,supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,0
Differentiate supervised and unsupervised deep learning procedures.,"Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.",Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output.Unsupervised learning is modeling the underlying or hidden structure or distribution in the data in order to learn more about the data,1
Differentiate supervised and unsupervised deep learning procedures.,"Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.",the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,0
What is the use of leaky ReLU function?,Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output.Unsupervised learning is modeling the underlying or hidden structure or distribution in the data in order to learn more about the data,"Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",0
Differentiate supervised and unsupervised deep learning procedures.,"Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.","supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",1
Differentiate supervised and unsupervised deep learning procedures.,"Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.",initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,0
What is the meaning of term weight initialization in neural networks?,"supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.","if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations",0
Differentiate supervised and unsupervised deep learning procedures.,"Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.","supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",1
Differentiate supervised and unsupervised deep learning procedures.,"Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.",deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,0
Do you think that deep network is better than a shallow one?,"supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.","A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.",0
Differentiate supervised and unsupervised deep learning procedures.,"Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.","Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",1
Differentiate supervised and unsupervised deep learning procedures.,"Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.",The hidden layer after the input layer and before the ouput layer.,0
what do you know about hidden layer?,"Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",The hidden layer after the input layer to send data to the output layer.,0
Differentiate supervised and unsupervised deep learning procedures.,"In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,1
Differentiate supervised and unsupervised deep learning procedures.,"In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.","Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.",0
"What do you mean by ""overfitting""?",supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,0
Differentiate supervised and unsupervised deep learning procedures.,"In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output.Unsupervised learning is modeling the underlying or hidden structure or distribution in the data in order to learn more about the data,1
Differentiate supervised and unsupervised deep learning procedures.,"In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.","Tensors are nothing but a de facto for representing the data in deep learning. They are just multidimensional arrays, which allows us to represent the data having higher dimensions. In general, we deal with high dimensional data sets where dimensions refer to different features present in the data set.",0
What do you understand by Tensors?,Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output.Unsupervised learning is modeling the underlying or hidden structure or distribution in the data in order to learn more about the data,A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,0
Differentiate supervised and unsupervised deep learning procedures.,"In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.","supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",1
Differentiate supervised and unsupervised deep learning procedures.,"In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.","A node or unit which implements the activation function is referred to as a rectified linear activation unit or ReLU for short. Generally, networks that use the rectifier function for the hidden layers are referred to as rectified networks.",0
What is ReLU function?,"supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.","The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.",0
Differentiate supervised and unsupervised deep learning procedures.,"In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.","supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",1
Differentiate supervised and unsupervised deep learning procedures.,"In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.","Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.",0
What is a Swish function?,"supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.","Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",0
Differentiate supervised and unsupervised deep learning procedures.,"In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.","Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",1
Differentiate supervised and unsupervised deep learning procedures.,"In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,0
Explain the layer of CNN: pooling,"Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.","while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.",0
Differentiate supervised and unsupervised deep learning procedures.,supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output.Unsupervised learning is modeling the underlying or hidden structure or distribution in the data in order to learn more about the data,1
Differentiate supervised and unsupervised deep learning procedures.,supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,Single layer perceptrons can learn only linearly separable patterns.,0
what is a single percepton?,Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output.Unsupervised learning is modeling the underlying or hidden structure or distribution in the data in order to learn more about the data,"As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",0
Differentiate supervised and unsupervised deep learning procedures.,supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,"supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",1
Differentiate supervised and unsupervised deep learning procedures.,supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,"A model with too little capacity cannot learn the training dataset meaning it will underfit, whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",0
What is Model Capacity?,"supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,0
Differentiate supervised and unsupervised deep learning procedures.,supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,"supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",1
Differentiate supervised and unsupervised deep learning procedures.,supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.",0
What do you understand by Boltzmann Machine?,"supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.","A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. hey dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.",0
Differentiate supervised and unsupervised deep learning procedures.,supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,"Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",1
Differentiate supervised and unsupervised deep learning procedures.,supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,The Rectified Linear Unit is the most commonly used activation function in deep learning models. An output is equal to zero when the input value is negative and the input value when the input is positive.,0
What is ReLU function?,"Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.","the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.",0
Differentiate supervised and unsupervised deep learning procedures.,Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output.Unsupervised learning is modeling the underlying or hidden structure or distribution in the data in order to learn more about the data,"supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",1
Differentiate supervised and unsupervised deep learning procedures.,Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output.Unsupervised learning is modeling the underlying or hidden structure or distribution in the data in order to learn more about the data,"The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.",0
What is ReLU function?,"supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",piecewise function returns zero if input is negative.,0
Differentiate supervised and unsupervised deep learning procedures.,Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output.Unsupervised learning is modeling the underlying or hidden structure or distribution in the data in order to learn more about the data,"supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",1
Differentiate supervised and unsupervised deep learning procedures.,Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output.Unsupervised learning is modeling the underlying or hidden structure or distribution in the data in order to learn more about the data,The code layer is used to represent the compressed input which is fed to the decoder.,0
What is the use of code layers in Autoencoders?,"supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",This part of the network represents the input that is fed into the decoder.,0
Differentiate supervised and unsupervised deep learning procedures.,Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output.Unsupervised learning is modeling the underlying or hidden structure or distribution in the data in order to learn more about the data,"Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",1
Differentiate supervised and unsupervised deep learning procedures.,Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output.Unsupervised learning is modeling the underlying or hidden structure or distribution in the data in order to learn more about the data,"This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",0
Explain the following variant of Gradient Descent batch?,"Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.","Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",0
Differentiate supervised and unsupervised deep learning procedures.,"supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.","supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",1
Differentiate supervised and unsupervised deep learning procedures.,"supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,0
What is matrix element-wise multiplication?,"supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",multiplies arrays A and B of same dimension to produce a new matrix.,0
Differentiate supervised and unsupervised deep learning procedures.,"supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.","Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",1
Differentiate supervised and unsupervised deep learning procedures.,"supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",sigmoid function have been used as the activation function of artificial neurons. Sigmoid functions most often show a return value (y axis) in the range 0 to 1,0
What is the sigmoid function?,"Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",activation function apply thresholding to input data and produce output between 0 and 1.,0
Differentiate supervised and unsupervised deep learning procedures.,"supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.","Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",1
Differentiate supervised and unsupervised deep learning procedures.,"supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.","AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems",0
Do you think that deep network is better than a shallow one?,"Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.","A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. That causes the number of parameters to increase a lot.There are quite conclusive results that a deep network can fit functions better with less parameters than a shallow network.",1
Do you think that deep network is better than a shallow one?,"Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.",Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,0
Explain the following variant of Gradient Descent batch?,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. That causes the number of parameters to increase a lot.There are quite conclusive results that a deep network can fit functions better with less parameters than a shallow network.","This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",0
Do you think that deep network is better than a shallow one?,"Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.","deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,",1
Do you think that deep network is better than a shallow one?,"Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.",This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,0
What is the use of decoder layers in Autoencoders?,"deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,",Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,0
Do you think that deep network is better than a shallow one?,"Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.",Shallow means that number of hidden layer = 1 . And in case of deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . So generally as we increase the depth of the model we increase the power of the model at the cost of the computational complexity .,1
Do you think that deep network is better than a shallow one?,"Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?",Shallow means that number of hidden layer = 1 . And in case of deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . So generally as we increase the depth of the model we increase the power of the model at the cost of the computational complexity .,"Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
Do you think that deep network is better than a shallow one?,"Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.",deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,1
Do you think that deep network is better than a shallow one?,"Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.","Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Autoencoder?,deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,"Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded",0
Do you think that deep network is better than a shallow one?,"Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.","A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.",1
Do you think that deep network is better than a shallow one?,"Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.",Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,0
"What do you mean by ""overfitting""?","A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.",occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,0
Do you think that deep network is better than a shallow one?,"Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.",deep network you have lots and lots of computational nodes and lots of layers of those nodes. Shallow means that number of hidden layer = 1 .,1
Do you think that deep network is better than a shallow one?,"Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.",Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,0
What is Backpropagation?,deep network you have lots and lots of computational nodes and lots of layers of those nodes. Shallow means that number of hidden layer = 1 .,Backpropagation is a process used to adjust the weights of a deep neural network. The weights that minimize the error,0
Do you think that deep network is better than a shallow one?,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. That causes the number of parameters to increase a lot.There are quite conclusive results that a deep network can fit functions better with less parameters than a shallow network.","deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,",1
Do you think that deep network is better than a shallow one?,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. That causes the number of parameters to increase a lot.There are quite conclusive results that a deep network can fit functions better with less parameters than a shallow network.","Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,",0
What is the function of the Fourier Transform in Deep Learning?,"deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,","data can be considered a signal, and making convolution easier.",0
Do you think that deep network is better than a shallow one?,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. That causes the number of parameters to increase a lot.There are quite conclusive results that a deep network can fit functions better with less parameters than a shallow network.",Shallow means that number of hidden layer = 1 . And in case of deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . So generally as we increase the depth of the model we increase the power of the model at the cost of the computational complexity .,1
Do you think that deep network is better than a shallow one?,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. That causes the number of parameters to increase a lot.There are quite conclusive results that a deep network can fit functions better with less parameters than a shallow network.","It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.",0
Explain the importance of LSTM.,Shallow means that number of hidden layer = 1 . And in case of deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . So generally as we increase the depth of the model we increase the power of the model at the cost of the computational complexity .,LSTMs have property of selectively remembering patterns for long durations of time.,0
Do you think that deep network is better than a shallow one?,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. That causes the number of parameters to increase a lot.There are quite conclusive results that a deep network can fit functions better with less parameters than a shallow network.",deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,1
What is the function of the Fourier Transform in Deep Learning?,deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,0
Do you think that deep network is better than a shallow one?,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. That causes the number of parameters to increase a lot.There are quite conclusive results that a deep network can fit functions better with less parameters than a shallow network.","A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.",1
Do you think that deep network is better than a shallow one?,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. That causes the number of parameters to increase a lot.There are quite conclusive results that a deep network can fit functions better with less parameters than a shallow network.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Autoencoder?,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.","Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.",0
Do you think that deep network is better than a shallow one?,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. That causes the number of parameters to increase a lot.There are quite conclusive results that a deep network can fit functions better with less parameters than a shallow network.",deep network you have lots and lots of computational nodes and lots of layers of those nodes. Shallow means that number of hidden layer = 1 .,1
Do you think that deep network is better than a shallow one?,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. That causes the number of parameters to increase a lot.There are quite conclusive results that a deep network can fit functions better with less parameters than a shallow network.","the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.",0
Explain Data Normalization.,deep network you have lots and lots of computational nodes and lots of layers of those nodes. Shallow means that number of hidden layer = 1 .,an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,0
Do you think that deep network is better than a shallow one?,"deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,",Shallow means that number of hidden layer = 1 . And in case of deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . So generally as we increase the depth of the model we increase the power of the model at the cost of the computational complexity .,1
Do you think that deep network is better than a shallow one?,"deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,",Hidden Layers: Layers of nodes between the input and output layers. There may be one or more of these layers.,0
what do you know about hidden layer?,Shallow means that number of hidden layer = 1 . And in case of deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . So generally as we increase the depth of the model we increase the power of the model at the cost of the computational complexity .,"Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.",0
Do you think that deep network is better than a shallow one?,"deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,",deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,1
Do you think that deep network is better than a shallow one?,"deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,","A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.",0
What is an RNN?,deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,"RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.",0
Do you think that deep network is better than a shallow one?,"deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,","A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.",1
Do you think that deep network is better than a shallow one?,"deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,",The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,0
What is the use of encoder layers in Autoencoders?,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.","This is the part of the network that compresses the input into a latent-space representation, and encodes the input image as a compressed representation in a reduced dimension.",0
Do you think that deep network is better than a shallow one?,"deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,",deep network you have lots and lots of computational nodes and lots of layers of those nodes. Shallow means that number of hidden layer = 1 .,1
Do you think that deep network is better than a shallow one?,"deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,",The input layer contains input neurons which send information to the hidden layer.,0
what do you know about input layer?,deep network you have lots and lots of computational nodes and lots of layers of those nodes. Shallow means that number of hidden layer = 1 .,"Input Layer: Input variables, contains your raw data.",0
Do you think that deep network is better than a shallow one?,Shallow means that number of hidden layer = 1 . And in case of deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . So generally as we increase the depth of the model we increase the power of the model at the cost of the computational complexity .,deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,1
Do you think that deep network is better than a shallow one?,Shallow means that number of hidden layer = 1 . And in case of deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . So generally as we increase the depth of the model we increase the power of the model at the cost of the computational complexity .,Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,0
What do you understand by Perceptron?,deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,0
Do you think that deep network is better than a shallow one?,Shallow means that number of hidden layer = 1 . And in case of deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . So generally as we increase the depth of the model we increase the power of the model at the cost of the computational complexity .,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.",1
Do you think that deep network is better than a shallow one?,Shallow means that number of hidden layer = 1 . And in case of deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . So generally as we increase the depth of the model we increase the power of the model at the cost of the computational complexity .,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.",0
What is a Swish function?,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.","Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.",0
Do you think that deep network is better than a shallow one?,Shallow means that number of hidden layer = 1 . And in case of deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . So generally as we increase the depth of the model we increase the power of the model at the cost of the computational complexity .,deep network you have lots and lots of computational nodes and lots of layers of those nodes. Shallow means that number of hidden layer = 1 .,1
Do you think that deep network is better than a shallow one?,Shallow means that number of hidden layer = 1 . And in case of deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . So generally as we increase the depth of the model we increase the power of the model at the cost of the computational complexity .,Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,0
What do you understand by Deep Autoencoders?,deep network you have lots and lots of computational nodes and lots of layers of those nodes. Shallow means that number of hidden layer = 1 .,"Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",0
Do you think that deep network is better than a shallow one?,deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.",1
Do you think that deep network is better than a shallow one?,deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,0
What is deep learning?,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.","Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.",0
Do you think that deep network is better than a shallow one?,deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,deep network you have lots and lots of computational nodes and lots of layers of those nodes. Shallow means that number of hidden layer = 1 .,1
Do you think that deep network is better than a shallow one?,deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,0
What is the use of leaky ReLU function?,deep network you have lots and lots of computational nodes and lots of layers of those nodes. Shallow means that number of hidden layer = 1 .,the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,0
Do you think that deep network is better than a shallow one?,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.",deep network you have lots and lots of computational nodes and lots of layers of those nodes. Shallow means that number of hidden layer = 1 .,1
Do you think that deep network is better than a shallow one?,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.","will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]",0
Explain the layer of CNN: pooling,deep network you have lots and lots of computational nodes and lots of layers of those nodes. Shallow means that number of hidden layer = 1 .,"while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.",0
"What do you mean by ""overfitting""?",Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.,Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,1
"What do you mean by ""overfitting""?",Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.,"Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.",0
Explain the layer of CNN: Full Collectedness,Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,"layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",0
"What do you mean by ""overfitting""?",Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.,Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,1
"What do you mean by ""overfitting""?",Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.,"The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1]",0
What is the softmax function?,Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,"The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.",0
"What do you mean by ""overfitting""?",Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.,"Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.",1
"What do you mean by ""overfitting""?",Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.,"a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",0
What is the use of leaky ReLU function?,"Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.",the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,0
"What do you mean by ""overfitting""?",Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.,"Overfitting refers to a model that models the training data too well, where a statistical model begins to describe the random error.",1
"What do you mean by ""overfitting""?",Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.,"When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.",0
What is the function of the Fourier Transform in Deep Learning?,"Overfitting refers to a model that models the training data too well, where a statistical model begins to describe the random error.","data can be considered a signal, and making convolution easier.",0
"What do you mean by ""overfitting""?",Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.,"Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.",1
"What do you mean by ""overfitting""?",Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.,It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,0
What is the cost function?,"Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.",the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,0
"What do you mean by ""overfitting""?",Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.,occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,1
"What do you mean by ""overfitting""?",Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.,"As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.",0
what is a single percepton?,occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,0
"What do you mean by ""overfitting""?",Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,1
"What do you mean by ""overfitting""?",Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,"Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,",0
What is the function of the Fourier Transform in Deep Learning?,Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,"data can be considered a signal, and making convolution easier.",0
"What do you mean by ""overfitting""?",Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,"Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.",1
"What do you mean by ""overfitting""?",Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,"Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.",0
What are the disadvantages of deep learning?,"Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.",Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,0
"What do you mean by ""overfitting""?",Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,"Overfitting refers to a model that models the training data too well, where a statistical model begins to describe the random error.",1
"What do you mean by ""overfitting""?",Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,multiplies arrays A and B of same dimension by multiplying corresponding elements.,0
What is matrix element-wise multiplication?,"Overfitting refers to a model that models the training data too well, where a statistical model begins to describe the random error.",multiplies arrays A and B of same dimension to produce a new matrix.,0
"What do you mean by ""overfitting""?",Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,"Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.",1
"What do you mean by ""overfitting""?",Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,This is a type of gradient descent which update the parameters on each example.,0
Explain the following variant of Gradient Descent Stochastic?,"Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.","Instead of going through all examples, the gradient based on a single training sample.",0
"What do you mean by ""overfitting""?",Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,1
"What do you mean by ""overfitting""?",Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,"A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",0
What do you understand by Perceptron?,occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,0
"What do you mean by ""overfitting""?",Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,"Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.",1
"What do you mean by ""overfitting""?",Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,0
Explain the following variant of Gradient Descent batch?,"Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.","Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",0
"What do you mean by ""overfitting""?",Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,"Overfitting refers to a model that models the training data too well, where a statistical model begins to describe the random error.",1
"What do you mean by ""overfitting""?",Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,0
What do you understand by Autoencoder?,"Overfitting refers to a model that models the training data too well, where a statistical model begins to describe the random error.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.",0
"What do you mean by ""overfitting""?",Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,"Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.",1
"What do you mean by ""overfitting""?",Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,0
What are the disadvantages of deep learning?,"Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.","Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.",0
"What do you mean by ""overfitting""?",Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,1
"What do you mean by ""overfitting""?",Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,"A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",0
What do you understand by Perceptron?,occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,Perceptron is a machine learning algorithm that helps provide classified outcomes. This algorithm enables neurons to learn and processes elements in the training set one at a time.,0
"What do you mean by ""overfitting""?","Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.","Overfitting refers to a model that models the training data too well, where a statistical model begins to describe the random error.",1
"What do you mean by ""overfitting""?","Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.",Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,0
What is matrix element-wise multiplication?,"Overfitting refers to a model that models the training data too well, where a statistical model begins to describe the random error.","takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.",0
"What do you mean by ""overfitting""?","Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.","Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.",1
"What do you mean by ""overfitting""?","Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
"What do you mean by ""overfitting""?","Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.",occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,1
"What do you mean by ""overfitting""?","Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.",RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,0
What is an RNN?,occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,"RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.",0
"What do you mean by ""overfitting""?","Overfitting refers to a model that models the training data too well, where a statistical model begins to describe the random error.","Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.",1
"What do you mean by ""overfitting""?","Overfitting refers to a model that models the training data too well, where a statistical model begins to describe the random error.",The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,0
What is the use of encoder layers in Autoencoders?,"Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.",This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,0
"What do you mean by ""overfitting""?","Overfitting refers to a model that models the training data too well, where a statistical model begins to describe the random error.",occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,1
"What do you mean by ""overfitting""?","Overfitting refers to a model that models the training data too well, where a statistical model begins to describe the random error.",Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,0
"What do you mean by ""overfitting""?","Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.",occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,1
"What do you mean by ""overfitting""?","Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.","A tensor is a generalization of vectors and matrices, In short, a single-dimensional tensor can be represented as a vector.",0
What do you understand by Tensors?,occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,"Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.",0
What is Backpropagation?,Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,Backpropagation is a process used to adjust the weights of a deep neural network. It reduces the loss between the predicted values and the actual values.,1
What is Backpropagation?,Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,The Rectified Linear Unit is the most commonly used activation function in deep learning models. An output is equal to zero when the input value is negative and the input value when the input is positive.,0
What is ReLU function?,Backpropagation is a process used to adjust the weights of a deep neural network. It reduces the loss between the predicted values and the actual values.,"the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.",0
What is Backpropagation?,Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem.,1
What is Backpropagation?,Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,"AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?",The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem.,"AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems",0
What is Backpropagation?,Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,"Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.",1
What is Backpropagation?,Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,has the same structure of a single layer perceptron with one or more hidden layers.,0
what is a multilayer percepton?,"Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.","A multilayer perceptron is a neural network connecting multiple layers in a directed graph, It is substantially formed from multiple layers of perceptron.",0
What is Backpropagation?,Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,Backpropagation is a process used to adjust the weights of a deep neural network. The weights that minimize the error,1
What is Backpropagation?,Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.",0
Explain the importance of LSTM.,Backpropagation is a process used to adjust the weights of a deep neural network. The weights that minimize the error,LSTMs have property of selectively remembering information to be used in the current neural network.,0
What is Backpropagation?,Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,"The Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent, looks for the minimum value of the error.",1
What is Backpropagation?,Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.,0
"What do you mean by ""overfitting""?","The Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent, looks for the minimum value of the error.","Overfitting refers to a model that models the training data too well, where a statistical model begins to describe the random error.",0
What is Backpropagation?,Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,"the method calculates the gradient of the error function with respect to the neural network's weights, It reduces the loss between the predicted values and the actual values.",1
What is Backpropagation?,Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,"tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.",0
What is Tanh function?,"the method calculates the gradient of the error function with respect to the neural network's weights, It reduces the loss between the predicted values and the actual values.",Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,0
What is Backpropagation?,Backpropagation is a process used to adjust the weights of a deep neural network. It reduces the loss between the predicted values and the actual values.,The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem. ,1
What is Backpropagation?,Backpropagation is a process used to adjust the weights of a deep neural network. It reduces the loss between the predicted values and the actual values.,the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,0
What is the use of the Activation function?,The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem. ,most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,0
What is Backpropagation?,Backpropagation is a process used to adjust the weights of a deep neural network. It reduces the loss between the predicted values and the actual values.,"Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.",1
What is Backpropagation?,Backpropagation is a process used to adjust the weights of a deep neural network. It reduces the loss between the predicted values and the actual values.,Initializing all the weights with zeros leads the neurons to learn the same features during training.,0
Why is zero initialization not a good weight initialization process?,"Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.","in this case, the equations of the learning algorithm would fail to make any changes to the network weights, and the model will be stuck.",0
What is Backpropagation?,Backpropagation is a process used to adjust the weights of a deep neural network. It reduces the loss between the predicted values and the actual values.,Backpropagation is a process used to adjust the weights of a deep neural network. The weights that minimize the error,1
What is Backpropagation?,Backpropagation is a process used to adjust the weights of a deep neural network. It reduces the loss between the predicted values and the actual values.,"The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.",0
What is the softmax function?,Backpropagation is a process used to adjust the weights of a deep neural network. The weights that minimize the error,"The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",0
What is Backpropagation?,Backpropagation is a process used to adjust the weights of a deep neural network. It reduces the loss between the predicted values and the actual values.,"The Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent, looks for the minimum value of the error.",1
What is Backpropagation?,Backpropagation is a process used to adjust the weights of a deep neural network. It reduces the loss between the predicted values and the actual values.,"A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.",0
What do you understand by a convolutional neural network?,"The Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent, looks for the minimum value of the error.",A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data.,0
What is Backpropagation?,Backpropagation is a process used to adjust the weights of a deep neural network. It reduces the loss between the predicted values and the actual values.,"the method calculates the gradient of the error function with respect to the neural network's weights, It reduces the loss between the predicted values and the actual values.",1
What is Backpropagation?,Backpropagation is a process used to adjust the weights of a deep neural network. It reduces the loss between the predicted values and the actual values.,the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,0
What is the use of leaky ReLU function?,"the method calculates the gradient of the error function with respect to the neural network's weights, It reduces the loss between the predicted values and the actual values.","the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",0
What is Backpropagation?,The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem. ,"Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.",1
What is Backpropagation?,The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem. ,"If all the weights are initialized with 0, leads the neurons to learn the same features during training.",0
Why is zero initialization not a good weight initialization process?,"Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.","Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.",0
What is Backpropagation?,The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem. ,Backpropagation is a process used to adjust the weights of a deep neural network. The weights that minimize the error,1
What is Backpropagation?,The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem. ,"The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.",0
What is Tanh function?,Backpropagation is a process used to adjust the weights of a deep neural network. The weights that minimize the error,"The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.",0
What is Backpropagation?,The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem.,"The Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent, looks for the minimum value of the error.",1
What is Backpropagation?,The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem.,"tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.",0
What is Tanh function?,"The Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent, looks for the minimum value of the error.","The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.",0
What is Backpropagation?,The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem. ,"the method calculates the gradient of the error function with respect to the neural network's weights, It reduces the loss between the predicted values and the actual values.",1
What is Backpropagation?,The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem. ,"Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).",0
What is the use of leaky ReLU function?,"the method calculates the gradient of the error function with respect to the neural network's weights, It reduces the loss between the predicted values and the actual values.","Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",0
What is Backpropagation?,"Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.",Backpropagation is a process used to adjust the weights of a deep neural network. The weights that minimize the error,1
What is Backpropagation?,"Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.",Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,0
"What do you mean by ""overfitting""?",Backpropagation is a process used to adjust the weights of a deep neural network. The weights that minimize the error,"Overfitting refers to a model that models the training data too well, where a statistical model begins to describe the random error.",0
What is Backpropagation?,"Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.","The Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent, looks for the minimum value of the error.",1
What is Backpropagation?,"Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.","if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations",0
What is the meaning of term weight initialization in neural networks?,"The Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent, looks for the minimum value of the error.","In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.",0
What is Backpropagation?,"Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.","the method calculates the gradient of the error function with respect to the neural network's weights, It reduces the loss between the predicted values and the actual values.",1
What is Backpropagation?,"Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.","Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.",0
What is the function of the Fourier Transform in Deep Learning?,"the method calculates the gradient of the error function with respect to the neural network's weights, It reduces the loss between the predicted values and the actual values.",Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,0
What is Backpropagation?,Backpropagation is a process used to adjust the weights of a deep neural network. The weights that minimize the error,"The Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent, looks for the minimum value of the error.",1
What is Backpropagation?,Backpropagation is a process used to adjust the weights of a deep neural network. The weights that minimize the error,"Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","The Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent, looks for the minimum value of the error.","AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems",0
What is Backpropagation?,Backpropagation is a process used to adjust the weights of a deep neural network. The weights that minimize the error,"the method calculates the gradient of the error function with respect to the neural network's weights, It reduces the loss between the predicted values and the actual values.",1
What is Backpropagation?,Backpropagation is a process used to adjust the weights of a deep neural network. The weights that minimize the error,The data is made available at the output layer.,0
what do you know about output layer?,"the method calculates the gradient of the error function with respect to the neural network's weights, It reduces the loss between the predicted values and the actual values.",The data is made available the output variables.,0
What is Backpropagation?,"The Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent, looks for the minimum value of the error.","the method calculates the gradient of the error function with respect to the neural network's weights, It reduces the loss between the predicted values and the actual values.",1
What is Backpropagation?,"The Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent, looks for the minimum value of the error.","initializing weights with too-small values will lead to divergence, too-large values will lead to exploding.",0
What is the meaning of term weight initialization in neural networks?,"the method calculates the gradient of the error function with respect to the neural network's weights, It reduces the loss between the predicted values and the actual values.","In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.",0
What is the function of the Fourier Transform in Deep Learning?,"Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.","Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,",1
What is the function of the Fourier Transform in Deep Learning?,"Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.",We combine corresponding values in an elementwise fashion to produce a new matrix.,0
What is matrix element-wise multiplication?,"Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,",multiplies arrays A and B of same dimension by multiplying corresponding elements.,0
What is the function of the Fourier Transform in Deep Learning?,"Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.","When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.",1
What is the function of the Fourier Transform in Deep Learning?,"Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.","LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.",0
Explain the importance of LSTM.,"When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.","LSTM use persistent previous information to classifying, processing and making predictions based on time series data",0
What is the function of the Fourier Transform in Deep Learning?,"Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.","processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.",1
What is the function of the Fourier Transform in Deep Learning?,"Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.","By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.",0
Explain Data Normalization.,"processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.","By normalizing all of our inputs to a standard scale, without distorting differences in the ranges of values.",0
What is the function of the Fourier Transform in Deep Learning?,"Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.",Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,1
What is the function of the Fourier Transform in Deep Learning?,"Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.",Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,0
Explain Data Normalization.,Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,"change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",0
What is the function of the Fourier Transform in Deep Learning?,"Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.","data can be considered a signal, and making convolution easier.",1
What is the function of the Fourier Transform in Deep Learning?,"Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.","tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.",0
What is Tanh function?,"data can be considered a signal, and making convolution easier.",Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,0
What is the function of the Fourier Transform in Deep Learning?,"Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.","processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",1
What is the function of the Fourier Transform in Deep Learning?,"Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.","The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.",0
What is the softmax function?,"processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.","The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",0
What is the function of the Fourier Transform in Deep Learning?,"Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,","When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.",1
What is the function of the Fourier Transform in Deep Learning?,"Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,","The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.",0
What do you mean by Dropout?,"When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.",Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,0
What is the function of the Fourier Transform in Deep Learning?,"Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,","processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.",1
What is the function of the Fourier Transform in Deep Learning?,"Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,","A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. That causes the number of parameters to increase a lot.There are quite conclusive results that a deep network can fit functions better with less parameters than a shallow network.",0
Do you think that deep network is better than a shallow one?,"processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.","deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,",0
What is the function of the Fourier Transform in Deep Learning?,"Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,",Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,1
What is the function of the Fourier Transform in Deep Learning?,"Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,",This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,0
What is the use of encoder layers in Autoencoders?,Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,"An encoder is a feedforward, fully connected neural network that compresses the input and encodes the input image, The compressed image is the distorted version of the original image.",0
What is the function of the Fourier Transform in Deep Learning?,"Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,","data can be considered a signal, and making convolution easier.",1
What is the function of the Fourier Transform in Deep Learning?,"Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,",most important feature in an activation function is its ability to add non-linearity into a neural network.,0
What is the use of the Activation function?,"data can be considered a signal, and making convolution easier.",the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,0
What is the function of the Fourier Transform in Deep Learning?,"Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,","processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",1
What is the function of the Fourier Transform in Deep Learning?,"Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,",The input layer contains input neurons which send information to the hidden layer.,0
what do you know about input layer?,"processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.","The input layer contains input neurons, sometimes called the visible layer.",0
What is the function of the Fourier Transform in Deep Learning?,"When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.","processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.",1
What is the function of the Fourier Transform in Deep Learning?,"When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.","A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.",0
What do you understand by Boltzmann Machine?,"processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.",Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,0
What is the function of the Fourier Transform in Deep Learning?,"When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.",Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,1
What is the function of the Fourier Transform in Deep Learning?,"When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.","In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
Differentiate supervised and unsupervised deep learning procedures.,Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,"supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",0
What is the function of the Fourier Transform in Deep Learning?,"When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.","data can be considered a signal, and making convolution easier.",1
What is the function of the Fourier Transform in Deep Learning?,"When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.",The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,0
What is the use of decoder layers in Autoencoders?,"data can be considered a signal, and making convolution easier.",This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,0
What is the function of the Fourier Transform in Deep Learning?,"When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.","processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",1
What is the function of the Fourier Transform in Deep Learning?,"When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.","Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.",0
What are the disadvantages of deep learning?,"processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,0
What is the function of the Fourier Transform in Deep Learning?,"processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.",Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,1
What is the function of the Fourier Transform in Deep Learning?,"processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.",Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,0
Explain the following variant of Gradient Descent Stochastic?,Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,"Instead of going through all examples, Stochastic Gradient Descent (SGD) performs the parameters update on each example.",0
What is the function of the Fourier Transform in Deep Learning?,"processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.","data can be considered a signal, and making convolution easier.",1
What is the function of the Fourier Transform in Deep Learning?,"processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.",Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,0
Explain gradient descent?,"data can be considered a signal, and making convolution easier.","Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",0
What is the function of the Fourier Transform in Deep Learning?,"processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.","processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",1
What is the function of the Fourier Transform in Deep Learning?,"processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.",The code layer is used to represent the compressed input which is fed to the decoder.,0
What is the use of code layers in Autoencoders?,"processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",This part of the network contains the reduced representation after encoding the input image.,0
What is the function of the Fourier Transform in Deep Learning?,Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,"data can be considered a signal, and making convolution easier.",1
What is the function of the Fourier Transform in Deep Learning?,Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,"The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.",0
What is Tanh function?,"data can be considered a signal, and making convolution easier.","tanh produces output ranges from -1 and 1, and used as activation function.",0
What is the function of the Fourier Transform in Deep Learning?,Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,"processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",1
What is the function of the Fourier Transform in Deep Learning?,Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,This part of the network contains the reduced representation of the input that is fed into the decoder.,0
What is the use of code layers in Autoencoders?,"processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",This part of the network represents the input that is fed into the decoder.,0
What is the function of the Fourier Transform in Deep Learning?,"data can be considered a signal, and making convolution easier.","processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",1
What is the function of the Fourier Transform in Deep Learning?,"data can be considered a signal, and making convolution easier.",The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,0
what do you know about input layer?,"processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.","Input Layer: Input variables, sometimes called the visible layer.",0
What are the disadvantages of deep learning?,"Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.",It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,1
What are the disadvantages of deep learning?,"Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.","Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data.",0
What is deep learning?,It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,"Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.",0
What are the disadvantages of deep learning?,"Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.",Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,1
What are the disadvantages of deep learning?,"Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.",the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,0
What is the use of leaky ReLU function?,Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,"Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",0
What are the disadvantages of deep learning?,"Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.","Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.",1
What are the disadvantages of deep learning?,"Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.","Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",0
Explain gradient descent?,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.",Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,0
What are the disadvantages of deep learning?,"Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.",It requires very large amount of data in order to perform better than other techniques. Is extremely computationally expensive to train.,1
What are the disadvantages of deep learning?,"Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.","if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations",0
What is the meaning of term weight initialization in neural networks?,It requires very large amount of data in order to perform better than other techniques. Is extremely computationally expensive to train.,"In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.",0
What are the disadvantages of deep learning?,"Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.",Requires a large amount of data. neural networks are also more computationally expensive can take several weeks to train completely from scratch.,1
What are the disadvantages of deep learning?,"Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.",The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,0
What is Model Capacity?,Requires a large amount of data. neural networks are also more computationally expensive can take several weeks to train completely from scratch.,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",0
What are the disadvantages of deep learning?,"Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.","Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.",1
What are the disadvantages of deep learning?,"Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.",This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,0
What is the use of encoder layers in Autoencoders?,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.",The encoder layer encodes the input image as a compressed representation in a reduced dimension. The compressed image is the distorted version of the original image.,0
What are the disadvantages of deep learning?,It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,1
What are the disadvantages of deep learning?,It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,"Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.",0
What is deep learning?,Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,"Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.",0
What are the disadvantages of deep learning?,It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.",1
What are the disadvantages of deep learning?,It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,"Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.",0
Explain the layer of CNN: Full Collectedness,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.",aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,0
What are the disadvantages of deep learning?,It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,It requires very large amount of data in order to perform better than other techniques. Is extremely computationally expensive to train.,1
What are the disadvantages of deep learning?,It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.",0
What do you understand by Boltzmann Machine?,It requires very large amount of data in order to perform better than other techniques. Is extremely computationally expensive to train.,The main purpose of Boltzmann Machine is to optimize the solution of a problem. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,0
What are the disadvantages of deep learning?,It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,Requires a large amount of data. neural networks are also more computationally expensive can take several weeks to train completely from scratch.,1
What are the disadvantages of deep learning?,It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,0
Explain the following variant of Gradient Descent batch?,Requires a large amount of data. neural networks are also more computationally expensive can take several weeks to train completely from scratch.,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",0
What are the disadvantages of deep learning?,It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.",1
What are the disadvantages of deep learning?,It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery",0
What do you understand by a convolutional neural network?,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.","A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.",0
What are the disadvantages of deep learning?,Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.",1
What are the disadvantages of deep learning?,Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,"Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.",0
What is the function of the Fourier Transform in Deep Learning?,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.",Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,0
What are the disadvantages of deep learning?,Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,It requires very large amount of data in order to perform better than other techniques. Is extremely computationally expensive to train.,1
What are the disadvantages of deep learning?,Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples.Here b examples where b<m are processed per iteration.",0
Explain the following variant of Gradient Descent mini-batch?,It requires very large amount of data in order to perform better than other techniques. Is extremely computationally expensive to train.,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.",0
What are the disadvantages of deep learning?,Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,Requires a large amount of data. neural networks are also more computationally expensive can take several weeks to train completely from scratch.,1
What are the disadvantages of deep learning?,Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,"A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.",0
What do you understand by a convolutional neural network?,Requires a large amount of data. neural networks are also more computationally expensive can take several weeks to train completely from scratch.,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.",0
What are the disadvantages of deep learning?,Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.",1
What are the disadvantages of deep learning?,Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,"With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.",0
What do you mean by Dropout?,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.","The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.",0
What are the disadvantages of deep learning?,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.",It requires very large amount of data in order to perform better than other techniques. Is extremely computationally expensive to train.,1
What are the disadvantages of deep learning?,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.",A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,0
What do you understand by Tensors?,It requires very large amount of data in order to perform better than other techniques. Is extremely computationally expensive to train.,"Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.",0
What are the disadvantages of deep learning?,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.",Requires a large amount of data. neural networks are also more computationally expensive can take several weeks to train completely from scratch.,1
What are the disadvantages of deep learning?,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.",Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,0
Explain Data Normalization.,Requires a large amount of data. neural networks are also more computationally expensive can take several weeks to train completely from scratch.,"change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",0
What are the disadvantages of deep learning?,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.","Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.",1
What are the disadvantages of deep learning?,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.","Using the Gradient Decent optimization algorithm, the weights are updated incrementally after each iteration over the training dataset.",0
Explain the following variant of Gradient Descent batch?,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.","Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.",0
What are the disadvantages of deep learning?,It requires very large amount of data in order to perform better than other techniques. Is extremely computationally expensive to train.,Requires a large amount of data. neural networks are also more computationally expensive can take several weeks to train completely from scratch.,1
What are the disadvantages of deep learning?,It requires very large amount of data in order to perform better than other techniques. Is extremely computationally expensive to train.,Single layer perceptrons can learn only linearly separable patterns.,0
what is a single percepton?,Requires a large amount of data. neural networks are also more computationally expensive can take several weeks to train completely from scratch.,A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,0
What are the disadvantages of deep learning?,It requires very large amount of data in order to perform better than other techniques. Is extremely computationally expensive to train.,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.",1
What are the disadvantages of deep learning?,It requires very large amount of data in order to perform better than other techniques. Is extremely computationally expensive to train.,This part of the network contains the reduced representation after encoding the input image.,0
What is the use of code layers in Autoencoders?,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.","produced after encoding the input image, represents the compressed input.",0
What are the disadvantages of deep learning?,Requires a large amount of data. neural networks are also more computationally expensive can take several weeks to train completely from scratch.,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.",1
What are the disadvantages of deep learning?,Requires a large amount of data. neural networks are also more computationally expensive can take several weeks to train completely from scratch.,Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,0
What is matrix element-wise multiplication?,"Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.","We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.",0
What is the meaning of term weight initialization in neural networks?,"n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.",The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,1
What is the meaning of term weight initialization in neural networks?,"n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.","the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.",0
Explain the following variant of Gradient Descent Stochastic?,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,"the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration",0
What is the meaning of term weight initialization in neural networks?,"n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.",initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,1
What is the meaning of term weight initialization in neural networks?,"n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.",RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,0
What is an RNN?,initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,"A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.",0
What is the meaning of term weight initialization in neural networks?,"n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.","In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations",1
What is the meaning of term weight initialization in neural networks?,"n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.","It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.",0
Explain the importance of LSTM.,"In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations",LSTM use persistent previous information to be used in the current neural network.,0
What is the meaning of term weight initialization in neural networks?,"n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.","initializing weights with too-small values will lead to divergence, too-large values will lead to exploding.",1
What is the meaning of term weight initialization in neural networks?,"n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.",This is a type of gradient descent which processes 1 training example per iteration,0
Explain the following variant of Gradient Descent Stochastic?,"initializing weights with too-small values will lead to divergence, too-large values will lead to exploding.","Instead of going through all examples, Stochastic Gradient Descent (SGD) performs the parameters update on each example.",0
What is the meaning of term weight initialization in neural networks?,"n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.","if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations",1
What is the meaning of term weight initialization in neural networks?,"n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.",The code layer is used to represent the compressed input which is fed to the decoder.,0
What is the use of code layers in Autoencoders?,"if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations","produced after encoding the input image, represents the compressed input.",0
What is the meaning of term weight initialization in neural networks?,"n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.","In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.",1
What is the meaning of term weight initialization in neural networks?,"n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.",a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,0
Explain the layer of CNN: ReLU,"In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.","Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.",0
What is the meaning of term weight initialization in neural networks?,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,1
What is the meaning of term weight initialization in neural networks?,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,0
What do you understand by Perceptron?,initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,"A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",0
What is the meaning of term weight initialization in neural networks?,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,"In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations",1
What is the meaning of term weight initialization in neural networks?,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.",0
Explain the following variant of Gradient Descent mini-batch?,"In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations","Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples.Here b examples where b<m are processed per iteration.",0
What is the meaning of term weight initialization in neural networks?,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,"initializing weights with too-small values will lead to divergence, too-large values will lead to exploding.",1
What is the meaning of term weight initialization in neural networks?,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,0
Explain the layer of CNN: convolution,"initializing weights with too-small values will lead to divergence, too-large values will lead to exploding.",The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,0
What is the meaning of term weight initialization in neural networks?,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,"if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations",1
What is the meaning of term weight initialization in neural networks?,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,0
what is a multilayer percepton?,"if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations",Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,0
What is the meaning of term weight initialization in neural networks?,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,"In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.",1
What is the meaning of term weight initialization in neural networks?,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,"The softmax function is used to calculate the probability distribution of the event over 'n' different events, the output range will be between 0 to 1, and the sum of all the probabilities will be equal to one.",0
What is the softmax function?,"In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.","The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",0
What is the meaning of term weight initialization in neural networks?,initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,"In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations",1
What is the meaning of term weight initialization in neural networks?,initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,is one of the most common activation function in neural networks. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,0
What is a binary step function?,"In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations","can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",0
What is the meaning of term weight initialization in neural networks?,initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,"initializing weights with too-small values will lead to divergence, too-large values will lead to exploding.",1
What is the meaning of term weight initialization in neural networks?,initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,"while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.",0
Explain the layer of CNN: pooling,"initializing weights with too-small values will lead to divergence, too-large values will lead to exploding.","pooling or downsampling layer is responsible for reducing the spatial dimensions (width, height), resulting in volume such as [16x16x12].",0
What is the meaning of term weight initialization in neural networks?,initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,"if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations",1
What is the meaning of term weight initialization in neural networks?,initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,"Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.",0
Do you think that deep network is better than a shallow one?,"if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations","deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,",0
What is the meaning of term weight initialization in neural networks?,initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,"In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.",1
What is the meaning of term weight initialization in neural networks?,initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,"The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.",0
What is the meaning of term weight initialization in neural networks?,"In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations","initializing weights with too-small values will lead to divergence, too-large values will lead to exploding.",1
What is the meaning of term weight initialization in neural networks?,"In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations",It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,0
What are the disadvantages of deep learning?,"initializing weights with too-small values will lead to divergence, too-large values will lead to exploding.","Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.",0
What is the meaning of term weight initialization in neural networks?,"In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations","if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations",1
What is the meaning of term weight initialization in neural networks?,"In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations",Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. This network is responsible for reconstructing the input back to the original dimensions from the code.,0
What is the use of decoder layers in Autoencoders?,"if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations","This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network",0
What is the meaning of term weight initialization in neural networks?,"In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations","In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.",1
What is the meaning of term weight initialization in neural networks?,"In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations",The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,0
What is the use of encoder layers in Autoencoders?,"In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.","An encoder is a feedforward, fully connected neural network that compresses the input and encodes the input image, The compressed image is the distorted version of the original image.",0
What is the meaning of term weight initialization in neural networks?,"initializing weights with too-small values will lead to divergence, too-large values will lead to exploding.","if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations",1
What is the meaning of term weight initialization in neural networks?,"initializing weights with too-small values will lead to divergence, too-large values will lead to exploding.","can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",0
What is a binary step function?,"if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations","A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",0
What is the meaning of term weight initialization in neural networks?,"initializing weights with too-small values will lead to divergence, too-large values will lead to exploding.","In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.",1
What is the meaning of term weight initialization in neural networks?,"initializing weights with too-small values will lead to divergence, too-large values will lead to exploding.","Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.",0
Explain the layer of CNN: Full Collectedness,"In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.",aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,0
What is the meaning of term weight initialization in neural networks?,"if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations","In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.",1
What is the meaning of term weight initialization in neural networks?,"if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations",This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,0
What is the use of decoder layers in Autoencoders?,"In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.",Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,0
Explain Data Normalization.,"Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.","the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.",1
Explain Data Normalization.,"Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.",Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,0
What do you understand by Autoencoder?,"the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.",0
Explain Data Normalization.,"Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.",Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,1
Explain Data Normalization.,"Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.","A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.",0
What is an RNN?,Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,"RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.",0
Explain Data Normalization.,"Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.","By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.",1
Explain Data Normalization.,"Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.",supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,0
Differentiate supervised and unsupervised deep learning procedures.,"By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.","supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",0
Explain Data Normalization.,"Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.","change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",1
Explain Data Normalization.,"Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.",Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,0
Explain the following variant of Gradient Descent Stochastic?,"change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",This is a type of gradient descent which update the parameters on each example.,0
Explain Data Normalization.,"Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.",an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,1
Explain Data Normalization.,"Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.","Softmax turns arbitrary real values into probabilities, which are often useful in Machine Learning. The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",0
What is the softmax function?,an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,"The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.",0
Explain Data Normalization.,"Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.","By normalizing all of our inputs to a standard scale, without distorting differences in the ranges of values.",1
Explain Data Normalization.,"Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","By normalizing all of our inputs to a standard scale, without distorting differences in the ranges of values.","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
Explain Data Normalization.,"the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.",Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,1
Explain Data Normalization.,"the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.","The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.",0
What do you mean by Dropout?,Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,"With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.",0
Explain Data Normalization.,"the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.","By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.",1
Explain Data Normalization.,"the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.",We combine corresponding values in an elementwise fashion to produce a new matrix.,0
What is matrix element-wise multiplication?,"By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.","We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.",0
Explain Data Normalization.,"the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.","change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",1
Explain Data Normalization.,"the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.","A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.",0
What do you understand by a convolutional neural network?,"change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.","convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery",0
Explain Data Normalization.,"the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.",an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,1
Explain Data Normalization.,"the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.","A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.",0
What do you understand by Boltzmann Machine?,an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,The main purpose of Boltzmann Machine is to optimize the solution of a problem. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,0
Explain Data Normalization.,"the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.","By normalizing all of our inputs to a standard scale, without distorting differences in the ranges of values.",1
Explain Data Normalization.,"the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.","As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",0
what is a single percepton?,"By normalizing all of our inputs to a standard scale, without distorting differences in the ranges of values.","As a linear classifier, the simplest type of artificial neural networks.",0
Explain Data Normalization.,Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,"By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.",1
Explain Data Normalization.,Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,"the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.",0
Explain the following variant of Gradient Descent Stochastic?,"By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.",This is a type of gradient descent which update the parameters on each example.,0
Explain Data Normalization.,Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,"change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",1
Explain Data Normalization.,Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,"It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.",0
Explain the importance of LSTM.,"change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.","LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.",0
Explain Data Normalization.,Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,1
Explain Data Normalization.,Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,"can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",0
What is a binary step function?,an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,"is one of the most common activation function in neural networks. if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",0
Explain Data Normalization.,Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,"By normalizing all of our inputs to a standard scale, without distorting differences in the ranges of values.",1
Explain Data Normalization.,Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,"In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
Differentiate supervised and unsupervised deep learning procedures.,"By normalizing all of our inputs to a standard scale, without distorting differences in the ranges of values.",supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,0
Explain Data Normalization.,"By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.","change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",1
Explain Data Normalization.,"By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.",a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,0
Explain the layer of CNN: ReLU,"change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.","Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.",0
Explain Data Normalization.,"By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.",an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,1
Explain Data Normalization.,"By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.",The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,0
What is the use of leaky ReLU function?,an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,"Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",0
Explain Data Normalization.,"By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.","By normalizing all of our inputs to a standard scale, without distorting differences in the ranges of values.",1
Explain Data Normalization.,"By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.","If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.",0
Why is zero initialization not a good weight initialization process?,"By normalizing all of our inputs to a standard scale, without distorting differences in the ranges of values.","If all the weights are initialized with 0, all weights have the same value in subsequent iterations.",0
Explain Data Normalization.,"change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,1
Explain Data Normalization.,"change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem. ,0
What is Backpropagation?,an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,"Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.",0
Explain Data Normalization.,"change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.","By normalizing all of our inputs to a standard scale, without distorting differences in the ranges of values.",1
Explain Data Normalization.,"change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.","As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.",0
what is a single percepton?,"By normalizing all of our inputs to a standard scale, without distorting differences in the ranges of values.","As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",0
Explain Data Normalization.,an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,"By normalizing all of our inputs to a standard scale, without distorting differences in the ranges of values.",1
Explain Data Normalization.,an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Autoencoder?,"By normalizing all of our inputs to a standard scale, without distorting differences in the ranges of values.","Autoencoders are neural networks. Neural networks are composed of multiple layers, and the defining aspect of an autoencoder is that the input layers contain exactly as much information as the output layer.",0
Why is zero initialization not a good weight initialization process?,"If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.","If all the weights are initialized with 0, all weights have the same value in subsequent iterations.",1
Why is zero initialization not a good weight initialization process?,"If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.","The input layer contains input neurons, sometimes called the visible layer.",0
what do you know about input layer?,"If all the weights are initialized with 0, all weights have the same value in subsequent iterations.","Input Layer: Input variables, contains your raw data.",0
Why is zero initialization not a good weight initialization process?,"If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.",Initializing all the weights with zeros leads the neurons to learn the same features during training.,1
Why is zero initialization not a good weight initialization process?,"If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.",The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,0
what do you know about input layer?,Initializing all the weights with zeros leads the neurons to learn the same features during training.,"The input layer contains input neurons, sometimes called the visible layer.",0
Why is zero initialization not a good weight initialization process?,"If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.","in this case, the equations of the learning algorithm would fail to make any changes to the network weights, and the model will be stuck.",1
Why is zero initialization not a good weight initialization process?,"If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.","convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.",0
What do you understand by a convolutional neural network?,"in this case, the equations of the learning algorithm would fail to make any changes to the network weights, and the model will be stuck.","A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.",0
Why is zero initialization not a good weight initialization process?,"If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.","If all the weights are initialized with 0, leads the neurons to learn the same features during training.",1
Why is zero initialization not a good weight initialization process?,"If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.","A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. That causes the number of parameters to increase a lot.There are quite conclusive results that a deep network can fit functions better with less parameters than a shallow network.",0
Do you think that deep network is better than a shallow one?,"If all the weights are initialized with 0, leads the neurons to learn the same features during training.",deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,0
Why is zero initialization not a good weight initialization process?,"If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.","Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.",1
Why is zero initialization not a good weight initialization process?,"If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.","Instead of going through all examples, Stochastic Gradient Descent (SGD) performs the parameters update on each example.",0
Explain the following variant of Gradient Descent Stochastic?,"Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.","the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.",0
Why is zero initialization not a good weight initialization process?,"If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.","in this case, the equations of the learning algorithm would fail, all weights have the same value in subsequent iterations.",1
Why is zero initialization not a good weight initialization process?,"If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.","Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.",0
Explain the layer of CNN: ReLU,"in this case, the equations of the learning algorithm would fail, all weights have the same value in subsequent iterations.","RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.",0
Why is zero initialization not a good weight initialization process?,"If all the weights are initialized with 0, all weights have the same value in subsequent iterations.",Initializing all the weights with zeros leads the neurons to learn the same features during training.,1
Why is zero initialization not a good weight initialization process?,"If all the weights are initialized with 0, all weights have the same value in subsequent iterations.",initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,0
What is the meaning of term weight initialization in neural networks?,Initializing all the weights with zeros leads the neurons to learn the same features during training.,"In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.",0
Why is zero initialization not a good weight initialization process?,"If all the weights are initialized with 0, all weights have the same value in subsequent iterations.","in this case, the equations of the learning algorithm would fail to make any changes to the network weights, and the model will be stuck.",1
Why is zero initialization not a good weight initialization process?,"If all the weights are initialized with 0, all weights have the same value in subsequent iterations.","Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.",0
What do you understand by Tensors?,"in this case, the equations of the learning algorithm would fail to make any changes to the network weights, and the model will be stuck.","A tensor is a generalization of vectors and matrices, In short, a single-dimensional tensor can be represented as a vector.",0
Why is zero initialization not a good weight initialization process?,"If all the weights are initialized with 0, all weights have the same value in subsequent iterations.","If all the weights are initialized with 0, leads the neurons to learn the same features during training.",1
Why is zero initialization not a good weight initialization process?,"If all the weights are initialized with 0, all weights have the same value in subsequent iterations.","layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",0
Explain the layer of CNN: Full Collectedness,"If all the weights are initialized with 0, leads the neurons to learn the same features during training.",aims to map the activation volume from the combination of previous different layers into a class probability distribution.,0
Why is zero initialization not a good weight initialization process?,"If all the weights are initialized with 0, all weights have the same value in subsequent iterations.","Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.",1
Why is zero initialization not a good weight initialization process?,"If all the weights are initialized with 0, all weights have the same value in subsequent iterations.",the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,0
What is the use of leaky ReLU function?,"Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.","the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",0
Why is zero initialization not a good weight initialization process?,"If all the weights are initialized with 0, all weights have the same value in subsequent iterations.","in this case, the equations of the learning algorithm would fail, all weights have the same value in subsequent iterations.",1
Why is zero initialization not a good weight initialization process?,"If all the weights are initialized with 0, all weights have the same value in subsequent iterations.",The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,0
What is the use of the Activation function?,"in this case, the equations of the learning algorithm would fail, all weights have the same value in subsequent iterations.",most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,0
Why is zero initialization not a good weight initialization process?,Initializing all the weights with zeros leads the neurons to learn the same features during training.,"in this case, the equations of the learning algorithm would fail to make any changes to the network weights, and the model will be stuck.",1
Why is zero initialization not a good weight initialization process?,Initializing all the weights with zeros leads the neurons to learn the same features during training.,Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,0
Explain Data Normalization.,"in this case, the equations of the learning algorithm would fail to make any changes to the network weights, and the model will be stuck.","By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.",0
Why is zero initialization not a good weight initialization process?,Initializing all the weights with zeros leads the neurons to learn the same features during training.,"If all the weights are initialized with 0, leads the neurons to learn the same features during training.",1
Why is zero initialization not a good weight initialization process?,Initializing all the weights with zeros leads the neurons to learn the same features during training.,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,0
What do you mean by Dropout?,"If all the weights are initialized with 0, leads the neurons to learn the same features during training.","With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.",0
Why is zero initialization not a good weight initialization process?,Initializing all the weights with zeros leads the neurons to learn the same features during training.,"Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.",1
What do you mean by Dropout?,"Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.","The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.",0
Why is zero initialization not a good weight initialization process?,Initializing all the weights with zeros leads the neurons to learn the same features during training.,"in this case, the equations of the learning algorithm would fail, all weights have the same value in subsequent iterations.",1
Why is zero initialization not a good weight initialization process?,Initializing all the weights with zeros leads the neurons to learn the same features during training.,fully connected neural network structure that drives the final classification decision.,0
Explain the layer of CNN: Full Collectedness,"in this case, the equations of the learning algorithm would fail, all weights have the same value in subsequent iterations.",aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,0
Why is zero initialization not a good weight initialization process?,"in this case, the equations of the learning algorithm would fail to make any changes to the network weights, and the model will be stuck.","If all the weights are initialized with 0, leads the neurons to learn the same features during training.",1
Why is zero initialization not a good weight initialization process?,"in this case, the equations of the learning algorithm would fail to make any changes to the network weights, and the model will be stuck.",The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,0
What is the use of the Activation function?,"If all the weights are initialized with 0, leads the neurons to learn the same features during training.",most important feature in an activation function is its ability to add non-linearity into a neural network.,0
Why is zero initialization not a good weight initialization process?,"in this case, the equations of the learning algorithm would fail to make any changes to the network weights, and the model will be stuck.","Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.",1
Why is zero initialization not a good weight initialization process?,"in this case, the equations of the learning algorithm would fail to make any changes to the network weights, and the model will be stuck.","n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.",0
What is the meaning of term weight initialization in neural networks?,"Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.","In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations",0
Why is zero initialization not a good weight initialization process?,"in this case, the equations of the learning algorithm would fail to make any changes to the network weights, and the model will be stuck.","in this case, the equations of the learning algorithm would fail, all weights have the same value in subsequent iterations.",1
Why is zero initialization not a good weight initialization process?,"in this case, the equations of the learning algorithm would fail to make any changes to the network weights, and the model will be stuck.",It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,0
What are the disadvantages of deep learning?,"in this case, the equations of the learning algorithm would fail, all weights have the same value in subsequent iterations.",Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,0
Why is zero initialization not a good weight initialization process?,"If all the weights are initialized with 0, leads the neurons to learn the same features during training.","Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.",1
Why is zero initialization not a good weight initialization process?,"If all the weights are initialized with 0, leads the neurons to learn the same features during training.",Multilayer perceptrons or feedforward neural networks with two or more layers have the higher processing power.,0
what is a multilayer percepton?,"Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.",has the same structure of a single layer perceptron with one or more hidden layers.,0
Why is zero initialization not a good weight initialization process?,"If all the weights are initialized with 0, leads the neurons to learn the same features during training.","in this case, the equations of the learning algorithm would fail, all weights have the same value in subsequent iterations.",1
Why is zero initialization not a good weight initialization process?,"If all the weights are initialized with 0, leads the neurons to learn the same features during training.","Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.",0
what do you know about hidden layer?,"in this case, the equations of the learning algorithm would fail, all weights have the same value in subsequent iterations.","Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.",0
Why is zero initialization not a good weight initialization process?,"Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.","in this case, the equations of the learning algorithm would fail, all weights have the same value in subsequent iterations.",1
Why is zero initialization not a good weight initialization process?,"Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.","Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.",0
Do you think that deep network is better than a shallow one?,"in this case, the equations of the learning algorithm would fail, all weights have the same value in subsequent iterations.",deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,0
what do you know about input layer?,The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,The input layer contains input neurons which send information to the hidden layer.,1
what do you know about input layer?,The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,"Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data.",0
What is deep learning?,The input layer contains input neurons which send information to the hidden layer.,"Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.",0
what do you know about input layer?,The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,"Input Layer: Input variables, sometimes called the visible layer.",1
what do you know about input layer?,The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,"Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.",0
What is a Swish function?,"Input Layer: Input variables, sometimes called the visible layer.","Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",0
what do you know about input layer?,The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,The input layer is contains your raw data.,1
what do you know about input layer?,The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,0
Explain the layer of CNN: ReLU,The input layer is contains your raw data.,"RELU layer will apply an elementwise activation function, such as the max(0,x) thresholding at zero.",0
what do you know about input layer?,The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,"The input layer contains input neurons, sometimes called the visible layer.",1
what do you know about input layer?,The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery",0
What do you understand by a convolutional neural network?,"The input layer contains input neurons, sometimes called the visible layer.","A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.",0
what do you know about input layer?,The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,"Input Layer: Input variables, contains your raw data.",1
what do you know about input layer?,The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance",0
What is a Swish function?,"Input Layer: Input variables, contains your raw data.","Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",0
what do you know about input layer?,The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,The input layer is contains your raw data. which send information to the hidden layer.,1
what do you know about input layer?,The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,"Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).",0
What is the use of leaky ReLU function?,The input layer is contains your raw data. which send information to the hidden layer.,"the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",0
what do you know about input layer?,The input layer contains input neurons which send information to the hidden layer.,"Input Layer: Input variables, sometimes called the visible layer.",1
what do you know about input layer?,The input layer contains input neurons which send information to the hidden layer.,"RELU layer will apply an elementwise activation function, such as the max(0,x) thresholding at zero.",0
Explain the layer of CNN: ReLU,"Input Layer: Input variables, sometimes called the visible layer.","RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.",0
what do you know about input layer?,The input layer contains input neurons which send information to the hidden layer.,The input layer is contains your raw data.,1
what do you know about input layer?,The input layer contains input neurons which send information to the hidden layer.,the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,0
What is the use of the Activation function?,The input layer is contains your raw data.,The basic purpose of the activation function its ability to add non-linearity into a neural network.,0
what do you know about input layer?,The input layer contains input neurons which send information to the hidden layer.,"The input layer contains input neurons, sometimes called the visible layer.",1
what do you know about input layer?,The input layer contains input neurons which send information to the hidden layer.,"Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.",0
What is the function of the Fourier Transform in Deep Learning?,"The input layer contains input neurons, sometimes called the visible layer.","processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.",0
what do you know about input layer?,The input layer contains input neurons which send information to the hidden layer.,"Input Layer: Input variables, contains your raw data.",1
what do you know about input layer?,The input layer contains input neurons which send information to the hidden layer.,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.",0
What is a Swish function?,"Input Layer: Input variables, contains your raw data.","Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.",0
what do you know about input layer?,The input layer contains input neurons which send information to the hidden layer.,The input layer is contains your raw data. which send information to the hidden layer.,1
what do you know about input layer?,The input layer contains input neurons which send information to the hidden layer.,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. They dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.,0
What do you understand by Boltzmann Machine?,The input layer is contains your raw data. which send information to the hidden layer.,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,0
what do you know about input layer?,"Input Layer: Input variables, sometimes called the visible layer.",The input layer is contains your raw data.,1
what do you know about input layer?,"Input Layer: Input variables, sometimes called the visible layer.","can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",0
What is a binary step function?,The input layer is contains your raw data.,is one of the most common activation function in neural networks. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,0
what do you know about input layer?,"Input Layer: Input variables, sometimes called the visible layer.","The input layer contains input neurons, sometimes called the visible layer.",1
what do you know about input layer?,"Input Layer: Input variables, sometimes called the visible layer.","A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.",0
What do you understand by Boltzmann Machine?,"The input layer contains input neurons, sometimes called the visible layer.",Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,0
what do you know about input layer?,"Input Layer: Input variables, sometimes called the visible layer.","Input Layer: Input variables, contains your raw data.",1
what do you know about input layer?,"Input Layer: Input variables, sometimes called the visible layer.","The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.",0
What do you mean by Dropout?,"Input Layer: Input variables, contains your raw data.","With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.",0
what do you know about input layer?,"Input Layer: Input variables, sometimes called the visible layer.",The input layer is contains your raw data. which send information to the hidden layer.,1
what do you know about input layer?,"Input Layer: Input variables, sometimes called the visible layer.","Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.",0
Do you think that deep network is better than a shallow one?,The input layer is contains your raw data. which send information to the hidden layer.,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.",0
what do you know about input layer?,The input layer is contains your raw data.,"The input layer contains input neurons, sometimes called the visible layer.",1
what do you know about input layer?,The input layer is contains your raw data.,multiplies arrays A and B of same dimension by multiplying corresponding elements.,0
What is matrix element-wise multiplication?,"The input layer contains input neurons, sometimes called the visible layer.","takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.",0
what do you know about input layer?,The input layer is contains your raw data.,"Input Layer: Input variables, contains your raw data.",1
what do you know about input layer?,The input layer is contains your raw data.,"Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.",0
What do you mean by Dropout?,"Input Layer: Input variables, contains your raw data.","The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.",0
what do you know about input layer?,The input layer is contains your raw data.,The input layer is contains your raw data. which send information to the hidden layer.,1
what do you know about input layer?,The input layer is contains your raw data.,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",0
What is a Swish function?,The input layer is contains your raw data. which send information to the hidden layer.,"Swish is a smooth, non-monotonic function. That means that it does not abruptly change direction like ReLU does near x = 0.",0
what do you know about input layer?,"The input layer contains input neurons, sometimes called the visible layer.","Input Layer: Input variables, contains your raw data.",1
what do you know about input layer?,"The input layer contains input neurons, sometimes called the visible layer.","Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.",0
what do you know about input layer?,"The input layer contains input neurons, sometimes called the visible layer.",The input layer is contains your raw data. which send information to the hidden layer.,1
what do you know about input layer?,"The input layer contains input neurons, sometimes called the visible layer.","A model with too little capacity cannot learn the training dataset meaning it will underfit, whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",0
What is Model Capacity?,The input layer is contains your raw data. which send information to the hidden layer.,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit.",0
what do you know about input layer?,"Input Layer: Input variables, contains your raw data.",The input layer is contains your raw data. which send information to the hidden layer.,1
what do you know about input layer?,"Input Layer: Input variables, contains your raw data.",This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,0
What is the use of encoder layers in Autoencoders?,The input layer is contains your raw data. which send information to the hidden layer.,The encoder layer encodes the input image as a compressed representation in a reduced dimension. The compressed image is the distorted version of the original image.,0
what do you know about hidden layer?,"Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.",The hidden layer is used to send data to the output layer.,1
what do you know about hidden layer?,"Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.",This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,0
Explain the following variant of Gradient Descent batch?,The hidden layer is used to send data to the output layer.,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally after each iteration over the training dataset.",0
what do you know about hidden layer?,"Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.",Hidden Layers: Layers of nodes between the input and output layers. There may be one or more of these layers.,1
what do you know about hidden layer?,"Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.","Input Layer: Input variables, sometimes called the visible layer.",0
what do you know about input layer?,Hidden Layers: Layers of nodes between the input and output layers. There may be one or more of these layers.,"Input Layer: Input variables, contains your raw data.",0
what do you know about hidden layer?,"Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.",The hidden layer after the input layer and before the ouput layer.,1
what do you know about hidden layer?,"Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.","Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,",0
What is the function of the Fourier Transform in Deep Learning?,The hidden layer after the input layer and before the ouput layer.,"data can be considered a signal, and making convolution easier.",0
what do you know about hidden layer?,"Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.","The hidden layer is used to send data, There may be one or more of these layers.",1
what do you know about hidden layer?,"Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.",The code layer is used to represent the compressed input which is fed to the decoder.,0
What is the use of code layers in Autoencoders?,"The hidden layer is used to send data, There may be one or more of these layers.",This part of the network represents the compressed input.,0
what do you know about hidden layer?,"Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.","Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.",1
what do you know about hidden layer?,"Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.",Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,0
Explain the following variant of Gradient Descent batch?,"Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.","Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",0
what do you know about hidden layer?,"Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.",The hidden layer after the input layer to send data to the output layer.,1
what do you know about hidden layer?,"Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.","A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.",0
What is an RNN?,The hidden layer after the input layer to send data to the output layer.,"RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.",0
what do you know about hidden layer?,The hidden layer is used to send data to the output layer.,Hidden Layers: Layers of nodes between the input and output layers. There may be one or more of these layers.,1
what do you know about hidden layer?,The hidden layer is used to send data to the output layer.,The data is made available at the output layer.,0
what do you know about output layer?,Hidden Layers: Layers of nodes between the input and output layers. There may be one or more of these layers.,"The output layer is the simplest, data is made available at the output layer.",0
what do you know about hidden layer?,The hidden layer is used to send data to the output layer.,The hidden layer after the input layer and before the ouput layer.,1
what do you know about hidden layer?,The hidden layer is used to send data to the output layer.,Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,0
What do you understand by Autoencoder?,The hidden layer after the input layer and before the ouput layer.,"Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded",0
what do you know about hidden layer?,The hidden layer is used to send data to the output layer.,"The hidden layer is used to send data, There may be one or more of these layers.",1
what do you know about hidden layer?,The hidden layer is used to send data to the output layer.,Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,0
What do you mean by Dropout?,"The hidden layer is used to send data, There may be one or more of these layers.","The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.",0
what do you know about hidden layer?,The hidden layer is used to send data to the output layer.,"Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.",1
what do you know about hidden layer?,The hidden layer is used to send data to the output layer.,The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,0
what do you know about input layer?,"Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.","Input Layer: Input variables, contains your raw data.",0
what do you know about hidden layer?,The hidden layer is used to send data to the output layer.,The hidden layer after the input layer to send data to the output layer.,1
what do you know about hidden layer?,The hidden layer is used to send data to the output layer.,"As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.",0
what is a single percepton?,The hidden layer after the input layer to send data to the output layer.,the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,0
what do you know about hidden layer?,Hidden Layers: Layers of nodes between the input and output layers. There may be one or more of these layers.,The hidden layer after the input layer and before the ouput layer.,1
what do you know about hidden layer?,Hidden Layers: Layers of nodes between the input and output layers. There may be one or more of these layers.,"By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.",0
Explain Data Normalization.,The hidden layer after the input layer and before the ouput layer.,"change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",0
what do you know about hidden layer?,Hidden Layers: Layers of nodes between the input and output layers. There may be one or more of these layers.,"The hidden layer is used to send data, There may be one or more of these layers.",1
what do you know about hidden layer?,Hidden Layers: Layers of nodes between the input and output layers. There may be one or more of these layers.,A convolutional neural network (CNN) is a type of artificial neural network most commonly applied to analyzing visual imagery.,0
What do you understand by a convolutional neural network?,"The hidden layer is used to send data, There may be one or more of these layers.","A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.",0
what do you know about hidden layer?,Hidden Layers: Layers of nodes between the input and output layers. There may be one or more of these layers.,"Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.",1
what do you know about hidden layer?,Hidden Layers: Layers of nodes between the input and output layers. There may be one or more of these layers.,multiplies arrays A and B of same dimension by multiplying corresponding elements.,0
What is matrix element-wise multiplication?,"Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.","We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.",0
what do you know about hidden layer?,Hidden Layers: Layers of nodes between the input and output layers. There may be one or more of these layers.,The hidden layer after the input layer to send data to the output layer.,1
what do you know about hidden layer?,Hidden Layers: Layers of nodes between the input and output layers. There may be one or more of these layers.,"The input layer contains input neurons, sometimes called the visible layer.",0
what do you know about input layer?,The hidden layer after the input layer to send data to the output layer.,The input layer is contains your raw data. which send information to the hidden layer.,0
what do you know about hidden layer?,The hidden layer after the input layer and before the ouput layer.,"The hidden layer is used to send data, There may be one or more of these layers.",1
what do you know about hidden layer?,The hidden layer after the input layer and before the ouput layer.,Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,0
What do you understand by Deep Autoencoders?,"The hidden layer is used to send data, There may be one or more of these layers.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",0
what do you know about hidden layer?,The hidden layer after the input layer and before the ouput layer.,"Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.",1
what do you know about hidden layer?,The hidden layer after the input layer and before the ouput layer.,"The Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value x it returns that value back.",0
What is ReLU function?,"Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.",piecewise function returns zero if input is negative.,0
what do you know about hidden layer?,The hidden layer after the input layer and before the ouput layer.,The hidden layer after the input layer to send data to the output layer.,1
what do you know about hidden layer?,The hidden layer after the input layer and before the ouput layer.,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,0
Explain the following variant of Gradient Descent batch?,The hidden layer after the input layer to send data to the output layer.,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",0
what do you know about hidden layer?,"The hidden layer is used to send data, There may be one or more of these layers.","Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.",1
what do you know about hidden layer?,"The hidden layer is used to send data, There may be one or more of these layers.","Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.",0
What are the disadvantages of deep learning?,"Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.","Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.",0
what do you know about hidden layer?,"The hidden layer is used to send data, There may be one or more of these layers.",The hidden layer after the input layer to send data to the output layer.,1
what do you know about hidden layer?,"The hidden layer is used to send data, There may be one or more of these layers.","The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.",0
What is the sigmoid function?,The hidden layer after the input layer to send data to the output layer.,can be used to predict probability as it produces output ranges between 0 and 1.,0
what do you know about hidden layer?,"Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.",The hidden layer after the input layer to send data to the output layer.,1
what do you know about hidden layer?,"Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.","n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.",0
What is the meaning of term weight initialization in neural networks?,The hidden layer after the input layer to send data to the output layer.,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,0
what do you know about output layer?,"layer takes in the inputs which are passed in from the layers before it, performs the calculations via its neurons and then the output is computed.",The data is made available at the output layer.,1
what do you know about output layer?,"layer takes in the inputs which are passed in from the layers before it, performs the calculations via its neurons and then the output is computed.","Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.",0
Explain Data Normalization.,The data is made available at the output layer.,"By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.",0
what do you know about output layer?,"layer takes in the inputs which are passed in from the layers before it, performs the calculations via its neurons and then the output is computed.",Output Layer: A layer of nodes that produce the output variables.,1
what do you know about output layer?,"layer takes in the inputs which are passed in from the layers before it, performs the calculations via its neurons and then the output is computed.",The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,0
What is the use of decoder layers in Autoencoders?,Output Layer: A layer of nodes that produce the output variables.,This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,0
what do you know about output layer?,"layer takes in the inputs which are passed in from the layers before it, performs the calculations via its neurons and then the output is computed.","The output layer is the simplest, usually consisting of a single output for classification problems.",1
what do you know about output layer?,"layer takes in the inputs which are passed in from the layers before it, performs the calculations via its neurons and then the output is computed.","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","The output layer is the simplest, usually consisting of a single output for classification problems.","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
what do you know about output layer?,"layer takes in the inputs which are passed in from the layers before it, performs the calculations via its neurons and then the output is computed.",The data is made available the output variables.,1
what do you know about output layer?,"layer takes in the inputs which are passed in from the layers before it, performs the calculations via its neurons and then the output is computed.",supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,0
Differentiate supervised and unsupervised deep learning procedures.,The data is made available the output variables.,"supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",0
what do you know about output layer?,"layer takes in the inputs which are passed in from the layers before it, performs the calculations via its neurons and then the output is computed.",Output Layer: A layer of nodes that usually consisting of a single output for classification problems.,1
what do you know about output layer?,"layer takes in the inputs which are passed in from the layers before it, performs the calculations via its neurons and then the output is computed.",The hidden layer is used to send data to the output layer.,0
what do you know about hidden layer?,Output Layer: A layer of nodes that usually consisting of a single output for classification problems.,The hidden layer after the input layer to send data to the output layer.,0
what do you know about output layer?,"layer takes in the inputs which are passed in from the layers before it, performs the calculations via its neurons and then the output is computed.","The output layer is the simplest, data is made available at the output layer.",1
what do you know about output layer?,"layer takes in the inputs which are passed in from the layers before it, performs the calculations via its neurons and then the output is computed.",initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,0
What is the meaning of term weight initialization in neural networks?,"The output layer is the simplest, data is made available at the output layer.","initializing weights with too-small values will lead to divergence, too-large values will lead to exploding.",0
what do you know about output layer?,The data is made available at the output layer.,Output Layer: A layer of nodes that produce the output variables.,1
what do you know about output layer?,The data is made available at the output layer.,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.",0
Explain the following variant of Gradient Descent mini-batch?,Output Layer: A layer of nodes that produce the output variables.,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.",0
what do you know about output layer?,The data is made available at the output layer.,"The output layer is the simplest, usually consisting of a single output for classification problems.",1
what do you know about output layer?,The data is made available at the output layer.,"a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",0
What is the use of leaky ReLU function?,"The output layer is the simplest, usually consisting of a single output for classification problems.",the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,0
what do you know about output layer?,The data is made available at the output layer.,The data is made available the output variables.,1
what do you know about output layer?,The data is made available at the output layer.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Deep Autoencoders?,The data is made available the output variables.,Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,0
what do you know about output layer?,The data is made available at the output layer.,Output Layer: A layer of nodes that usually consisting of a single output for classification problems.,1
what do you know about output layer?,The data is made available at the output layer.,"Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.",0
Do you think that deep network is better than a shallow one?,Output Layer: A layer of nodes that usually consisting of a single output for classification problems.,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.",0
what do you know about output layer?,The data is made available at the output layer.,"The output layer is the simplest, data is made available at the output layer.",1
what do you know about output layer?,The data is made available at the output layer.,This part of the network represents the input that is fed into the decoder.,0
What is the use of code layers in Autoencoders?,"The output layer is the simplest, data is made available at the output layer.",This part of the network contains the reduced representation after encoding the input image.,0
what do you know about output layer?,Output Layer: A layer of nodes that produce the output variables.,"The output layer is the simplest, usually consisting of a single output for classification problems.",1
what do you know about output layer?,Output Layer: A layer of nodes that produce the output variables.,"The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.",0
What is the softmax function?,"The output layer is the simplest, usually consisting of a single output for classification problems.","The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",0
what do you know about output layer?,Output Layer: A layer of nodes that produce the output variables.,The data is made available the output variables.,1
what do you know about output layer?,Output Layer: A layer of nodes that produce the output variables.,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,0
Explain the following variant of Gradient Descent batch?,The data is made available the output variables.,"This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",0
what do you know about output layer?,Output Layer: A layer of nodes that produce the output variables.,Output Layer: A layer of nodes that usually consisting of a single output for classification problems.,1
what do you know about output layer?,Output Layer: A layer of nodes that produce the output variables.,This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,0
What is the use of decoder layers in Autoencoders?,Output Layer: A layer of nodes that usually consisting of a single output for classification problems.,"This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network",0
what do you know about output layer?,Output Layer: A layer of nodes that produce the output variables.,"The output layer is the simplest, data is made available at the output layer.",1
what do you know about output layer?,Output Layer: A layer of nodes that produce the output variables.,"Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.",0
Why is zero initialization not a good weight initialization process?,"The output layer is the simplest, data is made available at the output layer.","in this case, the equations of the learning algorithm would fail, all weights have the same value in subsequent iterations.",0
what do you know about output layer?,"The output layer is the simplest, usually consisting of a single output for classification problems.",The data is made available the output variables.,1
what do you know about output layer?,"The output layer is the simplest, usually consisting of a single output for classification problems.",deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,0
Do you think that deep network is better than a shallow one?,The data is made available the output variables.,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.",0
what do you know about output layer?,"The output layer is the simplest, usually consisting of a single output for classification problems.",Output Layer: A layer of nodes that usually consisting of a single output for classification problems.,1
what do you know about output layer?,"The output layer is the simplest, usually consisting of a single output for classification problems.",Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,0
What do you understand by Autoencoder?,Output Layer: A layer of nodes that usually consisting of a single output for classification problems.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.",0
what do you know about output layer?,"The output layer is the simplest, usually consisting of a single output for classification problems.","The output layer is the simplest, data is made available at the output layer.",1
what do you know about output layer?,"The output layer is the simplest, usually consisting of a single output for classification problems.","can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",0
What is a binary step function?,"The output layer is the simplest, data is made available at the output layer.",is one of the most common activation function in neural networks. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,0
what do you know about output layer?,The data is made available the output variables.,Output Layer: A layer of nodes that usually consisting of a single output for classification problems.,1
what do you know about output layer?,The data is made available the output variables.,Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,0
What do you understand by Deep Autoencoders?,Output Layer: A layer of nodes that usually consisting of a single output for classification problems.,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",0
what do you know about output layer?,The data is made available the output variables.,"The output layer is the simplest, data is made available at the output layer.",1
what do you know about output layer?,The data is made available the output variables.,"the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.",0
Explain Data Normalization.,"The output layer is the simplest, data is made available at the output layer.",Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,0
what do you know about output layer?,Output Layer: A layer of nodes that usually consisting of a single output for classification problems.,"The output layer is the simplest, data is made available at the output layer.",1
what do you know about output layer?,Output Layer: A layer of nodes that usually consisting of a single output for classification problems.,"Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,",0
What is the function of the Fourier Transform in Deep Learning?,"The output layer is the simplest, data is made available at the output layer.","processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",0
What is the use of the Activation function?,"Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.",The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,1
What is the use of the Activation function?,"Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?",The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,"AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems",0
What is the use of the Activation function?,"Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.",most important feature in an activation function is its ability to add non-linearity into a neural network.,1
What is the use of the Activation function?,"Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.",The data is made available the output variables.,0
what do you know about output layer?,most important feature in an activation function is its ability to add non-linearity into a neural network.,Output Layer: A layer of nodes that usually consisting of a single output for classification problems.,0
What is the use of the Activation function?,"Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.",the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,1
What is the use of the Activation function?,"Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.","LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.",0
Explain the importance of LSTM.,the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,LSTM use persistent previous information to be used in the current neural network.,0
What is the use of the Activation function?,"Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.",The basic purpose of the activation function its ability to add non-linearity into a neural network.,1
What is the use of the Activation function?,"Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.","supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",0
Differentiate supervised and unsupervised deep learning procedures.,The basic purpose of the activation function its ability to add non-linearity into a neural network.,"supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",0
What is the use of the Activation function?,"Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.",most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,1
What is the use of the Activation function?,"Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.",This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,0
Explain the layer of CNN: convolution,most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,This layer computes the convolutions between the neurons and the various patches in the input,0
What is the use of the Activation function?,"Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.","the Neural Network can successfully approximate functions which does not follow linearity, into the output of a neuron.",1
What is the use of the Activation function?,"Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.","layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",0
Explain the layer of CNN: Full Collectedness,"the Neural Network can successfully approximate functions which does not follow linearity, into the output of a neuron.","layer will compute the class scores, resulting a class probability distribution.",0
What is the use of the Activation function?,The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,most important feature in an activation function is its ability to add non-linearity into a neural network.,1
What is the use of the Activation function?,The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output.Unsupervised learning is modeling the underlying or hidden structure or distribution in the data in order to learn more about the data,0
Differentiate supervised and unsupervised deep learning procedures.,most important feature in an activation function is its ability to add non-linearity into a neural network.,"supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",0
What is the use of the Activation function?,The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,1
What is the use of the Activation function?,The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,multiplies arrays A and B of same dimension by multiplying corresponding elements.,0
What is matrix element-wise multiplication?,the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,multiplies arrays A and B of same dimension to produce a new matrix.,0
What is the use of the Activation function?,The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,The basic purpose of the activation function its ability to add non-linearity into a neural network.,1
What is the use of the Activation function?,The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,0
Explain the following variant of Gradient Descent batch?,The basic purpose of the activation function its ability to add non-linearity into a neural network.,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,0
What is the use of the Activation function?,The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,1
What is the use of the Activation function?,The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,0
What do you mean by Dropout?,most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,"With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.",0
What is the use of the Activation function?,The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,"the Neural Network can successfully approximate functions which does not follow linearity, into the output of a neuron.",1
What is the use of the Activation function?,The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,"Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.",0
What do you mean by Dropout?,"the Neural Network can successfully approximate functions which does not follow linearity, into the output of a neuron.","The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.",0
What is the use of the Activation function?,most important feature in an activation function is its ability to add non-linearity into a neural network.,the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,1
What is the use of the Activation function?,most important feature in an activation function is its ability to add non-linearity into a neural network.,"By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.",0
Explain Data Normalization.,the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,"change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",0
What is the use of the Activation function?,most important feature in an activation function is its ability to add non-linearity into a neural network.,The basic purpose of the activation function its ability to add non-linearity into a neural network.,1
What is the use of the Activation function?,most important feature in an activation function is its ability to add non-linearity into a neural network.,"The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.",0
What is a binary step function?,The basic purpose of the activation function its ability to add non-linearity into a neural network.,"can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",0
What is the use of the Activation function?,most important feature in an activation function is its ability to add non-linearity into a neural network.,most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,1
What is the use of the Activation function?,most important feature in an activation function is its ability to add non-linearity into a neural network.,"The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.",0
What is Tanh function?,most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,"rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",0
What is the use of the Activation function?,most important feature in an activation function is its ability to add non-linearity into a neural network.,"the Neural Network can successfully approximate functions which does not follow linearity, into the output of a neuron.",1
What is the use of the Activation function?,most important feature in an activation function is its ability to add non-linearity into a neural network.,aims to map the activation volume from the combination of previous different layers into a class probability distribution.,0
Explain the layer of CNN: Full Collectedness,"the Neural Network can successfully approximate functions which does not follow linearity, into the output of a neuron.",aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,0
What is the use of the Activation function?,the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,The basic purpose of the activation function its ability to add non-linearity into a neural network.,1
What is the use of the Activation function?,the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,"the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.",0
Explain the following variant of Gradient Descent Stochastic?,The basic purpose of the activation function its ability to add non-linearity into a neural network.,"the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration",0
What is the use of the Activation function?,the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,1
What is the use of the Activation function?,the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,The code layer is used to represent the compressed input which is fed to the decoder.,0
What is the use of code layers in Autoencoders?,most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,"produced after encoding the input image, represents the compressed input.",0
What is the use of the Activation function?,the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,"the Neural Network can successfully approximate functions which does not follow linearity, into the output of a neuron.",1
What is the use of the Activation function?,the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,0
What is matrix element-wise multiplication?,"the Neural Network can successfully approximate functions which does not follow linearity, into the output of a neuron.",multiplies arrays A and B of same dimension by multiplying corresponding elements.,0
What is the use of the Activation function?,The basic purpose of the activation function its ability to add non-linearity into a neural network.,most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,1
What is the use of the Activation function?,The basic purpose of the activation function its ability to add non-linearity into a neural network.,"With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.",0
What is the use of the Activation function?,The basic purpose of the activation function its ability to add non-linearity into a neural network.,"the Neural Network can successfully approximate functions which does not follow linearity, into the output of a neuron.",1
What is the use of the Activation function?,The basic purpose of the activation function its ability to add non-linearity into a neural network.,"Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.",0
What is the function of the Fourier Transform in Deep Learning?,"the Neural Network can successfully approximate functions which does not follow linearity, into the output of a neuron.",Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,0
What is the use of the Activation function?,most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,"the Neural Network can successfully approximate functions which does not follow linearity, into the output of a neuron.",1
What is the use of the Activation function?,most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,"Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","the Neural Network can successfully approximate functions which does not follow linearity, into the output of a neuron.","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
What is a binary step function?,"The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.","can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",1
What is a binary step function?,"The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.","Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.",0
Explain the layer of CNN: Full Collectedness,"can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.","fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",0
What is a binary step function?,"The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.","A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",1
What is a binary step function?,"The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.",Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,0
What is matrix element-wise multiplication?,"A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",multiplies arrays A and B of same dimension to produce a new matrix.,0
What is a binary step function?,"The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.",is one of the most common activation function in neural networks. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,1
What is a binary step function?,"The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.","A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.",0
What do you understand by a convolutional neural network?,is one of the most common activation function in neural networks. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,"A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.",0
What is a binary step function?,"The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.","can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",1
What is a binary step function?,"The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.","RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.",0
What is an RNN?,"can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.","RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.",0
What is a binary step function?,"The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.",A binary step function is a threshold-based activation function. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,1
What is a binary step function?,"The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.",This part of the network contains the reduced representation of the input that is fed into the decoder.,0
What is the use of code layers in Autoencoders?,A binary step function is a threshold-based activation function. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,produced after encoding the input image.,0
What is a binary step function?,"The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.","is one of the most common activation function in neural networks. if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",1
What is a binary step function?,"The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.",Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,0
what is a multilayer percepton?,"is one of the most common activation function in neural networks. if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,0
What is a binary step function?,"can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.","A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",1
What is a binary step function?,"can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.","RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.",0
Explain the layer of CNN: ReLU,"A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.","Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.",0
What is a binary step function?,"can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",is one of the most common activation function in neural networks. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,1
What is a binary step function?,"can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",fully connected neural network structure that drives the final classification decision.,0
Explain the layer of CNN: Full Collectedness,is one of the most common activation function in neural networks. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,"fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",0
What is a binary step function?,"can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.","can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",1
What is a binary step function?,"can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.","while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.",0
Explain the layer of CNN: pooling,"can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,0
What is a binary step function?,"can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",A binary step function is a threshold-based activation function. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,1
What is a binary step function?,"can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,0
Explain the layer of CNN: ReLU,A binary step function is a threshold-based activation function. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,"the most commonly deployed activation function, such as the max(0,x) thresholding at zero.",0
What is a binary step function?,"can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.","is one of the most common activation function in neural networks. if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",1
What is a binary step function?,"can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,0
Differentiate supervised and unsupervised deep learning procedures.,"is one of the most common activation function in neural networks. if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.","supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",0
What is a binary step function?,"A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",is one of the most common activation function in neural networks. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,1
What is a binary step function?,"A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.","In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations",0
What is the meaning of term weight initialization in neural networks?,is one of the most common activation function in neural networks. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,"if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations",0
What is a binary step function?,"A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.","can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",1
What is a binary step function?,"A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.","A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",0
What do you understand by Perceptron?,"can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",Perceptron is a machine learning algorithm that helps provide classified outcomes. This algorithm enables neurons to learn and processes elements in the training set one at a time.,0
What is a binary step function?,"A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",A binary step function is a threshold-based activation function. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,1
What is a binary step function?,"A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.","Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.",0
What is a Swish function?,A binary step function is a threshold-based activation function. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.",0
What is a binary step function?,"A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.","is one of the most common activation function in neural networks. if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",1
What is a binary step function?,"A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.","LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.",0
Explain the importance of LSTM.,"is one of the most common activation function in neural networks. if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",LSTMs have property of selectively remembering patterns for long durations of time.,0
What is a binary step function?,is one of the most common activation function in neural networks. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,"can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",1
What is a binary step function?,is one of the most common activation function in neural networks. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,0
What is the use of the Activation function?,"can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.","the Neural Network can successfully approximate functions which does not follow linearity, into the output of a neuron.",0
What is a binary step function?,is one of the most common activation function in neural networks. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,A binary step function is a threshold-based activation function. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,1
What is a binary step function?,is one of the most common activation function in neural networks. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,"The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.",0
What is ReLU function?,A binary step function is a threshold-based activation function. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,piecewise function returns zero if input is negative.,0
What is a binary step function?,is one of the most common activation function in neural networks. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,"is one of the most common activation function in neural networks. if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",1
What is a binary step function?,is one of the most common activation function in neural networks. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,"Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.",0
what do you know about hidden layer?,"is one of the most common activation function in neural networks. if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",The hidden layer after the input layer to send data to the output layer.,0
What is a binary step function?,"can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",A binary step function is a threshold-based activation function. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,1
What is a binary step function?,"can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.","Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.",0
Explain Data Normalization.,A binary step function is a threshold-based activation function. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,"the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.",0
What is a binary step function?,"can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.","is one of the most common activation function in neural networks. if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",1
What is a binary step function?,"can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,0
What is Tanh function?,"is one of the most common activation function in neural networks. if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.","Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),",0
What is a binary step function?,A binary step function is a threshold-based activation function. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,"is one of the most common activation function in neural networks. if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",1
What is a binary step function?,A binary step function is a threshold-based activation function. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,"Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.",0
Explain Data Normalization.,"is one of the most common activation function in neural networks. if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.","By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.",0
What is the sigmoid function?,"trendy activation function for neural networks. The input data to the function is transformed into a value between 0.0 and 1.0. Input values that are much larger than 1.0 are transformed to the value 1.0. Similarly, values that are much smaller than 0.0 are transformed into 0.0. The shape of the function for all possible inputs is an S-shape from zero up through 0.5 to 1.0.",used as activation function a sigmoid neuron outputs a more smooth or continous range of values between 0 and 1.,1
What is the sigmoid function?,"trendy activation function for neural networks. The input data to the function is transformed into a value between 0.0 and 1.0. Input values that are much larger than 1.0 are transformed to the value 1.0. Similarly, values that are much smaller than 0.0 are transformed into 0.0. The shape of the function for all possible inputs is an S-shape from zero up through 0.5 to 1.0.","Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?",used as activation function a sigmoid neuron outputs a more smooth or continous range of values between 0 and 1.,"Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
What is the sigmoid function?,"trendy activation function for neural networks. The input data to the function is transformed into a value between 0.0 and 1.0. Input values that are much larger than 1.0 are transformed to the value 1.0. Similarly, values that are much smaller than 0.0 are transformed into 0.0. The shape of the function for all possible inputs is an S-shape from zero up through 0.5 to 1.0.",sigmoid function have been used as the activation function of artificial neurons. Sigmoid functions most often show a return value (y axis) in the range 0 to 1,1
What is the sigmoid function?,"trendy activation function for neural networks. The input data to the function is transformed into a value between 0.0 and 1.0. Input values that are much larger than 1.0 are transformed to the value 1.0. Similarly, values that are much smaller than 0.0 are transformed into 0.0. The shape of the function for all possible inputs is an S-shape from zero up through 0.5 to 1.0.","Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.",0
What is the use of the Activation function?,sigmoid function have been used as the activation function of artificial neurons. Sigmoid functions most often show a return value (y axis) in the range 0 to 1,most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,0
What is the sigmoid function?,"trendy activation function for neural networks. The input data to the function is transformed into a value between 0.0 and 1.0. Input values that are much larger than 1.0 are transformed to the value 1.0. Similarly, values that are much smaller than 0.0 are transformed into 0.0. The shape of the function for all possible inputs is an S-shape from zero up through 0.5 to 1.0.","The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.",1
What is the sigmoid function?,"trendy activation function for neural networks. The input data to the function is transformed into a value between 0.0 and 1.0. Input values that are much larger than 1.0 are transformed to the value 1.0. Similarly, values that are much smaller than 0.0 are transformed into 0.0. The shape of the function for all possible inputs is an S-shape from zero up through 0.5 to 1.0.",The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,0
what do you know about input layer?,"The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.","Input Layer: Input variables, contains your raw data.",0
What is the sigmoid function?,"trendy activation function for neural networks. The input data to the function is transformed into a value between 0.0 and 1.0. Input values that are much larger than 1.0 are transformed to the value 1.0. Similarly, values that are much smaller than 0.0 are transformed into 0.0. The shape of the function for all possible inputs is an S-shape from zero up through 0.5 to 1.0.","The input data to the function is transformed into a value between 0.0 and 1.0, outputs a more smooth or continous range.",1
What is the sigmoid function?,"trendy activation function for neural networks. The input data to the function is transformed into a value between 0.0 and 1.0. Input values that are much larger than 1.0 are transformed to the value 1.0. Similarly, values that are much smaller than 0.0 are transformed into 0.0. The shape of the function for all possible inputs is an S-shape from zero up through 0.5 to 1.0.",Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,0
what is a multilayer percepton?,"The input data to the function is transformed into a value between 0.0 and 1.0, outputs a more smooth or continous range.","has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",0
What is the sigmoid function?,"trendy activation function for neural networks. The input data to the function is transformed into a value between 0.0 and 1.0. Input values that are much larger than 1.0 are transformed to the value 1.0. Similarly, values that are much smaller than 0.0 are transformed into 0.0. The shape of the function for all possible inputs is an S-shape from zero up through 0.5 to 1.0.",can be used to predict probability as it produces output ranges between 0 and 1.,1
What is the sigmoid function?,"trendy activation function for neural networks. The input data to the function is transformed into a value between 0.0 and 1.0. Input values that are much larger than 1.0 are transformed to the value 1.0. Similarly, values that are much smaller than 0.0 are transformed into 0.0. The shape of the function for all possible inputs is an S-shape from zero up through 0.5 to 1.0.","This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",0
Explain the following variant of Gradient Descent batch?,can be used to predict probability as it produces output ranges between 0 and 1.,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",0
What is the sigmoid function?,"trendy activation function for neural networks. The input data to the function is transformed into a value between 0.0 and 1.0. Input values that are much larger than 1.0 are transformed to the value 1.0. Similarly, values that are much smaller than 0.0 are transformed into 0.0. The shape of the function for all possible inputs is an S-shape from zero up through 0.5 to 1.0.",activation function apply thresholding to input data and produce output between 0 and 1.,1
What is the sigmoid function?,"trendy activation function for neural networks. The input data to the function is transformed into a value between 0.0 and 1.0. Input values that are much larger than 1.0 are transformed to the value 1.0. Similarly, values that are much smaller than 0.0 are transformed into 0.0. The shape of the function for all possible inputs is an S-shape from zero up through 0.5 to 1.0.","Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.",0
What do you understand by Tensors?,activation function apply thresholding to input data and produce output between 0 and 1.,"A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.",0
What is the sigmoid function?,used as activation function a sigmoid neuron outputs a more smooth or continous range of values between 0 and 1.,sigmoid function have been used as the activation function of artificial neurons. Sigmoid functions most often show a return value (y axis) in the range 0 to 1,1
What is the sigmoid function?,used as activation function a sigmoid neuron outputs a more smooth or continous range of values between 0 and 1.,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.",0
What is a Swish function?,sigmoid function have been used as the activation function of artificial neurons. Sigmoid functions most often show a return value (y axis) in the range 0 to 1,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",0
What is the sigmoid function?,used as activation function a sigmoid neuron outputs a more smooth or continous range of values between 0 and 1.,"The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.",1
What is the sigmoid function?,used as activation function a sigmoid neuron outputs a more smooth or continous range of values between 0 and 1.,"A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.",0
What is the cost function?,"The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.",It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,0
What is the sigmoid function?,used as activation function a sigmoid neuron outputs a more smooth or continous range of values between 0 and 1.,"The input data to the function is transformed into a value between 0.0 and 1.0, outputs a more smooth or continous range.",1
What is the sigmoid function?,used as activation function a sigmoid neuron outputs a more smooth or continous range of values between 0 and 1.,"Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.",0
Explain gradient descent?,"The input data to the function is transformed into a value between 0.0 and 1.0, outputs a more smooth or continous range.","Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",0
What is the sigmoid function?,used as activation function a sigmoid neuron outputs a more smooth or continous range of values between 0 and 1.,can be used to predict probability as it produces output ranges between 0 and 1.,1
What is the sigmoid function?,used as activation function a sigmoid neuron outputs a more smooth or continous range of values between 0 and 1.,"Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.",0
What is the function of the Fourier Transform in Deep Learning?,can be used to predict probability as it produces output ranges between 0 and 1.,"processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.",0
What is the sigmoid function?,used as activation function a sigmoid neuron outputs a more smooth or continous range of values between 0 and 1.,activation function apply thresholding to input data and produce output between 0 and 1.,1
What is the sigmoid function?,used as activation function a sigmoid neuron outputs a more smooth or continous range of values between 0 and 1.,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,0
Explain the following variant of Gradient Descent batch?,activation function apply thresholding to input data and produce output between 0 and 1.,"This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",0
What is the sigmoid function?,sigmoid function have been used as the activation function of artificial neurons. Sigmoid functions most often show a return value (y axis) in the range 0 to 1,"The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.",1
What is the sigmoid function?,sigmoid function have been used as the activation function of artificial neurons. Sigmoid functions most often show a return value (y axis) in the range 0 to 1,A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,0
What do you understand by Perceptron?,"The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.","A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",0
What is the sigmoid function?,sigmoid function have been used as the activation function of artificial neurons. Sigmoid functions most often show a return value (y axis) in the range 0 to 1,"The input data to the function is transformed into a value between 0.0 and 1.0, outputs a more smooth or continous range.",1
What is the sigmoid function?,sigmoid function have been used as the activation function of artificial neurons. Sigmoid functions most often show a return value (y axis) in the range 0 to 1,"Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",0
What is the use of leaky ReLU function?,"The input data to the function is transformed into a value between 0.0 and 1.0, outputs a more smooth or continous range.","the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",0
What is the sigmoid function?,sigmoid function have been used as the activation function of artificial neurons. Sigmoid functions most often show a return value (y axis) in the range 0 to 1,can be used to predict probability as it produces output ranges between 0 and 1.,1
What is the sigmoid function?,sigmoid function have been used as the activation function of artificial neurons. Sigmoid functions most often show a return value (y axis) in the range 0 to 1,The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,0
What is the use of leaky ReLU function?,can be used to predict probability as it produces output ranges between 0 and 1.,"Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).",0
What is the sigmoid function?,sigmoid function have been used as the activation function of artificial neurons. Sigmoid functions most often show a return value (y axis) in the range 0 to 1,activation function apply thresholding to input data and produce output between 0 and 1.,1
What is the sigmoid function?,sigmoid function have been used as the activation function of artificial neurons. Sigmoid functions most often show a return value (y axis) in the range 0 to 1,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,0
Explain the layer of CNN: ReLU,activation function apply thresholding to input data and produce output between 0 and 1.,"RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.",0
What is the sigmoid function?,"The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.","The input data to the function is transformed into a value between 0.0 and 1.0, outputs a more smooth or continous range.",1
What is the sigmoid function?,"The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.","RNN) are the state of the art algorithm for sequential data, It is the first algorithm that remembers its input.",0
What is an RNN?,"The input data to the function is transformed into a value between 0.0 and 1.0, outputs a more smooth or continous range.","RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.",0
What is the sigmoid function?,"The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.",can be used to predict probability as it produces output ranges between 0 and 1.,1
What is the sigmoid function?,"The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.","Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.",0
What is the use of the Activation function?,can be used to predict probability as it produces output ranges between 0 and 1.,the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,0
What is the sigmoid function?,"The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.",activation function apply thresholding to input data and produce output between 0 and 1.,1
What is the sigmoid function?,"The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.","a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",0
What is the use of leaky ReLU function?,activation function apply thresholding to input data and produce output between 0 and 1.,the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,0
What is the sigmoid function?,"The input data to the function is transformed into a value between 0.0 and 1.0, outputs a more smooth or continous range.",can be used to predict probability as it produces output ranges between 0 and 1.,1
What is the sigmoid function?,"The input data to the function is transformed into a value between 0.0 and 1.0, outputs a more smooth or continous range.",pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,0
Explain the layer of CNN: pooling,can be used to predict probability as it produces output ranges between 0 and 1.,"while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.",0
What is the sigmoid function?,"The input data to the function is transformed into a value between 0.0 and 1.0, outputs a more smooth or continous range.",activation function apply thresholding to input data and produce output between 0 and 1.,1
What is the sigmoid function?,"The input data to the function is transformed into a value between 0.0 and 1.0, outputs a more smooth or continous range.",Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,0
What do you understand by Deep Autoencoders?,activation function apply thresholding to input data and produce output between 0 and 1.,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",0
What is the sigmoid function?,can be used to predict probability as it produces output ranges between 0 and 1.,activation function apply thresholding to input data and produce output between 0 and 1.,1
What is the sigmoid function?,can be used to predict probability as it produces output ranges between 0 and 1.,The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,0
What is the use of encoder layers in Autoencoders?,activation function apply thresholding to input data and produce output between 0 and 1.,"An encoder is a feedforward, fully connected neural network that compresses the input into a latent space representation and encodes the input image as a compressed representation in a reduced dimension.",0
What is Tanh function?,"The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.","tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.",1
What is Tanh function?,"The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.",the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,0
What is ReLU function?,"tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.","the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.",0
What is Tanh function?,"The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.","The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.",1
What is Tanh function?,"The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.",Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,0
What is deep learning?,"The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.","Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.",0
What is Tanh function?,"The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.",Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,1
What is Tanh function?,"The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.","Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.",0
What is Backpropagation?,Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,Backpropagation is a process used to adjust the weights of a deep neural network. The weights that minimize the error,0
What is Tanh function?,"The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.","tanh produces output ranges from -1 and 1, and used as activation function.",1
What is Tanh function?,"The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.",The input layer contains input neurons which send information to the hidden layer.,0
what do you know about input layer?,"tanh produces output ranges from -1 and 1, and used as activation function.",The input layer is contains your raw data.,0
What is Tanh function?,"The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.","rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",1
What is Tanh function?,"The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.","cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.",0
What is the cost function?,"rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,0
What is Tanh function?,"The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.","Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),",1
What is Tanh function?,"The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.","Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Autoencoder?,"Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),","Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded",0
What is Tanh function?,"tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.","The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.",1
What is Tanh function?,"tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.","It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.",0
Explain the importance of LSTM.,"The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.","LSTM use persistent previous information to classifying, processing and making predictions based on time series data",0
What is Tanh function?,"tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.",Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,1
What is Tanh function?,"tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.","A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Deep Autoencoders?,Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",0
What is Tanh function?,"tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.","tanh produces output ranges from -1 and 1, and used as activation function.",1
What is Tanh function?,"tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.",The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,0
What is Model Capacity?,"tanh produces output ranges from -1 and 1, and used as activation function.","The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.",0
What is Tanh function?,"tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.","rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",1
What is Tanh function?,"tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.",It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,0
What are the disadvantages of deep learning?,"rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero","Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.",0
What is Tanh function?,"tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.","Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),",1
What is Tanh function?,"tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.",Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.,0
"What do you mean by ""overfitting""?","Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),","Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.",0
What is Tanh function?,"The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.",Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,1
What is Tanh function?,"The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.",Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,0
What is the function of the Fourier Transform in Deep Learning?,Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,"data can be considered a signal, and making convolution easier.",0
What is Tanh function?,"The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.","tanh produces output ranges from -1 and 1, and used as activation function.",1
What is Tanh function?,"The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.","When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.",0
What is the function of the Fourier Transform in Deep Learning?,"tanh produces output ranges from -1 and 1, and used as activation function.","processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",0
What is Tanh function?,"The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.","rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",1
What is Tanh function?,"The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.","The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.",0
What is ReLU function?,"rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,0
What is Tanh function?,"The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.","Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),",1
What is Tanh function?,"The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.",The input layer is contains your raw data.,0
what do you know about input layer?,"Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),","The input layer contains input neurons, sometimes called the visible layer.",0
What is Tanh function?,Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,"tanh produces output ranges from -1 and 1, and used as activation function.",1
What is Tanh function?,Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,"A node or unit which implements the activation function is referred to as a rectified linear activation unit or ReLU for short. Generally, networks that use the rectifier function for the hidden layers are referred to as rectified networks.",0
What is ReLU function?,"tanh produces output ranges from -1 and 1, and used as activation function.","The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.",0
What is Tanh function?,Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,"rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",1
What is Tanh function?,Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,Initializing all the weights with zeros leads the neurons to learn the same features during training.,0
Why is zero initialization not a good weight initialization process?,"rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero","Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.",0
What is Tanh function?,Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,"Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),",1
What is Tanh function?,Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,Shallow means that number of hidden layer = 1 . And in case of deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . So generally as we increase the depth of the model we increase the power of the model at the cost of the computational complexity .,0
Do you think that deep network is better than a shallow one?,"Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),","A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.",0
What is Tanh function?,"tanh produces output ranges from -1 and 1, and used as activation function.","rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",1
What is Tanh function?,"tanh produces output ranges from -1 and 1, and used as activation function.",The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,0
What is the use of the Activation function?,"rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,0
What is Tanh function?,"tanh produces output ranges from -1 and 1, and used as activation function.","Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),",1
What is Tanh function?,"tanh produces output ranges from -1 and 1, and used as activation function.",The data is made available at the output layer.,0
what do you know about output layer?,"Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),",Output Layer: A layer of nodes that produce the output variables.,0
What is Tanh function?,"rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero","Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),",1
What is Tanh function?,"rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem.,0
What is Backpropagation?,"Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),","The Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent, looks for the minimum value of the error.",0
What is ReLU function?,"A node or unit which implements the activation function is referred to as a rectified linear activation unit or ReLU for short. Generally, networks that use the rectifier function for the hidden layers are referred to as rectified networks.","The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.",1
What is ReLU function?,"A node or unit which implements the activation function is referred to as a rectified linear activation unit or ReLU for short. Generally, networks that use the rectifier function for the hidden layers are referred to as rectified networks.",initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,0
What is the meaning of term weight initialization in neural networks?,"The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.","In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations",0
What is ReLU function?,"A node or unit which implements the activation function is referred to as a rectified linear activation unit or ReLU for short. Generally, networks that use the rectifier function for the hidden layers are referred to as rectified networks.","The Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value x it returns that value back.",1
What is ReLU function?,"A node or unit which implements the activation function is referred to as a rectified linear activation unit or ReLU for short. Generally, networks that use the rectifier function for the hidden layers are referred to as rectified networks.","A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",0
What do you understand by Deep Autoencoders?,"The Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value x it returns that value back.","Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",0
What is ReLU function?,"A node or unit which implements the activation function is referred to as a rectified linear activation unit or ReLU for short. Generally, networks that use the rectifier function for the hidden layers are referred to as rectified networks.",the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,1
What is ReLU function?,"A node or unit which implements the activation function is referred to as a rectified linear activation unit or ReLU for short. Generally, networks that use the rectifier function for the hidden layers are referred to as rectified networks.",The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,0
What is the use of leaky ReLU function?,the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,"a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",0
What is ReLU function?,"A node or unit which implements the activation function is referred to as a rectified linear activation unit or ReLU for short. Generally, networks that use the rectifier function for the hidden layers are referred to as rectified networks.",piecewise function returns zero if input is negative.,1
What is ReLU function?,"A node or unit which implements the activation function is referred to as a rectified linear activation unit or ReLU for short. Generally, networks that use the rectifier function for the hidden layers are referred to as rectified networks.",Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,0
Explain the following variant of Gradient Descent batch?,piecewise function returns zero if input is negative.,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,0
What is ReLU function?,"A node or unit which implements the activation function is referred to as a rectified linear activation unit or ReLU for short. Generally, networks that use the rectifier function for the hidden layers are referred to as rectified networks.",The Rectified Linear Unit is the most commonly used activation function in deep learning models. An output is equal to zero when the input value is negative and the input value when the input is positive.,1
What is the use of leaky ReLU function?,The Rectified Linear Unit is the most commonly used activation function in deep learning models. An output is equal to zero when the input value is negative and the input value when the input is positive.,"a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",0
What is ReLU function?,"A node or unit which implements the activation function is referred to as a rectified linear activation unit or ReLU for short. Generally, networks that use the rectifier function for the hidden layers are referred to as rectified networks.","the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.",1
What is ReLU function?,"A node or unit which implements the activation function is referred to as a rectified linear activation unit or ReLU for short. Generally, networks that use the rectifier function for the hidden layers are referred to as rectified networks.","Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data.",0
What is deep learning?,"the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.","Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.",0
What is ReLU function?,"The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.","The Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value x it returns that value back.",1
What is ReLU function?,"The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.",The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,0
What is Model Capacity?,"The Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value x it returns that value back.","The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.",0
What is ReLU function?,"The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.",the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,1
What is ReLU function?,"The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.","Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.",0
What do you mean by Dropout?,the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,0
What is ReLU function?,"The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.",piecewise function returns zero if input is negative.,1
What is ReLU function?,"The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.",This part of the network contains the reduced representation after encoding the input image.,0
What is the use of code layers in Autoencoders?,piecewise function returns zero if input is negative.,"produced after encoding the input image, represents the compressed input.",0
What is ReLU function?,"The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.",The Rectified Linear Unit is the most commonly used activation function in deep learning models. An output is equal to zero when the input value is negative and the input value when the input is positive.,1
What is ReLU function?,"The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.",The basic purpose of the activation function its ability to add non-linearity into a neural network.,0
What is the use of the Activation function?,The Rectified Linear Unit is the most commonly used activation function in deep learning models. An output is equal to zero when the input value is negative and the input value when the input is positive.,most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,0
What is ReLU function?,"The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.","the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.",1
What is ReLU function?,"The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.",Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,0
"What do you mean by ""overfitting""?","the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.","Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.",0
What is ReLU function?,"The Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value x it returns that value back.",the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,1
What is ReLU function?,"The Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value x it returns that value back.","If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.",0
Why is zero initialization not a good weight initialization process?,the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,Initializing all the weights with zeros leads the neurons to learn the same features during training.,0
What is ReLU function?,"The Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value x it returns that value back.",piecewise function returns zero if input is negative.,1
What is ReLU function?,"The Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value x it returns that value back.","Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.",0
What are the disadvantages of deep learning?,piecewise function returns zero if input is negative.,It requires very large amount of data in order to perform better than other techniques. Is extremely computationally expensive to train.,0
What is ReLU function?,"The Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value x it returns that value back.",The Rectified Linear Unit is the most commonly used activation function in deep learning models. An output is equal to zero when the input value is negative and the input value when the input is positive.,1
What is ReLU function?,"The Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value x it returns that value back.",used as activation function a sigmoid neuron outputs a more smooth or continous range of values between 0 and 1.,0
What is the sigmoid function?,The Rectified Linear Unit is the most commonly used activation function in deep learning models. An output is equal to zero when the input value is negative and the input value when the input is positive.,can be used to predict probability as it produces output ranges between 0 and 1.,0
What is ReLU function?,"The Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value x it returns that value back.","the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.",1
What is ReLU function?,"The Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value x it returns that value back.",A convolutional neural network (CNN) is a type of artificial neural network most commonly applied to analyzing visual imagery.,0
What do you understand by a convolutional neural network?,"the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.","A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.",0
What is ReLU function?,the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,piecewise function returns zero if input is negative.,1
What is ReLU function?,the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,"A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.",0
What do you understand by a convolutional neural network?,piecewise function returns zero if input is negative.,A convolutional neural network (CNN) is a type of artificial neural network most commonly applied to analyzing visual imagery.,0
What is ReLU function?,the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,The Rectified Linear Unit is the most commonly used activation function in deep learning models. An output is equal to zero when the input value is negative and the input value when the input is positive.,1
What is ReLU function?,the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,"The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.",0
What is Tanh function?,The Rectified Linear Unit is the most commonly used activation function in deep learning models. An output is equal to zero when the input value is negative and the input value when the input is positive.,"rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",0
What is ReLU function?,the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,"the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.",1
What is ReLU function?,the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,0
What do you understand by Perceptron?,"the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.",A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,0
What is ReLU function?,piecewise function returns zero if input is negative.,The Rectified Linear Unit is the most commonly used activation function in deep learning models. An output is equal to zero when the input value is negative and the input value when the input is positive.,1
What is ReLU function?,piecewise function returns zero if input is negative.,This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,0
What is the use of decoder layers in Autoencoders?,The Rectified Linear Unit is the most commonly used activation function in deep learning models. An output is equal to zero when the input value is negative and the input value when the input is positive.,"This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network",0
What is ReLU function?,piecewise function returns zero if input is negative.,"the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.",1
What is ReLU function?,piecewise function returns zero if input is negative.,This layer computes the convolutions between the neurons and the various patches in the input,0
Explain the layer of CNN: convolution,"the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.",The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,0
What is ReLU function?,The Rectified Linear Unit is the most commonly used activation function in deep learning models. An output is equal to zero when the input value is negative and the input value when the input is positive.,"the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.",1
What is ReLU function?,The Rectified Linear Unit is the most commonly used activation function in deep learning models. An output is equal to zero when the input value is negative and the input value when the input is positive.,"The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.",0
What is the softmax function?,"the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.","Softmax turns arbitrary real values into probabilities, The output values are between the range [0,1].",0
What is the use of leaky ReLU function?,The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,"a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",1
What is the use of leaky ReLU function?,The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,0
What is the use of decoder layers in Autoencoders?,"a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,0
What is the use of leaky ReLU function?,The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,"Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).",1
What is the use of leaky ReLU function?,The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,"We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.",0
What is matrix element-wise multiplication?,"Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).",multiplies arrays A and B of same dimension to produce a new matrix.,0
What is the use of leaky ReLU function?,The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,1
What is the use of leaky ReLU function?,The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,"tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.",0
What is Tanh function?,the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,"rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",0
What is the use of leaky ReLU function?,The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,"Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",1
What is the use of leaky ReLU function?,The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,"Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Autoencoder?,"Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.","Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded",0
What is the use of leaky ReLU function?,The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,1
What is the use of leaky ReLU function?,The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,This part of the network contains the reduced representation of the input that is fed into the decoder.,0
What is the use of code layers in Autoencoders?,the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,"produced after encoding the input image, represents the compressed input.",0
What is the use of leaky ReLU function?,The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,"the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",1
What is the use of leaky ReLU function?,The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,0
What is the use of the Activation function?,"the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,0
What is the use of leaky ReLU function?,"a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).","Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).",1
What is the use of leaky ReLU function?,"a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
What is the use of leaky ReLU function?,"a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,1
What is the use of leaky ReLU function?,"a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).","A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.",0
Do you think that deep network is better than a shallow one?,the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,deep network you have lots and lots of computational nodes and lots of layers of those nodes. Shallow means that number of hidden layer = 1 .,0
What is the use of leaky ReLU function?,"a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).","Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",1
What is the use of leaky ReLU function?,"a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",The code layer is used to represent the compressed input which is fed to the decoder.,0
What is the use of code layers in Autoencoders?,"Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",This part of the network contains the reduced representation of the input that is fed into the decoder.,0
What is the use of leaky ReLU function?,"a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,1
What is the use of leaky ReLU function?,"a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,0
What do you mean by Dropout?,the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,"With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.",0
What is the use of leaky ReLU function?,"a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).","the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",1
What is the use of leaky ReLU function?,"a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,0
What is an RNN?,"the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±","RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.",0
What is the use of leaky ReLU function?,"Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).",the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,1
What is the use of leaky ReLU function?,"Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).","the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.",0
Explain Data Normalization.,the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,"change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",0
What is the use of leaky ReLU function?,"Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).","Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",1
What is the use of leaky ReLU function?,"Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).","LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.",0
Explain the importance of LSTM.,"Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.","LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.",0
What is the use of leaky ReLU function?,"Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).",the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,1
What is the use of leaky ReLU function?,"Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).","RNN stands for Recurrent Neural Networks. These are the artificial neural networks which are designed to recognize patterns in sequences of data such as handwriting, text, the spoken word, genomes, and numerical time series data.",0
What is an RNN?,the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,0
What is the use of leaky ReLU function?,"Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).","the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",1
What is the use of leaky ReLU function?,"Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).","The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1]",0
What is the softmax function?,"the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±","The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.",0
What is the use of leaky ReLU function?,the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,"Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",1
What is the use of leaky ReLU function?,the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,"Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.",0
what do you know about hidden layer?,"Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.","The hidden layer is used to send data, There may be one or more of these layers.",0
What is the use of leaky ReLU function?,the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,1
What is the use of leaky ReLU function?,the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit.",0
What is Model Capacity?,the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",0
What is the use of leaky ReLU function?,the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,"the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",1
What is the use of leaky ReLU function?,the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,0
Explain the following variant of Gradient Descent Stochastic?,"the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±","Instead of going through all examples, the gradient based on a single training sample.",0
What is the use of leaky ReLU function?,"Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,1
What is the use of leaky ReLU function?,"Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?",the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,"AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
What is the use of leaky ReLU function?,"Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.","the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",1
What is the use of leaky ReLU function?,"Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",The main purpose of Boltzmann Machine is to optimize the solution of a problem. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,0
What do you understand by Boltzmann Machine?,"the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±","A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.",0
What is the use of leaky ReLU function?,the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,"the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",1
What is the use of leaky ReLU function?,the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,The input layer is contains your raw data.,0
what do you know about input layer?,"the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±","Input Layer: Input variables, contains your raw data.",0
What is the softmax function?,"The softmax function is used to calculate the probability distribution of the event over 'n' different events, the output range will be between 0 to 1, and the sum of all the probabilities will be equal to one.","The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1]",1
What is the softmax function?,"The softmax function is used to calculate the probability distribution of the event over 'n' different events, the output range will be between 0 to 1, and the sum of all the probabilities will be equal to one.","The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.",0
What is Model Capacity?,"The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1]","The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.",0
What is the softmax function?,"The softmax function is used to calculate the probability distribution of the event over 'n' different events, the output range will be between 0 to 1, and the sum of all the probabilities will be equal to one.","The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.",1
What is the softmax function?,"The softmax function is used to calculate the probability distribution of the event over 'n' different events, the output range will be between 0 to 1, and the sum of all the probabilities will be equal to one.",Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,0
What do you understand by Boltzmann Machine?,"The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.","A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. hey dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.",0
What is the softmax function?,"The softmax function is used to calculate the probability distribution of the event over 'n' different events, the output range will be between 0 to 1, and the sum of all the probabilities will be equal to one.","Softmax turns arbitrary real values into probabilities, which are often useful in Machine Learning. The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",1
What is the softmax function?,"The softmax function is used to calculate the probability distribution of the event over 'n' different events, the output range will be between 0 to 1, and the sum of all the probabilities will be equal to one.",Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,0
"What do you mean by ""overfitting""?","Softmax turns arbitrary real values into probabilities, which are often useful in Machine Learning. The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.","Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.",0
What is the softmax function?,"The softmax function is used to calculate the probability distribution of the event over 'n' different events, the output range will be between 0 to 1, and the sum of all the probabilities will be equal to one.","The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.",1
What is the softmax function?,"The softmax function is used to calculate the probability distribution of the event over 'n' different events, the output range will be between 0 to 1, and the sum of all the probabilities will be equal to one.","The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.",0
What is ReLU function?,"The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.",The Rectified Linear Unit is the most commonly used activation function in deep learning models. An output is equal to zero when the input value is negative and the input value when the input is positive.,0
What is the softmax function?,"The softmax function is used to calculate the probability distribution of the event over 'n' different events, the output range will be between 0 to 1, and the sum of all the probabilities will be equal to one.","The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",1
What is Model Capacity?,"The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.","The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. models with higher Capacity than needed are prompt to overfit, low Capacity tend to underfit.",0
What is the softmax function?,"The softmax function is used to calculate the probability distribution of the event over 'n' different events, the output range will be between 0 to 1, and the sum of all the probabilities will be equal to one.","Softmax turns arbitrary real values into probabilities, The output values are between the range [0,1].",1
What is the softmax function?,"The softmax function is used to calculate the probability distribution of the event over 'n' different events, the output range will be between 0 to 1, and the sum of all the probabilities will be equal to one.",supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,0
Differentiate supervised and unsupervised deep learning procedures.,"Softmax turns arbitrary real values into probabilities, The output values are between the range [0,1].","supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",0
What is the softmax function?,"The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1]","The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.",1
What is the softmax function?,"The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1]","A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.",0
What do you understand by a convolutional neural network?,"The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.","convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.",0
What is the softmax function?,"The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1]","Softmax turns arbitrary real values into probabilities, which are often useful in Machine Learning. The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",1
What is the softmax function?,"The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1]",This layer computes the convolutions between the neurons and the various patches in the input,0
Explain the layer of CNN: convolution,"Softmax turns arbitrary real values into probabilities, which are often useful in Machine Learning. The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",This layer computes the convolutions between the neurons of an input that results in an activation.,0
What is the softmax function?,"The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1]","The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.",1
What is the softmax function?,"The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1]",Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,0
what is a multilayer percepton?,"The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.","has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",0
What is the softmax function?,"The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1]","The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",1
What is the softmax function?,"The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1]","Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.",0
Explain Data Normalization.,"The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.","change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",0
What is the softmax function?,"The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1]","Softmax turns arbitrary real values into probabilities, The output values are between the range [0,1].",1
What is the softmax function?,"The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1]",Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,0
Explain Data Normalization.,"Softmax turns arbitrary real values into probabilities, The output values are between the range [0,1].","By normalizing all of our inputs to a standard scale, without distorting differences in the ranges of values.",0
What is the softmax function?,"The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.","Softmax turns arbitrary real values into probabilities, which are often useful in Machine Learning. The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",1
What is the softmax function?,"The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.",initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,0
What is the meaning of term weight initialization in neural networks?,"Softmax turns arbitrary real values into probabilities, which are often useful in Machine Learning. The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.","if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations",0
What is the softmax function?,"The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.","The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.",1
What is the softmax function?,"The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.",Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,0
What is Backpropagation?,"The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.","The Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent, looks for the minimum value of the error.",0
What is the softmax function?,"The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.","The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",1
What is the softmax function?,"The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.",Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,0
What is deep learning?,"The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.","Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.",0
What is the softmax function?,"The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.","Softmax turns arbitrary real values into probabilities, The output values are between the range [0,1].",1
What is the softmax function?,"The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.","When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.",0
What is the function of the Fourier Transform in Deep Learning?,"Softmax turns arbitrary real values into probabilities, The output values are between the range [0,1].","data can be considered a signal, and making convolution easier.",0
What is the softmax function?,"Softmax turns arbitrary real values into probabilities, which are often useful in Machine Learning. The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.","The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.",1
What is the softmax function?,"Softmax turns arbitrary real values into probabilities, which are often useful in Machine Learning. The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem. ,0
What is Backpropagation?,"The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.","Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.",0
What is the softmax function?,"Softmax turns arbitrary real values into probabilities, which are often useful in Machine Learning. The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.","The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",1
What is the softmax function?,"Softmax turns arbitrary real values into probabilities, which are often useful in Machine Learning. The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.","while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.",0
Explain the layer of CNN: pooling,"The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,0
What is the softmax function?,"Softmax turns arbitrary real values into probabilities, which are often useful in Machine Learning. The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.","Softmax turns arbitrary real values into probabilities, The output values are between the range [0,1].",1
What is the softmax function?,"Softmax turns arbitrary real values into probabilities, which are often useful in Machine Learning. The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,0
What is Tanh function?,"Softmax turns arbitrary real values into probabilities, The output values are between the range [0,1].","rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",0
What is the softmax function?,"The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.","The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",1
What is the softmax function?,"The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.",Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,0
Explain the following variant of Gradient Descent Stochastic?,"The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",This is a type of gradient descent which processes 1 training example per iteration,0
What is the softmax function?,"The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.","Softmax turns arbitrary real values into probabilities, The output values are between the range [0,1].",1
What is the softmax function?,"The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.","The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.",0
What is Tanh function?,"Softmax turns arbitrary real values into probabilities, The output values are between the range [0,1].","The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.",0
What is the softmax function?,"The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.","Softmax turns arbitrary real values into probabilities, The output values are between the range [0,1].",1
What is the softmax function?,"The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.","The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.",0
What is Tanh function?,"Softmax turns arbitrary real values into probabilities, The output values are between the range [0,1].",Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,0
What is a Swish function?,"Like ReLU, Swish is bounded below but unbounded above. However, unlike ReLU, Swish is smooth and non-monotonic.","Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.",1
What is a Swish function?,"Like ReLU, Swish is bounded below but unbounded above. However, unlike ReLU, Swish is smooth and non-monotonic.","Input Layer: Input variables, sometimes called the visible layer.",0
what do you know about input layer?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.","Input Layer: Input variables, contains your raw data.",0
What is a Swish function?,"Like ReLU, Swish is bounded below but unbounded above. However, unlike ReLU, Swish is smooth and non-monotonic.","Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance",1
What is a Swish function?,"Like ReLU, Swish is bounded below but unbounded above. However, unlike ReLU, Swish is smooth and non-monotonic.","When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.",0
What is the function of the Fourier Transform in Deep Learning?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance","processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.",0
What is a Swish function?,"Like ReLU, Swish is bounded below but unbounded above. However, unlike ReLU, Swish is smooth and non-monotonic.","Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.",1
What is a Swish function?,"Like ReLU, Swish is bounded below but unbounded above. However, unlike ReLU, Swish is smooth and non-monotonic.","Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.",0
Explain the following variant of Gradient Descent batch?,"Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.","Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",0
What is a Swish function?,"Like ReLU, Swish is bounded below but unbounded above. However, unlike ReLU, Swish is smooth and non-monotonic.","Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.",1
What is a Swish function?,"Like ReLU, Swish is bounded below but unbounded above. However, unlike ReLU, Swish is smooth and non-monotonic.","Tensors are nothing but a de facto for representing the data in deep learning. They are just multidimensional arrays, which allows us to represent the data having higher dimensions. In general, we deal with high dimensional data sets where dimensions refer to different features present in the data set.",0
What do you understand by Tensors?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.","A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.",0
What is a Swish function?,"Like ReLU, Swish is bounded below but unbounded above. However, unlike ReLU, Swish is smooth and non-monotonic.","Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",1
What is a Swish function?,"Like ReLU, Swish is bounded below but unbounded above. However, unlike ReLU, Swish is smooth and non-monotonic.",Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,0
What do you understand by Autoencoder?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,0
What is a Swish function?,"Like ReLU, Swish is bounded below but unbounded above. However, unlike ReLU, Swish is smooth and non-monotonic.","Swish is a smooth, non-monotonic function. That means that it does not abruptly change direction like ReLU does near x = 0.",1
What is a Swish function?,"Like ReLU, Swish is bounded below but unbounded above. However, unlike ReLU, Swish is smooth and non-monotonic.","A multilayer perceptron is a neural network connecting multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",0
what is a multilayer percepton?,"Swish is a smooth, non-monotonic function. That means that it does not abruptly change direction like ReLU does near x = 0.",Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,0
What is a Swish function?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.","Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance",1
What is a Swish function?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.","A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",0
What do you understand by Deep Autoencoders?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",0
What is a Swish function?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.","Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.",1
What is a Swish function?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.",Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,0
What do you understand by Deep Autoencoders?,"Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.","A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",0
What is a Swish function?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.","Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.",1
What is a Swish function?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.","As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.",0
what is a single percepton?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.","As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",0
What is a Swish function?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.","Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",1
What is a Swish function?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.",Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,0
Explain the following variant of Gradient Descent Stochastic?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.","Instead of going through all examples, the gradient based on a single training sample.",0
What is a Swish function?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.","Swish is a smooth, non-monotonic function. That means that it does not abruptly change direction like ReLU does near x = 0.",1
What is a Swish function?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.",It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,0
What is the cost function?,"Swish is a smooth, non-monotonic function. That means that it does not abruptly change direction like ReLU does near x = 0.",the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,0
What is a Swish function?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance","Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.",1
What is a Swish function?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance","As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.",0
what is a single percepton?,"Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.",A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,0
What is a Swish function?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance","Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.",1
What is a Swish function?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance","Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.",0
Explain the following variant of Gradient Descent batch?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.","Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",0
What is a Swish function?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance","Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",1
What is a Swish function?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance","Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.",0
Explain the following variant of Gradient Descent mini-batch?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.","Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.",0
What is a Swish function?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance","Swish is a smooth, non-monotonic function. That means that it does not abruptly change direction like ReLU does near x = 0.",1
What is a Swish function?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance",Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,0
What do you understand by Autoencoder?,"Swish is a smooth, non-monotonic function. That means that it does not abruptly change direction like ReLU does near x = 0.",Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,0
What is a Swish function?,"Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.","Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.",1
What is a Swish function?,"Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.",Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,0
What is deep learning?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.",Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,0
What is a Swish function?,"Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.","Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",1
What is a Swish function?,"Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.",most important feature in an activation function is its ability to add non-linearity into a neural network.,0
What is the use of the Activation function?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,0
What is a Swish function?,"Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.","Swish is a smooth, non-monotonic function. That means that it does not abruptly change direction like ReLU does near x = 0.",1
What is a Swish function?,"Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.","A multilayer perceptron is a neural network connecting multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",0
what is a multilayer percepton?,"Swish is a smooth, non-monotonic function. That means that it does not abruptly change direction like ReLU does near x = 0.","has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",0
What is a Swish function?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.","Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",1
What is a Swish function?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.",Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,0
what is a multilayer percepton?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,0
What is a Swish function?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.","Swish is a smooth, non-monotonic function. That means that it does not abruptly change direction like ReLU does near x = 0.",1
What is a Swish function?,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.","As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.",0
what is a single percepton?,"Swish is a smooth, non-monotonic function. That means that it does not abruptly change direction like ReLU does near x = 0.",the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,0
What is a Swish function?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.","Swish is a smooth, non-monotonic function. That means that it does not abruptly change direction like ReLU does near x = 0.",1
What is a Swish function?,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,0
What do you understand by Deep Autoencoders?,"Swish is a smooth, non-monotonic function. That means that it does not abruptly change direction like ReLU does near x = 0.","Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",0
What do you understand by Autoencoder?,Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,1
What do you understand by Autoencoder?,Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,"Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.",0
What do you mean by Dropout?,Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,0
What do you understand by Autoencoder?,Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",1
What do you understand by Autoencoder?,Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,"change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",0
Explain Data Normalization.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,0
What do you understand by Autoencoder?,Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,"Autoencoders are neural networks. Neural networks are composed of multiple layers, and the defining aspect of an autoencoder is that the input layers contain exactly as much information as the output layer.",1
What do you understand by Autoencoder?,Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,0
Explain the layer of CNN: pooling,"Autoencoders are neural networks. Neural networks are composed of multiple layers, and the defining aspect of an autoencoder is that the input layers contain exactly as much information as the output layer.","will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]",0
What do you understand by Autoencoder?,Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,"Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.",1
What do you understand by Autoencoder?,Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,"If all the weights are initialized with 0, all weights have the same value in subsequent iterations.",0
Why is zero initialization not a good weight initialization process?,"Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.","in this case, the equations of the learning algorithm would fail, all weights have the same value in subsequent iterations.",0
What do you understand by Autoencoder?,Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.",1
What do you understand by Autoencoder?,Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.",0
What is matrix element-wise multiplication?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.",multiplies arrays A and B of same dimension to produce a new matrix.,0
What do you understand by Autoencoder?,Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,"Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded",1
What do you understand by Autoencoder?,Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,"Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.",0
Differentiate supervised and unsupervised deep learning procedures.,"Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded","supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",0
What do you understand by Autoencoder?,Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",1
What do you understand by Autoencoder?,Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery",0
What do you understand by a convolutional neural network?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.","convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.",0
What do you understand by Autoencoder?,Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,"Autoencoders are neural networks. Neural networks are composed of multiple layers, and the defining aspect of an autoencoder is that the input layers contain exactly as much information as the output layer.",1
What do you understand by Autoencoder?,Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,"Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).",0
What is the use of leaky ReLU function?,"Autoencoders are neural networks. Neural networks are composed of multiple layers, and the defining aspect of an autoencoder is that the input layers contain exactly as much information as the output layer.","Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",0
What do you understand by Autoencoder?,Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,"Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.",1
What do you understand by Autoencoder?,Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,0
"What do you mean by ""overfitting""?","Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.",occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,0
What do you understand by Autoencoder?,Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.",1
What do you understand by Autoencoder?,Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,"The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.",0
What is Model Capacity?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.",The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,0
What do you understand by Autoencoder?,Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,"Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded",1
What do you understand by Autoencoder?,Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,"Input Layer: Input variables, contains your raw data.",0
what do you know about input layer?,"Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded",The input layer is contains your raw data. which send information to the hidden layer.,0
What do you understand by Autoencoder?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.","Autoencoders are neural networks. Neural networks are composed of multiple layers, and the defining aspect of an autoencoder is that the input layers contain exactly as much information as the output layer.",1
What do you understand by Autoencoder?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",The Backpropagation algorithm looks for the minimum value of the error function in weight space using a technique called the delta rule or gradient descent. The weights that minimize the error function is then considered to be a solution to the learning problem.,0
What is Backpropagation?,"Autoencoders are neural networks. Neural networks are composed of multiple layers, and the defining aspect of an autoencoder is that the input layers contain exactly as much information as the output layer.","The Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent, looks for the minimum value of the error.",0
What do you understand by Autoencoder?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.","Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.",1
What do you understand by Autoencoder?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,0
What is the cost function?,"Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.","cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.",0
What do you understand by Autoencoder?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.",1
What do you understand by Autoencoder?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.","The input data to the function is transformed into a value between 0.0 and 1.0, outputs a more smooth or continous range.",0
What is the sigmoid function?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.",activation function apply thresholding to input data and produce output between 0 and 1.,0
What do you understand by Autoencoder?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.","Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded",1
What do you understand by Autoencoder?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.","Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.",0
What do you mean by Dropout?,"Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded",Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,0
What do you understand by Autoencoder?,"Autoencoders are neural networks. Neural networks are composed of multiple layers, and the defining aspect of an autoencoder is that the input layers contain exactly as much information as the output layer.","Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.",1
What do you understand by Autoencoder?,"Autoencoders are neural networks. Neural networks are composed of multiple layers, and the defining aspect of an autoencoder is that the input layers contain exactly as much information as the output layer.",A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,0
what is a single percepton?,"Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.","As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",0
What do you understand by Autoencoder?,"Autoencoders are neural networks. Neural networks are composed of multiple layers, and the defining aspect of an autoencoder is that the input layers contain exactly as much information as the output layer.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.",1
What do you understand by Autoencoder?,"Autoencoders are neural networks. Neural networks are composed of multiple layers, and the defining aspect of an autoencoder is that the input layers contain exactly as much information as the output layer.","supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",0
Differentiate supervised and unsupervised deep learning procedures.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.","Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
What do you understand by Autoencoder?,"Autoencoders are neural networks. Neural networks are composed of multiple layers, and the defining aspect of an autoencoder is that the input layers contain exactly as much information as the output layer.","Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded",1
What do you understand by Autoencoder?,"Autoencoders are neural networks. Neural networks are composed of multiple layers, and the defining aspect of an autoencoder is that the input layers contain exactly as much information as the output layer.",A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.,0
What do you understand by Tensors?,"Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded","A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.",0
What do you understand by Autoencoder?,"Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.",1
What do you understand by Autoencoder?,"Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.",Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,0
What do you understand by Deep Autoencoders?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Autoencoder?,"Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.","Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded",1
What do you understand by Autoencoder?,"Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.",The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,0
Explain the layer of CNN: convolution,"Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded",This layer computes the convolutions between the neurons of an input that results in an activation.,0
What do you understand by Autoencoder?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.","Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded",1
What do you understand by Autoencoder?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.",The hidden layer is used to send data to the output layer.,0
what do you know about hidden layer?,"Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded",The hidden layer after the input layer to send data to the output layer.,0
What do you mean by Dropout?,"Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.",Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,1
What do you mean by Dropout?,"Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.","The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.",0
What is Tanh function?,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,"Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),",0
What do you mean by Dropout?,"Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.","The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.",1
What do you mean by Dropout?,"Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Autoencoder?,"The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.",0
What do you mean by Dropout?,"Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.","With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.",1
What do you mean by Dropout?,"Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.","Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.",0
What is the function of the Fourier Transform in Deep Learning?,"With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.","processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",0
What do you mean by Dropout?,"Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.",Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,1
What do you mean by Dropout?,"Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.",The data is made available at the output layer.,0
what do you know about output layer?,Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,"The output layer is the simplest, usually consisting of a single output for classification problems.",0
What do you mean by Dropout?,"Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.","The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.",1
What do you understand by Deep Autoencoders?,"The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.","Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",0
What do you mean by Dropout?,"Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.","With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.",1
What is Tanh function?,"With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.","Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),",0
What do you mean by Dropout?,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,"The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.",1
What do you mean by Dropout?,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,has the same structure of a single layer perceptron with one or more hidden layers.,0
what is a multilayer percepton?,"The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.","A multilayer perceptron is a neural network connecting multiple layers in a directed graph, It is substantially formed from multiple layers of perceptron.",0
What do you mean by Dropout?,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,"With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.",1
What do you mean by Dropout?,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,"Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.",0
Differentiate supervised and unsupervised deep learning procedures.,"With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.","supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",0
What do you mean by Dropout?,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,1
What do you mean by Dropout?,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.",0
What is a Swish function?,Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,"Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.",0
What do you mean by Dropout?,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,"The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.",1
What do you mean by Dropout?,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,0
What do you understand by Autoencoder?,"The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.","Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded",0
What do you mean by Dropout?,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,"With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.",1
What do you mean by Dropout?,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,"Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.",0
What do you understand by Tensors?,"With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.","A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.",0
What do you mean by Dropout?,"The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.","With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.",1
What do you mean by Dropout?,"The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.","The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.",0
What is a binary step function?,"With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.","can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",0
What do you mean by Dropout?,"The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.",Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,1
What do you mean by Dropout?,"The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.","When each sample in the dataset is a signal it can be represneted in the Fourier domain, and making convolution easier.",0
What is the function of the Fourier Transform in Deep Learning?,Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,0
What do you mean by Dropout?,"The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.","The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.",1
What do you mean by Dropout?,"The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.",The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,0
What is the use of the Activation function?,"The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.",most important feature in an activation function is its ability to add non-linearity into a neural network.,0
What do you mean by Dropout?,"The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.","With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.",1
What do you mean by Dropout?,"The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.",Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,0
What do you understand by Autoencoder?,"With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.","Autoencoders are neural networks. Neural networks are composed of multiple layers, and the defining aspect of an autoencoder is that the input layers contain exactly as much information as the output layer.",0
What do you mean by Dropout?,"With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.",Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,1
What do you mean by Dropout?,"With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.","The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.",0
What is Model Capacity?,Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",0
What do you mean by Dropout?,"With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.","The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.",1
What do you mean by Dropout?,"With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.",aims to map the activation volume from the combination of previous different layers into a class probability distribution.,0
Explain the layer of CNN: Full Collectedness,"The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.","fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",0
What do you mean by Dropout?,"With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.","With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.",1
What do you mean by Dropout?,"With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.","The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.",0
What is Model Capacity?,"With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.","A model with too little capacity cannot learn the training dataset meaning it will underfit, whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",0
What do you mean by Dropout?,Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,"The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.",1
What do you mean by Dropout?,Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,0
What is an RNN?,"The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.","A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.",0
What do you mean by Dropout?,Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,"With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.",1
What do you mean by Dropout?,Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior.,0
What is an RNN?,"With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.","RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.",0
What do you mean by Dropout?,"The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.","With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.",1
What do you mean by Dropout?,"The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.",We combine corresponding values in an elementwise fashion to produce a new matrix.,0
What is matrix element-wise multiplication?,"With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.",multiplies arrays A and B of same dimension to produce a new matrix.,0
What do you understand by Tensors?,"Tensors are nothing but a de facto for representing the data in deep learning. They are just multidimensional arrays, which allows us to represent the data having higher dimensions. In general, we deal with high dimensional data sets where dimensions refer to different features present in the data set.",A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.,1
What do you understand by Tensors?,"Tensors are nothing but a de facto for representing the data in deep learning. They are just multidimensional arrays, which allows us to represent the data having higher dimensions. In general, we deal with high dimensional data sets where dimensions refer to different features present in the data set.",has the same structure of a single layer perceptron with one or more hidden layers.,0
what is a multilayer percepton?,A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.,"has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",0
What do you understand by Tensors?,"Tensors are nothing but a de facto for representing the data in deep learning. They are just multidimensional arrays, which allows us to represent the data having higher dimensions. In general, we deal with high dimensional data sets where dimensions refer to different features present in the data set.","Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.",1
What do you understand by Tensors?,"Tensors are nothing but a de facto for representing the data in deep learning. They are just multidimensional arrays, which allows us to represent the data having higher dimensions. In general, we deal with high dimensional data sets where dimensions refer to different features present in the data set.",Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,0
What do you understand by Deep Autoencoders?,"Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.","A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Tensors?,"Tensors are nothing but a de facto for representing the data in deep learning. They are just multidimensional arrays, which allows us to represent the data having higher dimensions. In general, we deal with high dimensional data sets where dimensions refer to different features present in the data set.",A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,1
What do you understand by Tensors?,"Tensors are nothing but a de facto for representing the data in deep learning. They are just multidimensional arrays, which allows us to represent the data having higher dimensions. In general, we deal with high dimensional data sets where dimensions refer to different features present in the data set.","The Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value x it returns that value back.",0
What is ReLU function?,A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,The Rectified Linear Unit is the most commonly used activation function in deep learning models. An output is equal to zero when the input value is negative and the input value when the input is positive.,0
What do you understand by Tensors?,"Tensors are nothing but a de facto for representing the data in deep learning. They are just multidimensional arrays, which allows us to represent the data having higher dimensions. In general, we deal with high dimensional data sets where dimensions refer to different features present in the data set.","A tensor is a generalization of vectors and matrices, In short, a single-dimensional tensor can be represented as a vector.",1
What do you understand by Tensors?,"Tensors are nothing but a de facto for representing the data in deep learning. They are just multidimensional arrays, which allows us to represent the data having higher dimensions. In general, we deal with high dimensional data sets where dimensions refer to different features present in the data set.","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","A tensor is a generalization of vectors and matrices, In short, a single-dimensional tensor can be represented as a vector.","AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
What do you understand by Tensors?,"Tensors are nothing but a de facto for representing the data in deep learning. They are just multidimensional arrays, which allows us to represent the data having higher dimensions. In general, we deal with high dimensional data sets where dimensions refer to different features present in the data set.","Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.",1
What do you understand by Tensors?,"Tensors are nothing but a de facto for representing the data in deep learning. They are just multidimensional arrays, which allows us to represent the data having higher dimensions. In general, we deal with high dimensional data sets where dimensions refer to different features present in the data set.","A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",0
What do you understand by Deep Autoencoders?,"Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.","A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Tensors?,"Tensors are nothing but a de facto for representing the data in deep learning. They are just multidimensional arrays, which allows us to represent the data having higher dimensions. In general, we deal with high dimensional data sets where dimensions refer to different features present in the data set.","A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.",1
What do you understand by Tensors?,"Tensors are nothing but a de facto for representing the data in deep learning. They are just multidimensional arrays, which allows us to represent the data having higher dimensions. In general, we deal with high dimensional data sets where dimensions refer to different features present in the data set.","In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
Differentiate supervised and unsupervised deep learning procedures.,"A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.","supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",0
What do you understand by Tensors?,A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.,"Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.",1
What do you understand by Tensors?,A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.,the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,0
What is the cost function?,"Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.",the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,0
What do you understand by Tensors?,A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.,A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,1
What do you understand by Tensors?,A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.",0
What do you understand by Boltzmann Machine?,A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. hey dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.",0
What do you understand by Tensors?,A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.,"A tensor is a generalization of vectors and matrices, In short, a single-dimensional tensor can be represented as a vector.",1
What do you understand by Boltzmann Machine?,"A tensor is a generalization of vectors and matrices, In short, a single-dimensional tensor can be represented as a vector.",The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,0
What do you understand by Tensors?,A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.,"Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.",1
What do you understand by Tensors?,A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.,most important feature in an activation function is its ability to add non-linearity into a neural network.,0
What is the use of the Activation function?,"Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.","the Neural Network can successfully approximate functions which does not follow linearity, into the output of a neuron.",0
What do you understand by Tensors?,A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.,"A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.",1
What do you understand by Tensors?,A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.,The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,0
What is the use of leaky ReLU function?,"A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.","Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",0
What do you understand by Tensors?,"Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.",A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,1
What do you understand by Tensors?,"Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.","The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.",0
What is the softmax function?,A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,"The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",0
What do you understand by Tensors?,"Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.","A tensor is a generalization of vectors and matrices, In short, a single-dimensional tensor can be represented as a vector.",1
What do you understand by Tensors?,"Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.","the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.",0
Explain Data Normalization.,"A tensor is a generalization of vectors and matrices, In short, a single-dimensional tensor can be represented as a vector.","change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",0
What do you understand by Tensors?,"Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.","Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.",1
What do you understand by Tensors?,"Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.",is one of the most common activation function in neural networks. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,0
What is a binary step function?,"Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.","is one of the most common activation function in neural networks. if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",0
What do you understand by Tensors?,"Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.","A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.",1
What do you understand by Tensors?,"Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.",This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,0
Explain the layer of CNN: convolution,"A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.",A convolution is the simple application of a filter to an input that results in an activation.,0
What do you understand by Tensors?,A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,"A tensor is a generalization of vectors and matrices, In short, a single-dimensional tensor can be represented as a vector.",1
What do you understand by Tensors?,A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,"Both shallow and deep networks are good enough and capable of approximating any function. But for the same level of accuracy, deeper networks can be much more efficient in terms of computation and number of parameters. Deeper networks can create deep representations. At every layer, the network learns a new, more abstract representation of the input.",0
Do you think that deep network is better than a shallow one?,"A tensor is a generalization of vectors and matrices, In short, a single-dimensional tensor can be represented as a vector.",Shallow means that number of hidden layer = 1 . And in case of deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . So generally as we increase the depth of the model we increase the power of the model at the cost of the computational complexity .,0
What do you understand by Tensors?,A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,"Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.",1
What do you understand by Tensors?,A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.",0
Explain the following variant of Gradient Descent mini-batch?,"Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.","This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",0
What do you understand by Tensors?,A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,"A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.",1
What do you understand by Tensors?,A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,0
What is Tanh function?,"A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.","rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",0
What do you understand by Tensors?,"A tensor is a generalization of vectors and matrices, In short, a single-dimensional tensor can be represented as a vector.","Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.",1
What do you understand by Tensors?,"A tensor is a generalization of vectors and matrices, In short, a single-dimensional tensor can be represented as a vector.","Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.",0
Explain the layer of CNN: Full Collectedness,"Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.",aims to map the activation volume from the combination of previous different layers into a class probability distribution.,0
What do you understand by Tensors?,"A tensor is a generalization of vectors and matrices, In short, a single-dimensional tensor can be represented as a vector.","A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.",1
What do you understand by Tensors?,"A tensor is a generalization of vectors and matrices, In short, a single-dimensional tensor can be represented as a vector.","convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery",0
What do you understand by a convolutional neural network?,"A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.","A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.",0
What do you understand by Tensors?,"Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.","A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.",1
What do you understand by Tensors?,"Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.",This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,0
What is the use of encoder layers in Autoencoders?,"A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.",The encoder layer encodes the input image as a compressed representation. It can be represented by an encoding function h=f(x).,0
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.",Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. They dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.,1
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.","Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.",0
"What do you mean by ""overfitting""?",Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. They dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.,occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,0
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.",The main purpose of Boltzmann Machine is to optimize the solution of a problem. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,1
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.","a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",0
Explain the following variant of Gradient Descent mini-batch?,The main purpose of Boltzmann Machine is to optimize the solution of a problem. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.",0
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.","A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.",1
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.","Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.",0
What is a Swish function?,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.","Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.",0
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.",Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,1
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Deep Autoencoders?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,"Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",0
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.",The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,1
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.",The hidden layer after the input layer and before the ouput layer.,0
what do you know about hidden layer?,The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,"The hidden layer is used to send data, There may be one or more of these layers.",0
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.","A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. hey dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.",1
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.","RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.",0
Explain the layer of CNN: ReLU,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. hey dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.","the most commonly deployed activation function, such as the max(0,x) thresholding at zero.",0
What do you understand by Boltzmann Machine?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. They dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.,The main purpose of Boltzmann Machine is to optimize the solution of a problem. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,1
What do you understand by Boltzmann Machine?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. They dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,0
What is the meaning of term weight initialization in neural networks?,The main purpose of Boltzmann Machine is to optimize the solution of a problem. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,"In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations",0
What do you understand by Boltzmann Machine?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. They dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.",1
What do you understand by Boltzmann Machine?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. They dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.,"The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.",0
What is Model Capacity?,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.","A model with too little capacity cannot learn the training dataset meaning it will underfit, whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",0
What do you understand by Boltzmann Machine?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. They dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,1
What do you understand by Boltzmann Machine?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. They dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.,The data is made available at the output layer.,0
what do you know about output layer?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,"The output layer is the simplest, usually consisting of a single output for classification problems.",0
What do you understand by Boltzmann Machine?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. They dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.,The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,1
What do you understand by Boltzmann Machine?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. They dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.,fully connected neural network structure that drives the final classification decision.,0
Explain the layer of CNN: Full Collectedness,The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,"layer will compute the class scores, resulting a class probability distribution.",0
What do you understand by Boltzmann Machine?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. They dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. hey dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.",1
What do you understand by Boltzmann Machine?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. They dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.,The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,0
What is the use of decoder layers in Autoencoders?,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. hey dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.",This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,0
What do you understand by Boltzmann Machine?,The main purpose of Boltzmann Machine is to optimize the solution of a problem. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.",1
What do you understand by Boltzmann Machine?,The main purpose of Boltzmann Machine is to optimize the solution of a problem. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,aims to map the activation volume from the combination of previous different layers into a class probability distribution.,0
Explain the layer of CNN: Full Collectedness,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.",fully connected neural network structure that drives the final classification decision.,0
What do you understand by Boltzmann Machine?,The main purpose of Boltzmann Machine is to optimize the solution of a problem. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,1
What do you understand by Boltzmann Machine?,The main purpose of Boltzmann Machine is to optimize the solution of a problem. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,We combine corresponding values in an elementwise fashion to produce a new matrix.,0
What is matrix element-wise multiplication?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.",0
What do you understand by Boltzmann Machine?,The main purpose of Boltzmann Machine is to optimize the solution of a problem. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,1
What do you understand by Boltzmann Machine?,The main purpose of Boltzmann Machine is to optimize the solution of a problem. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,0
What is matrix element-wise multiplication?,The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.",0
What do you understand by Boltzmann Machine?,The main purpose of Boltzmann Machine is to optimize the solution of a problem. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. hey dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.",1
What do you understand by Boltzmann Machine?,The main purpose of Boltzmann Machine is to optimize the solution of a problem. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,"The softmax function is used to calculate the probability distribution of the event over 'n' different events, the output range will be between 0 to 1, and the sum of all the probabilities will be equal to one.",0
What is the softmax function?,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. hey dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.","The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.",0
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.",Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,1
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.",Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,0
Explain the following variant of Gradient Descent batch?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",0
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.",The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,1
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.",The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,0
What is the use of decoder layers in Autoencoders?,The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).,0
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.","A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. hey dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.",1
What do you understand by Boltzmann Machine?,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.",Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.,0
"What do you mean by ""overfitting""?","A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. hey dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.",Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,0
What do you understand by Boltzmann Machine?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,1
What do you understand by Boltzmann Machine?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,"AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?",The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,"AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
What do you understand by Boltzmann Machine?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. hey dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.",1
What do you understand by Boltzmann Machine?,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,"can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",0
What is a binary step function?,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. hey dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.","A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",0
What do you understand by Boltzmann Machine?,The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. hey dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.",1
What do you understand by Boltzmann Machine?,The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,the most commonly deployed activation function for the outputs of the CNN neurons.,0
What is Model Capacity?,"The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.","A model with too little capacity cannot learn the training dataset meaning it will underfit, whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",1
What is Model Capacity?,"The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.","A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",0
What do you understand by Perceptron?,"A model with too little capacity cannot learn the training dataset meaning it will underfit, whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,0
What is Model Capacity?,"The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.",The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,1
What is Model Capacity?,"The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.",Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,0
Explain the following variant of Gradient Descent Stochastic?,The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,This is a type of gradient descent which processes 1 training example per iteration,0
What is Model Capacity?,"The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.","Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit.",1
What is Model Capacity?,"The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.","Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",0
What is the use of leaky ReLU function?,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit.","the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",0
What is Model Capacity?,"The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.","The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.",1
What is Model Capacity?,"The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.","A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.",0
What is the cost function?,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.",the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,0
What is Model Capacity?,"The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.","The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. models with higher Capacity than needed are prompt to overfit, low Capacity tend to underfit.",1
What is Model Capacity?,"The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.",Overfitting is the most common issue which occurs in deep learning. It usually occurs when a deep learning algorithm apprehends the sound of specific data. It also appears when the particular algorithm is well suitable for the data and shows up when the algorithm or model represents high variance and low bias.,0
"What do you mean by ""overfitting""?","The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. models with higher Capacity than needed are prompt to overfit, low Capacity tend to underfit.",Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,0
What is Model Capacity?,"The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.","Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",1
What is Model Capacity?,"The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.","Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
What is Model Capacity?,"A model with too little capacity cannot learn the training dataset meaning it will underfit, whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,1
What is Model Capacity?,"A model with too little capacity cannot learn the training dataset meaning it will underfit, whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.","RNN) are the state of the art algorithm for sequential data, It is the first algorithm that remembers its input.",0
What is an RNN?,The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,0
What is Model Capacity?,"A model with too little capacity cannot learn the training dataset meaning it will underfit, whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.","Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit.",1
What is Model Capacity?,"A model with too little capacity cannot learn the training dataset meaning it will underfit, whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.","The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.",0
What do you mean by Dropout?,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit.","With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.",0
What is Model Capacity?,"A model with too little capacity cannot learn the training dataset meaning it will underfit, whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.","The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.",1
What is Model Capacity?,"A model with too little capacity cannot learn the training dataset meaning it will underfit, whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Autoencoder?,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.","Autoencoders are neural networks. Neural networks are composed of multiple layers, compress and encode data then learns how to reconstruct the data back from the reduced encoded",0
What is Model Capacity?,"A model with too little capacity cannot learn the training dataset meaning it will underfit, whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.","The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. models with higher Capacity than needed are prompt to overfit, low Capacity tend to underfit.",1
What is Model Capacity?,"A model with too little capacity cannot learn the training dataset meaning it will underfit, whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.","Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.",0
what do you know about hidden layer?,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. models with higher Capacity than needed are prompt to overfit, low Capacity tend to underfit.","Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.",0
What is Model Capacity?,"A model with too little capacity cannot learn the training dataset meaning it will underfit, whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.","Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",1
What do you understand by Autoencoder?,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.",0
What is Model Capacity?,The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit.",1
What is Model Capacity?,The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,"change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",0
Explain Data Normalization.,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit.",an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,0
What is Model Capacity?,The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.",1
What is Model Capacity?,The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,"An optimization algorithm that is used to minimize some function by repeatedly moving in the direction of steepest descent as specified by the negative of the gradient is known as gradient descent. It's an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameter of the function",0
Explain gradient descent?,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.","Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",0
What is Model Capacity?,The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. models with higher Capacity than needed are prompt to overfit, low Capacity tend to underfit.",1
What is Model Capacity?,The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,"trendy activation function for neural networks. The input data to the function is transformed into a value between 0.0 and 1.0. Input values that are much larger than 1.0 are transformed to the value 1.0. Similarly, values that are much smaller than 0.0 are transformed into 0.0. The shape of the function for all possible inputs is an S-shape from zero up through 0.5 to 1.0.",0
What is the sigmoid function?,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. models with higher Capacity than needed are prompt to overfit, low Capacity tend to underfit.",sigmoid function have been used as the activation function of artificial neurons. Sigmoid functions most often show a return value (y axis) in the range 0 to 1,0
What is Model Capacity?,The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",1
What is Model Capacity?,The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,0
What do you understand by Perceptron?,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",Perceptron is a machine learning algorithm that helps provide classified outcomes. This algorithm enables neurons to learn and processes elements in the training set one at a time.,0
What is Model Capacity?,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit.","The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.",1
What is Model Capacity?,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit.",This part of the network contains the reduced representation of the input that is fed into the decoder.,0
What is the use of code layers in Autoencoders?,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.",produced after encoding the input image.,0
What is Model Capacity?,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit.","The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. models with higher Capacity than needed are prompt to overfit, low Capacity tend to underfit.",1
What is Model Capacity?,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit.","In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
Differentiate supervised and unsupervised deep learning procedures.,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. models with higher Capacity than needed are prompt to overfit, low Capacity tend to underfit.","Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
What is Model Capacity?,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit.","Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",1
What is Model Capacity?,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit.","a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",0
What is the use of leaky ReLU function?,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.","the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",0
What is Model Capacity?,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.","The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. models with higher Capacity than needed are prompt to overfit, low Capacity tend to underfit.",1
What is Model Capacity?,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.",Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,0
What is deep learning?,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. models with higher Capacity than needed are prompt to overfit, low Capacity tend to underfit.","Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.",0
What is Model Capacity?,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.","Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",1
What is Model Capacity?,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.","Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.",0
Explain the following variant of Gradient Descent mini-batch?,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,0
What is Model Capacity?,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. models with higher Capacity than needed are prompt to overfit, low Capacity tend to underfit.","Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",1
What is Model Capacity?,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. models with higher Capacity than needed are prompt to overfit, low Capacity tend to underfit.","The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.",0
What is Tanh function?,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.","tanh produces output ranges from -1 and 1, and used as activation function.",0
What is the cost function?,"A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.",It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,1
What is the cost function?,"A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.","Instead of going through all examples, Stochastic Gradient Descent (SGD) performs the parameters update on each example.",0
Explain the following variant of Gradient Descent Stochastic?,It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,"the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.",0
What is the cost function?,"A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.","cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.",1
What is the cost function?,"A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.","can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",0
What is a binary step function?,"cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.","can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",0
What is the cost function?,"A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.",the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,1
What is the cost function?,"A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?",the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,"AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
What is the cost function?,"A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.",It is a function that measures the performance of a Machine Learning model for given data. to estimate the relationship between X and y.,1
What is the cost function?,"A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.","LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.",0
Explain the importance of LSTM.,It is a function that measures the performance of a Machine Learning model for given data. to estimate the relationship between X and y.,LSTMs have property of selectively remembering information to be used in the current neural network.,0
What is the cost function?,"A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.",cost functions are used to estimate how badly models are performing. The aim of supervised machine learning is to minimize the overall cost,1
What is the cost function?,"A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.","Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.",0
What are the disadvantages of deep learning?,cost functions are used to estimate how badly models are performing. The aim of supervised machine learning is to minimize the overall cost,Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,0
What is the cost function?,"A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.",the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,1
What is the cost function?,"A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.",Backpropagation is a process used to adjust the weights of a deep neural network. The weights that minimize the error,0
What is Backpropagation?,the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,"the method calculates the gradient of the error function with respect to the neural network's weights, It reduces the loss between the predicted values and the actual values.",0
What is the cost function?,It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,"cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.",1
What is the cost function?,It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,0
Explain the layer of CNN: ReLU,"cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.","Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.",0
What is the cost function?,It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,1
What is the cost function?,It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,"Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?",the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,"Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
What is the cost function?,It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,It is a function that measures the performance of a Machine Learning model for given data. to estimate the relationship between X and y.,1
What is the cost function?,It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. That causes the number of parameters to increase a lot.There are quite conclusive results that a deep network can fit functions better with less parameters than a shallow network.",0
Do you think that deep network is better than a shallow one?,It is a function that measures the performance of a Machine Learning model for given data. to estimate the relationship between X and y.,deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,0
What is the cost function?,It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,cost functions are used to estimate how badly models are performing. The aim of supervised machine learning is to minimize the overall cost,1
What is the cost function?,It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,"Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).",0
What is the use of leaky ReLU function?,cost functions are used to estimate how badly models are performing. The aim of supervised machine learning is to minimize the overall cost,the Leaky ReLU which attempts to resolve issues with traditional ReLU that are related to dying neural networks by allowing small values.,0
What is the cost function?,It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,1
What is the cost function?,It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,"The softmax function is used to calculate the probability distribution of the event over 'n' different events, the output range will be between 0 to 1, and the sum of all the probabilities will be equal to one.",0
What is the softmax function?,the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,"Softmax turns arbitrary real values into probabilities, The output values are between the range [0,1].",0
What is the cost function?,"cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.",the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,1
What is the cost function?,"cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Deep Autoencoders?,the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",0
What is the cost function?,"cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.",It is a function that measures the performance of a Machine Learning model for given data. to estimate the relationship between X and y.,1
What is the cost function?,"cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.",This part of the network represents the compressed input.,0
What is the use of code layers in Autoencoders?,It is a function that measures the performance of a Machine Learning model for given data. to estimate the relationship between X and y.,This part of the network represents the input that is fed into the decoder.,0
What is the cost function?,"cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.",cost functions are used to estimate how badly models are performing. The aim of supervised machine learning is to minimize the overall cost,1
What is the cost function?,"cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.","a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",0
What is the use of leaky ReLU function?,cost functions are used to estimate how badly models are performing. The aim of supervised machine learning is to minimize the overall cost,"the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",0
What is the cost function?,"cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.",the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,1
What is the cost function?,"cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.","If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.",0
Why is zero initialization not a good weight initialization process?,the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,"If all the weights are initialized with 0, leads the neurons to learn the same features during training.",0
What is the cost function?,the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,It is a function that measures the performance of a Machine Learning model for given data. to estimate the relationship between X and y.,1
What is the cost function?,the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,0
Explain the following variant of Gradient Descent mini-batch?,It is a function that measures the performance of a Machine Learning model for given data. to estimate the relationship between X and y.,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.",0
What is the cost function?,the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,cost functions are used to estimate how badly models are performing. The aim of supervised machine learning is to minimize the overall cost,1
What is the cost function?,the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,"Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.",0
Explain the layer of CNN: Full Collectedness,cost functions are used to estimate how badly models are performing. The aim of supervised machine learning is to minimize the overall cost,"layer will compute the class scores, resulting a class probability distribution.",0
What is the cost function?,the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,1
What is the cost function?,the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,0
What is the meaning of term weight initialization in neural networks?,the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,"In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations",0
What is the cost function?,It is a function that measures the performance of a Machine Learning model for given data. to estimate the relationship between X and y.,cost functions are used to estimate how badly models are performing. The aim of supervised machine learning is to minimize the overall cost,1
What is the cost function?,It is a function that measures the performance of a Machine Learning model for given data. to estimate the relationship between X and y.,"processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.",0
What is the function of the Fourier Transform in Deep Learning?,cost functions are used to estimate how badly models are performing. The aim of supervised machine learning is to minimize the overall cost,"processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",0
What is the cost function?,It is a function that measures the performance of a Machine Learning model for given data. to estimate the relationship between X and y.,the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,1
What is the cost function?,It is a function that measures the performance of a Machine Learning model for given data. to estimate the relationship between X and y.,"n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.",0
What is the meaning of term weight initialization in neural networks?,the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,0
What is the cost function?,cost functions are used to estimate how badly models are performing. The aim of supervised machine learning is to minimize the overall cost,the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,1
What is the cost function?,cost functions are used to estimate how badly models are performing. The aim of supervised machine learning is to minimize the overall cost,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,0
What do you mean by Dropout?,the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,"The basic idea of this method is to, based on probability drop out neurons from our original network, They are temporarily removed from the network.",0
Explain gradient descent?,"An optimization algorithm that is used to minimize some function by repeatedly moving in the direction of steepest descent as specified by the negative of the gradient is known as gradient descent. It's an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameter of the function","Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.",1
Explain gradient descent?,"An optimization algorithm that is used to minimize some function by repeatedly moving in the direction of steepest descent as specified by the negative of the gradient is known as gradient descent. It's an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameter of the function",Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,0
What is deep learning?,"Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.","Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.",0
Explain gradient descent?,"An optimization algorithm that is used to minimize some function by repeatedly moving in the direction of steepest descent as specified by the negative of the gradient is known as gradient descent. It's an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameter of the function","Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",1
Explain gradient descent?,"An optimization algorithm that is used to minimize some function by repeatedly moving in the direction of steepest descent as specified by the negative of the gradient is known as gradient descent. It's an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameter of the function",This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,0
What is the use of decoder layers in Autoencoders?,"Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).,0
Explain gradient descent?,"An optimization algorithm that is used to minimize some function by repeatedly moving in the direction of steepest descent as specified by the negative of the gradient is known as gradient descent. It's an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameter of the function",Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,1
Explain gradient descent?,"An optimization algorithm that is used to minimize some function by repeatedly moving in the direction of steepest descent as specified by the negative of the gradient is known as gradient descent. It's an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameter of the function","Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,",0
What is the function of the Fourier Transform in Deep Learning?,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,"processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.",0
Explain gradient descent?,"An optimization algorithm that is used to minimize some function by repeatedly moving in the direction of steepest descent as specified by the negative of the gradient is known as gradient descent. It's an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameter of the function","Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",1
Explain gradient descent?,"An optimization algorithm that is used to minimize some function by repeatedly moving in the direction of steepest descent as specified by the negative of the gradient is known as gradient descent. It's an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameter of the function","change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",0
Explain Data Normalization.,"Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,0
Explain gradient descent?,"An optimization algorithm that is used to minimize some function by repeatedly moving in the direction of steepest descent as specified by the negative of the gradient is known as gradient descent. It's an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameter of the function",Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,1
Explain gradient descent?,"An optimization algorithm that is used to minimize some function by repeatedly moving in the direction of steepest descent as specified by the negative of the gradient is known as gradient descent. It's an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameter of the function",A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,0
What do you understand by Perceptron?,Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,0
Explain gradient descent?,"An optimization algorithm that is used to minimize some function by repeatedly moving in the direction of steepest descent as specified by the negative of the gradient is known as gradient descent. It's an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameter of the function",Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,1
Explain gradient descent?,"An optimization algorithm that is used to minimize some function by repeatedly moving in the direction of steepest descent as specified by the negative of the gradient is known as gradient descent. It's an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameter of the function","The Rectified Linear Unit is the most commonly used activation function in deep learning models. The function returns 0 if it receives any negative input, but for any positive value x it returns that value back.",0
What is ReLU function?,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,piecewise function returns zero if input is negative.,0
Explain gradient descent?,"Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.","Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",1
Explain gradient descent?,"Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.","A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. That causes the number of parameters to increase a lot.There are quite conclusive results that a deep network can fit functions better with less parameters than a shallow network.",0
Do you think that deep network is better than a shallow one?,"Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.","deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,",0
Explain gradient descent?,"Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.",Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,1
Explain gradient descent?,"Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.","if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations",0
What is the meaning of term weight initialization in neural networks?,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,"In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.",0
Explain gradient descent?,"Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.","Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",1
Explain gradient descent?,"Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.",The hidden layer is used to send data to the output layer.,0
what do you know about hidden layer?,"Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",Hidden Layers: Layers of nodes between the input and output layers. There may be one or more of these layers.,0
Explain gradient descent?,"Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.",Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,1
Explain gradient descent?,"Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.","Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?",Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,"Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
Explain gradient descent?,"Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.",Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,1
Explain gradient descent?,"Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.","An encoder is a feedforward, fully connected neural network that compresses the input into a latent space representation and encodes the input image as a compressed representation in a reduced dimension.",0
What is the use of encoder layers in Autoencoders?,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,The encoder layer encodes the input image as a compressed representation. It can be represented by an encoding function h=f(x).,0
Explain gradient descent?,"Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,1
Explain gradient descent?,"Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.","processing a large dataset can be hard, but it can be considered a signal and be represented In fourier domain and making processing easy.",0
What is the function of the Fourier Transform in Deep Learning?,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,"processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",0
Explain gradient descent?,"Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.","Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",1
Explain gradient descent?,"Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.","a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",0
Explain the following variant of Gradient Descent mini-batch?,"Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.","a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.",0
Explain gradient descent?,"Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,1
Explain gradient descent?,"Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.","a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",0
What is the use of leaky ReLU function?,Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,"the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",0
Explain gradient descent?,"Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,1
Explain gradient descent?,"Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,0
What do you understand by Deep Autoencoders?,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",0
Explain gradient descent?,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,"Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",1
Explain gradient descent?,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,It requires very large amount of data in order to perform better than other techniques. Is extremely computationally expensive to train.,0
What are the disadvantages of deep learning?,"Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.","Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.",0
Explain gradient descent?,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,1
Explain gradient descent?,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,0
Explain the following variant of Gradient Descent batch?,Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,"Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.",0
Explain gradient descent?,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,1
Explain gradient descent?,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,Multilayer perceptrons or feedforward neural networks with two or more layers have the higher processing power.,0
what is a multilayer percepton?,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,0
Explain gradient descent?,"Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,1
Explain gradient descent?,"Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.","Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.",0
Differentiate supervised and unsupervised deep learning procedures.,Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,"In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
Explain gradient descent?,"Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,1
Explain gradient descent?,"Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,0
What is the use of the Activation function?,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,0
Explain gradient descent?,Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,1
Explain gradient descent?,Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,"supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",0
Differentiate supervised and unsupervised deep learning procedures.,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,"Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
Explain the following variant of Gradient Descent Stochastic?,Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,This is a type of gradient descent which processes 1 training example per iteration,1
Explain the following variant of Gradient Descent Stochastic?,Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,0
Explain the following variant of Gradient Descent batch?,This is a type of gradient descent which processes 1 training example per iteration,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,0
Explain the following variant of Gradient Descent Stochastic?,Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,"Instead of going through all examples, Stochastic Gradient Descent (SGD) performs the parameters update on each example.",1
Explain the following variant of Gradient Descent Stochastic?,Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,"Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.",0
Explain the following variant of Gradient Descent batch?,"Instead of going through all examples, Stochastic Gradient Descent (SGD) performs the parameters update on each example.","Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",0
Explain the following variant of Gradient Descent Stochastic?,Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,"the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.",1
Explain the following variant of Gradient Descent Stochastic?,Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,"Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",0
Explain gradient descent?,"the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.",Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,0
Explain the following variant of Gradient Descent Stochastic?,Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,This is a type of gradient descent which update the parameters on each example.,1
Explain the following variant of Gradient Descent Stochastic?,Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,0
What do you understand by Perceptron?,This is a type of gradient descent which update the parameters on each example.,A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,0
Explain the following variant of Gradient Descent Stochastic?,Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,"Instead of going through all examples, the gradient based on a single training sample.",1
Explain the following variant of Gradient Descent Stochastic?,Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,0
What is the function of the Fourier Transform in Deep Learning?,"Instead of going through all examples, the gradient based on a single training sample.","data can be considered a signal, and making convolution easier.",0
Explain the following variant of Gradient Descent Stochastic?,Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,"the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration",1
Explain the following variant of Gradient Descent Stochastic?,Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,"By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.",0
Explain Data Normalization.,"the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration","change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",0
Explain the following variant of Gradient Descent Stochastic?,This is a type of gradient descent which processes 1 training example per iteration,"Instead of going through all examples, Stochastic Gradient Descent (SGD) performs the parameters update on each example.",1
Explain the following variant of Gradient Descent Stochastic?,This is a type of gradient descent which processes 1 training example per iteration,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Autoencoder?,"Instead of going through all examples, Stochastic Gradient Descent (SGD) performs the parameters update on each example.","Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.",0
Explain the following variant of Gradient Descent Stochastic?,This is a type of gradient descent which processes 1 training example per iteration,"the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.",1
Explain the following variant of Gradient Descent Stochastic?,This is a type of gradient descent which processes 1 training example per iteration,"RNN stands for Recurrent Neural Networks. These are the artificial neural networks which are designed to recognize patterns in sequences of data such as handwriting, text, the spoken word, genomes, and numerical time series data.",0
What is an RNN?,"the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.","RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.",0
Explain the following variant of Gradient Descent Stochastic?,This is a type of gradient descent which processes 1 training example per iteration,This is a type of gradient descent which update the parameters on each example.,1
Explain the following variant of Gradient Descent Stochastic?,This is a type of gradient descent which processes 1 training example per iteration,Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,0
Explain gradient descent?,This is a type of gradient descent which update the parameters on each example.,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,0
Explain the following variant of Gradient Descent Stochastic?,This is a type of gradient descent which processes 1 training example per iteration,"Instead of going through all examples, the gradient based on a single training sample.",1
Explain the following variant of Gradient Descent Stochastic?,This is a type of gradient descent which processes 1 training example per iteration,"layer takes in the inputs which are passed in from the layers before it, performs the calculations via its neurons and then the output is computed.",0
what do you know about output layer?,"Instead of going through all examples, the gradient based on a single training sample.",The data is made available the output variables.,0
Explain the following variant of Gradient Descent Stochastic?,This is a type of gradient descent which processes 1 training example per iteration,"the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration",1
Explain the following variant of Gradient Descent Stochastic?,This is a type of gradient descent which processes 1 training example per iteration,"It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.",0
Explain the importance of LSTM.,"the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration","LSTM use persistent previous information to classifying, processing and making predictions based on time series data",0
Explain the following variant of Gradient Descent Stochastic?,"Instead of going through all examples, Stochastic Gradient Descent (SGD) performs the parameters update on each example.","the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.",1
Explain the following variant of Gradient Descent Stochastic?,"Instead of going through all examples, Stochastic Gradient Descent (SGD) performs the parameters update on each example.","Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.",0
Explain the layer of CNN: ReLU,"the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.","the most commonly deployed activation function, such as the max(0,x) thresholding at zero.",0
Explain the following variant of Gradient Descent Stochastic?,"Instead of going through all examples, Stochastic Gradient Descent (SGD) performs the parameters update on each example.",This is a type of gradient descent which update the parameters on each example.,1
Explain the layer of CNN: ReLU,This is a type of gradient descent which update the parameters on each example.,"the most commonly deployed activation function, such as the max(0,x) thresholding at zero.",0
Explain the following variant of Gradient Descent Stochastic?,"Instead of going through all examples, Stochastic Gradient Descent (SGD) performs the parameters update on each example.","Instead of going through all examples, the gradient based on a single training sample.",1
Explain the following variant of Gradient Descent Stochastic?,"Instead of going through all examples, Stochastic Gradient Descent (SGD) performs the parameters update on each example.","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","Instead of going through all examples, the gradient based on a single training sample.","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
Explain the following variant of Gradient Descent Stochastic?,"Instead of going through all examples, Stochastic Gradient Descent (SGD) performs the parameters update on each example.","the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration",1
Explain the following variant of Gradient Descent Stochastic?,"Instead of going through all examples, Stochastic Gradient Descent (SGD) performs the parameters update on each example.",The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,0
Explain the layer of CNN: convolution,"the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration",A convolution is the simple application of a filter to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,0
Explain the following variant of Gradient Descent Stochastic?,"the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.",This is a type of gradient descent which update the parameters on each example.,1
Explain the following variant of Gradient Descent Stochastic?,"the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.",This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,0
Explain the following variant of Gradient Descent batch?,This is a type of gradient descent which update the parameters on each example.,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",0
Explain the following variant of Gradient Descent Stochastic?,"the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.","Instead of going through all examples, the gradient based on a single training sample.",1
Explain the following variant of Gradient Descent Stochastic?,"the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.","Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",0
Explain gradient descent?,"Instead of going through all examples, the gradient based on a single training sample.",Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,0
Explain the following variant of Gradient Descent Stochastic?,"the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.","the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration",1
Explain the following variant of Gradient Descent Stochastic?,"the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.","Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.",0
what do you know about hidden layer?,"the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration","Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.",0
Explain the following variant of Gradient Descent Stochastic?,This is a type of gradient descent which update the parameters on each example.,"Instead of going through all examples, the gradient based on a single training sample.",1
Explain the following variant of Gradient Descent Stochastic?,This is a type of gradient descent which update the parameters on each example.,"deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,",0
Do you think that deep network is better than a shallow one?,"Instead of going through all examples, the gradient based on a single training sample.",Shallow means that number of hidden layer = 1 . And in case of deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . So generally as we increase the depth of the model we increase the power of the model at the cost of the computational complexity .,0
Explain the following variant of Gradient Descent Stochastic?,This is a type of gradient descent which update the parameters on each example.,"the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration",1
Explain the following variant of Gradient Descent Stochastic?,This is a type of gradient descent which update the parameters on each example.,"Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,",0
What is the function of the Fourier Transform in Deep Learning?,"the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration","processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",0
Explain the following variant of Gradient Descent Stochastic?,"Instead of going through all examples, the gradient based on a single training sample.","the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration",1
Explain the following variant of Gradient Descent Stochastic?,"Instead of going through all examples, the gradient based on a single training sample.","Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.",0
What is deep learning?,"the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration","Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.",0
Explain the following variant of Gradient Descent batch?,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,1
Explain the following variant of Gradient Descent batch?,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,"Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.",0
What is deep learning?,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,0
Explain the following variant of Gradient Descent batch?,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,1
Explain the following variant of Gradient Descent batch?,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit.",0
What is Model Capacity?,This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. models with higher Capacity than needed are prompt to overfit, low Capacity tend to underfit.",0
Explain the following variant of Gradient Descent batch?,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally after each iteration over the training dataset.",1
Explain the following variant of Gradient Descent batch?,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,will perform a downsampling operation along the spatial dimensions for flatten as it is converted to a single dimension array.,0
Explain the layer of CNN: pooling,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally after each iteration over the training dataset.","pooling or downsampling layer is responsible for reducing the spatial dimensions (width, height), resulting in volume such as [16x16x12].",0
Explain the following variant of Gradient Descent batch?,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,"Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.",1
Explain the following variant of Gradient Descent batch?,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,We combine corresponding values in an elementwise fashion to produce a new matrix.,0
What is matrix element-wise multiplication?,"Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.","We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.",0
Explain the following variant of Gradient Descent batch?,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,"This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",1
Explain the following variant of Gradient Descent batch?,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,has the same structure of a single layer perceptron with one or more hidden layers.,0
what is a multilayer percepton?,"This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,0
Explain the following variant of Gradient Descent batch?,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",1
Explain the following variant of Gradient Descent batch?,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,0
Differentiate supervised and unsupervised deep learning procedures.,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.","Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
Explain the following variant of Gradient Descent batch?,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,1
Explain the following variant of Gradient Descent batch?,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,"data can be considered a signal, and making convolution easier.",0
What is the function of the Fourier Transform in Deep Learning?,This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,"processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",0
Explain the following variant of Gradient Descent batch?,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally after each iteration over the training dataset.",1
Explain the following variant of Gradient Descent batch?,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,"Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU on deep networks applied to a variety of challenging domains such as Image classification and Machine translation.",0
What is a Swish function?,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally after each iteration over the training dataset.","Swish is a smooth, non-monotonic function that consistently matches or outperforms ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance.",0
Explain the following variant of Gradient Descent batch?,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,"Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.",1
Explain the following variant of Gradient Descent batch?,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,Overfitting refers to a model that models the training data too well. Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data.,0
"What do you mean by ""overfitting""?","Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.",Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,0
Explain the following variant of Gradient Descent batch?,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,"This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",1
Explain the following variant of Gradient Descent batch?,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.",0
Explain the following variant of Gradient Descent mini-batch?,"This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.","Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.",0
Explain the following variant of Gradient Descent batch?,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",1
Explain the following variant of Gradient Descent batch?,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",0
What do you understand by Deep Autoencoders?,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",0
Explain the following variant of Gradient Descent batch?,This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally after each iteration over the training dataset.",1
Explain the following variant of Gradient Descent batch?,This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,0
what is a single percepton?,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally after each iteration over the training dataset.","As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",0
Explain the following variant of Gradient Descent batch?,This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,"Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.",1
Explain the following variant of Gradient Descent batch?,This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,0
Explain gradient descent?,"Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.",Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,0
Explain the following variant of Gradient Descent batch?,This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,"This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",1
Explain the following variant of Gradient Descent batch?,This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,"Supervised learning is a system in which both input and desired output data are provided. Input and output data are labeled to provide a learning basis for future data processing.Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same. The common unsupervised learning method is cluster analysis. It is used for exploratory data analysis to find hidden patterns or grouping in data.",0
Differentiate supervised and unsupervised deep learning procedures.,"This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.","supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",0
Explain the following variant of Gradient Descent batch?,This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",1
Explain the following variant of Gradient Descent batch?,This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,0
Explain the layer of CNN: convolution,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",This layer computes the convolutions between the neurons of an input that results in an activation.,0
Explain the following variant of Gradient Descent batch?,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally after each iteration over the training dataset.","Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.",1
Explain the following variant of Gradient Descent batch?,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally after each iteration over the training dataset.","while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.",0
Explain the layer of CNN: pooling,"Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.",pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,0
Explain the following variant of Gradient Descent batch?,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally after each iteration over the training dataset.","This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",1
Explain the following variant of Gradient Descent batch?,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally after each iteration over the training dataset.",A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,0
what is a single percepton?,"This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,0
Explain the following variant of Gradient Descent batch?,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally after each iteration over the training dataset.","Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",1
Explain the following variant of Gradient Descent batch?,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally after each iteration over the training dataset.",The hidden layer is used to send data to the output layer.,0
what do you know about hidden layer?,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.","The hidden layer is used to send data, There may be one or more of these layers.",0
Explain the following variant of Gradient Descent batch?,"Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.","This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",1
Explain the following variant of Gradient Descent batch?,"Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.","a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",0
What is the use of leaky ReLU function?,"This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,0
Explain the following variant of Gradient Descent batch?,"Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.","Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",1
Explain the following variant of Gradient Descent batch?,"Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.","Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.",0
Explain the following variant of Gradient Descent mini-batch?,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.","Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples.Here b examples where b<m are processed per iteration.",0
Explain the following variant of Gradient Descent batch?,"This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.","Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",1
Explain the following variant of Gradient Descent batch?,"This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,0
What is the meaning of term weight initialization in neural networks?,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.","initializing weights with too-small values will lead to divergence, too-large values will lead to exploding.",0
Explain the following variant of Gradient Descent mini-batch?,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.","Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.",1
Explain the following variant of Gradient Descent mini-batch?,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.","The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.",0
What is Tanh function?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.","Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),",0
Explain the following variant of Gradient Descent mini-batch?,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.",This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,1
Explain the following variant of Gradient Descent mini-batch?,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.","With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.",0
What do you mean by Dropout?,This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,0
Explain the following variant of Gradient Descent mini-batch?,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.","a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",1
Explain the following variant of Gradient Descent mini-batch?,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.","will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]",0
Explain the layer of CNN: pooling,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",will perform a downsampling operation along the spatial dimensions for flatten as it is converted to a single dimension array.,0
Explain the following variant of Gradient Descent mini-batch?,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.","Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples.Here b examples where b<m are processed per iteration.",1
Explain the following variant of Gradient Descent mini-batch?,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.","a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",0
What is the use of leaky ReLU function?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples.Here b examples where b<m are processed per iteration.","the Leaky ReLU which attempts to resolve issues with traditional ReLU by allowing a small, non-zero, constant gradient Î±",0
Explain the following variant of Gradient Descent mini-batch?,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.","This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",1
Explain the following variant of Gradient Descent mini-batch?,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.","can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",0
What is a binary step function?,"This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples","can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",0
Explain the following variant of Gradient Descent mini-batch?,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.","a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.",1
Explain the following variant of Gradient Descent mini-batch?,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.",Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,0
"What do you mean by ""overfitting""?","a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.","Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.",0
Explain the following variant of Gradient Descent mini-batch?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.",This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,1
Explain the following variant of Gradient Descent mini-batch?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.","Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.",0
What is Backpropagation?,This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,"the method calculates the gradient of the error function with respect to the neural network's weights, It reduces the loss between the predicted values and the actual values.",0
Explain the following variant of Gradient Descent mini-batch?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.","a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",1
Explain the following variant of Gradient Descent mini-batch?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.",The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,0
Explain the layer of CNN: convolution,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,0
Explain the following variant of Gradient Descent mini-batch?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.","Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples.Here b examples where b<m are processed per iteration.",1
Explain the following variant of Gradient Descent mini-batch?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.",Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,0
What is matrix element-wise multiplication?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples.Here b examples where b<m are processed per iteration.",We combine corresponding values in an elementwise fashion to produce a new matrix.,0
Explain the following variant of Gradient Descent mini-batch?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.","This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",1
Explain the following variant of Gradient Descent mini-batch?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.",This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,0
What is the use of decoder layers in Autoencoders?,"This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).,0
Explain the following variant of Gradient Descent mini-batch?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.","a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.",1
Explain the following variant of Gradient Descent mini-batch?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.","A multilayer perceptron is a neural network connecting multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",0
what is a multilayer percepton?,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.","has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",0
Explain the following variant of Gradient Descent mini-batch?,This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",1
Explain the following variant of Gradient Descent mini-batch?,This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,0
Explain the layer of CNN: convolution,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",A convolution is the simple application of a filter to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,0
Explain the following variant of Gradient Descent mini-batch?,This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples.Here b examples where b<m are processed per iteration.",1
Explain the following variant of Gradient Descent mini-batch?,This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,"layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",0
Explain the layer of CNN: Full Collectedness,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples.Here b examples where b<m are processed per iteration.",aims to map the activation volume from the combination of previous different layers into a class probability distribution.,0
Explain the following variant of Gradient Descent mini-batch?,This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,"This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",1
Explain the following variant of Gradient Descent mini-batch?,This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,"deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,",0
Do you think that deep network is better than a shallow one?,"This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",Shallow means that number of hidden layer = 1 . And in case of deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . So generally as we increase the depth of the model we increase the power of the model at the cost of the computational complexity .,0
Explain the following variant of Gradient Descent mini-batch?,This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.",1
Explain the following variant of Gradient Descent mini-batch?,This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,"Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.",0
"What do you mean by ""overfitting""?","a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.",occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,0
Explain the following variant of Gradient Descent mini-batch?,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples","Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples.Here b examples where b<m are processed per iteration.",1
Explain the following variant of Gradient Descent mini-batch?,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples","A node or unit which implements the activation function is referred to as a rectified linear activation unit or ReLU for short. Generally, networks that use the rectifier function for the hidden layers are referred to as rectified networks.",0
What is ReLU function?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples.Here b examples where b<m are processed per iteration.","the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.",0
Explain the following variant of Gradient Descent mini-batch?,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples","This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",1
Explain the following variant of Gradient Descent mini-batch?,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples","Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.",0
what do you know about hidden layer?,"This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",Hidden Layers: Layers of nodes between the input and output layers. There may be one or more of these layers.,0
Explain the following variant of Gradient Descent mini-batch?,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples","a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.",1
Explain the following variant of Gradient Descent mini-batch?,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,0
Explain the following variant of Gradient Descent batch?,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.","Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",0
Explain the following variant of Gradient Descent mini-batch?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples.Here b examples where b<m are processed per iteration.","This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",1
Explain the following variant of Gradient Descent mini-batch?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples.Here b examples where b<m are processed per iteration.","deep network you have lots and lots of computational nodes and lots of layers of those nodes. A shallower network means that there are fewer computations so it is less math going on,",0
Explain the following variant of Gradient Descent mini-batch?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples.Here b examples where b<m are processed per iteration.","a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.",1
Explain the following variant of Gradient Descent mini-batch?,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples.Here b examples where b<m are processed per iteration.",This part of the network contains the reduced representation of the input that is fed into the decoder.,0
What is the use of code layers in Autoencoders?,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.",produced after encoding the input image.,0
Explain the following variant of Gradient Descent mini-batch?,"This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples","a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.",1
Explain the following variant of Gradient Descent mini-batch?,"This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,0
What is deep learning?,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.","Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.",0
What is matrix element-wise multiplication?,Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,We combine corresponding values in an elementwise fashion to produce a new matrix.,1
What is matrix element-wise multiplication?,Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. A model with too little capacity cannot learn the training dataset meaning it will underfit, A model with high capacity will overfit.",0
What is Model Capacity?,We combine corresponding values in an elementwise fashion to produce a new matrix.,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",0
What is matrix element-wise multiplication?,Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.",1
What is matrix element-wise multiplication?,Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.",0
Do you think that deep network is better than a shallow one?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.",deep network you have lots and lots of computational nodes and lots of layers of those nodes. Shallow means that number of hidden layer = 1 .,0
What is matrix element-wise multiplication?,Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,multiplies arrays A and B of same dimension by multiplying corresponding elements.,1
What is matrix element-wise multiplication?,Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,0
what do you know about input layer?,multiplies arrays A and B of same dimension by multiplying corresponding elements.,The input layer is contains your raw data. which send information to the hidden layer.,0
What is matrix element-wise multiplication?,Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,"We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.",1
What is matrix element-wise multiplication?,Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,0
Explain the layer of CNN: ReLU,"We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.","Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.",0
What is matrix element-wise multiplication?,Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.",1
What is matrix element-wise multiplication?,Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,used as activation function a sigmoid neuron outputs a more smooth or continous range of values between 0 and 1.,0
What is the sigmoid function?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.","The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.",0
What is matrix element-wise multiplication?,Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,multiplies arrays A and B of same dimension to produce a new matrix.,1
What is matrix element-wise multiplication?,Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,0
Explain the following variant of Gradient Descent batch?,multiplies arrays A and B of same dimension to produce a new matrix.,"This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",0
What is matrix element-wise multiplication?,We combine corresponding values in an elementwise fashion to produce a new matrix.,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.",1
What is matrix element-wise multiplication?,We combine corresponding values in an elementwise fashion to produce a new matrix.,This is a type of gradient descent which update the parameters on each example.,0
Explain the following variant of Gradient Descent Stochastic?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.","Instead of going through all examples, the gradient based on a single training sample.",0
What is matrix element-wise multiplication?,We combine corresponding values in an elementwise fashion to produce a new matrix.,multiplies arrays A and B of same dimension by multiplying corresponding elements.,1
What is matrix element-wise multiplication?,We combine corresponding values in an elementwise fashion to produce a new matrix.,This is a type of gradient descent which processes all the training examples for each iteration of gradient descent.,0
Explain the following variant of Gradient Descent batch?,multiplies arrays A and B of same dimension by multiplying corresponding elements.,"Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.",0
What is matrix element-wise multiplication?,We combine corresponding values in an elementwise fashion to produce a new matrix.,"We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.",1
What is matrix element-wise multiplication?,We combine corresponding values in an elementwise fashion to produce a new matrix.,"Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.",0
What is the use of the Activation function?,"We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.",most important feature in an activation function is its ability to add non-linearity or it can successfully predict the class of a function which is divided by a decision,0
What is matrix element-wise multiplication?,We combine corresponding values in an elementwise fashion to produce a new matrix.,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.",1
What is matrix element-wise multiplication?,We combine corresponding values in an elementwise fashion to produce a new matrix.,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery",0
What do you understand by a convolutional neural network?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.","convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.",0
What is matrix element-wise multiplication?,We combine corresponding values in an elementwise fashion to produce a new matrix.,multiplies arrays A and B of same dimension to produce a new matrix.,1
What is matrix element-wise multiplication?,We combine corresponding values in an elementwise fashion to produce a new matrix.,"AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?",multiplies arrays A and B of same dimension to produce a new matrix.,"Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
What is matrix element-wise multiplication?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.",multiplies arrays A and B of same dimension by multiplying corresponding elements.,1
What is matrix element-wise multiplication?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.","n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.",0
What is the meaning of term weight initialization in neural networks?,multiplies arrays A and B of same dimension by multiplying corresponding elements.,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,0
What is matrix element-wise multiplication?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.","We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.",1
What is matrix element-wise multiplication?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.",A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,0
What do you understand by Tensors?,"We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.","A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.",0
What is matrix element-wise multiplication?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.","takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.",1
What is matrix element-wise multiplication?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.","the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.",0
Explain the following variant of Gradient Descent Stochastic?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.","the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration",0
What is matrix element-wise multiplication?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.",multiplies arrays A and B of same dimension to produce a new matrix.,1
What is matrix element-wise multiplication?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.","A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.",0
What is the cost function?,multiplies arrays A and B of same dimension to produce a new matrix.,the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,0
What is matrix element-wise multiplication?,multiplies arrays A and B of same dimension by multiplying corresponding elements.,"We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.",1
What is matrix element-wise multiplication?,multiplies arrays A and B of same dimension by multiplying corresponding elements.,"A tensor is a generalization of vectors and matrices, In short, a single-dimensional tensor can be represented as a vector.",0
What do you understand by Tensors?,"We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.","Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.",0
What is matrix element-wise multiplication?,multiplies arrays A and B of same dimension by multiplying corresponding elements.,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.",1
What is matrix element-wise multiplication?,multiplies arrays A and B of same dimension by multiplying corresponding elements.,"This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",0
Explain the following variant of Gradient Descent batch?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.","Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",0
What is matrix element-wise multiplication?,multiplies arrays A and B of same dimension by multiplying corresponding elements.,multiplies arrays A and B of same dimension to produce a new matrix.,1
What is matrix element-wise multiplication?,multiplies arrays A and B of same dimension by multiplying corresponding elements.,The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,0
Explain the layer of CNN: convolution,multiplies arrays A and B of same dimension to produce a new matrix.,This layer computes the convolutions between the neurons of an input that results in an activation.,0
What is matrix element-wise multiplication?,"We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.","takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.",1
What is matrix element-wise multiplication?,"We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.",A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,0
What do you understand by Tensors?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.","A tensor is a generalization of vectors and matrices, In short, a single-dimensional tensor can be represented as a vector.",0
What is matrix element-wise multiplication?,"We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.",multiplies arrays A and B of same dimension to produce a new matrix.,1
What is matrix element-wise multiplication?,"We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.","The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.",0
What is a binary step function?,multiplies arrays A and B of same dimension to produce a new matrix.,"A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",0
What is matrix element-wise multiplication?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.",multiplies arrays A and B of same dimension to produce a new matrix.,1
What is matrix element-wise multiplication?,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.",This part of the network contains the reduced representation of the input that is fed into the decoder.,0
What is the use of code layers in Autoencoders?,multiplies arrays A and B of same dimension to produce a new matrix.,This part of the network contains the reduced representation after encoding the input image.,0
What do you understand by a convolutional neural network?,"A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.",A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data.,1
What do you understand by a convolutional neural network?,"A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.","A node or unit which implements the activation function is referred to as a rectified linear activation unit or ReLU for short. Generally, networks that use the rectifier function for the hidden layers are referred to as rectified networks.",0
What is ReLU function?,A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data.,the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,0
What do you understand by a convolutional neural network?,"A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.","convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery",1
What do you understand by a convolutional neural network?,"A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.",Initializing all the weights with zeros leads the neurons to learn the same features during training.,0
Why is zero initialization not a good weight initialization process?,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery","Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.",0
What do you understand by a convolutional neural network?,"A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.","A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.",1
What do you understand by a convolutional neural network?,"A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.","will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]",0
Explain the layer of CNN: pooling,"A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.","pooling or downsampling layer is responsible for reducing the spatial dimensions (width, height), resulting in volume such as [16x16x12].",0
What do you understand by a convolutional neural network?,"A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.",A convolutional neural network (CNN) is a type of artificial neural network most commonly applied to analyzing visual imagery.,1
What do you understand by a convolutional neural network?,"A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.",The code layer is used to represent the compressed input which is fed to the decoder.,0
What is the use of code layers in Autoencoders?,A convolutional neural network (CNN) is a type of artificial neural network most commonly applied to analyzing visual imagery.,This part of the network represents the compressed input.,0
What do you understand by a convolutional neural network?,"A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.","convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.",1
What do you understand by a convolutional neural network?,"A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.","tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.",0
What is Tanh function?,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.","The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.",0
What do you understand by a convolutional neural network?,"A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.","A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.",1
What do you understand by a convolutional neural network?,"A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.",Deep learning is an artificial intelligence (AI) function that imitates the workings of the human brain in processing data and creating patterns for use in decision making.,0
What is deep learning?,"A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.","Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.",0
What do you understand by a convolutional neural network?,A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data.,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery",1
What do you understand by a convolutional neural network?,A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data.,aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,0
Explain the layer of CNN: Full Collectedness,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery","fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",0
What do you understand by a convolutional neural network?,A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data.,"A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.",1
What do you understand by a convolutional neural network?,A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data.,"layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",0
Explain the layer of CNN: Full Collectedness,"A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.",aims to map the activation volume from the combination of previous different layers into a class probability distribution.,0
What do you understand by a convolutional neural network?,A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data.,A convolutional neural network (CNN) is a type of artificial neural network most commonly applied to analyzing visual imagery.,1
What do you understand by a convolutional neural network?,A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data.,Performing convolutions efficiently as products in the Fourier domain. When each sample in the dataset is a signal,0
What is the function of the Fourier Transform in Deep Learning?,A convolutional neural network (CNN) is a type of artificial neural network most commonly applied to analyzing visual imagery.,"data can be considered a signal, and making convolution easier.",0
What do you understand by a convolutional neural network?,A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data.,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.",1
What do you understand by a convolutional neural network?,A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data.,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.",0
What do you understand by Boltzmann Machine?,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.","A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. hey dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.",0
What do you understand by a convolutional neural network?,A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data.,"A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.",1
What do you understand by a convolutional neural network?,A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data.,initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,0
What is the meaning of term weight initialization in neural networks?,"A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.","In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations",0
What do you understand by a convolutional neural network?,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery","A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.",1
What do you understand by a convolutional neural network?,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
What do you understand by a convolutional neural network?,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery",A convolutional neural network (CNN) is a type of artificial neural network most commonly applied to analyzing visual imagery.,1
What do you understand by a convolutional neural network?,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery",It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,0
Explain the layer of CNN: pooling,A convolutional neural network (CNN) is a type of artificial neural network most commonly applied to analyzing visual imagery.,will perform a downsampling operation along the spatial dimensions for flatten as it is converted to a single dimension array.,0
What do you understand by a convolutional neural network?,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery","convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.",1
What do you understand by a convolutional neural network?,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery",LSTM use persistent previous information to be used in the current neural network.,0
Explain the importance of LSTM.,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.","LSTM use persistent previous information to classifying, processing and making predictions based on time series data",0
What do you understand by a convolutional neural network?,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery","A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.",1
What do you understand by a convolutional neural network?,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery","a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",0
What is the use of leaky ReLU function?,"A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.","Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",0
What do you understand by a convolutional neural network?,"A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.",A convolutional neural network (CNN) is a type of artificial neural network most commonly applied to analyzing visual imagery.,1
What do you understand by a convolutional neural network?,"A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.","The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.",0
What do you mean by Dropout?,A convolutional neural network (CNN) is a type of artificial neural network most commonly applied to analyzing visual imagery.,Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,0
What do you understand by a convolutional neural network?,"A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.","convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.",1
What do you understand by a convolutional neural network?,"A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.","In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations",0
What is the meaning of term weight initialization in neural networks?,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.","In case of deep networks, if the weights are too-small the layers are the slowest to train, A too-large initialization this leads to the exploding gradient problem.",0
What do you understand by a convolutional neural network?,"A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.","A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.",1
What do you understand by a convolutional neural network?,"A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.","change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",0
Explain Data Normalization.,"A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.",an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,0
What do you understand by a convolutional neural network?,A convolutional neural network (CNN) is a type of artificial neural network most commonly applied to analyzing visual imagery.,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.",1
What do you understand by a convolutional neural network?,A convolutional neural network (CNN) is a type of artificial neural network most commonly applied to analyzing visual imagery.,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,0
Explain the layer of CNN: ReLU,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.","RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.",0
What do you understand by a convolutional neural network?,A convolutional neural network (CNN) is a type of artificial neural network most commonly applied to analyzing visual imagery.,"A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.",1
What do you understand by a convolutional neural network?,A convolutional neural network (CNN) is a type of artificial neural network most commonly applied to analyzing visual imagery.,This part of the network represents the compressed input.,0
What is the use of code layers in Autoencoders?,"A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.",This part of the network contains the reduced representation of the input that is fed into the decoder.,0
What do you understand by a convolutional neural network?,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.","A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.",1
What do you understand by a convolutional neural network?,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.",The hidden layer after the input layer and before the ouput layer.,0
what do you know about hidden layer?,"A convolutional neural network, or CNN, is a deep learning neural network used in image recognition and processing that is specifically designed to process pixel data.","Hidden Layers: Layers of nodes between the input and output layers, after the input layer and before the ouput layer.",0
Explain the layer of CNN: convolution,This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,1
Explain the layer of CNN: convolution,This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,"can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",0
What is a binary step function?,The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,"can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",0
Explain the layer of CNN: convolution,This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,This layer computes the convolutions between the neurons and the various patches in the input,1
Explain the layer of CNN: convolution,This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,The input layer contains input neurons which send information to the hidden layer.,0
what do you know about input layer?,This layer computes the convolutions between the neurons and the various patches in the input,The input layer is contains your raw data. which send information to the hidden layer.,0
Explain the layer of CNN: convolution,This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,A convolution is the simple application of a filter to an input that results in an activation.,1
Explain the layer of CNN: convolution,This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,"The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.",0
What is Model Capacity?,A convolution is the simple application of a filter to an input that results in an activation.,The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,0
Explain the layer of CNN: convolution,This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,1
Explain the layer of CNN: convolution,This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,Multilayer perceptrons or feedforward neural networks with two or more layers have the higher processing power.,0
what is a multilayer percepton?,The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,"has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",0
Explain the layer of CNN: convolution,This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,This layer computes the convolutions between the neurons of an input that results in an activation.,1
Explain the layer of CNN: convolution,This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.,0
What do you understand by Tensors?,This layer computes the convolutions between the neurons of an input that results in an activation.,"A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.",0
Explain the layer of CNN: convolution,This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,A convolution is the simple application of a filter to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,1
Explain the layer of CNN: convolution,This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,0
What do you mean by Dropout?,A convolution is the simple application of a filter to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,"With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.",0
Explain the layer of CNN: convolution,The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,This layer computes the convolutions between the neurons and the various patches in the input,1
Explain the layer of CNN: convolution,The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,"Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",0
Explain gradient descent?,This layer computes the convolutions between the neurons and the various patches in the input,Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,0
Explain the layer of CNN: convolution,The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,A convolution is the simple application of a filter to an input that results in an activation.,1
Explain the layer of CNN: convolution,The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,0
What are the disadvantages of deep learning?,A convolution is the simple application of a filter to an input that results in an activation.,Requires a large amount of data. neural networks are also more computationally expensive can take several weeks to train completely from scratch.,0
Explain the layer of CNN: convolution,The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,1
Explain the layer of CNN: convolution,The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,"Overfitting refers to a model that models the training data too well, where a statistical model begins to describe the random error.",0
"What do you mean by ""overfitting""?",The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,"Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.",0
Explain the layer of CNN: convolution,The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,This layer computes the convolutions between the neurons of an input that results in an activation.,1
Explain the layer of CNN: convolution,The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.",0
What is matrix element-wise multiplication?,This layer computes the convolutions between the neurons of an input that results in an activation.,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.",0
Explain the layer of CNN: convolution,The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,A convolution is the simple application of a filter to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,1
Explain the layer of CNN: convolution,The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,0
What is Backpropagation?,A convolution is the simple application of a filter to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,"Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks.",0
Explain the layer of CNN: convolution,This layer computes the convolutions between the neurons and the various patches in the input,A convolution is the simple application of a filter to an input that results in an activation.,1
Explain the layer of CNN: convolution,This layer computes the convolutions between the neurons and the various patches in the input,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,0
Explain the layer of CNN: ReLU,A convolution is the simple application of a filter to an input that results in an activation.,"RELU layer will apply an elementwise activation function, such as the max(0,x) thresholding at zero.",0
Explain the layer of CNN: convolution,This layer computes the convolutions between the neurons and the various patches in the input,The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,1
Explain the layer of CNN: convolution,This layer computes the convolutions between the neurons and the various patches in the input,The Leaky ReLU (LReLU or LReL) manages the function to allow small negative values when the input is less than zero.,0
What is the use of leaky ReLU function?,The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,"Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",0
Explain the layer of CNN: convolution,This layer computes the convolutions between the neurons and the various patches in the input,This layer computes the convolutions between the neurons of an input that results in an activation.,1
Explain the layer of CNN: convolution,This layer computes the convolutions between the neurons and the various patches in the input,The data is made available the output variables.,0
what do you know about output layer?,This layer computes the convolutions between the neurons of an input that results in an activation.,"The output layer is the simplest, data is made available at the output layer.",0
Explain the layer of CNN: convolution,This layer computes the convolutions between the neurons and the various patches in the input,A convolution is the simple application of a filter to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,1
Explain the layer of CNN: convolution,This layer computes the convolutions between the neurons and the various patches in the input,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.",0
What do you understand by Boltzmann Machine?,A convolution is the simple application of a filter to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. They dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.,0
Explain the layer of CNN: convolution,A convolution is the simple application of a filter to an input that results in an activation.,The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,1
Explain the layer of CNN: convolution,A convolution is the simple application of a filter to an input that results in an activation.,"Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",0
Explain gradient descent?,The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,0
Explain the layer of CNN: convolution,A convolution is the simple application of a filter to an input that results in an activation.,This layer computes the convolutions between the neurons of an input that results in an activation.,1
Explain the layer of CNN: convolution,A convolution is the simple application of a filter to an input that results in an activation.,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",0
What do you understand by Deep Autoencoders?,This layer computes the convolutions between the neurons of an input that results in an activation.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",0
Explain the layer of CNN: convolution,A convolution is the simple application of a filter to an input that results in an activation.,A convolution is the simple application of a filter to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,1
Explain the layer of CNN: convolution,A convolution is the simple application of a filter to an input that results in an activation.,"the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.",0
Explain Data Normalization.,A convolution is the simple application of a filter to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,"By normalizing all of our inputs to a standard scale, without distorting differences in the ranges of values.",0
Explain the layer of CNN: convolution,The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,This layer computes the convolutions between the neurons of an input that results in an activation.,1
Explain the layer of CNN: convolution,The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,0
What is Backpropagation?,This layer computes the convolutions between the neurons of an input that results in an activation.,"the method calculates the gradient of the error function with respect to the neural network's weights, It reduces the loss between the predicted values and the actual values.",0
Explain the layer of CNN: convolution,The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,A convolution is the simple application of a filter to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,1
Explain the layer of CNN: convolution,The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,"Input Layer: Input variables, sometimes called the visible layer.",0
what do you know about input layer?,A convolution is the simple application of a filter to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,"Input Layer: Input variables, contains your raw data.",0
Explain the layer of CNN: convolution,This layer computes the convolutions between the neurons of an input that results in an activation.,A convolution is the simple application of a filter to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,1
Explain the layer of CNN: convolution,This layer computes the convolutions between the neurons of an input that results in an activation.,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.",0
Explain the following variant of Gradient Descent mini-batch?,A convolution is the simple application of a filter to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.",0
Explain the layer of CNN: ReLU,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,"RELU layer will apply an elementwise activation function, such as the max(0,x) thresholding at zero.",1
Explain the layer of CNN: ReLU,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,multiplies arrays A and B of same dimension by multiplying corresponding elements.,0
What is matrix element-wise multiplication?,"RELU layer will apply an elementwise activation function, such as the max(0,x) thresholding at zero.","We combine corresponding values in an elementwise fashion to produce a new matrix. where each element i, j is the product of elements i, j of the original two matrices.",0
Explain the layer of CNN: ReLU,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,"Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.",1
Explain the layer of CNN: ReLU,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,0
What is the use of decoder layers in Autoencoders?,"Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.",Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. This network is responsible for reconstructing the input back to the original dimensions from the code.,0
Explain the layer of CNN: ReLU,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,the most commonly deployed activation function for the outputs of the CNN neurons.,1
Explain the layer of CNN: ReLU,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,0
Explain the following variant of Gradient Descent batch?,the most commonly deployed activation function for the outputs of the CNN neurons.,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",0
Explain the layer of CNN: ReLU,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,"RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.",1
Explain the following variant of Gradient Descent batch?,"RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.","Batch Gradient Descent is when we sum up over all examples, when performing the updates to the parameters.",0
Explain the layer of CNN: ReLU,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,"Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.",1
Explain the layer of CNN: ReLU,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,0
what is a single percepton?,"Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.","As a linear classifier, the simplest type of artificial neural networks.",0
Explain the layer of CNN: ReLU,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,"the most commonly deployed activation function, such as the max(0,x) thresholding at zero.",1
Explain the layer of CNN: ReLU,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,"Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.",0
What do you understand by Tensors?,"the most commonly deployed activation function, such as the max(0,x) thresholding at zero.","Tensors are mathematical objects that generalize scalars, vectors and matrices to N-dimensional space.",0
Explain the layer of CNN: ReLU,"RELU layer will apply an elementwise activation function, such as the max(0,x) thresholding at zero.","Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.",1
Explain the layer of CNN: ReLU,"RELU layer will apply an elementwise activation function, such as the max(0,x) thresholding at zero.","Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.",0
Explain the layer of CNN: Full Collectedness,"Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.","fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",0
Explain the layer of CNN: ReLU,"RELU layer will apply an elementwise activation function, such as the max(0,x) thresholding at zero.",the most commonly deployed activation function for the outputs of the CNN neurons.,1
Explain the layer of CNN: ReLU,"RELU layer will apply an elementwise activation function, such as the max(0,x) thresholding at zero.","The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.",0
What is the sigmoid function?,the most commonly deployed activation function for the outputs of the CNN neurons.,"The input data to the function is transformed into a value between 0.0 and 1.0, outputs a more smooth or continous range.",0
Explain the layer of CNN: ReLU,"RELU layer will apply an elementwise activation function, such as the max(0,x) thresholding at zero.","RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.",1
Explain the layer of CNN: ReLU,"RELU layer will apply an elementwise activation function, such as the max(0,x) thresholding at zero.","the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.",0
Explain Data Normalization.,"RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.",Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,0
Explain the layer of CNN: ReLU,"RELU layer will apply an elementwise activation function, such as the max(0,x) thresholding at zero.","Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.",1
Explain the layer of CNN: ReLU,"RELU layer will apply an elementwise activation function, such as the max(0,x) thresholding at zero.",fully connected neural network structure that drives the final classification decision.,0
Explain the layer of CNN: Full Collectedness,"Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.","fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",0
Explain the layer of CNN: ReLU,"RELU layer will apply an elementwise activation function, such as the max(0,x) thresholding at zero.","the most commonly deployed activation function, such as the max(0,x) thresholding at zero.",1
Explain the layer of CNN: ReLU,"RELU layer will apply an elementwise activation function, such as the max(0,x) thresholding at zero.","The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.",0
What is Tanh function?,"the most commonly deployed activation function, such as the max(0,x) thresholding at zero.","tanh produces output ranges from -1 and 1, and used as activation function.",0
Explain the layer of CNN: ReLU,"Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.",the most commonly deployed activation function for the outputs of the CNN neurons.,1
Explain the layer of CNN: ReLU,"Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.",LSTM use persistent previous information to be used in the current neural network.,0
Explain the importance of LSTM.,the most commonly deployed activation function for the outputs of the CNN neurons.,"LSTM use persistent previous information to classifying, processing and making predictions based on time series data",0
Explain the layer of CNN: ReLU,"Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.","RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.",1
Explain the layer of CNN: ReLU,"Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.","If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.",0
Why is zero initialization not a good weight initialization process?,"RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.","If all the weights are initialized with 0, leads the neurons to learn the same features during training.",0
Explain the layer of CNN: ReLU,"Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.","Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.",1
Explain the layer of CNN: ReLU,"Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.","the term ""stochastic"" comes from the fact that the gradient based on a single training sample is a ""stochastic approximation"" of the ""true"" cost gradient.",0
Explain the following variant of Gradient Descent Stochastic?,"Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.","Instead of going through all examples, the gradient based on a single training sample.",0
Explain the layer of CNN: ReLU,"Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.","the most commonly deployed activation function, such as the max(0,x) thresholding at zero.",1
Explain the layer of CNN: ReLU,"Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.","Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance",0
What is a Swish function?,"the most commonly deployed activation function, such as the max(0,x) thresholding at zero.","Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.",0
Explain the layer of CNN: ReLU,the most commonly deployed activation function for the outputs of the CNN neurons.,"RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.",1
Explain the layer of CNN: ReLU,the most commonly deployed activation function for the outputs of the CNN neurons.,"The input data to the function is transformed into a value between 0.0 and 1.0, outputs a more smooth or continous range.",0
What is the sigmoid function?,"RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.",activation function apply thresholding to input data and produce output between 0 and 1.,0
Explain the layer of CNN: ReLU,the most commonly deployed activation function for the outputs of the CNN neurons.,"Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.",1
Explain the layer of CNN: ReLU,the most commonly deployed activation function for the outputs of the CNN neurons.,"Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.",0
Explain the layer of CNN: ReLU,the most commonly deployed activation function for the outputs of the CNN neurons.,"the most commonly deployed activation function, such as the max(0,x) thresholding at zero.",1
Explain the layer of CNN: ReLU,the most commonly deployed activation function for the outputs of the CNN neurons.,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",0
Explain the following variant of Gradient Descent mini-batch?,"the most commonly deployed activation function, such as the max(0,x) thresholding at zero.","a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.",0
Explain the layer of CNN: ReLU,"RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.","Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.",1
Explain the layer of CNN: ReLU,"RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.","Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).",0
What is the use of leaky ReLU function?,"Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.","Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",0
Explain the layer of CNN: ReLU,"RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.","the most commonly deployed activation function, such as the max(0,x) thresholding at zero.",1
Explain the layer of CNN: ReLU,"RELU layer will apply an elementwise activation function, we can pass each value in the feature map through a nonlinearity.","Deep learning is a subset of machine learning where artificial neural networks, algorithms inspired by the human brain, learn from large amounts of data.",0
What is deep learning?,"the most commonly deployed activation function, such as the max(0,x) thresholding at zero.","Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised algorithms inspired by the human brain, learn from large amounts of data.",0
Explain the layer of CNN: ReLU,"Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.","the most commonly deployed activation function, such as the max(0,x) thresholding at zero.",1
Explain the layer of CNN: ReLU,"Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.",A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.,0
What do you understand by Tensors?,"the most commonly deployed activation function, such as the max(0,x) thresholding at zero.","A tensor is a container which can house data in N dimensions, and is easily understood as a multidimensional array.",0
Explain the layer of CNN: pooling,It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,"will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]",1
Explain the layer of CNN: pooling,It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,"Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.",0
What do you understand by Tensors?,"will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]",A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,0
Explain the layer of CNN: pooling,It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,"while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.",1
Explain the layer of CNN: pooling,It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,"If all the weights are initialized with 0, all weights have the same value in subsequent iterations.",0
Why is zero initialization not a good weight initialization process?,"while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.","Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.",0
Explain the layer of CNN: pooling,It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,1
Explain the layer of CNN: pooling,It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,The data is made available at the output layer.,0
what do you know about output layer?,pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,"The output layer is the simplest, usually consisting of a single output for classification problems.",0
Explain the layer of CNN: pooling,It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,will perform a downsampling operation along the spatial dimensions for flatten as it is converted to a single dimension array.,1
Explain the layer of CNN: pooling,It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,"The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.",0
What is the softmax function?,will perform a downsampling operation along the spatial dimensions for flatten as it is converted to a single dimension array.,"The Softmax regression is a form of logistic regression that normalizes an input value, transforms them into values between 0 and 1.",0
Explain the layer of CNN: pooling,It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,"while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.",1
Explain the layer of CNN: pooling,It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,"Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",0
Explain gradient descent?,"while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.",Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. we use gradient descent to update the parameters of our model.,0
Explain the layer of CNN: pooling,It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,"pooling or downsampling layer is responsible for reducing the spatial dimensions (width, height), resulting in volume such as [16x16x12].",1
Explain the layer of CNN: pooling,It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,"A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.",0
What do you understand by Boltzmann Machine?,"pooling or downsampling layer is responsible for reducing the spatial dimensions (width, height), resulting in volume such as [16x16x12].",Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,0
Explain the layer of CNN: pooling,"will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]","while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.",1
Explain the layer of CNN: pooling,"will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]","a leaky ReLU allows a small, non-zero, constant gradient Î± (Normally, Î±=0.01).",0
What is the use of leaky ReLU function?,"while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.","Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",0
Explain the layer of CNN: pooling,"will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]",pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,1
Explain the layer of CNN: pooling,"will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]","Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.",0
What are the disadvantages of deep learning?,pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,0
Explain the layer of CNN: pooling,"will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]",will perform a downsampling operation along the spatial dimensions for flatten as it is converted to a single dimension array.,1
Explain the layer of CNN: pooling,"will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]",Output Layer: A layer of nodes that produce the output variables.,0
what do you know about output layer?,will perform a downsampling operation along the spatial dimensions for flatten as it is converted to a single dimension array.,Output Layer: A layer of nodes that usually consisting of a single output for classification problems.,0
Explain the layer of CNN: pooling,"will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]","while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.",1
Explain the layer of CNN: pooling,"will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]","Fourier transform is highly efficient for analyzing, maintaining, and managing a large databases, and extremely helpful for processing all categories of signals.",0
What is the function of the Fourier Transform in Deep Learning?,"while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.","processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",0
Explain the layer of CNN: pooling,"will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]","pooling or downsampling layer is responsible for reducing the spatial dimensions (width, height), resulting in volume such as [16x16x12].",1
Explain the layer of CNN: pooling,"will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12]","Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.",0
Explain the layer of CNN: Full Collectedness,"pooling or downsampling layer is responsible for reducing the spatial dimensions (width, height), resulting in volume such as [16x16x12].","layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",0
Explain the layer of CNN: pooling,"while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.",pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,1
Explain the layer of CNN: pooling,"while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.","Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.",0
What is deep learning?,pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,"Deep learning is an artificial intelligence (AI) function that imitates the workings of the human, capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.",0
Explain the layer of CNN: pooling,"while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.",will perform a downsampling operation along the spatial dimensions for flatten as it is converted to a single dimension array.,1
Explain the layer of CNN: pooling,"while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.",Autoencoder is an artificial neural network. It can learn representation for a set of data without any supervision. The network automatically learns by copying its input to the output.,0
What do you understand by Autoencoder?,will perform a downsampling operation along the spatial dimensions for flatten as it is converted to a single dimension array.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",0
Explain the layer of CNN: pooling,"while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.","while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.",1
Explain the layer of CNN: pooling,"while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.","The tanh function, a.k.a. hyperbolic tangent function, is a rescaling of the logistic sigmoid, such that its outputs range from -1 to 1.",0
What is Tanh function?,"while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.",Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,0
Explain the layer of CNN: pooling,"while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.","pooling or downsampling layer is responsible for reducing the spatial dimensions (width, height), resulting in volume such as [16x16x12].",1
Explain the layer of CNN: pooling,"while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.",The input layer passes the data directly to the first hidden layer where the data is multiplied by the first hidden layer's weights.,0
what do you know about input layer?,"pooling or downsampling layer is responsible for reducing the spatial dimensions (width, height), resulting in volume such as [16x16x12].",The input layer is contains your raw data.,0
Explain the layer of CNN: pooling,pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,will perform a downsampling operation along the spatial dimensions for flatten as it is converted to a single dimension array.,1
Explain the layer of CNN: pooling,pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,We combine corresponding values in an elementwise fashion to produce a new matrix.,0
What is matrix element-wise multiplication?,will perform a downsampling operation along the spatial dimensions for flatten as it is converted to a single dimension array.,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.",0
Explain the layer of CNN: pooling,pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,"while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.",1
Explain the layer of CNN: pooling,pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data.,0
What do you understand by a convolutional neural network?,"while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.","convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery",0
Explain the layer of CNN: pooling,pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,"pooling or downsampling layer is responsible for reducing the spatial dimensions (width, height), resulting in volume such as [16x16x12].",1
Explain the layer of CNN: pooling,pooling or downsampling layer is responsible for reducing the spacial size of the activation maps.,This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).,0
What is the use of decoder layers in Autoencoders?,"pooling or downsampling layer is responsible for reducing the spatial dimensions (width, height), resulting in volume such as [16x16x12].","This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network",0
Explain the layer of CNN: pooling,will perform a downsampling operation along the spatial dimensions for flatten as it is converted to a single dimension array.,"while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.",1
Explain the layer of CNN: pooling,will perform a downsampling operation along the spatial dimensions for flatten as it is converted to a single dimension array.,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,0
Explain the following variant of Gradient Descent batch?,"while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.","Using the Gradient Decent optimization algorithm, the weights are updated incrementally after each iteration over the training dataset.",0
Explain the layer of CNN: pooling,will perform a downsampling operation along the spatial dimensions for flatten as it is converted to a single dimension array.,"pooling or downsampling layer is responsible for reducing the spatial dimensions (width, height), resulting in volume such as [16x16x12].",1
Explain the layer of CNN: pooling,will perform a downsampling operation along the spatial dimensions for flatten as it is converted to a single dimension array.,The data is made available at the output layer.,0
what do you know about output layer?,"pooling or downsampling layer is responsible for reducing the spatial dimensions (width, height), resulting in volume such as [16x16x12].","The output layer is the simplest, usually consisting of a single output for classification problems.",0
Explain the layer of CNN: pooling,"while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.","pooling or downsampling layer is responsible for reducing the spatial dimensions (width, height), resulting in volume such as [16x16x12].",1
Explain the layer of CNN: pooling,"while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.","A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.",0
What do you understand by a convolutional neural network?,"pooling or downsampling layer is responsible for reducing the spatial dimensions (width, height), resulting in volume such as [16x16x12].","convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.",0
Explain the layer of CNN: Full Collectedness,"Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.","layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",1
Explain the layer of CNN: Full Collectedness,"Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.",LSTM use persistent previous information to be used in the current neural network.,0
Explain the importance of LSTM.,"layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",LSTMs have property of selectively remembering information to be used in the current neural network.,0
Explain the layer of CNN: Full Collectedness,"Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.",aims to map the activation volume from the combination of previous different layers into a class probability distribution.,1
Explain the layer of CNN: Full Collectedness,"Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.",Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,0
Explain the following variant of Gradient Descent batch?,aims to map the activation volume from the combination of previous different layers into a class probability distribution.,"This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",0
Explain the layer of CNN: Full Collectedness,"Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.",fully connected neural network structure that drives the final classification decision.,1
Explain the layer of CNN: Full Collectedness,"Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.","In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
Differentiate supervised and unsupervised deep learning procedures.,fully connected neural network structure that drives the final classification decision.,"Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
Explain the layer of CNN: Full Collectedness,"Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.","layer will compute the class scores, resulting a class probability distribution.",1
Explain the layer of CNN: Full Collectedness,"Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.","RNN stands for Recurrent Neural Networks. These are the artificial neural networks which are designed to recognize patterns in sequences of data such as handwriting, text, the spoken word, genomes, and numerical time series data.",0
What is an RNN?,"layer will compute the class scores, resulting a class probability distribution.",RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,0
Explain the layer of CNN: Full Collectedness,"Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.",aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,1
Explain the layer of CNN: Full Collectedness,"Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.","The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.",0
What is a binary step function?,aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,"A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",0
Explain the layer of CNN: Full Collectedness,"Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.","fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",1
Explain the layer of CNN: Full Collectedness,"Neurons in a completely connected layer have complete connections to all activations in the previous layer, as seen in regular Neural Networks. Their activations can be easily computed with a matrix multiplication followed by a bias offset.","Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.",0
what do you know about hidden layer?,"fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",The hidden layer after the input layer to send data to the output layer.,0
Explain the layer of CNN: Full Collectedness,"layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",aims to map the activation volume from the combination of previous different layers into a class probability distribution.,1
Explain the layer of CNN: Full Collectedness,"layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,0
What is the use of decoder layers in Autoencoders?,aims to map the activation volume from the combination of previous different layers into a class probability distribution.,"This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network",0
Explain the layer of CNN: Full Collectedness,"layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",fully connected neural network structure that drives the final classification decision.,1
Explain the layer of CNN: Full Collectedness,"layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.","In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
Differentiate supervised and unsupervised deep learning procedures.,fully connected neural network structure that drives the final classification decision.,"supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",0
Explain the layer of CNN: Full Collectedness,"layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.","layer will compute the class scores, resulting a class probability distribution.",1
Explain the layer of CNN: Full Collectedness,"layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.","The softmax function is used to calculate the probability distribution of the event over 'n' different events, the output range will be between 0 to 1, and the sum of all the probabilities will be equal to one.",0
What is the softmax function?,"layer will compute the class scores, resulting a class probability distribution.","The input values can be positive, negative, zero, or greater than one, The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",0
Explain the layer of CNN: Full Collectedness,"layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,1
Explain the layer of CNN: Full Collectedness,"layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,0
what is a multilayer percepton?,aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, It is substantially formed from multiple layers of perceptron.",0
Explain the layer of CNN: Full Collectedness,"layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.","fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",1
Explain the layer of CNN: Full Collectedness,"layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,0
What is the cost function?,"fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,0
Explain the layer of CNN: Full Collectedness,aims to map the activation volume from the combination of previous different layers into a class probability distribution.,fully connected neural network structure that drives the final classification decision.,1
Explain the layer of CNN: Full Collectedness,aims to map the activation volume from the combination of previous different layers into a class probability distribution.,A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array.,0
What do you understand by Tensors?,fully connected neural network structure that drives the final classification decision.,A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,0
Explain the layer of CNN: Full Collectedness,aims to map the activation volume from the combination of previous different layers into a class probability distribution.,"layer will compute the class scores, resulting a class probability distribution.",1
Explain the layer of CNN: Full Collectedness,aims to map the activation volume from the combination of previous different layers into a class probability distribution.,"Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","layer will compute the class scores, resulting a class probability distribution.","AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems",0
Explain the layer of CNN: Full Collectedness,aims to map the activation volume from the combination of previous different layers into a class probability distribution.,aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,1
Explain the layer of CNN: Full Collectedness,aims to map the activation volume from the combination of previous different layers into a class probability distribution.,Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,0
What do you understand by Deep Autoencoders?,aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",0
Explain the layer of CNN: Full Collectedness,aims to map the activation volume from the combination of previous different layers into a class probability distribution.,"fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",1
Explain the layer of CNN: Full Collectedness,aims to map the activation volume from the combination of previous different layers into a class probability distribution.,"Instead of going through all examples, the gradient based on a single training sample.",0
Explain the following variant of Gradient Descent Stochastic?,"fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.","the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration",0
Explain the layer of CNN: Full Collectedness,fully connected neural network structure that drives the final classification decision.,"layer will compute the class scores, resulting a class probability distribution.",1
Explain the layer of CNN: Full Collectedness,fully connected neural network structure that drives the final classification decision.,Backpropagation is a training algorithm which is used for multilayer neural networks. It transfers the error information from the end of the network to all the weights inside the network. It allows the efficient computation of the gradient.,0
What is Backpropagation?,"layer will compute the class scores, resulting a class probability distribution.",Backpropagation is a process used to adjust the weights of a deep neural network. It reduces the loss between the predicted values and the actual values.,0
Explain the layer of CNN: Full Collectedness,fully connected neural network structure that drives the final classification decision.,aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,1
Explain the layer of CNN: Full Collectedness,fully connected neural network structure that drives the final classification decision.,It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,0
What is the cost function?,aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,"cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.",0
Explain the layer of CNN: Full Collectedness,fully connected neural network structure that drives the final classification decision.,"fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",1
Explain the layer of CNN: Full Collectedness,fully connected neural network structure that drives the final classification decision.,The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,0
What is the use of the Activation function?,"fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,0
Explain the layer of CNN: Full Collectedness,"layer will compute the class scores, resulting a class probability distribution.",aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,1
Explain the layer of CNN: Full Collectedness,"layer will compute the class scores, resulting a class probability distribution.",It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,0
What are the disadvantages of deep learning?,aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,0
Explain the layer of CNN: Full Collectedness,"layer will compute the class scores, resulting a class probability distribution.","fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",1
Explain the layer of CNN: Full Collectedness,"layer will compute the class scores, resulting a class probability distribution.","A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",0
What do you understand by Perceptron?,"fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,0
Explain the layer of CNN: Full Collectedness,aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,"fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",1
Explain the layer of CNN: Full Collectedness,aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. They dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.,0
What do you understand by Boltzmann Machine?,"fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,0
What is an RNN?,"RNN stands for Recurrent Neural Networks. These are the artificial neural networks which are designed to recognize patterns in sequences of data such as handwriting, text, the spoken word, genomes, and numerical time series data.",A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior.,1
What is an RNN?,"RNN stands for Recurrent Neural Networks. These are the artificial neural networks which are designed to recognize patterns in sequences of data such as handwriting, text, the spoken word, genomes, and numerical time series data.",Requires a large amount of data. Is extremely computationally expensive to train. The most complex models take weeks to train using hundreds of machines equipped with expensive GPUs.,0
What are the disadvantages of deep learning?,A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior.,It requires very large amount of data in order to perform better than other techniques. Is extremely computationally expensive to train.,0
What is an RNN?,"RNN stands for Recurrent Neural Networks. These are the artificial neural networks which are designed to recognize patterns in sequences of data such as handwriting, text, the spoken word, genomes, and numerical time series data.","RNN) are the state of the art algorithm for sequential data, It is the first algorithm that remembers its input.",1
What is an RNN?,"RNN stands for Recurrent Neural Networks. These are the artificial neural networks which are designed to recognize patterns in sequences of data such as handwriting, text, the spoken word, genomes, and numerical time series data.","Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","RNN) are the state of the art algorithm for sequential data, It is the first algorithm that remembers its input.","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
What is an RNN?,"RNN stands for Recurrent Neural Networks. These are the artificial neural networks which are designed to recognize patterns in sequences of data such as handwriting, text, the spoken word, genomes, and numerical time series data.",RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,1
What is an RNN?,"RNN stands for Recurrent Neural Networks. These are the artificial neural networks which are designed to recognize patterns in sequences of data such as handwriting, text, the spoken word, genomes, and numerical time series data.","Autoencoders are neural networks. Neural networks are composed of multiple layers, and the defining aspect of an autoencoder is that the input layers contain exactly as much information as the output layer.",0
What do you understand by Autoencoder?,RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,"Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data, and then uncompress that code into whatever format best matches the original input.",0
What is an RNN?,"RNN stands for Recurrent Neural Networks. These are the artificial neural networks which are designed to recognize patterns in sequences of data such as handwriting, text, the spoken word, genomes, and numerical time series data.","A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.",1
What is an RNN?,"RNN stands for Recurrent Neural Networks. These are the artificial neural networks which are designed to recognize patterns in sequences of data such as handwriting, text, the spoken word, genomes, and numerical time series data.","can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",0
What is a binary step function?,"A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.",A binary step function is a threshold-based activation function. The function produces 1 when input passes threshold limit whereas it produces 0 when input does not pass threshold.,0
What is an RNN?,"RNN stands for Recurrent Neural Networks. These are the artificial neural networks which are designed to recognize patterns in sequences of data such as handwriting, text, the spoken word, genomes, and numerical time series data.","RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.",1
What is an RNN?,"RNN stands for Recurrent Neural Networks. These are the artificial neural networks which are designed to recognize patterns in sequences of data such as handwriting, text, the spoken word, genomes, and numerical time series data.","The input values can be positive, negative, zero, or greater than one, but the softmax transforms them into values between 0 and 1, so that they can be interpreted as probabilities.",0
What is the softmax function?,"RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.","Softmax turns arbitrary real values into probabilities, which are often useful in Machine Learning. The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",0
What is an RNN?,"RNN stands for Recurrent Neural Networks. These are the artificial neural networks which are designed to recognize patterns in sequences of data such as handwriting, text, the spoken word, genomes, and numerical time series data.","RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.",1
What is an RNN?,"RNN stands for Recurrent Neural Networks. These are the artificial neural networks which are designed to recognize patterns in sequences of data such as handwriting, text, the spoken word, genomes, and numerical time series data.","A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.",0
What do you understand by Boltzmann Machine?,"RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.",Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,0
What is an RNN?,A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior.,"RNN) are the state of the art algorithm for sequential data, It is the first algorithm that remembers its input.",1
What is an RNN?,A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior.,"Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.",0
"What do you mean by ""overfitting""?","RNN) are the state of the art algorithm for sequential data, It is the first algorithm that remembers its input.",occurs when a function corresponds too closely to a particular set of the training data to the extent that it negatively impacts the performance of the model on new data.,0
What is an RNN?,A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior.,RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,1
What is an RNN?,A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior.,a special implementation that combines non-linearity and rectification layers in convolutional neural networks.,0
Explain the layer of CNN: ReLU,RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,"the most commonly deployed activation function, such as the max(0,x) thresholding at zero.",0
What is an RNN?,A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior.,"A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.",1
What is an RNN?,A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior.,"Performing convolutions efficiently as products in the Fourier domain. An example would be training large convolutional neural nets. Like sparse signal processing,",0
What is the function of the Fourier Transform in Deep Learning?,"A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.","processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",0
What is an RNN?,A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior.,"RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.",1
What is an RNN?,A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior.,"The Softmax regression is a form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. The output values are between the range [0,1]",0
What is the softmax function?,"RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.","Softmax turns arbitrary real values into probabilities, The output values are between the range [0,1].",0
What is an RNN?,A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior.,"RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.",1
What is an RNN?,A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior.,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,0
What do you understand by Perceptron?,"RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.",A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,0
What is an RNN?,"RNN) are the state of the art algorithm for sequential data, It is the first algorithm that remembers its input.",RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,1
What is an RNN?,"RNN) are the state of the art algorithm for sequential data, It is the first algorithm that remembers its input.","It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.",0
Explain the importance of LSTM.,RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.",0
What is an RNN?,"RNN) are the state of the art algorithm for sequential data, It is the first algorithm that remembers its input.","A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.",1
What is an RNN?,"RNN) are the state of the art algorithm for sequential data, It is the first algorithm that remembers its input.",The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,0
What is the use of decoder layers in Autoencoders?,"A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.",Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,0
What is an RNN?,"RNN) are the state of the art algorithm for sequential data, It is the first algorithm that remembers its input.","RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.",1
What is an RNN?,"RNN) are the state of the art algorithm for sequential data, It is the first algorithm that remembers its input.",Autoencoder is an unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.,0
What do you understand by Autoencoder?,"RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, the input layers contain exactly as much information as the output layer.",0
What is an RNN?,"RNN) are the state of the art algorithm for sequential data, It is the first algorithm that remembers its input.","RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.",1
What is an RNN?,"RNN) are the state of the art algorithm for sequential data, It is the first algorithm that remembers its input.",This part of the network represents the compressed input.,0
What is the use of code layers in Autoencoders?,"RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.",This part of the network contains the reduced representation of the input that is fed into the decoder.,0
What is an RNN?,RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,"A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.",1
What is an RNN?,RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,"Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.",0
What is a Swish function?,"A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.","Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",0
What is an RNN?,RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,"RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.",1
What is an RNN?,RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,"An encoder is a feedforward, fully connected neural network that compresses the input into a latent space representation and encodes the input image as a compressed representation in a reduced dimension.",0
What is the use of encoder layers in Autoencoders?,"RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.","An encoder is a feedforward, fully connected neural network that compresses the input and encodes the input image, The compressed image is the distorted version of the original image.",0
What is an RNN?,RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,"RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.",1
What is an RNN?,RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.",0
Explain the importance of LSTM.,"RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.","LSTM use persistent previous information to classifying, processing and making predictions based on time series data",0
What is an RNN?,"A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.","RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.",1
What is an RNN?,"A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.",Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,0
What do you mean by Dropout?,"RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.","With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.",0
What is an RNN?,"A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.","RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.",1
What is an RNN?,"A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.","The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.",0
What is Model Capacity?,"RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.","A model with too little capacity cannot learn the training dataset meaning it will underfit, whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",0
What is an RNN?,"RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.","RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.",1
What is an RNN?,"RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.",LSTM use persistent previous information to be used in the current neural network.,0
Explain the importance of LSTM.,"It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.","LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.",1
Explain the importance of LSTM.,"It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.",It requires very large amount of data in order to perform better than other techniques. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.,0
What are the disadvantages of deep learning?,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.","Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. neural networks are also more computationally expensive can take several weeks to train completely from scratch.",0
Explain the importance of LSTM.,"It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.",LSTMs have property of selectively remembering patterns for long durations of time.,1
Explain the importance of LSTM.,"It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.",RNNs are designed to recognize the sequential characteristics in data and use patterns to predict the next likely scenario,0
What is an RNN?,LSTMs have property of selectively remembering patterns for long durations of time.,"RNN) are the state of the art algorithm for sequential data, and use patterns to predict the next likely scenario.",0
Explain the importance of LSTM.,"It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.",LSTM use persistent previous information to be used in the current neural network.,1
Explain the importance of LSTM.,"It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.","The capacity of a deep learning neural network controls the scope of the types of mapping functions that it can learn. Model capacity can approximate any given function. When there is a higher model capacity, it means that the larger amount of information can be stored in the network.",0
What is Model Capacity?,LSTM use persistent previous information to be used in the current neural network.,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. models with higher Capacity than needed are prompt to overfit, low Capacity tend to underfit.",0
Explain the importance of LSTM.,"It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.","LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.",1
Explain the importance of LSTM.,"It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.",The basic purpose of the activation function its ability to add non-linearity into a neural network.,0
What is the use of the Activation function?,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.","the Neural Network can successfully approximate functions which does not follow linearity, into the output of a neuron.",0
Explain the importance of LSTM.,"It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.",LSTMs have property of selectively remembering information to be used in the current neural network.,1
Explain the importance of LSTM.,"It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.",Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,0
What is Tanh function?,LSTMs have property of selectively remembering information to be used in the current neural network.,"Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians, the range of the tanh function is from (-1 to 1),",0
Explain the importance of LSTM.,"It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.","LSTM use persistent previous information to classifying, processing and making predictions based on time series data",1
Explain the importance of LSTM.,"It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.","Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",0
Explain gradient descent?,"LSTM use persistent previous information to classifying, processing and making predictions based on time series data","Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",0
Explain the importance of LSTM.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.",LSTMs have property of selectively remembering patterns for long durations of time.,1
Explain the importance of LSTM.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.","layer takes in the inputs which are passed in from the layers before it, performs the calculations via its neurons and then the output is computed.",0
what do you know about output layer?,LSTMs have property of selectively remembering patterns for long durations of time.,"The output layer is the simplest, data is made available at the output layer.",0
Explain the importance of LSTM.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.",LSTM use persistent previous information to be used in the current neural network.,1
Explain the importance of LSTM.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.",The main purpose of Boltzmann Machine is to optimize the solution of a problem. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,0
What do you understand by Boltzmann Machine?,LSTM use persistent previous information to be used in the current neural network.,"A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. hey dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.",0
Explain the importance of LSTM.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.","LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.",1
Explain the importance of LSTM.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.","A Boltzmann machine is a network of symmetrically connected, neuron-like units that make stochastic decisions about whether to be on or off. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.",0
What do you understand by Boltzmann Machine?,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.",Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,0
Explain the importance of LSTM.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.",LSTMs have property of selectively remembering information to be used in the current neural network.,1
Explain the importance of LSTM.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.","The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.",0
What is a binary step function?,LSTMs have property of selectively remembering information to be used in the current neural network.,"A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",0
Explain the importance of LSTM.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.","LSTM use persistent previous information to classifying, processing and making predictions based on time series data",1
Explain the importance of LSTM.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.","RNN) are the state of the art algorithm for sequential data, It is the first algorithm that remembers its input.",0
What is an RNN?,"LSTM use persistent previous information to classifying, processing and making predictions based on time series data","RNNs are designed to recognize the sequential characteristics in data, This allows it to exhibit temporal dynamic behavior.",0
Explain the importance of LSTM.,LSTMs have property of selectively remembering patterns for long durations of time.,LSTM use persistent previous information to be used in the current neural network.,1
Explain the importance of LSTM.,LSTMs have property of selectively remembering patterns for long durations of time.,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",0
What do you understand by Deep Autoencoders?,LSTM use persistent previous information to be used in the current neural network.,"Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",0
Explain the importance of LSTM.,LSTMs have property of selectively remembering patterns for long durations of time.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.",1
Explain the importance of LSTM.,LSTMs have property of selectively remembering patterns for long durations of time.,The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,0
Explain the layer of CNN: convolution,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.",A convolution is the simple application of a filter to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,0
Explain the importance of LSTM.,LSTMs have property of selectively remembering patterns for long durations of time.,LSTMs have property of selectively remembering information to be used in the current neural network.,1
Explain the importance of LSTM.,LSTMs have property of selectively remembering patterns for long durations of time.,This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,0
Explain the layer of CNN: convolution,LSTMs have property of selectively remembering information to be used in the current neural network.,The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,0
Explain the importance of LSTM.,LSTMs have property of selectively remembering patterns for long durations of time.,"LSTM use persistent previous information to classifying, processing and making predictions based on time series data",1
Explain the importance of LSTM.,LSTMs have property of selectively remembering patterns for long durations of time.,Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output.Unsupervised learning is modeling the underlying or hidden structure or distribution in the data in order to learn more about the data,0
Differentiate supervised and unsupervised deep learning procedures.,"LSTM use persistent previous information to classifying, processing and making predictions based on time series data","supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",0
Explain the importance of LSTM.,LSTM use persistent previous information to be used in the current neural network.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.",1
Explain the importance of LSTM.,LSTM use persistent previous information to be used in the current neural network.,"A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.",0
What is the cost function?,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.","cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.",0
Explain the importance of LSTM.,LSTM use persistent previous information to be used in the current neural network.,LSTMs have property of selectively remembering information to be used in the current neural network.,1
Explain the importance of LSTM.,LSTM use persistent previous information to be used in the current neural network.,The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,0
What is the use of encoder layers in Autoencoders?,LSTMs have property of selectively remembering information to be used in the current neural network.,"An encoder is a feedforward, fully connected neural network that compresses the input into a latent space representation and encodes the input image as a compressed representation in a reduced dimension.",0
Explain the importance of LSTM.,LSTM use persistent previous information to be used in the current neural network.,"LSTM use persistent previous information to classifying, processing and making predictions based on time series data",1
Explain the importance of LSTM.,LSTM use persistent previous information to be used in the current neural network.,Computes the hyperbolic tangent of an input value for a hyperbolic angle measured in radians. The value can be a Decimal or Integer literal or a reference to a column containing numeric value nad ranges between -1 and 1,0
What is Tanh function?,"LSTM use persistent previous information to classifying, processing and making predictions based on time series data","rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",0
Explain the importance of LSTM.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.",LSTMs have property of selectively remembering information to be used in the current neural network.,1
Explain the importance of LSTM.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.",Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,0
What do you understand by Perceptron?,LSTMs have property of selectively remembering information to be used in the current neural network.,"A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",0
Explain the importance of LSTM.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.","LSTM use persistent previous information to classifying, processing and making predictions based on time series data",1
Explain the importance of LSTM.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.",The basic purpose of the activation function is to introduce non-linearity into the output of a neuron.,0
What is the use of the Activation function?,"LSTM use persistent previous information to classifying, processing and making predictions based on time series data",the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,0
Explain the importance of LSTM.,LSTMs have property of selectively remembering information to be used in the current neural network.,"LSTM use persistent previous information to classifying, processing and making predictions based on time series data",1
Explain the importance of LSTM.,LSTMs have property of selectively remembering information to be used in the current neural network.,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,0
What is the meaning of term weight initialization in neural networks?,"LSTM use persistent previous information to classifying, processing and making predictions based on time series data",initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,0
What is the use of encoder layers in Autoencoders?,The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,1
What is the use of encoder layers in Autoencoders?,The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.",0
Explain the importance of LSTM.,This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, remembering patterns for long durations of time.",0
What is the use of encoder layers in Autoencoders?,The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,"An encoder is a feedforward, fully connected neural network that compresses the input into a latent space representation and encodes the input image as a compressed representation in a reduced dimension.",1
What is the use of encoder layers in Autoencoders?,The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.",0
What is matrix element-wise multiplication?,"An encoder is a feedforward, fully connected neural network that compresses the input into a latent space representation and encodes the input image as a compressed representation in a reduced dimension.",multiplies arrays A and B of same dimension to produce a new matrix.,0
What is the use of encoder layers in Autoencoders?,The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,The encoder layer encodes the input image as a compressed representation in a reduced dimension. The compressed image is the distorted version of the original image.,1
What is the use of encoder layers in Autoencoders?,The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,Single layer perceptrons can learn only linearly separable patterns.,0
what is a single percepton?,The encoder layer encodes the input image as a compressed representation in a reduced dimension. The compressed image is the distorted version of the original image.,A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,0
What is the use of encoder layers in Autoencoders?,The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,"This is the part of the network that compresses the input into a latent-space representation, and encodes the input image as a compressed representation in a reduced dimension.",1
What is the use of encoder layers in Autoencoders?,The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,"Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.",0
Why is zero initialization not a good weight initialization process?,"This is the part of the network that compresses the input into a latent-space representation, and encodes the input image as a compressed representation in a reduced dimension.","in this case, the equations of the learning algorithm would fail, all weights have the same value in subsequent iterations.",0
What is the use of encoder layers in Autoencoders?,The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,"An encoder is a feedforward, fully connected neural network that compresses the input and encodes the input image, The compressed image is the distorted version of the original image.",1
What is the use of encoder layers in Autoencoders?,The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,Backpropagation is a process used to adjust the weights of a deep neural network. The weights that minimize the error,0
What is Backpropagation?,"An encoder is a feedforward, fully connected neural network that compresses the input and encodes the input image, The compressed image is the distorted version of the original image.","the method calculates the gradient of the error function with respect to the neural network's weights, It reduces the loss between the predicted values and the actual values.",0
What is the use of encoder layers in Autoencoders?,The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,The encoder layer encodes the input image as a compressed representation. It can be represented by an encoding function h=f(x).,1
What is the use of encoder layers in Autoencoders?,The encoder is used to compress the input into a latent space representation. It encodes the input images as a compressed representation in a reduced dimension. The compressed images are the distorted version of the original image.,This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,0
Explain the following variant of Gradient Descent mini-batch?,The encoder layer encodes the input image as a compressed representation. It can be represented by an encoding function h=f(x).,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",0
What is the use of encoder layers in Autoencoders?,This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,"An encoder is a feedforward, fully connected neural network that compresses the input into a latent space representation and encodes the input image as a compressed representation in a reduced dimension.",1
What is the use of encoder layers in Autoencoders?,This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,"Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.",0
What is deep learning?,"An encoder is a feedforward, fully connected neural network that compresses the input into a latent space representation and encodes the input image as a compressed representation in a reduced dimension.","Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.",0
What is the use of encoder layers in Autoencoders?,This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,The encoder layer encodes the input image as a compressed representation in a reduced dimension. The compressed image is the distorted version of the original image.,1
What is the use of encoder layers in Autoencoders?,This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,"layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",0
Explain the layer of CNN: Full Collectedness,The encoder layer encodes the input image as a compressed representation in a reduced dimension. The compressed image is the distorted version of the original image.,aims to map the activation volume from the combination of previous different layers that drives the final classification decision.,0
What is the use of encoder layers in Autoencoders?,This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,"This is the part of the network that compresses the input into a latent-space representation, and encodes the input image as a compressed representation in a reduced dimension.",1
What is the use of encoder layers in Autoencoders?,This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,Element-wise matrix multiplication is used to take two matrices of the same dimensions. It further produces another combined matrix with the elements that are a product of corresponding elements of matrix a and b.,0
What is matrix element-wise multiplication?,"This is the part of the network that compresses the input into a latent-space representation, and encodes the input image as a compressed representation in a reduced dimension.",multiplies arrays A and B of same dimension by multiplying corresponding elements.,0
What is the use of encoder layers in Autoencoders?,This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,"An encoder is a feedforward, fully connected neural network that compresses the input and encodes the input image, The compressed image is the distorted version of the original image.",1
What is the use of encoder layers in Autoencoders?,This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,"Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.",0
Why is zero initialization not a good weight initialization process?,"An encoder is a feedforward, fully connected neural network that compresses the input and encodes the input image, The compressed image is the distorted version of the original image.","in this case, the equations of the learning algorithm would fail, all weights have the same value in subsequent iterations.",0
What is the use of encoder layers in Autoencoders?,This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,The encoder layer encodes the input image as a compressed representation. It can be represented by an encoding function h=f(x).,1
What is the use of encoder layers in Autoencoders?,This is the part of the network that compresses the input into a latent-space representation. It can be represented by an encoding function h=f(x).,"A cost function describes us how well the neural network is performing with respect to its given training sample and the expected output. It may depend on variables such as weights and biases.It provides the performance of a neural network as a whole. In deep learning, our priority is to minimize the cost function. That's why we prefer to use the concept of gradient descent.",0
What is the cost function?,The encoder layer encodes the input image as a compressed representation. It can be represented by an encoding function h=f(x).,the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,0
What is the use of encoder layers in Autoencoders?,"An encoder is a feedforward, fully connected neural network that compresses the input into a latent space representation and encodes the input image as a compressed representation in a reduced dimension.",The encoder layer encodes the input image as a compressed representation in a reduced dimension. The compressed image is the distorted version of the original image.,1
What is the use of encoder layers in Autoencoders?,"An encoder is a feedforward, fully connected neural network that compresses the input into a latent space representation and encodes the input image as a compressed representation in a reduced dimension.","A Boltzmann machine is a type of recurrent neural network. In a Boltzmann machine, nodes make binary decisions with some bias. Boltzmann machines can be strung together to create more sophisticated systems such as deep belief networks. Boltzmann Machines can be used to optimize the solution to a problem.",0
What do you understand by Boltzmann Machine?,The encoder layer encodes the input image as a compressed representation in a reduced dimension. The compressed image is the distorted version of the original image.,The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,0
What is the use of encoder layers in Autoencoders?,"An encoder is a feedforward, fully connected neural network that compresses the input into a latent space representation and encodes the input image as a compressed representation in a reduced dimension.","This is the part of the network that compresses the input into a latent-space representation, and encodes the input image as a compressed representation in a reduced dimension.",1
What is the use of encoder layers in Autoencoders?,"An encoder is a feedforward, fully connected neural network that compresses the input into a latent space representation and encodes the input image as a compressed representation in a reduced dimension.","data can be considered a signal, and making convolution easier.",0
What is the function of the Fourier Transform in Deep Learning?,"This is the part of the network that compresses the input into a latent-space representation, and encodes the input image as a compressed representation in a reduced dimension.","processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",0
What is the use of encoder layers in Autoencoders?,"An encoder is a feedforward, fully connected neural network that compresses the input into a latent space representation and encodes the input image as a compressed representation in a reduced dimension.","An encoder is a feedforward, fully connected neural network that compresses the input and encodes the input image, The compressed image is the distorted version of the original image.",1
What is the use of encoder layers in Autoencoders?,"An encoder is a feedforward, fully connected neural network that compresses the input into a latent space representation and encodes the input image as a compressed representation in a reduced dimension.",Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. This network is responsible for reconstructing the input back to the original dimensions from the code.,0
What is the use of decoder layers in Autoencoders?,"An encoder is a feedforward, fully connected neural network that compresses the input and encodes the input image, The compressed image is the distorted version of the original image.",Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,0
What is the use of encoder layers in Autoencoders?,"An encoder is a feedforward, fully connected neural network that compresses the input into a latent space representation and encodes the input image as a compressed representation in a reduced dimension.",The encoder layer encodes the input image as a compressed representation. It can be represented by an encoding function h=f(x).,1
What is the use of encoder layers in Autoencoders?,"An encoder is a feedforward, fully connected neural network that compresses the input into a latent space representation and encodes the input image as a compressed representation in a reduced dimension.",The main task of the convolutional layer is to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,0
Explain the layer of CNN: convolution,The encoder layer encodes the input image as a compressed representation. It can be represented by an encoding function h=f(x).,The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,0
What is the use of encoder layers in Autoencoders?,The encoder layer encodes the input image as a compressed representation in a reduced dimension. The compressed image is the distorted version of the original image.,"This is the part of the network that compresses the input into a latent-space representation, and encodes the input image as a compressed representation in a reduced dimension.",1
What is the use of encoder layers in Autoencoders?,The encoder layer encodes the input image as a compressed representation in a reduced dimension. The compressed image is the distorted version of the original image.,"Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","This is the part of the network that compresses the input into a latent-space representation, and encodes the input image as a compressed representation in a reduced dimension.","AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
What is the use of encoder layers in Autoencoders?,The encoder layer encodes the input image as a compressed representation in a reduced dimension. The compressed image is the distorted version of the original image.,"An encoder is a feedforward, fully connected neural network that compresses the input and encodes the input image, The compressed image is the distorted version of the original image.",1
What is the use of encoder layers in Autoencoders?,The encoder layer encodes the input image as a compressed representation in a reduced dimension. The compressed image is the distorted version of the original image.,"Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.",0
what do you know about hidden layer?,"An encoder is a feedforward, fully connected neural network that compresses the input and encodes the input image, The compressed image is the distorted version of the original image.",The hidden layer after the input layer and before the ouput layer.,0
What is the use of encoder layers in Autoencoders?,The encoder layer encodes the input image as a compressed representation in a reduced dimension. The compressed image is the distorted version of the original image.,The encoder layer encodes the input image as a compressed representation. It can be represented by an encoding function h=f(x).,1
What is the use of encoder layers in Autoencoders?,The encoder layer encodes the input image as a compressed representation in a reduced dimension. The compressed image is the distorted version of the original image.,The aim of weight initialization is to prevent layer activation outputs from exploding or vanishing during the course of a forward pass through a deep neural network.,0
What is the meaning of term weight initialization in neural networks?,The encoder layer encodes the input image as a compressed representation. It can be represented by an encoding function h=f(x).,initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,0
What is the use of encoder layers in Autoencoders?,"This is the part of the network that compresses the input into a latent-space representation, and encodes the input image as a compressed representation in a reduced dimension.","An encoder is a feedforward, fully connected neural network that compresses the input and encodes the input image, The compressed image is the distorted version of the original image.",1
What is the use of encoder layers in Autoencoders?,"This is the part of the network that compresses the input into a latent-space representation, and encodes the input image as a compressed representation in a reduced dimension.","Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.",0
Explain the following variant of Gradient Descent mini-batch?,"An encoder is a feedforward, fully connected neural network that compresses the input and encodes the input image, The compressed image is the distorted version of the original image.",This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,0
What is the use of encoder layers in Autoencoders?,"This is the part of the network that compresses the input into a latent-space representation, and encodes the input image as a compressed representation in a reduced dimension.",The encoder layer encodes the input image as a compressed representation. It can be represented by an encoding function h=f(x).,1
What is the use of encoder layers in Autoencoders?,"This is the part of the network that compresses the input into a latent-space representation, and encodes the input image as a compressed representation in a reduced dimension.","Input Layer: Input variables, sometimes called the visible layer.",0
what do you know about input layer?,The encoder layer encodes the input image as a compressed representation. It can be represented by an encoding function h=f(x).,"Input Layer: Input variables, contains your raw data.",0
What is the use of encoder layers in Autoencoders?,"An encoder is a feedforward, fully connected neural network that compresses the input and encodes the input image, The compressed image is the distorted version of the original image.",The encoder layer encodes the input image as a compressed representation. It can be represented by an encoding function h=f(x).,1
What is the use of encoder layers in Autoencoders?,"An encoder is a feedforward, fully connected neural network that compresses the input and encodes the input image, The compressed image is the distorted version of the original image.","Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.",0
Explain the following variant of Gradient Descent mini-batch?,The encoder layer encodes the input image as a compressed representation. It can be represented by an encoding function h=f(x).,"This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",0
What is the use of code layers in Autoencoders?,The code layer is used to represent the compressed input which is fed to the decoder.,This part of the network represents the compressed input.,1
What is the use of code layers in Autoencoders?,The code layer is used to represent the compressed input which is fed to the decoder.,"If the set of weights in the network is put to a zero, then all the neurons at each layer will start producing the same output and the same gradients during backpropagation.",0
Why is zero initialization not a good weight initialization process?,This part of the network represents the compressed input.,"If all the weights are initialized with 0, all weights have the same value in subsequent iterations.",0
What is the use of code layers in Autoencoders?,The code layer is used to represent the compressed input which is fed to the decoder.,This part of the network contains the reduced representation of the input that is fed into the decoder.,1
What is the use of code layers in Autoencoders?,The code layer is used to represent the compressed input which is fed to the decoder.,"Instead of going through all examples, the gradient based on a single training sample.",0
Explain the following variant of Gradient Descent Stochastic?,This part of the network contains the reduced representation of the input that is fed into the decoder.,"the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration",0
What is the use of code layers in Autoencoders?,The code layer is used to represent the compressed input which is fed to the decoder.,produced after encoding the input image.,1
What is the use of code layers in Autoencoders?,The code layer is used to represent the compressed input which is fed to the decoder.,most important feature in an activation function is its ability to add non-linearity into a neural network.,0
What is the use of the Activation function?,produced after encoding the input image.,the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,0
What is the use of code layers in Autoencoders?,The code layer is used to represent the compressed input which is fed to the decoder.,This part of the network represents the input that is fed into the decoder.,1
What is the use of code layers in Autoencoders?,The code layer is used to represent the compressed input which is fed to the decoder.,"If all the weights are initialized with 0, all weights have the same value in subsequent iterations.",0
Why is zero initialization not a good weight initialization process?,This part of the network represents the input that is fed into the decoder.,"If all the weights are initialized with 0, leads the neurons to learn the same features during training.",0
What is the use of code layers in Autoencoders?,The code layer is used to represent the compressed input which is fed to the decoder.,This part of the network contains the reduced representation after encoding the input image.,1
What is the use of code layers in Autoencoders?,The code layer is used to represent the compressed input which is fed to the decoder.,The data is made available the output variables.,0
what do you know about output layer?,This part of the network contains the reduced representation after encoding the input image.,"The output layer is the simplest, data is made available at the output layer.",0
What is the use of code layers in Autoencoders?,The code layer is used to represent the compressed input which is fed to the decoder.,"produced after encoding the input image, represents the compressed input.",1
What is the use of code layers in Autoencoders?,The code layer is used to represent the compressed input which is fed to the decoder.,"a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; instead of computing the gradient from 1 sample (SGD) or all n training samples (GD), we compute the gradient from 1<k<n training samples",0
Explain the following variant of Gradient Descent mini-batch?,"produced after encoding the input image, represents the compressed input.","a compromise between batch GD and SGD. In MB-GD, we update the model based on smaller groups of training samples; sums up over lower number of examples based on the batch size.",0
What is the use of code layers in Autoencoders?,This part of the network represents the compressed input.,This part of the network contains the reduced representation of the input that is fed into the decoder.,1
What is the use of code layers in Autoencoders?,This part of the network represents the compressed input.,Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,0
"What do you mean by ""overfitting""?",This part of the network contains the reduced representation of the input that is fed into the decoder.,"Overfitting refers to a model that models the training data too well, where a statistical model begins to describe the random error.",0
What is the use of code layers in Autoencoders?,This part of the network represents the compressed input.,produced after encoding the input image.,1
What is the use of code layers in Autoencoders?,This part of the network represents the compressed input.,The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,0
What is the use of decoder layers in Autoencoders?,produced after encoding the input image.,This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,0
What is the use of code layers in Autoencoders?,This part of the network represents the compressed input.,This part of the network represents the input that is fed into the decoder.,1
What is the use of code layers in Autoencoders?,This part of the network represents the compressed input.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Deep Autoencoders?,This part of the network represents the input that is fed into the decoder.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",0
What is the use of code layers in Autoencoders?,This part of the network represents the compressed input.,This part of the network contains the reduced representation after encoding the input image.,1
What is the use of code layers in Autoencoders?,This part of the network represents the compressed input.,Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output.Unsupervised learning is modeling the underlying or hidden structure or distribution in the data in order to learn more about the data,0
Differentiate supervised and unsupervised deep learning procedures.,This part of the network contains the reduced representation after encoding the input image.,"Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
What is the use of code layers in Autoencoders?,This part of the network represents the compressed input.,"produced after encoding the input image, represents the compressed input.",1
What is the use of code layers in Autoencoders?,This part of the network represents the compressed input.,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. This network is responsible for reconstructing the input back to the original dimensions from the code.,0
What is the use of decoder layers in Autoencoders?,"produced after encoding the input image, represents the compressed input.",Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,0
What is the use of code layers in Autoencoders?,This part of the network contains the reduced representation of the input that is fed into the decoder.,produced after encoding the input image.,1
What is the use of code layers in Autoencoders?,This part of the network contains the reduced representation of the input that is fed into the decoder.,"Swish is a smooth function. That means that it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again. This observation means that its also non-monotonic.",0
What is a Swish function?,produced after encoding the input image.,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",0
What is the use of code layers in Autoencoders?,This part of the network contains the reduced representation of the input that is fed into the decoder.,This part of the network represents the input that is fed into the decoder.,1
What is the use of code layers in Autoencoders?,This part of the network contains the reduced representation of the input that is fed into the decoder.,the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,0
What is ReLU function?,This part of the network represents the input that is fed into the decoder.,"the output of ReLu is the maximum value between zero and the input value. will output the input directly if it is positive, otherwise, it will output zero.",0
What is the use of code layers in Autoencoders?,This part of the network contains the reduced representation of the input that is fed into the decoder.,This part of the network contains the reduced representation after encoding the input image.,1
What is the use of code layers in Autoencoders?,This part of the network contains the reduced representation of the input that is fed into the decoder.,aims to map the activation volume from the combination of previous different layers into a class probability distribution.,0
Explain the layer of CNN: Full Collectedness,This part of the network contains the reduced representation after encoding the input image.,"layer will compute the class scores, resulting a class probability distribution.",0
What is the use of code layers in Autoencoders?,This part of the network contains the reduced representation of the input that is fed into the decoder.,"produced after encoding the input image, represents the compressed input.",1
What is the use of code layers in Autoencoders?,This part of the network contains the reduced representation of the input that is fed into the decoder.,the cost function returns the error between predicted outcomes compared with the actual outcomes. The aim of supervised machine learning is to minimize the overall cost.,0
What is the cost function?,"produced after encoding the input image, represents the compressed input.",the cost function returns the error between predicted outcomes compared with the actual outcomes. presents it in the form of a single real number.,0
What is the use of code layers in Autoencoders?,produced after encoding the input image.,This part of the network represents the input that is fed into the decoder.,1
What is the use of code layers in Autoencoders?,produced after encoding the input image.,The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,0
What is the use of decoder layers in Autoencoders?,This part of the network represents the input that is fed into the decoder.,This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,0
What is the use of code layers in Autoencoders?,produced after encoding the input image.,This part of the network contains the reduced representation after encoding the input image.,1
What is the use of code layers in Autoencoders?,produced after encoding the input image.,Dropout is a technique where randomly selected neurons are ignored during training. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.,0
What do you mean by Dropout?,This part of the network contains the reduced representation after encoding the input image.,"The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.",0
What is the use of code layers in Autoencoders?,produced after encoding the input image.,"produced after encoding the input image, represents the compressed input.",1
What is the use of code layers in Autoencoders?,produced after encoding the input image.,Normalization is an approach which is applied during the preparation of data in order to change the values of numeric columns in a dataset to use a common scale when the features in the data have different ranges.,0
Explain Data Normalization.,"produced after encoding the input image, represents the compressed input.","change the values of numeric columns in the dataset to a common scale, when the features in the data have different ranges.",0
What is the use of code layers in Autoencoders?,This part of the network represents the input that is fed into the decoder.,This part of the network contains the reduced representation after encoding the input image.,1
What is the use of code layers in Autoencoders?,This part of the network represents the input that is fed into the decoder.,"The output layer is the simplest, usually consisting of a single output for classification problems.",0
What is the use of code layers in Autoencoders?,This part of the network represents the input that is fed into the decoder.,"produced after encoding the input image, represents the compressed input.",1
What is the use of code layers in Autoencoders?,This part of the network represents the input that is fed into the decoder.,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,0
Explain the following variant of Gradient Descent batch?,"produced after encoding the input image, represents the compressed input.","This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",0
What is the use of code layers in Autoencoders?,This part of the network contains the reduced representation after encoding the input image.,"produced after encoding the input image, represents the compressed input.",1
What is the use of code layers in Autoencoders?,This part of the network contains the reduced representation after encoding the input image.,can be used to predict probability as it produces output ranges between 0 and 1.,0
What is the sigmoid function?,"produced after encoding the input image, represents the compressed input.",activation function apply thresholding to input data and produce output between 0 and 1.,0
What is the use of decoder layers in Autoencoders?,The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,1
What is the use of decoder layers in Autoencoders?,The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data.,0
What do you understand by a convolutional neural network?,This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,"convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, for processing structured arrays of data such as images.",0
What is the use of decoder layers in Autoencoders?,The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).,1
What is the use of decoder layers in Autoencoders?,The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,0
what is a single percepton?,This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).,A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,0
What is the use of decoder layers in Autoencoders?,The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. This network is responsible for reconstructing the input back to the original dimensions from the code.,1
What is the use of decoder layers in Autoencoders?,The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,"n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.",0
What is the meaning of term weight initialization in neural networks?,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. This network is responsible for reconstructing the input back to the original dimensions from the code.,"In case of deep networks, if the weights are too-small the layers are the slowest to train in such a case, if the weights are large may cause number overflow resulting in incorrect computations",0
What is the use of decoder layers in Autoencoders?,The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,1
What is the use of decoder layers in Autoencoders?,The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,It is a function that measures the performance of a Machine Learning model for given data. Cost Function quantifies the error between predicted values and expected values and presents it in the form of a single real number.,0
What is the cost function?,This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,cost functions are used to estimate how badly models are performing. The aim of supervised machine learning is to minimize the overall cost,0
What is the use of decoder layers in Autoencoders?,The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,"This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network",1
What do you understand by a convolutional neural network?,"This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network","A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.",0
What is the use of decoder layers in Autoencoders?,The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,1
What is the use of decoder layers in Autoencoders?,The decoder layer decodes the encoded image back to its original dimension. The decoded image is a reduced reconstruction of the original image. It is automatically reconstructed from the latent space representation.,This is a type of gradient descent which works faster than both batch gradient descent and stochastic gradient descent. Here b examples where b<m are processed per iteration.,0
Explain the following variant of Gradient Descent mini-batch?,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples.Here b examples where b<m are processed per iteration.",0
What is the use of decoder layers in Autoencoders?,This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).,1
What is the use of decoder layers in Autoencoders?,This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,"If all the weights are initialized with 0, all weights have the same value in subsequent iterations.",0
Why is zero initialization not a good weight initialization process?,This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).,"Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.",0
What is the use of decoder layers in Autoencoders?,This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. This network is responsible for reconstructing the input back to the original dimensions from the code.,1
What is the use of decoder layers in Autoencoders?,This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,0
What do you understand by Deep Autoencoders?,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. This network is responsible for reconstructing the input back to the original dimensions from the code.,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",0
What is the use of decoder layers in Autoencoders?,This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,1
What is the use of decoder layers in Autoencoders?,This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,"while pooling , the number of nodes are reduced.And for flatten as it is converted to a single dimension array.",0
Explain the layer of CNN: pooling,This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,"pooling or downsampling layer is responsible for reducing the spatial dimensions (width, height), resulting in volume such as [16x16x12].",0
What is the use of decoder layers in Autoencoders?,This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,"This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network",1
What is the use of decoder layers in Autoencoders?,This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,the most commonly deployed activation function for the outputs of the CNN neurons.,0
Explain the layer of CNN: ReLU,"This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network","Once a feature map is created, we can use ReLU for the outputs of the CNN neurons.",0
What is the use of decoder layers in Autoencoders?,This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,1
What is the use of decoder layers in Autoencoders?,This layer decodes the encoded image back to the original dimension. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Deep Autoencoders?,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",0
What is the use of decoder layers in Autoencoders?,This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. This network is responsible for reconstructing the input back to the original dimensions from the code.,1
What is the use of decoder layers in Autoencoders?,This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).,"AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior.Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences.Deep learning is a part of Machine learning, which makes the computation of multi-layer neural networks feasible. It takes advantage of neural networks to simulate human-like decision making.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?",Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. This network is responsible for reconstructing the input back to the original dimensions from the code.,"AI means getting a computer to mimic human behavior in some way.Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications.Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems",0
What is the use of decoder layers in Autoencoders?,This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).,This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,1
What is the use of decoder layers in Autoencoders?,This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).,"The main reason why we use sigmoid function is because it exists between (0 to 1). Therefore, it is especially used for models where we have to predict the probability as an output.",0
What is the sigmoid function?,This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,activation function apply thresholding to input data and produce output between 0 and 1.,0
What is the use of decoder layers in Autoencoders?,This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).,"This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network",1
What is the use of decoder layers in Autoencoders?,This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).,"Hidden layers, are layers of mathematical functions each designed to produce an output specific to an intended result.",0
what do you know about hidden layer?,"This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network",The hidden layer after the input layer and before the ouput layer.,0
What is the use of decoder layers in Autoencoders?,This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,1
What is the use of decoder layers in Autoencoders?,This part aims to reconstruct the input from the latent space representation. It can be represented by a decoding function r=g(h).,"The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. models with higher Capacity than needed are prompt to overfit, low Capacity tend to underfit.",0
What is Model Capacity?,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",0
What is the use of decoder layers in Autoencoders?,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. This network is responsible for reconstructing the input back to the original dimensions from the code.,This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,1
What is the use of decoder layers in Autoencoders?,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. This network is responsible for reconstructing the input back to the original dimensions from the code.,initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,0
What is the meaning of term weight initialization in neural networks?,This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,"if the weights are too-small the layers will vanish, if the weights are large may cause number overflow resulting in incorrect computations",0
What is the use of decoder layers in Autoencoders?,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. This network is responsible for reconstructing the input back to the original dimensions from the code.,"This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network",1
What is the use of decoder layers in Autoencoders?,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. This network is responsible for reconstructing the input back to the original dimensions from the code.,most important feature in an activation function is its ability to add non-linearity into a neural network.,0
What is the use of the Activation function?,"This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network",the Neural Network can successfully approximate functions which does not follow linearity or it can successfully predict the class of a function which is divided by a decision boundary which is not linear.,0
What is the use of decoder layers in Autoencoders?,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. This network is responsible for reconstructing the input back to the original dimensions from the code.,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,1
What is the use of decoder layers in Autoencoders?,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. This network is responsible for reconstructing the input back to the original dimensions from the code.,"In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
Differentiate supervised and unsupervised deep learning procedures.,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,"supervised learning is where I have the input data and the corresponding output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",0
What is the use of decoder layers in Autoencoders?,This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,"This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network",1
What is the use of decoder layers in Autoencoders?,This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,"By normalizing all of our inputs to a standard scale so that they fit in specific range, we're allowing the network to more quickly learn the optimal parameters for each input node.",0
Explain Data Normalization.,"This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network",an approach which is applied during the preparation of data allowing the network to more quickly learn the optimal parameters for each input node.,0
What is the use of decoder layers in Autoencoders?,This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,1
What is the use of decoder layers in Autoencoders?,This layer decodes the encoded image back to the original dimension. It can be represented by a decoding function r=g(h).,"Mini-batch gradient descent is a variation of stochastic gradient descent. Instead of a single training example, mini-batch of samples is used. Mini-batch gradient descent is one of the most popular optimization algorithms.",0
Explain the following variant of Gradient Descent mini-batch?,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,"Instead of going over all examples, Mini-batch Gradient Descent sums up over lower number of examples based on the batch size.",0
What is the use of decoder layers in Autoencoders?,"This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network",Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,1
What is the use of decoder layers in Autoencoders?,"This part aims to reconstruct the input from the latent space representation, Decoder is also a feedforward network","As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",0
what is a single percepton?,Decoder is also a feedforward network like the encoder and has a similar structure to the encoder. The decoded image is a lossy reconstruction of the original image and it is reconstructed from the latent space representation.,"As a linear classifier, the simplest type of artificial neural networks.",0
What do you understand by Deep Autoencoders?,Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",1
What do you understand by Deep Autoencoders?,Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,"cost functions are used to estimate how badly models are performing. Put simply, a cost function is a measure of how wrong the model is in terms of its ability to estimate the relationship between X and y.",0
What is the cost function?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",It is a function that measures the performance of a Machine Learning model for given data. to estimate the relationship between X and y.,0
What do you understand by Deep Autoencoders?,Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",1
What do you understand by Deep Autoencoders?,Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,This part of the network represents the input that is fed into the decoder.,0
What is the use of code layers in Autoencoders?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.","produced after encoding the input image, represents the compressed input.",0
What do you understand by Deep Autoencoders?,Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,1
What do you understand by Deep Autoencoders?,Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,"n neural networking, weight initialization is one of the essential factors. A bad weight initialization prevents a network from learning. On the other side, a good weight initialization helps in giving a quicker convergence and a better overall error.",0
What is the meaning of term weight initialization in neural networks?,Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,initializing weights with too-small values will lead to divergence or a slow-down in the training of your neural network A too-large initialization this leads to the exploding gradient problem.,0
What do you understand by Deep Autoencoders?,Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",1
What is the cost function?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",It is a function that measures the performance of a Machine Learning model for given data. to estimate the relationship between X and y.,0
What do you understand by Deep Autoencoders?,Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",1
What do you understand by Deep Autoencoders?,Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,"Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",0
Explain gradient descent?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,0
What do you understand by Deep Autoencoders?,Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,"Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",1
What do you understand by Deep Autoencoders?,Deep Autoencoder is the extension of the simple Autoencoder. The first layer present is responsible for first-order functions in the raw input. The second layer is responsible for second-order functions corresponding to patterns in the appearance of first-order functions.,"Dropout is a cheap regulation technique used for reducing overfitting in neural networks. We randomly drop out a set of nodes at each training step. As a result, we create a different model for each training case, and all of these models share weights. It's a form of model averaging.",0
What do you mean by Dropout?,"Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.","The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.",0
What do you understand by Deep Autoencoders?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",1
What do you understand by Deep Autoencoders?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",Single layer perceptrons can learn only linearly separable patterns.,0
what is a single percepton?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.","As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",0
What do you understand by Deep Autoencoders?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,1
What do you understand by Deep Autoencoders?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",supervised learning is where I have the input data and the corresponding output.Unsupervised learning is where only the input data is present and no corresponding output variable is there.,0
Differentiate supervised and unsupervised deep learning procedures.,Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,"Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output. Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
What do you understand by Deep Autoencoders?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.","A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",1
What do you understand by Deep Autoencoders?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.","If all the weights are initialized with 0, all weights have the same value in subsequent iterations.",0
Why is zero initialization not a good weight initialization process?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.","in this case, the equations of the learning algorithm would fail to make any changes to the network weights, and the model will be stuck.",0
What do you understand by Deep Autoencoders?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",1
What do you understand by Deep Autoencoders?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.","An optimization algorithm that is used to minimize some function by repeatedly moving in the direction of steepest descent as specified by the negative of the gradient is known as gradient descent. It's an iteration algorithm, in every iteration algorithm, we compute the gradient of a cost function, concerning each parameter and update the parameter of the function",0
Explain gradient descent?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.","Gradient descent is an optimization algorithm used to minimize some function, To find a local minimum of a function using gradient descent, we take steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.",0
What do you understand by Deep Autoencoders?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.","Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",1
What do you understand by Deep Autoencoders?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.","With Dropout, the training process essentially drops out neurons in a neural network. They are temporarily removed from the network.",0
What do you mean by Dropout?,"Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",Dropout is a technique where randomly selected neurons are ignored during training. Doing this for every training example gives us different models for each one.,0
What do you understand by Deep Autoencoders?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,1
What do you understand by Deep Autoencoders?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,0
What do you understand by Perceptron?,Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,"A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",0
What do you understand by Deep Autoencoders?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.","A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",1
What do you understand by Deep Autoencoders?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,0
Explain the following variant of Gradient Descent batch?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.","This is a type of gradient descent which processes all the training example, the weights are updated incrementally after each iteration over the training dataset.",0
What do you understand by Deep Autoencoders?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",1
What do you understand by Deep Autoencoders?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.","Once a feature map is created, we can pass each value in the feature map through a nonlinearity, such as a ReLU.",0
Explain the layer of CNN: ReLU,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",the most commonly deployed activation function for the outputs of the CNN neurons.,0
What do you understand by Deep Autoencoders?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.","Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",1
What do you understand by Deep Autoencoders?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, and then uncompress that code into whatever format best matches the original input.",This layer computes the convolutions between the neurons of an input that results in an activation.,0
Explain the layer of CNN: convolution,"Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",A convolution is the simple application of a filter to detect local conjunctions of features from the previous layer and mapping their appearance to a feature map.,0
What do you understand by Deep Autoencoders?,Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",1
What do you understand by Deep Autoencoders?,Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,"A convolutional neural network, often called CNN, is a feedforward neural network. It uses convolution in at least one of its layers. The convolutional layer contains a set of filter (kernels). This filter is sliding across the entire input image, computing the dot product between the weights of the filter and the input image. As a result of training, the network automatically learns filters that can detect specific features.",0
What do you understand by a convolutional neural network?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.","A convolutional neural network, or CNN, is a deep learning neural network designed for processing structured arrays of data such as images.",0
What do you understand by Deep Autoencoders?,Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",1
What do you understand by Deep Autoencoders?,Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,"Leaky ReLUs are one attempt to fix the dying ReLU problem by allowing small, non-zero, constant gradient Î±.",0
What is the use of leaky ReLU function?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,0
What do you understand by Deep Autoencoders?,Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,"Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",1
What do you understand by Deep Autoencoders?,Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,"layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",0
Explain the layer of CNN: Full Collectedness,"Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.","layer will compute the class scores, resulting a class probability distribution.",0
What do you understand by Deep Autoencoders?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",1
What do you understand by Deep Autoencoders?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",This part of the network represents the input that is fed into the decoder.,0
What is the use of code layers in Autoencoders?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.","produced after encoding the input image, represents the compressed input.",0
What do you understand by Deep Autoencoders?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.","Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",1
What do you understand by Deep Autoencoders?,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.","Tensors are mathematical objects that generalize scalars, vectors and matrices to higher dimensions. In short, a single-dimensional tensor can be represented as a vector.",0
What do you understand by Tensors?,"Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,0
What do you understand by Deep Autoencoders?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.","Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",1
What do you understand by Deep Autoencoders?,"Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",The data is made available the output variables.,0
what do you know about output layer?,"Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",Output Layer: A layer of nodes that usually consisting of a single output for classification problems.,0
What do you understand by Perceptron?,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,"A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",1
What do you understand by Perceptron?,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,This part of the network contains the reduced representation of the input that is fed into the decoder.,0
What is the use of code layers in Autoencoders?,"A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.","produced after encoding the input image, represents the compressed input.",0
What do you understand by Perceptron?,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,1
What do you understand by Perceptron?,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,"data can be considered a signal, and making convolution easier.",0
What is the function of the Fourier Transform in Deep Learning?,Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,"processing a large dataset can be hard, but it can be considered a signal, Performing convolutions efficiently as products in the Fourier domain.",0
What do you understand by Perceptron?,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,1
What do you understand by Perceptron?,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. They dont have the typical 1 or 0 type output through which patterns are learned and optimized using Stochastic Gradient Descent.,0
What do you understand by Boltzmann Machine?,A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,0
What do you understand by Perceptron?,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,1
What do you understand by Perceptron?,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,"In Supervised learning, you train the machine using data which is well labeled.Unsupervised learning is a machine learning technique, where you do not need to supervise the model. Instead, you need to allow the model to work on its own to discover information. It mainly deals with the unlabelled data.",0
Differentiate supervised and unsupervised deep learning procedures.,A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,"supervised learning is where I have the input data and the corresponding output. Unsupervised procedure does not need labeling information explicitly, and the operations can be carried out without the same.",0
What do you understand by Perceptron?,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,Perceptron is a machine learning algorithm that helps provide classified outcomes. This algorithm enables neurons to learn and processes elements in the training set one at a time.,1
What do you understand by Perceptron?,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",0
What do you understand by Deep Autoencoders?,Perceptron is a machine learning algorithm that helps provide classified outcomes. This algorithm enables neurons to learn and processes elements in the training set one at a time.,"Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",0
What do you understand by Perceptron?,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,"A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",1
What do you understand by Perceptron?,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,The hidden layer is used to send data to the output layer.,0
what do you know about hidden layer?,"A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",The hidden layer after the input layer to send data to the output layer.,0
What do you understand by Perceptron?,"A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,1
What do you understand by Perceptron?,"A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",The encoder layer encodes the input image as a compressed representation in a reduced dimension. The compressed image is the distorted version of the original image.,0
What is the use of encoder layers in Autoencoders?,Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,The encoder layer encodes the input image as a compressed representation. It can be represented by an encoding function h=f(x).,0
What do you understand by Perceptron?,"A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,1
What do you understand by Perceptron?,"A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.","AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?",A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,"AI means getting a computer to mimic human behavior in some way, Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
What do you understand by Perceptron?,"A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,1
What do you understand by Perceptron?,"A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",Output Layer: A layer of nodes that produce the output variables.,0
what do you know about output layer?,A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,"The output layer is the simplest, data is made available at the output layer.",0
What do you understand by Perceptron?,"A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",Perceptron is a machine learning algorithm that helps provide classified outcomes. This algorithm enables neurons to learn and processes elements in the training set one at a time.,1
What do you understand by Perceptron?,"A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",This layer comprises of a set of independent filters. All these filters are initialized randomly. These filters then become our parameters which will be learned by the network subsequently.,0
Explain the layer of CNN: convolution,Perceptron is a machine learning algorithm that helps provide classified outcomes. This algorithm enables neurons to learn and processes elements in the training set one at a time.,The main task of the convolutional layer is to detect local conjunctions of features between the neurons and the various patches in the input.,0
What do you understand by Perceptron?,"A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.","A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",1
What do you understand by Perceptron?,"A Perceptron is an algorithm used for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.","The hyperbolic tangent function, also known as tanh for short, is a similar shaped nonlinear activation function. It provides output values between -1.0 and 1.0.It was easier to train and often had better predictive performance.",0
What is Tanh function?,"A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.","tanh is also like logistic sigmoid but better. The range of the tanh function is from (-1 to 1), The advantage is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero in the tanh graph.",0
What do you understand by Perceptron?,Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,1
What do you understand by Perceptron?,Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,The hidden layer is used to send data to the output layer.,0
what do you know about hidden layer?,A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,The hidden layer after the input layer and before the ouput layer.,0
What do you understand by Perceptron?,Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,1
What do you understand by Perceptron?,Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,"can be used as activation function would be a threshold based classifier if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated.",0
What is a binary step function?,A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,"A binary step function is a threshold-based activation function. If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",0
What do you understand by Perceptron?,Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,Perceptron is a machine learning algorithm that helps provide classified outcomes. This algorithm enables neurons to learn and processes elements in the training set one at a time.,1
What do you understand by Perceptron?,Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,"Data normalization is an essential preprocessing step, which is used to rescale values to fit in a specific range. It assures better convergence during backpropagation.",0
Explain Data Normalization.,Perceptron is a machine learning algorithm that helps provide classified outcomes. This algorithm enables neurons to learn and processes elements in the training set one at a time.,"the goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.",0
What do you understand by Perceptron?,Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,"A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",1
What do you understand by Perceptron?,Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,Overfitting a model is a condition where a statistical model begins to describe the random error in the data rather than the relationships between variables.,0
"What do you mean by ""overfitting""?","A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.","Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.",0
What do you understand by Perceptron?,A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,1
What do you understand by Perceptron?,A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,It reduces the spatial size of the representation to lower the number of parameters and computation in the network. This layer operates on each feature map independently.,0
Explain the layer of CNN: pooling,A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,"while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.",0
What do you understand by Perceptron?,A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,Perceptron is a machine learning algorithm that helps provide classified outcomes. This algorithm enables neurons to learn and processes elements in the training set one at a time.,1
What do you understand by Perceptron?,A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,"As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.",0
what is a single percepton?,Perceptron is a machine learning algorithm that helps provide classified outcomes. This algorithm enables neurons to learn and processes elements in the training set one at a time.,A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,0
What do you understand by Perceptron?,A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,"A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",1
What do you understand by Perceptron?,A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,"Tensors are nothing but a de facto for representing the data in deep learning. They are just multidimensional arrays, which allows us to represent the data having higher dimensions. In general, we deal with high dimensional data sets where dimensions refer to different features present in the data set.",0
What do you understand by Tensors?,"A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",A tensor is a container which can house data in N dimensions. tensors are generalizations of matrices to N-dimensional space.,0
What do you understand by Perceptron?,A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,Perceptron is a machine learning algorithm that helps provide classified outcomes. This algorithm enables neurons to learn and processes elements in the training set one at a time.,1
What do you understand by Perceptron?,A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,"The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero.",0
What is ReLU function?,Perceptron is a machine learning algorithm that helps provide classified outcomes. This algorithm enables neurons to learn and processes elements in the training set one at a time.,the output of ReLu is the maximum value between zero and the input value. An output is equal to zero when the input value is negative and the input value when the input is positive.,0
What do you understand by Perceptron?,A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,"A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",1
What do you understand by Perceptron?,A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,fully connected neural network structure that drives the final classification decision.,0
Explain the layer of CNN: Full Collectedness,"A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.","fully connected neural network structure, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",0
What do you understand by Perceptron?,Perceptron is a machine learning algorithm that helps provide classified outcomes. This algorithm enables neurons to learn and processes elements in the training set one at a time.,"A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",1
What do you understand by Perceptron?,Perceptron is a machine learning algorithm that helps provide classified outcomes. This algorithm enables neurons to learn and processes elements in the training set one at a time.,"Without the Activation function, the neural network would be only able to learn function, which is a linear combination of its input data.",0
What is the use of the Activation function?,"A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",The basic purpose of the activation function its ability to add non-linearity into a neural network.,0
what is a single percepton?,Single layer perceptrons can learn only linearly separable patterns.,"As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.",1
what is a single percepton?,Single layer perceptrons can learn only linearly separable patterns.,"tanh produces output ranges from -1 and 1, and used as activation function.",0
What is Tanh function?,"As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.","rescaling of the logistic sigmoid, inputs will be mapped strongly negative and the zero inputs will be mapped near zero",0
what is a single percepton?,Single layer perceptrons can learn only linearly separable patterns.,A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,1
what is a single percepton?,Single layer perceptrons can learn only linearly separable patterns.,Stochastic gradient descent is used to calculate the gradient and update the parameters by using only a single training example.,0
Explain the following variant of Gradient Descent Stochastic?,A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,"the term ""stochastic"" comes from the fact that the gradient based on processing 1 training example per iteration",0
what is a single percepton?,Single layer perceptrons can learn only linearly separable patterns.,the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,1
what is a single percepton?,Single layer perceptrons can learn only linearly separable patterns.,will perform a downsampling operation along the spatial dimensions for flatten as it is converted to a single dimension array.,0
Explain the layer of CNN: pooling,the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,"while pooling , the number of nodes are reduced. for reducing the spacial size of the activation maps.",0
what is a single percepton?,Single layer perceptrons can learn only linearly separable patterns.,"As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",1
what is a single percepton?,Single layer perceptrons can learn only linearly separable patterns.,"Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. Along the same lines, models with higher Capacity than needed are prompt to overfit.",0
What is Model Capacity?,"As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.","Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",0
what is a single percepton?,Single layer perceptrons can learn only linearly separable patterns.,A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,1
what is a single percepton?,Single layer perceptrons can learn only linearly separable patterns.,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, however it is differentiable at all points and is non-monotonic, that's why it gives better performance",0
What is a Swish function?,A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,"Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",0
what is a single percepton?,Single layer perceptrons can learn only linearly separable patterns.,"As a linear classifier, the simplest type of artificial neural networks.",1
what is a single percepton?,Single layer perceptrons can learn only linearly separable patterns.,"Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.",0
What is deep learning?,"As a linear classifier, the simplest type of artificial neural networks.","Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.",0
what is a single percepton?,"As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.",A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,1
what is a single percepton?,"As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.",A Perceptron is an algorithm for supervised learning of binary classifiers. This algorithm enables neurons to learn and processes elements in the training set one at a time.,0
What do you understand by Perceptron?,A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,"A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",0
what is a single percepton?,"As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.",the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,1
what is a single percepton?,"As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.","Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.",0
Explain gradient descent?,the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. Gradient descent is simply used to find the values of a function's parameters (coefficients) that minimize a cost function as far as possible.,0
what is a single percepton?,"As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.","As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",1
what is a single percepton?,"As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.",Multilayer perceptrons or feedforward neural networks with two or more layers have the higher processing power.,0
what is a multilayer percepton?,"As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",has the same structure of a single layer perceptron with one or more hidden layers.,0
what is a single percepton?,"As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.",A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,1
what is a single percepton?,"As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.","Leaky ReLUs are one attempt to fix the dying ReLU problem by having a small negative slope (of 0.01, or so).",0
What is the use of leaky ReLU function?,A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,the Leaky ReLU which attempts to resolve issues with traditional ReLU by having a small negative slope.,0
what is a single percepton?,"As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.","As a linear classifier, the simplest type of artificial neural networks.",1
what is a single percepton?,"As a linear classifier, the single-layer perceptron is the simplest feedforward neural network.",Backpropagation is a process used to adjust the weights of a deep neural network. It reduces the loss between the predicted values and the actual values.,0
What is Backpropagation?,"As a linear classifier, the simplest type of artificial neural networks.","The Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent, looks for the minimum value of the error.",0
what is a single percepton?,A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,1
what is a single percepton?,A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,"Softmax turns arbitrary real values into probabilities, which are often useful in Machine Learning. The outputs of the Softmax transform are always in the range [0,1][0, 1][0,1] and add up to 1.",0
What is the softmax function?,the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,"Softmax turns arbitrary real values into probabilities, The output values are between the range [0,1].",0
what is a single percepton?,A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,"As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",1
what is a single percepton?,A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,Batch Gradient Descent is when we sum up over all examples on each iteration when performing the updates to the parameters.,0
Explain the following variant of Gradient Descent batch?,"As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.","Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",0
what is a single percepton?,A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,1
what is a single percepton?,A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,"It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.",0
Explain the importance of LSTM.,A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,LSTMs have property of selectively remembering information to be used in the current neural network.,0
what is a single percepton?,A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,"As a linear classifier, the simplest type of artificial neural networks.",1
what is a single percepton?,A single layer perceptron (SLP) is a feed-forward network based on a threshold transfer function.,"Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.",0
What are the disadvantages of deep learning?,"As a linear classifier, the simplest type of artificial neural networks.",It requires very large amount of data in order to perform better than other techniques. Is extremely computationally expensive to train.,0
what is a single percepton?,the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,"As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",1
what is a single percepton?,the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,"It is an artificial RNN (Recurrent Neural Network) architecture, which is used in the field of deep learning. LSTM has feedback connections which makes it a ""general purpose computer."" It can process not only a single data point but also entire sequences of data.",0
Explain the importance of LSTM.,"As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",LSTMs have property of selectively remembering patterns for long durations of time.,0
what is a single percepton?,the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,1
what is a single percepton?,the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,"AI stands for Artificial Intelligence. It is a technique which enables machines to mimic human behavior, .Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn, Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?",A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,"Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, .Machine Learning is a subset of AI which uses statistical methods to enable machines to improve with experiences, Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
what is a single percepton?,the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,"As a linear classifier, the simplest type of artificial neural networks.",1
what is a single percepton?,the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and second set of four or five layers that make up the decoding half.",0
What do you understand by Deep Autoencoders?,"As a linear classifier, the simplest type of artificial neural networks.","Autoencoder networks teach themselves how to compress data from the input layer into a shorter code, The autoencoders reconstruct each dimension of the input by passing it through the network.",0
what is a single percepton?,"As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,1
what is a single percepton?,"As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",This is a type of gradient descent which update the parameters on each example.,0
Explain the following variant of Gradient Descent Stochastic?,A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,"Instead of going through all examples, the gradient based on a single training sample.",0
what is a single percepton?,"As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.","As a linear classifier, the simplest type of artificial neural networks.",1
what is a single percepton?,"As a linear classifier, the single-layer perceptron is feed-forward network based on a threshold transfer function.",This part of the network represents the compressed input.,0
What is the use of code layers in Autoencoders?,"As a linear classifier, the simplest type of artificial neural networks.",This part of the network represents the input that is fed into the decoder.,0
what is a single percepton?,A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,"As a linear classifier, the simplest type of artificial neural networks.",1
what is a single percepton?,A single layer perceptron (SLP) is a feed-forward network can only classify linearly separable cases with a binary target.,"The binary step function is an activation function, which is usually based on a threshold. If the input value is above or below a particular threshold limit, the neuron is activated, then it sends the same signal to the next layer. This function does not allow multi-value outputs.",0
What is a binary step function?,"As a linear classifier, the simplest type of artificial neural networks.","can be used as activation function would be a threshold based classifier, If the input value is above or below a certain threshold, the neuron is activated and sends exactly the same signal to the next layer.",0
what is a multilayer percepton?,Multilayer perceptrons or feedforward neural networks with two or more layers have the higher processing power.,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,1
what is a multilayer percepton?,Multilayer perceptrons or feedforward neural networks with two or more layers have the higher processing power.,deep network we have more than equal to 2 hidden layers . The idea of having more layers is to extract more finer features of the input vector . A shallow network has less number of hidden layers.,0
Do you think that deep network is better than a shallow one?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,"A shallow network has less number of hidden layers. While there are studies that a shallow network can fit any function, it will need to be really fat. deep network you have lots and lots of computational nodes and lots of layers of those nodes.",0
what is a multilayer percepton?,Multilayer perceptrons or feedforward neural networks with two or more layers have the higher processing power.,has the same structure of a single layer perceptron with one or more hidden layers.,1
what is a multilayer percepton?,Multilayer perceptrons or feedforward neural networks with two or more layers have the higher processing power.,Batch gradient descent is used to calculate the gradients for the whole dataset and perform just one update at each iteration.,0
Explain the following variant of Gradient Descent batch?,has the same structure of a single layer perceptron with one or more hidden layers.,"Using the Gradient Decent optimization algorithm, the weights are updated incrementally on each iteration.",0
what is a multilayer percepton?,Multilayer perceptrons or feedforward neural networks with two or more layers have the higher processing power.,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",1
what is a multilayer percepton?,Multilayer perceptrons or feedforward neural networks with two or more layers have the higher processing power.,A perceptron is a neural network unit (an artificial neuron) that does certain computations to detect features. It is an algorithm for supervised learning of binary classifiers.,0
What do you understand by Perceptron?,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",A Perceptron is an algorithm used for supervised learning of binary classifiers. helps provide classified outcomes for computing.,0
what is a multilayer percepton?,Multilayer perceptrons or feedforward neural networks with two or more layers have the higher processing power.,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,1
what is a multilayer percepton?,Multilayer perceptrons or feedforward neural networks with two or more layers have the higher processing power.,"Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.",0
What is deep learning?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,0
what is a multilayer percepton?,Multilayer perceptrons or feedforward neural networks with two or more layers have the higher processing power.,"has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",1
what is a multilayer percepton?,Multilayer perceptrons or feedforward neural networks with two or more layers have the higher processing power.,Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.,0
What is deep learning?,"has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.","Deep learning is a subset of machine learning where artificial neural networks, imitates the workings of the human brain in processing data and creating patterns for use in decision making.",0
what is a multilayer percepton?,Multilayer perceptrons or feedforward neural networks with two or more layers have the higher processing power.,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, It is substantially formed from multiple layers of perceptron.",1
what is a multilayer percepton?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,has the same structure of a single layer perceptron with one or more hidden layers.,1
what is a multilayer percepton?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,"The basic idea of this method is to, based on probability, temporarily drop out neurons from our original network. Doing this for every training example gives us different models for each one.",0
What do you mean by Dropout?,has the same structure of a single layer perceptron with one or more hidden layers.,"With Dropout, the training process essentially drops out neurons in a neural network, This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.",0
what is a multilayer percepton?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",1
what is a multilayer percepton?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,"takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, where each element i, j is the product of elements i, j of the original two matrices.",0
What is matrix element-wise multiplication?,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.","takes two matrices of the same dimensions and produces another matrix of the same dimension as the operands, by multiplying corresponding elements.",0
what is a multilayer percepton?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,1
what is a multilayer percepton?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,"Overfitting is a term used in statistics that refers to a modeling error that occurs when a function corresponds too closely to a particular set of data. As a result, overfitting may fail to fit additional data, and this may affect the accuracy of predicting future observations.",0
"What do you mean by ""overfitting""?",Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,"Overfitting is a term used in statistics that refers to a modeling error, rather than the relationships between variables.",0
what is a multilayer percepton?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,"has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",1
what is a multilayer percepton?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,The capacity of a deep learning neural network model controls the scope of the types of mapping functions that it is able to learn. The capacity of a neural network model is defined by configuring the number of nodes and the number of layers.,0
What is Model Capacity?,"has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.","Machine learning models with low Capacity are impractical when comes to solve complex tasks and tend to underfit. whereas a model with too much capacity may memorize the training dataset, meaning it will overfit or may get stuck or lost during the optimization process.",0
what is a multilayer percepton?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, It is substantially formed from multiple layers of perceptron.",1
what is a multilayer percepton?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. It is substantially formed from multiple layers of perceptron.,"LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series.",0
Explain the importance of LSTM.,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, It is substantially formed from multiple layers of perceptron.","LSTM use persistent previous information to classifying, processing and making predictions based on time series data",0
what is a multilayer percepton?,has the same structure of a single layer perceptron with one or more hidden layers.,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",1
what is a multilayer percepton?,has the same structure of a single layer perceptron with one or more hidden layers.,Single layer perceptrons can learn only linearly separable patterns.,0
what is a single percepton?,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",the simplest type of artificial neural networks and can only classify linearly separable cases with a binary target,0
what is a multilayer percepton?,has the same structure of a single layer perceptron with one or more hidden layers.,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,1
what is a multilayer percepton?,has the same structure of a single layer perceptron with one or more hidden layers.,"If all the weights are initialized with 0, leads the neurons to learn the same features during training.",0
Why is zero initialization not a good weight initialization process?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,"Initializing all the weights with zeros leads the neurons fail to make any changes to the network weights, and the model will be stuck.",0
what is a multilayer percepton?,has the same structure of a single layer perceptron with one or more hidden layers.,"has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",1
what is a multilayer percepton?,has the same structure of a single layer perceptron with one or more hidden layers.,"Deep learning model takes longer time to execute the model. In some cases, it even takes several days to execute a single model depends on complexity. The deep learning model is not good for small data sets, and it fails here.",0
What are the disadvantages of deep learning?,"has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.","Neural networks usually require much more data than traditional machine learning algorithms, as in at least thousands if not millions of labeled samples. It is extremely expensive to train due to complex data models. Moreover deep learning requires expensive GPUs and hundreds of machines. This increases cost to the users.",0
what is a multilayer percepton?,has the same structure of a single layer perceptron with one or more hidden layers.,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, It is substantially formed from multiple layers of perceptron.",1
what is a multilayer percepton?,has the same structure of a single layer perceptron with one or more hidden layers.,"Like ReLU, Swish is bounded below but unbounded above. However, unlike ReLU, Swish is smooth and non-monotonic.",0
What is a Swish function?,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, It is substantially formed from multiple layers of perceptron.","Swish Activation Function is continuous at all points. The shape of Swish Activation Function looks similar to ReLU, but unlike ReLU it does not abruptly change direction like ReLU does near x = 0. Rather, it smoothly bends from 0 towards values < 0 and then upwards again.",0
what is a multilayer percepton?,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,1
what is a multilayer percepton?,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",Autoencoder is a type of neural network where the output layer has the same dimensionality as the input layer. The autoencoders reconstruct each dimension of the input by passing it through the network.,0
What do you understand by Deep Autoencoders?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,"A deep autoencoder is composed of two, symmetrical deep-belief networks that typically have four or five shallow layers representing the encoding half of the net, and then uncompress that code into whatever format best matches the original input.",0
what is a multilayer percepton?,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.","has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",1
what is a multilayer percepton?,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.","Artificial intelligence is any computer program that does something smart. It can be a stack of a complex statistical model or if-then statements.Machine learning is a subset of AI. The theory is simple, machines take data for themselvesDeep learning is a subset of machine learning. Deep artificial neural networks are a set of algorithms reaching new levels of accuracy for many important problems.",0
"What are the main differences between AI, Machine Learning, and Deep Learning?","has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.","Artificial intelligence is a science like mathematics or biology. It studies ways to build intelligent programs and machines that can creatively solve problems, which has always been considered a human prerogative.Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. In ML, there are different algorithms (e.g. neural networks) that help to solve problems.Deep learning, is a subset of machine learning, which uses the neural networks to analyze different factors with a structure that is similar to the human neural system.",0
what is a multilayer percepton?,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.","A multilayer perceptron is a neural network connecting multiple layers in a directed graph, It is substantially formed from multiple layers of perceptron.",1
what is a multilayer percepton?,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",Perceptron is a machine learning algorithm that helps provide classified outcomes for computing,0
What do you understand by Perceptron?,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, It is substantially formed from multiple layers of perceptron.","A Perceptron is an algorithm for supervised learning of binary classifiers. Binary classifiers decide whether an input, usually represented by a series of vectors, belongs to a specific class.",0
what is a multilayer percepton?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,"has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",1
what is a multilayer percepton?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,Boltzmann machines are non-deterministic (or stochastic) generative Deep Learning models with only two types of nodes  hidden and visible nodes. It is the work of Boltzmann Machine to optimize the weights and quantity related to that particular problem.,0
What do you understand by Boltzmann Machine?,"has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.",The main purpose of Boltzmann Machine is to optimize the solution of a problem. Boltzmann machines have a simple learning algorithm that allows them to discover interesting features that represent complex regularities in the training data.,0
what is a multilayer percepton?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, It is substantially formed from multiple layers of perceptron.",1
what is a multilayer percepton?,Multi-Layer perceptron defines the most complicated architecture of artificial neural networks. with one or more hidden layers.,A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior.,0
What is an RNN?,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, It is substantially formed from multiple layers of perceptron.","A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes, It is the first algorithm that remembers its input.",0
what is a multilayer percepton?,"has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.","A multilayer perceptron is a neural network connecting multiple layers in a directed graph, It is substantially formed from multiple layers of perceptron.",1
what is a multilayer percepton?,"has the same structure of a single layer perceptron but with multiple layers in a directed graph, which means that the signal path through the nodes only goes one way.","layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score.",0
Explain the layer of CNN: Full Collectedness,"A multilayer perceptron is a neural network connecting multiple layers in a directed graph, It is substantially formed from multiple layers of perceptron.",fully connected neural network structure that drives the final classification decision.,0
Define precison and recall ?,"precision is the ratio of serveral events you can correctly recall to the total number of events you recall , precision = (True Positive)/(True Positive + False Negative), recall is the ratio of a number of events you can recall the total events , recall = (True Positive)/(True Positive + False Negative)","precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances, while recall (also known as sensitivity) is the fraction of the total amount of relevant instances that were actually retrieved. Both precision and recall are therefore based on an understanding and measure of relevance.",1
Define precison and recall ?,"precision is the ratio of serveral events you can correctly recall to the total number of events you recall , precision = (True Positive)/(True Positive + False Negative), recall is the ratio of a number of events you can recall the total events , recall = (True Positive)/(True Positive + False Negative)","Reinforcement learning is the training of machine learning models to make a sequence of decisions. The agent learns to achieve a goal in an uncertain, potentially complex environment. In reinforcement learning, an artificial intelligence faces a game-like situation. The computer employs trial and error to come up with a solution to the problem. To get the machine to do what the programmer wants, the artificial intelligence gets either rewards or penalties for the actions it performs. Its goal is to maximize the total reward.",0
what it the reinforcement learning ?,"precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances, while recall (also known as sensitivity) is the fraction of the total amount of relevant instances that were actually retrieved. Both precision and recall are therefore based on an understanding and measure of relevance.",Reinforcement Learning is defined as a Machine Learning method that is concerned with how software agents should take actions in an environment. Reinforcement Learning is a part of the deep learning method that helps you to maximize some portion of the cumulative reward.,0
Define precison and recall ?,"precision is the ratio of serveral events you can correctly recall to the total number of events you recall , precision = (True Positive)/(True Positive + False Negative), recall is the ratio of a number of events you can recall the total events , recall = (True Positive)/(True Positive + False Negative)","Precision attempts to answer the following question:
What proportion of positive identifications was actually correct?Recall attempts to answer the following question:
What proportion of actual positives was identified correctly?",1
Define precison and recall ?,"precision is the ratio of serveral events you can correctly recall to the total number of events you recall , precision = (True Positive)/(True Positive + False Negative), recall is the ratio of a number of events you can recall the total events , recall = (True Positive)/(True Positive + False Negative)",False positives are those cases which wrongly get classified as True but are False.False negatives are those cases which wrongly get classified as False but are True.,0
What Is a False Positive and False Negative and How Are They Significant?,"Precision attempts to answer the following question:
What proportion of positive identifications was actually correct?Recall attempts to answer the following question:
What proportion of actual positives was identified correctly?",A false positive is an outcome where the model incorrectly predicts the positive class.false negative is an outcome where the model incorrectly predicts the negative class.,0
what is the difference between supervised learning and unsupervised learning ?,"Supervised learning requires training labeled data.Unsupervised learning, in contrast, does not require labeling data explicitly.","In Supervised learning, you train the machine using data which is well ""labeled."".Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",1
what is the difference between supervised learning and unsupervised learning ?,"Supervised learning requires training labeled data.Unsupervised learning, in contrast, does not require labeling data explicitly.",Linear Regression is a supervised Machine Learning algorithm. It is used to find the linear relationship between the dependent and the independent variables for predictive analysis.,0
What is Linear Regression?,"In Supervised learning, you train the machine using data which is well ""labeled."".Unsupervised learning is a machine learning technique, where you do not need to supervise the model.","Linear regression algorithm shows a linear relationship between a dependent (y) and one or more independent (y) variables, hence called as linear regression. Since linear regression shows the linear relationship, which means it finds how the value of the dependent variable is changing according to the value of the independent variable.",0
what is the difference between supervised learning and unsupervised learning ?,"Supervised learning requires training labeled data.Unsupervised learning, in contrast, does not require labeling data explicitly.",Supervised learning is simply a process of learning algorithm from the training dataset. Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output,1
what is the difference between supervised learning and unsupervised learning ?,"Supervised learning requires training labeled data.Unsupervised learning, in contrast, does not require labeling data explicitly.",Overfitting is a situation that occurs when a model learns the training set too well,0
what is the overfitting ?,Supervised learning is simply a process of learning algorithm from the training dataset. Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output,"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably",0
what is the difference between supervised learning and unsupervised learning ?,"Supervised learning requires training labeled data.Unsupervised learning, in contrast, does not require labeling data explicitly.","In supervised machine learning, a model makes predictions or decisions based on past or labeled data. Labeled data refers to sets of data that are given tags or labels, and thus made more meaningful.In unsupervised learning, we don't have labeled data. A model can identify patterns, anomalies, and relationships in the input data.",1
what is the difference between supervised learning and unsupervised learning ?,"Supervised learning requires training labeled data.Unsupervised learning, in contrast, does not require labeling data explicitly.","Reinforcement learning is the training of machine learning models to make a sequence of decisions. The agent learns to achieve a goal in an uncertain, potentially complex environment. In reinforcement learning, an artificial intelligence faces a game-like situation. The computer employs trial and error to come up with a solution to the problem. To get the machine to do what the programmer wants, the artificial intelligence gets either rewards or penalties for the actions it performs. Its goal is to maximize the total reward.",0
what it the reinforcement learning ?,"In supervised machine learning, a model makes predictions or decisions based on past or labeled data. Labeled data refers to sets of data that are given tags or labels, and thus made more meaningful.In unsupervised learning, we don't have labeled data. A model can identify patterns, anomalies, and relationships in the input data.",Reinforcement learning is an area of Machine Learning. It is about taking suitable action to maximize reward in a particular situation. It is employed by various software and machines to find the best possible behavior or path it should take in a specific situation.,0
what is the difference between supervised learning and unsupervised learning ?,"Supervised learning requires training labeled data.Unsupervised learning, in contrast, does not require labeling data explicitly.","In supervised machine learning algorithms, we have to provide labeled data, for example, prediction of stock market prices, whereas in unsupervised we need not have labeled data, for example, classification of emails into spam and non-spam.",1
what is the difference between supervised learning and unsupervised learning ?,"Supervised learning requires training labeled data.Unsupervised learning, in contrast, does not require labeling data explicitly.","The F1 score is a measure of a model’s performance. It is a weighted average of the precision and recall of a model, with results tending to 1 being the best, and those tending to 0 being the worst. You would use it in classification tests where true negatives don’t matter much.",0
What’s the F1 score? How would you use it?,"In supervised machine learning algorithms, we have to provide labeled data, for example, prediction of stock market prices, whereas in unsupervised we need not have labeled data, for example, classification of emails into spam and non-spam.","The F-score, also called the F1-score, is a measure of a model’s accuracy on a dataset. It is used to evaluate binary classification systems, which classify examples into ‘positive’ or ‘negative’.

The F-score is a way of combining the precision and recall of the model, and it is defined as the harmonic mean of the model’s precision and recall.

The F-score is commonly used for evaluating information retrieval systems such as search engines, and also for many kinds of machine learning models, in particular in natural language processing.",0
what is the difference between supervised learning and unsupervised learning ?,"In Supervised learning, you train the machine using data which is well ""labeled."".Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",Supervised learning is simply a process of learning algorithm from the training dataset. Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output,1
what is the difference between supervised learning and unsupervised learning ?,"In Supervised learning, you train the machine using data which is well ""labeled."".Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",The difference between inductive machine learning and deductive machine learning are as follows: machine-learning where the model learns by examples from a set of observed instances to draw a generalized conclusion whereas in deductive learning the model first draws the conclusion and then the conclusion is drawn.,0
What is the difference between inductive machine learning and deductive machine learning?,Supervised learning is simply a process of learning algorithm from the training dataset. Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output,"INDUCTIVE MACHINE LEARNING: From the perspective of inductive learning, we are given input samples (x) and output samples (f(x)) and the problem is to estimate the function (f). Specifically, the problem is to generalize from the samples and the mapping to be useful to estimate the output for new samples in the future.Deductive Machine Learning: A deductive approach to teaching language starts by giving learners rules, then examples, then practice. It is a teacher-centered approach to presenting new content. This is compared with an inductive approach, which starts with examples and asks learners to find rules and hence is more learner-centered.",0
what is the difference between supervised learning and unsupervised learning ?,"In Supervised learning, you train the machine using data which is well ""labeled."".Unsupervised learning is a machine learning technique, where you do not need to supervise the model.","In supervised machine learning algorithms, we have to provide labeled data, for example, prediction of stock market prices, whereas in unsupervised we need not have labeled data, for example, classification of emails into spam and non-spam.",1
what is the difference between supervised learning and unsupervised learning ?,"In Supervised learning, you train the machine using data which is well ""labeled."".Unsupervised learning is a machine learning technique, where you do not need to supervise the model.","Data augmentation is a technique for synthesizing new data by modifying existing data in such a way that the target is not changed, or it is changed in a known way.
CV is one of the fields where data augmentation is very useful. There are many modifications that we can do to images: Resize, Horizontal or vertical flip, Rotate, Add noise, Deform, and Modify colors. Each problem needs a customized data augmentation pipeline. For example, on OCR, doing flips will change the text and won’t be beneficial; however, resizes and small rotations may help.",0
What is data augmentation? Can you give some examples?,"In supervised machine learning algorithms, we have to provide labeled data, for example, prediction of stock market prices, whereas in unsupervised we need not have labeled data, for example, classification of emails into spam and non-spam.",Data augmentation in data analysis are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. It acts as a regularizer and helps reduce overfitting when training a machine learning model.,0
What is the difference between inductive machine learning and deductive machine learning?,Supervised learning is simply a process of learning algorithm from the training dataset. Supervised learning is where you have input variables and an output variable and you use an algorithm to learn the mapping function from the input to the output,inductive machine learning : Observe and learn from the set of instances and then draw the conclusion.It is Statistical machine learning like KNN (K-nearest neighbour) or SVM (Support Vector Machine).Deductive Machine Learning: Derives conclusion and then work on it based on the previous decision.Machine learning algorithm to deductive reasoning using a decision tree,0
what is the difference between supervised learning and unsupervised learning ?,"In Supervised learning, you train the machine using data which is well ""labeled."".Unsupervised learning is a machine learning technique, where you do not need to supervise the model.","In supervised machine learning, a model makes predictions or decisions based on past or labeled data. Labeled data refers to sets of data that are given tags or labels, and thus made more meaningful.In unsupervised learning, we don't have labeled data. A model can identify patterns, anomalies, and relationships in the input data.",1
what is the difference between supervised learning and unsupervised learning ?,"In Supervised learning, you train the machine using data which is well ""labeled."".Unsupervised learning is a machine learning technique, where you do not need to supervise the model.","L2 regularization tends to spread error among all the terms.while L1 is more binary/sparse, with many variables eithger being assigned a 1 or 0 in weighting L1 corresponds to setting a Laplacean prior to the terms , while L2 corresponds to a Gaussian error",0
Explain the difference between L1 and L2 regularization,"In supervised machine learning, a model makes predictions or decisions based on past or labeled data. Labeled data refers to sets of data that are given tags or labels, and thus made more meaningful.In unsupervised learning, we don't have labeled data. A model can identify patterns, anomalies, and relationships in the input data.","L1 regularization helps perform feature selection in sparse feature spaces, and that is a good practical reason to use L1 in some situations. However, beyond that particular reason I have never seen L1 to perform better than L2 in practice. And, to be clear, I don't think I am the only one to be in this situation. If you take a look at LIBLINEAR FAQ on this issue you will see how they have not seen a practical example where L1 beats L2 and encourage users of the library to contact them if they find one. Even in a situation where you might benefit from L1's sparsity in order to do feature selection, using L2 on the remaining variables is likely to give better results than L1 by itself.",0
what is the overfitting ?,Overfitting is a situation that occurs when a model learns the training set too well,Overfitting is a modeling error that occurs when a function is too closely fit to a limited set of data points.,1
what is the overfitting ?,Overfitting is a situation that occurs when a model learns the training set too well,"Reinforcement learning is the training of machine learning models to make a sequence of decisions. The agent learns to achieve a goal in an uncertain, potentially complex environment. In reinforcement learning, an artificial intelligence faces a game-like situation. The computer employs trial and error to come up with a solution to the problem. To get the machine to do what the programmer wants, the artificial intelligence gets either rewards or penalties for the actions it performs. Its goal is to maximize the total reward.",0
what it the reinforcement learning ?,Overfitting is a modeling error that occurs when a function is too closely fit to a limited set of data points.,Reinforcement Learning is defined as a Machine Learning method that is concerned with how software agents should take actions in an environment. Reinforcement Learning is a part of the deep learning method that helps you to maximize some portion of the cumulative reward.,0
what is the overfitting ?,Overfitting is a modeling error that occurs when a function is too closely fit to a limited set of data points.,"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably",1
what is the overfitting ?,Overfitting is a modeling error that occurs when a function is too closely fit to a limited set of data points.,A confusion matrix is a technique for summarizing the performance of a classification algorithm.,0
 What is a Confusion Matrix? ,"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably",A much better way to evaluate the performance of a classifier is to look at the confusion matrix.,0
what is the overfitting ?,Overfitting is a situation that occurs when a model learns the training set too well,"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably",1
what is the overfitting ?,Overfitting is a situation that occurs when a model learns the training set too well,If the algorithm is too simple (hypothesis with linear eq.) then it may be on high bias and low variance condition and thus is error-prone. If algorithms fit too complex ( hypothesis with high degree eq.) then it may be on high variance and low bias.,0
what is the trade off between bias and variance ?,"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably",predicitve models have a tradeoff between bias (how well the model fits the data) and variance (how much the model changes based on changes In the inputs). Simpler models are stable (low variance) but they don't get close to the truth (high bias) more complex models are more prone to overfitting (high variance) but they are expressive enough to get close to the truth (low bias) . The best model for a given problem usually lies somewhere in the middle.,0
What is ‘training Set’ and ‘test Set’ in a Machine Learning Model?,The training set is examples given to the model to analyze and learn.The test set is used to test the accuracy of the hypothesis generated by the model,a subset to train a model.a subset to test the trained model.,1
What is ‘training Set’ and ‘test Set’ in a Machine Learning Model?,The training set is examples given to the model to analyze and learn.The test set is used to test the accuracy of the hypothesis generated by the model,"Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.",0
what it the reinforcement learning ?,a subset to train a model.a subset to test the trained model.,Reinforcement Learning is defined as a Machine Learning method that is concerned with how software agents should take actions in an environment. Reinforcement Learning is a part of the deep learning method that helps you to maximize some portion of the cumulative reward.,0
What is ‘training Set’ and ‘test Set’ in a Machine Learning Model?,a subset to train a model.a subset to test the trained model.,"We split the given data set into two different sections namely,’Training set’ and ‘Test Set’. ‘Training set’ is the portion of the dataset used to train the model.
‘Testing set’ is the portion of the dataset used to test the trained model.",1
What is ‘training Set’ and ‘test Set’ in a Machine Learning Model?,a subset to train a model.a subset to test the trained model.,"Causality applies to situations where one action, say X, causes an outcome, say Y, whereas Correlation is just relating one action (X) to another action(Y) but X does not necessarily cause Y.",0
State the differences between causality and correlation?,"We split the given data set into two different sections namely,’Training set’ and ‘Test Set’. ‘Training set’ is the portion of the dataset used to train the model.
‘Testing set’ is the portion of the dataset used to test the trained model.","While causation and correlation can exist at the same time, correlation does not imply causation. Causation explicitly applies to cases where action A {quote:right}Causation explicitly applies to cases where action A causes outcome B.{/quote} causes outcome B. On the other hand, correlation is simply a relationship. Action A relates to Action B—but one event doesn’t necessarily cause the other event to happen.",0
What is ‘training Set’ and ‘test Set’ in a Machine Learning Model?,The training set is examples given to the model to analyze and learn.The test set is used to test the accuracy of the hypothesis generated by the model,The actual dataset that we use to train the model (weights and biases in the case of a Neural Network). The model sees and learns from this data.,1
What is ‘training Set’ and ‘test Set’ in a Machine Learning Model?,The training set is examples given to the model to analyze and learn.The test set is used to test the accuracy of the hypothesis generated by the model,"AUC is the area under the ROC curve, and it's a common performance metric for evaluating binary classification models.",0
what is AUC,The actual dataset that we use to train the model (weights and biases in the case of a Neural Network). The model sees and learns from this data.,"AUC stands for ""Area under the ROC Curve."" That is, AUC measures the entire two-dimensional area underneath the entire ROC curve (think integral calculus) from (0,0) to (1,1).",0
What is ‘training Set’ and ‘test Set’ in a Machine Learning Model?,The training set is examples given to the model to analyze and learn.The test set is used to test the accuracy of the hypothesis generated by the model,"We split the given data set into two different sections namely,’Training set’ and ‘Test Set’. ‘Training set’ is the portion of the dataset used to train the model.
‘Testing set’ is the portion of the dataset used to test the trained model.",1
What is ‘training Set’ and ‘test Set’ in a Machine Learning Model?,The training set is examples given to the model to analyze and learn.The test set is used to test the accuracy of the hypothesis generated by the model,Associative Rule Mining is one of the techniques to discover patterns in data like features (dimensions) which occur together and features (dimensions) which are correlated.,0
What do you mean by Associative Rule Mining (ARM)?,"We split the given data set into two different sections namely,’Training set’ and ‘Test Set’. ‘Training set’ is the portion of the dataset used to train the model.
‘Testing set’ is the portion of the dataset used to test the trained model.",Association Rule Mining is one of the ways to find patterns in data. It finds: features (dimensions) which occur together and features (dimensions) which are “correlated”,0
What is ‘training Set’ and ‘test Set’ in a Machine Learning Model?,a subset to train a model.a subset to test the trained model.,The actual dataset that we use to train the model (weights and biases in the case of a Neural Network). The model sees and learns from this data.,1
What is ‘training Set’ and ‘test Set’ in a Machine Learning Model?,a subset to train a model.a subset to test the trained model.,A confusion matrix is a technique for summarizing the performance of a classification algorithm.,0
 What is a Confusion Matrix? ,The actual dataset that we use to train the model (weights and biases in the case of a Neural Network). The model sees and learns from this data.,"a confusion matrix, also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm,",0
What Is a False Positive and False Negative and How Are They Significant?,False positives are those cases which wrongly get classified as True but are False.False negatives are those cases which wrongly get classified as False but are True.,A false positive is an outcome where the model incorrectly predicts the positive class.false negative is an outcome where the model incorrectly predicts the negative class.,1
What Is a False Positive and False Negative and How Are They Significant?,False positives are those cases which wrongly get classified as True but are False.False negatives are those cases which wrongly get classified as False but are True.,A confusion matrix is a technique for summarizing the performance of a classification algorithm.,0
 What is a Confusion Matrix? ,A false positive is an outcome where the model incorrectly predicts the positive class.false negative is an outcome where the model incorrectly predicts the negative class.,A much better way to evaluate the performance of a classifier is to look at the confusion matrix.,0
What Is a False Positive and False Negative and How Are They Significant?,False positives are those cases which wrongly get classified as True but are False.False negatives are those cases which wrongly get classified as False but are True.,"Classification is the process of finding or discovering a model or function which helps in separating the data into multiple categorical classes i.e. discrete values. In classification, data is categorized under different labels according to some parameters given in input and then the labels are predicted for the data.Regression is the process of finding a model or function for distinguishing the data into continuous real values instead of using classes or discrete values. It can also identify the distribution movement depending on the historical data. Because a regression predictive model predicts a quantity, therefore, the skill of the model must be reported as an error in those predictions",0
what is the difference between classification and regression ?,A false positive is an outcome where the model incorrectly predicts the positive class.false negative is an outcome where the model incorrectly predicts the negative class.,"The most significant difference between regression vs classification is that while regression helps predict a continuous quantity, classification predicts discrete class labels. There are also some overlaps between the two types of machine learning algorithms.",0
What Is a False Positive and False Negative and How Are They Significant?,False positives are those cases which wrongly get classified as True but are False.False negatives are those cases which wrongly get classified as False but are True.,False negative: When a data point is classified as a negative example(say class 0) but it is actually a positive example(belongs to class 1).False positive: When a data point is classified as a positive example(say class 1) but it is actually a negative example(belongs to class 0).,1
What Is a False Positive and False Negative and How Are They Significant?,False positives are those cases which wrongly get classified as True but are False.False negatives are those cases which wrongly get classified as False but are True.,predicitve models have a tradeoff between bias (how well the model fits the data) and variance (how much the model changes based on changes In the inputs). Simpler models are stable (low variance) but they don't get close to the truth (high bias) more complex models are more prone to overfitting (high variance) but they are expressive enough to get close to the truth (low bias) . The best model for a given problem usually lies somewhere in the middle.,0
what is the trade off between bias and variance ?,False negative: When a data point is classified as a negative example(say class 0) but it is actually a positive example(belongs to class 1).False positive: When a data point is classified as a positive example(say class 1) but it is actually a negative example(belongs to class 0).,the bias–variance tradeoff is the property of a model that the variance of the parameter estimates across samples can be reduced by increasing the bias in the estimated parameters.,0
 What is a Confusion Matrix? ,A confusion matrix is a technique for summarizing the performance of a classification algorithm.,A much better way to evaluate the performance of a classifier is to look at the confusion matrix.,1
 What is a Confusion Matrix? ,A confusion matrix is a technique for summarizing the performance of a classification algorithm.,"Both algorithms are methods for finding a set of parameters that minimize a loss function by evaluating parameters against data and then making adjustments. In standard gradient descent, you'll evaluate all training samples for each set of parameters. This is akin to taking big, slow steps toward the solution. In stochastic gradient descent, you'll evaluate only 1 training sample for the set of parameters before updating them. This is akin to taking small, quick steps toward the solution.",0
What is the difference between stochastic gradient descent (SGD) and gradient descent (GD)?,A much better way to evaluate the performance of a classifier is to look at the confusion matrix.,"In both gradient descent (GD) and stochastic gradient descent (SGD), you update a set of parameters in an iterative manner to minimize an error function. While in GD, you have to run through ALL the samples in your training set to do a single update for a parameter in a particular iteration, in SGD, on the other hand, you use ONLY ONE or SUBSET of training sample from your training set to do the update for a parameter in a particular iteration. If you use SUBSET, it is called Minibatch Stochastic gradient Descent.",0
 What is a Confusion Matrix? ,A confusion matrix is a technique for summarizing the performance of a classification algorithm.,"A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes.",1
 What is a Confusion Matrix? ,A confusion matrix is a technique for summarizing the performance of a classification algorithm.,"Parametric models are those with a finite number of parameters. To predict new data, you only need to know the parameters of the model. Examples include linear regression, logistic regression, and linear SVMs.",0
What are the parametric models? Give an example.,"A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes.",a parametric model is a family of probability distributions that has a finite number of parameters.,0
 What is a Confusion Matrix? ,"a confusion matrix, also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm,",A confusion matrix is a table which is used for summarizing the performance of a classification algorithm.,1
 What is a Confusion Matrix? ,"a confusion matrix, also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm,","While causation and correlation can exist at the same time, correlation does not imply causation. Causation explicitly applies to cases where action A Causation explicitly applies to cases where action A causes outcome B. causes outcome B. On the other hand, correlation is simply a relationship. Action A relates to Action B—but one event doesn’t necessarily cause the other event to happen.",0
State the differences between causality and correlation?,A confusion matrix is a table which is used for summarizing the performance of a classification algorithm.,"Correlation means there is a relationship or pattern between the values of two variables. A scatterplot displays data about two variables as a set of points in the xyxyx, y-plane and is a useful tool for determining if there is a correlation between the variables.
Causation means that one event causes another event to occur. Causation can only be determined from an appropriately designed experiment. In such experiments, similar groups receive different treatments, and the outcomes of each group are studied. We can only conclude that a treatment causes an effect if the groups have noticeably different outcomes.",0
 What is a Confusion Matrix? ,A confusion matrix is a technique for summarizing the performance of a classification algorithm.,"a confusion matrix, also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm,",1
 What is a Confusion Matrix? ,A confusion matrix is a technique for summarizing the performance of a classification algorithm.,"L2 regularization tends to spread error among all the terms.while L1 is more binary/sparse, with many variables eithger being assigned a 1 or 0 in weighting L1 corresponds to setting a Laplacean prior to the terms , while L2 corresponds to a Gaussian error",0
Explain the difference between L1 and L2 regularization,"a confusion matrix, also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm,","From a practical standpoint, L1 tends to shrink coefficients to zero whereas L2 tends to shrink coefficients evenly. L1 is therefore useful for feature selection, as we can drop any variables associated with coefficients that go to zero. L2, on the other hand, is useful when you have collinear/codependent features.",0
what is the trade off between bias and variance ?,If the algorithm is too simple (hypothesis with linear eq.) then it may be on high bias and low variance condition and thus is error-prone. If algorithms fit too complex ( hypothesis with high degree eq.) then it may be on high variance and low bias.,predicitve models have a tradeoff between bias (how well the model fits the data) and variance (how much the model changes based on changes In the inputs). Simpler models are stable (low variance) but they don't get close to the truth (high bias) more complex models are more prone to overfitting (high variance) but they are expressive enough to get close to the truth (low bias) . The best model for a given problem usually lies somewhere in the middle.,1
what is the trade off between bias and variance ?,If the algorithm is too simple (hypothesis with linear eq.) then it may be on high bias and low variance condition and thus is error-prone. If algorithms fit too complex ( hypothesis with high degree eq.) then it may be on high variance and low bias.,"precision is the ratio of serveral events you can correctly recall to the total number of events you recall , precision = (True Positive)/(True Positive + False Negative), recall is the ratio of a number of events you can recall the total events , recall = (True Positive)/(True Positive + False Negative)",0
Define precison and recall ?,predicitve models have a tradeoff between bias (how well the model fits the data) and variance (how much the model changes based on changes In the inputs). Simpler models are stable (low variance) but they don't get close to the truth (high bias) more complex models are more prone to overfitting (high variance) but they are expressive enough to get close to the truth (low bias) . The best model for a given problem usually lies somewhere in the middle.,"precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances, while recall (also known as sensitivity) is the fraction of the total amount of relevant instances that were actually retrieved. Both precision and recall are therefore based on an understanding and measure of relevance.",0
what is the trade off between bias and variance ?,If the algorithm is too simple (hypothesis with linear eq.) then it may be on high bias and low variance condition and thus is error-prone. If algorithms fit too complex ( hypothesis with high degree eq.) then it may be on high variance and low bias.,"Bias is the simplifying assumptions made by the model to make the target function easier to approximate.
Variance is the amount that the estimate of the target function will change given different training data.
Trade-off is tension between the error introduced by the bias and the variance.",1
what is the trade off between bias and variance ?,If the algorithm is too simple (hypothesis with linear eq.) then it may be on high bias and low variance condition and thus is error-prone. If algorithms fit too complex ( hypothesis with high degree eq.) then it may be on high variance and low bias.,Linear Regression is a supervised Machine Learning algorithm. It is used to find the linear relationship between the dependent and the independent variables for predictive analysis.,0
What is Linear Regression?,"Bias is the simplifying assumptions made by the model to make the target function easier to approximate.
Variance is the amount that the estimate of the target function will change given different training data.
Trade-off is tension between the error introduced by the bias and the variance.",Simple linear regression is a type of regression analysis where the number of independent variables is one and there is a linear relationship between the independent(x) and dependent(y) variable.,0
what is the trade off between bias and variance ?,If the algorithm is too simple (hypothesis with linear eq.) then it may be on high bias and low variance condition and thus is error-prone. If algorithms fit too complex ( hypothesis with high degree eq.) then it may be on high variance and low bias.,the bias–variance tradeoff is the property of a model that the variance of the parameter estimates across samples can be reduced by increasing the bias in the estimated parameters.,1
what is the trade off between bias and variance ?,If the algorithm is too simple (hypothesis with linear eq.) then it may be on high bias and low variance condition and thus is error-prone. If algorithms fit too complex ( hypothesis with high degree eq.) then it may be on high variance and low bias.,An ROC curve is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters: True Positive Rate and False Positive Rate,0
What is the ROC Curve,the bias–variance tradeoff is the property of a model that the variance of the parameter estimates across samples can be reduced by increasing the bias in the estimated parameters.,"ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The method was originally developed for operators of military radar receivers, which is why it is so named.",0
what is the trade off between bias and variance ?,predicitve models have a tradeoff between bias (how well the model fits the data) and variance (how much the model changes based on changes In the inputs). Simpler models are stable (low variance) but they don't get close to the truth (high bias) more complex models are more prone to overfitting (high variance) but they are expressive enough to get close to the truth (low bias) . The best model for a given problem usually lies somewhere in the middle.,"Bias is the simplifying assumptions made by the model to make the target function easier to approximate.
Variance is the amount that the estimate of the target function will change given different training data.
Trade-off is tension between the error introduced by the bias and the variance.",1
what is the trade off between bias and variance ?,predicitve models have a tradeoff between bias (how well the model fits the data) and variance (how much the model changes based on changes In the inputs). Simpler models are stable (low variance) but they don't get close to the truth (high bias) more complex models are more prone to overfitting (high variance) but they are expressive enough to get close to the truth (low bias) . The best model for a given problem usually lies somewhere in the middle.,"In Supervised learning, you train the machine using data which is well ""labeled."".Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",0
what is the difference between supervised learning and unsupervised learning ?,"Bias is the simplifying assumptions made by the model to make the target function easier to approximate.
Variance is the amount that the estimate of the target function will change given different training data.
Trade-off is tension between the error introduced by the bias and the variance.","In supervised machine learning, a model makes predictions or decisions based on past or labeled data. Labeled data refers to sets of data that are given tags or labels, and thus made more meaningful.In unsupervised learning, we don't have labeled data. A model can identify patterns, anomalies, and relationships in the input data.",0
what is the trade off between bias and variance ?,predicitve models have a tradeoff between bias (how well the model fits the data) and variance (how much the model changes based on changes In the inputs). Simpler models are stable (low variance) but they don't get close to the truth (high bias) more complex models are more prone to overfitting (high variance) but they are expressive enough to get close to the truth (low bias) . The best model for a given problem usually lies somewhere in the middle.,the bias–variance tradeoff is the property of a model that the variance of the parameter estimates across samples can be reduced by increasing the bias in the estimated parameters.,1
what is the trade off between bias and variance ?,predicitve models have a tradeoff between bias (how well the model fits the data) and variance (how much the model changes based on changes In the inputs). Simpler models are stable (low variance) but they don't get close to the truth (high bias) more complex models are more prone to overfitting (high variance) but they are expressive enough to get close to the truth (low bias) . The best model for a given problem usually lies somewhere in the middle.,Entropy is the measure of uncertainty associated with random variable Y. It is the expected number of bits required to communicate the value of the variable.,0
Define entropy?,the bias–variance tradeoff is the property of a model that the variance of the parameter estimates across samples can be reduced by increasing the bias in the estimated parameters.,Entropy is nothing but the measure of disorder.,0
Explain the difference between L1 and L2 regularization,"L2 regularization tends to spread error among all the terms.while L1 is more binary/sparse, with many variables eithger being assigned a 1 or 0 in weighting L1 corresponds to setting a Laplacean prior to the terms , while L2 corresponds to a Gaussian error","From a practical standpoint, L1 tends to shrink coefficients to zero whereas L2 tends to shrink coefficients evenly. L1 is therefore useful for feature selection, as we can drop any variables associated with coefficients that go to zero. L2, on the other hand, is useful when you have collinear/codependent features.",1
Explain the difference between L1 and L2 regularization,"L2 regularization tends to spread error among all the terms.while L1 is more binary/sparse, with many variables eithger being assigned a 1 or 0 in weighting L1 corresponds to setting a Laplacean prior to the terms , while L2 corresponds to a Gaussian error","Data augmentation is a technique for synthesizing new data by modifying existing data in such a way that the target is not changed, or it is changed in a known way.
CV is one of the fields where data augmentation is very useful. There are many modifications that we can do to images: Resize, Horizontal or vertical flip, Rotate, Add noise, Deform, and Modify colors. Each problem needs a customized data augmentation pipeline. For example, on OCR, doing flips will change the text and won’t be beneficial; however, resizes and small rotations may help.",0
What is data augmentation? Can you give some examples?,"From a practical standpoint, L1 tends to shrink coefficients to zero whereas L2 tends to shrink coefficients evenly. L1 is therefore useful for feature selection, as we can drop any variables associated with coefficients that go to zero. L2, on the other hand, is useful when you have collinear/codependent features.",Data augmentation in data analysis are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. It acts as a regularizer and helps reduce overfitting when training a machine learning model.,0
Explain the difference between L1 and L2 regularization,"L2 regularization tends to spread error among all the terms.while L1 is more binary/sparse, with many variables eithger being assigned a 1 or 0 in weighting L1 corresponds to setting a Laplacean prior to the terms , while L2 corresponds to a Gaussian error","L1 regularization helps perform feature selection in sparse feature spaces, and that is a good practical reason to use L1 in some situations. However, beyond that particular reason I have never seen L1 to perform better than L2 in practice. And, to be clear, I don't think I am the only one to be in this situation. If you take a look at LIBLINEAR FAQ on this issue you will see how they have not seen a practical example where L1 beats L2 and encourage users of the library to contact them if they find one. Even in a situation where you might benefit from L1's sparsity in order to do feature selection, using L2 on the remaining variables is likely to give better results than L1 by itself.",1
Explain the difference between L1 and L2 regularization,"L2 regularization tends to spread error among all the terms.while L1 is more binary/sparse, with many variables eithger being assigned a 1 or 0 in weighting L1 corresponds to setting a Laplacean prior to the terms , while L2 corresponds to a Gaussian error",An ROC curve is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters: True Positive Rate and False Positive Rate,0
What is the ROC Curve,"L1 regularization helps perform feature selection in sparse feature spaces, and that is a good practical reason to use L1 in some situations. However, beyond that particular reason I have never seen L1 to perform better than L2 in practice. And, to be clear, I don't think I am the only one to be in this situation. If you take a look at LIBLINEAR FAQ on this issue you will see how they have not seen a practical example where L1 beats L2 and encourage users of the library to contact them if they find one. Even in a situation where you might benefit from L1's sparsity in order to do feature selection, using L2 on the remaining variables is likely to give better results than L1 by itself.","ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The method was originally developed for operators of military radar receivers, which is why it is so named.",0
what is the difference between classification and regression ?,"Classification is used to produce discrete results, classification is used to classify data into some specific categories. For example, classifying emails into spam and non-spam categories.
Whereas, We use regression analysis when we are dealing with continuous data, for example predicting stock prices at a certain point in time","Fundamentally, classification is about predicting a label and regression is about predicting a quantity",1
what is the difference between classification and regression ?,"Classification is used to produce discrete results, classification is used to classify data into some specific categories. For example, classifying emails into spam and non-spam categories.
Whereas, We use regression analysis when we are dealing with continuous data, for example predicting stock prices at a certain point in time","Machine learning (ML) is the study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, known as ""training data"", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.",0
what is the machine learning ?,"Fundamentally, classification is about predicting a label and regression is about predicting a quantity","Machine learning is a form of AI that enables a system to learn from data rather than through explicit programming. However, machine learning is not a simple process. As the algorithms ingest training data, it is then possible to produce more precise models based on that data. A machine-learning model is the output generated when you train your machine-learning algorithm with data. After training, when you provide a model with an input, you will be given an output. For example, a predictive algorithm will create a predictive model. Then, when you provide the predictive model with data, you will receive a prediction based on the data that trained the model.",0
what is the difference between classification and regression ?,"Classification is used to produce discrete results, classification is used to classify data into some specific categories. For example, classifying emails into spam and non-spam categories.
Whereas, We use regression analysis when we are dealing with continuous data, for example predicting stock prices at a certain point in time","Classification is the process of finding or discovering a model or function which helps in separating the data into multiple categorical classes i.e. discrete values. In classification, data is categorized under different labels according to some parameters given in input and then the labels are predicted for the data.Regression is the process of finding a model or function for distinguishing the data into continuous real values instead of using classes or discrete values. It can also identify the distribution movement depending on the historical data. Because a regression predictive model predicts a quantity, therefore, the skill of the model must be reported as an error in those predictions",1
what is the difference between classification and regression ?,"Classification is used to produce discrete results, classification is used to classify data into some specific categories. For example, classifying emails into spam and non-spam categories.
Whereas, We use regression analysis when we are dealing with continuous data, for example predicting stock prices at a certain point in time",Marginalization is summing the probability of a random variable X given the joint probability distribution of X with other variables. It is an application of the law of total probability.,0
What is Marginalisation? Explain the process.,"Classification is the process of finding or discovering a model or function which helps in separating the data into multiple categorical classes i.e. discrete values. In classification, data is categorized under different labels according to some parameters given in input and then the labels are predicted for the data.Regression is the process of finding a model or function for distinguishing the data into continuous real values instead of using classes or discrete values. It can also identify the distribution movement depending on the historical data. Because a regression predictive model predicts a quantity, therefore, the skill of the model must be reported as an error in those predictions",Marginalisation is a method that requires summing over the possible values of one variable to determine the marginal contribution of another.,0
what is the difference between classification and regression ?,"Classification is the process of finding or discovering a model or function which helps in separating the data into multiple categorical classes i.e. discrete values. In classification, data is categorized under different labels according to some parameters given in input and then the labels are predicted for the data.Regression is the process of finding a model or function for distinguishing the data into continuous real values instead of using classes or discrete values. It can also identify the distribution movement depending on the historical data. Because a regression predictive model predicts a quantity, therefore, the skill of the model must be reported as an error in those predictions","The most significant difference between regression vs classification is that while regression helps predict a continuous quantity, classification predicts discrete class labels. There are also some overlaps between the two types of machine learning algorithms.",1
what is the difference between classification and regression ?,"Classification is the process of finding or discovering a model or function which helps in separating the data into multiple categorical classes i.e. discrete values. In classification, data is categorized under different labels according to some parameters given in input and then the labels are predicted for the data.Regression is the process of finding a model or function for distinguishing the data into continuous real values instead of using classes or discrete values. It can also identify the distribution movement depending on the historical data. Because a regression predictive model predicts a quantity, therefore, the skill of the model must be reported as an error in those predictions","Reinforcement learning is the training of machine learning models to make a sequence of decisions. The agent learns to achieve a goal in an uncertain, potentially complex environment. In reinforcement learning, an artificial intelligence faces a game-like situation. The computer employs trial and error to come up with a solution to the problem. To get the machine to do what the programmer wants, the artificial intelligence gets either rewards or penalties for the actions it performs. Its goal is to maximize the total reward.",0
what it the reinforcement learning ?,"The most significant difference between regression vs classification is that while regression helps predict a continuous quantity, classification predicts discrete class labels. There are also some overlaps between the two types of machine learning algorithms.",Reinforcement Learning is defined as a Machine Learning method that is concerned with how software agents should take actions in an environment. Reinforcement Learning is a part of the deep learning method that helps you to maximize some portion of the cumulative reward.,0
What is the Convex Function?,"A convex function is a continuous function, and the value of the midpoint at every interval in its given domain is less than the numerical mean of the values at the two ends of the interval.","In mathematics, a real-valued function defined on an n-dimensional interval is called convex if the line segment between any two points on the graph of the function lies above the graph between the two points. Equivalently, a function is convex if its epigraph (the set of points on or above the graph of the function) is a convex set. A twice-differentiable function of a single variable is convex if and only if its second derivative is nonnegative on its entire domain. Well-known examples of convex functions of a single variable include the squaring function {\displaystyle x^{2}}x^{2} and the exponential function {\displaystyle e^{x}}e^{x}.",1
What is the Convex Function?,"A convex function is a continuous function, and the value of the midpoint at every interval in its given domain is less than the numerical mean of the values at the two ends of the interval.","Kernel SVM is the abbreviated version of the kernel support vector machine. Kernel methods are a class of algorithms for pattern analysis, and the most common one is the kernel SVM.",0
What Is Kernel SVM?,"In mathematics, a real-valued function defined on an n-dimensional interval is called convex if the line segment between any two points on the graph of the function lies above the graph between the two points. Equivalently, a function is convex if its epigraph (the set of points on or above the graph of the function) is a convex set. A twice-differentiable function of a single variable is convex if and only if its second derivative is nonnegative on its entire domain. Well-known examples of convex functions of a single variable include the squaring function {\displaystyle x^{2}}x^{2} and the exponential function {\displaystyle e^{x}}e^{x}.","In machine learning, kernel machines are a class of algorithms for pattern analysis, whose best known member is the support vector machine (SVM).",0
What are the parametric models? Give an example.,"Parametric models are those with a finite number of parameters. To predict new data, you only need to know the parameters of the model. Examples include linear regression, logistic regression, and linear SVMs.",a parametric model is a family of probability distributions that has a finite number of parameters.,1
What are the parametric models? Give an example.,"Parametric models are those with a finite number of parameters. To predict new data, you only need to know the parameters of the model. Examples include linear regression, logistic regression, and linear SVMs.","Machine learning (ML) is the study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, known as ""training data"", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.",0
what is the machine learning ?,a parametric model is a family of probability distributions that has a finite number of parameters.,Machine learning is a branch of artificial intelligence (AI) focused on building applications that learn from data and improve their accuracy over time without being programmed to do so.,0
What are the parametric models? Give an example.,"Parametric models are those with a finite number of parameters. To predict new data, you only need to know the parameters of the model. Examples include linear regression, logistic regression, and linear SVMs.","A Parametric Model is a concept used in statistics to describe a model in which all its information is represented within its parameters. In short, the only information needed to predict future or unknown values from the current value is the parameters. Parametric models often deal with discrete values,",1
What are the parametric models? Give an example.,"Parametric models are those with a finite number of parameters. To predict new data, you only need to know the parameters of the model. Examples include linear regression, logistic regression, and linear SVMs.",False positives are those cases which wrongly get classified as True but are False.False negatives are those cases which wrongly get classified as False but are True.,0
What Is a False Positive and False Negative and How Are They Significant?,"A Parametric Model is a concept used in statistics to describe a model in which all its information is represented within its parameters. In short, the only information needed to predict future or unknown values from the current value is the parameters. Parametric models often deal with discrete values,",False negative: When a data point is classified as a negative example(say class 0) but it is actually a positive example(belongs to class 1).False positive: When a data point is classified as a positive example(say class 1) but it is actually a negative example(belongs to class 0).,0
What are the parametric models? Give an example.,"Parametric models are those with a finite number of parameters. To predict new data, you only need to know the parameters of the model. Examples include linear regression, logistic regression, and linear SVMs.","In machine learning, a parametric model is any model that captures all the information about its predictions within a finite set of parameters. Sometimes the model must be trained to select its parameters, as in the case of neural networks. Sometimes the parameters are selected by hand or through a simple calculation process.",1
What are the parametric models? Give an example.,"Parametric models are those with a finite number of parameters. To predict new data, you only need to know the parameters of the model. Examples include linear regression, logistic regression, and linear SVMs.","precision is the ratio of serveral events you can correctly recall to the total number of events you recall , precision = (True Positive)/(True Positive + False Negative), recall is the ratio of a number of events you can recall the total events , recall = (True Positive)/(True Positive + False Negative)",0
Define precison and recall ?,"In machine learning, a parametric model is any model that captures all the information about its predictions within a finite set of parameters. Sometimes the model must be trained to select its parameters, as in the case of neural networks. Sometimes the parameters are selected by hand or through a simple calculation process.","Precision attempts to answer the following question:
What proportion of positive identifications was actually correct?Recall attempts to answer the following question:
What proportion of actual positives was identified correctly?",0
What’s the difference between a generative and discriminative model?,A generative model will learn categories of data while a discriminative model will simply learn the distinction between different categories of data. Discriminative models will generally outperform generative models on classification tasks.,"Discriminative models learn the (hard or soft) boundary between classes
Generative models model the distribution of individual classes",1
What’s the difference between a generative and discriminative model?,A generative model will learn categories of data while a discriminative model will simply learn the distinction between different categories of data. Discriminative models will generally outperform generative models on classification tasks.,The difference between inductive machine learning and deductive machine learning are as follows: machine-learning where the model learns by examples from a set of observed instances to draw a generalized conclusion whereas in deductive learning the model first draws the conclusion and then the conclusion is drawn.,0
What is the difference between inductive machine learning and deductive machine learning?,"Discriminative models learn the (hard or soft) boundary between classes
Generative models model the distribution of individual classes",inductive machine learning : Observe and learn from the set of instances and then draw the conclusion.It is Statistical machine learning like KNN (K-nearest neighbour) or SVM (Support Vector Machine).Deductive Machine Learning: Derives conclusion and then work on it based on the previous decision.Machine learning algorithm to deductive reasoning using a decision tree,0
What’s the difference between a generative and discriminative model?,A generative model will learn categories of data while a discriminative model will simply learn the distinction between different categories of data. Discriminative models will generally outperform generative models on classification tasks.,"Discriminative machine learning is essentially training a model to distinguish the correct output among possible output choices, given something about the data. This is typically done by learning model parameters that maximize the conditional probability P(Y/X).Generative machine learning is training a model to learn parameters maximizing the joint probability of P(X,Y) often learnt in probabilistic models in its factorized form (e.g. P(Y). P(X/Y) simplified in most scenarios, with assumptions of conditional independence - P(Y). P(X1/Y). P(X2/Y)… P(Xn/Y) (or in some cases assumed for obtaining functional form but ignored during the optimization process, as explained below)",1
What’s the difference between a generative and discriminative model?,A generative model will learn categories of data while a discriminative model will simply learn the distinction between different categories of data. Discriminative models will generally outperform generative models on classification tasks.,"While causation and correlation can exist at the same time, correlation does not imply causation. Causation explicitly applies to cases where action A Causation explicitly applies to cases where action A causes outcome B. causes outcome B. On the other hand, correlation is simply a relationship. Action A relates to Action B—but one event doesn’t necessarily cause the other event to happen.",0
State the differences between causality and correlation?,"Discriminative machine learning is essentially training a model to distinguish the correct output among possible output choices, given something about the data. This is typically done by learning model parameters that maximize the conditional probability P(Y/X).Generative machine learning is training a model to learn parameters maximizing the joint probability of P(X,Y) often learnt in probabilistic models in its factorized form (e.g. P(Y). P(X/Y) simplified in most scenarios, with assumptions of conditional independence - P(Y). P(X1/Y). P(X2/Y)… P(Xn/Y) (or in some cases assumed for obtaining functional form but ignored during the optimization process, as explained below)","Correlation tests for a relationship between two variables. However, seeing two variables moving together does not necessarily mean we know whether one variable causes the other to occur. This is why we commonly say “correlation does not imply causation.”",0
What Is Semi-supervised Machine Learning?,"In the case of semi-supervised learning, the training data contains a small amount of labeled data and a large amount of unlabeled data.","the algorithm is trained upon a combination of labeled and unlabeled data. Typically, this combination will contain a very small amount of labeled data and a very large amount of unlabeled data.",1
What Is Semi-supervised Machine Learning?,"In the case of semi-supervised learning, the training data contains a small amount of labeled data and a large amount of unlabeled data.","AUC is the area under the ROC curve, and it's a common performance metric for evaluating binary classification models.",0
what is AUC,"the algorithm is trained upon a combination of labeled and unlabeled data. Typically, this combination will contain a very small amount of labeled data and a very large amount of unlabeled data.","AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.",0
What Is Semi-supervised Machine Learning?,"In the case of semi-supervised learning, the training data contains a small amount of labeled data and a large amount of unlabeled data.","In semi-supervised learning, an algorithm learns from a dataset that includes both labeled and unlabeled data, usually mostly unlabeled.",1
What Is Semi-supervised Machine Learning?,"In the case of semi-supervised learning, the training data contains a small amount of labeled data and a large amount of unlabeled data.","Parametric models are those with a finite number of parameters. To predict new data, you only need to know the parameters of the model. Examples include linear regression, logistic regression, and linear SVMs.",0
What are the parametric models? Give an example.,"In semi-supervised learning, an algorithm learns from a dataset that includes both labeled and unlabeled data, usually mostly unlabeled.","A Parametric Model is a concept used in statistics to describe a model in which all its information is represented within its parameters. In short, the only information needed to predict future or unknown values from the current value is the parameters. Parametric models often deal with discrete values,",0
What Is Kernel SVM?,"Kernel SVM is the abbreviated version of the kernel support vector machine. Kernel methods are a class of algorithms for pattern analysis, and the most common one is the kernel SVM.","In machine learning, kernel machines are a class of algorithms for pattern analysis, whose best known member is the support vector machine (SVM).",1
What Is Kernel SVM?,"Kernel SVM is the abbreviated version of the kernel support vector machine. Kernel methods are a class of algorithms for pattern analysis, and the most common one is the kernel SVM.","While causation and correlation can exist at the same time, correlation does not imply causation. Causation explicitly applies to cases where action A Causation explicitly applies to cases where action A causes outcome B. causes outcome B. On the other hand, correlation is simply a relationship. Action A relates to Action B—but one event doesn’t necessarily cause the other event to happen.",0
State the differences between causality and correlation?,"In machine learning, kernel machines are a class of algorithms for pattern analysis, whose best known member is the support vector machine (SVM).","Correlation means there is a relationship or pattern between the values of two variables. A scatterplot displays data about two variables as a set of points in the xyxyx, y-plane and is a useful tool for determining if there is a correlation between the variables.
Causation means that one event causes another event to occur. Causation can only be determined from an appropriately designed experiment. In such experiments, similar groups receive different treatments, and the outcomes of each group are studied. We can only conclude that a treatment causes an effect if the groups have noticeably different outcomes.",0
What are support vector machines?,Support vector machines are supervised learning algorithms used for classification and regression analysis.,"support-vector machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.",1
What are support vector machines?,Support vector machines are supervised learning algorithms used for classification and regression analysis.,"The F-score, also called the F1-score, is a measure of a model’s accuracy on a dataset. It is used to evaluate binary classification systems, which classify examples into ‘positive’ or ‘negative’.

The F-score is a way of combining the precision and recall of the model, and it is defined as the harmonic mean of the model’s precision and recall.

The F-score is commonly used for evaluating information retrieval systems such as search engines, and also for many kinds of machine learning models, in particular in natural language processing.",0
What’s the F1 score? How would you use it?,"support-vector machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.","the F-score or F-measure is a measure of a test's accuracy. It is calculated from the precision and recall of the test,",0
What are support vector machines?,Support vector machines are supervised learning algorithms used for classification and regression analysis.,"Support vector machines (SVMs) are powerful yet flexible supervised machine learning algorithms which are used both for classification and regression. But generally, they are used in classification problems.",1
What is Linear Regression?,Linear Regression is a supervised Machine Learning algorithm. It is used to find the linear relationship between the dependent and the independent variables for predictive analysis.,Simple linear regression is a type of regression analysis where the number of independent variables is one and there is a linear relationship between the independent(x) and dependent(y) variable.,1
What is Linear Regression?,Linear Regression is a supervised Machine Learning algorithm. It is used to find the linear relationship between the dependent and the independent variables for predictive analysis.,The ROC (receiver operating characteristic) the performance plot for binary classifiers of True Positive Rate (y axis) vs. False Positive Rate (x axis).,0
What is the ROC Curve,Simple linear regression is a type of regression analysis where the number of independent variables is one and there is a linear relationship between the independent(x) and dependent(y) variable.,"ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The method was originally developed for operators of military radar receivers, which is why it is so named.",0
What is Linear Regression?,Linear Regression is a supervised Machine Learning algorithm. It is used to find the linear relationship between the dependent and the independent variables for predictive analysis.,"Linear regression algorithm shows a linear relationship between a dependent (y) and one or more independent (y) variables, hence called as linear regression. Since linear regression shows the linear relationship, which means it finds how the value of the dependent variable is changing according to the value of the independent variable.",1
What is Linear Regression?,Linear Regression is a supervised Machine Learning algorithm. It is used to find the linear relationship between the dependent and the independent variables for predictive analysis.,"Data augmentation is a technique for synthesizing new data by modifying existing data in such a way that the target is not changed, or it is changed in a known way.
CV is one of the fields where data augmentation is very useful. There are many modifications that we can do to images: Resize, Horizontal or vertical flip, Rotate, Add noise, Deform, and Modify colors. Each problem needs a customized data augmentation pipeline. For example, on OCR, doing flips will change the text and won’t be beneficial; however, resizes and small rotations may help.",0
What is data augmentation? Can you give some examples?,"Linear regression algorithm shows a linear relationship between a dependent (y) and one or more independent (y) variables, hence called as linear regression. Since linear regression shows the linear relationship, which means it finds how the value of the dependent variable is changing according to the value of the independent variable.",Data augmentation in data analysis are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. It acts as a regularizer and helps reduce overfitting when training a machine learning model.,0
What is Linear Regression?,Linear Regression is a supervised Machine Learning algorithm. It is used to find the linear relationship between the dependent and the independent variables for predictive analysis.,linear regression is a linear approach to modelling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables).,1
What is Linear Regression?,Linear Regression is a supervised Machine Learning algorithm. It is used to find the linear relationship between the dependent and the independent variables for predictive analysis.,"Classification is the process of finding or discovering a model or function which helps in separating the data into multiple categorical classes i.e. discrete values. In classification, data is categorized under different labels according to some parameters given in input and then the labels are predicted for the data.Regression is the process of finding a model or function for distinguishing the data into continuous real values instead of using classes or discrete values. It can also identify the distribution movement depending on the historical data. Because a regression predictive model predicts a quantity, therefore, the skill of the model must be reported as an error in those predictions",0
what is the difference between classification and regression ?,linear regression is a linear approach to modelling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables).,"The most significant difference between regression vs classification is that while regression helps predict a continuous quantity, classification predicts discrete class labels. There are also some overlaps between the two types of machine learning algorithms.",0
What is Linear Regression?,"Linear regression algorithm shows a linear relationship between a dependent (y) and one or more independent (y) variables, hence called as linear regression. Since linear regression shows the linear relationship, which means it finds how the value of the dependent variable is changing according to the value of the independent variable.",Simple linear regression is a type of regression analysis where the number of independent variables is one and there is a linear relationship between the independent(x) and dependent(y) variable.,1
What is Linear Regression?,"Linear regression algorithm shows a linear relationship between a dependent (y) and one or more independent (y) variables, hence called as linear regression. Since linear regression shows the linear relationship, which means it finds how the value of the dependent variable is changing according to the value of the independent variable.","precision is the ratio of serveral events you can correctly recall to the total number of events you recall , precision = (True Positive)/(True Positive + False Negative), recall is the ratio of a number of events you can recall the total events , recall = (True Positive)/(True Positive + False Negative)",0
Define precison and recall ?,Simple linear regression is a type of regression analysis where the number of independent variables is one and there is a linear relationship between the independent(x) and dependent(y) variable.,"Precision attempts to answer the following question:
What proportion of positive identifications was actually correct?Recall attempts to answer the following question:
What proportion of actual positives was identified correctly?",0
What is Marginalisation? Explain the process.,Marginalization is summing the probability of a random variable X given the joint probability distribution of X with other variables. It is an application of the law of total probability.,Marginalisation is a method that requires summing over the possible values of one variable to determine the marginal contribution of another.,1
What is Marginalisation? Explain the process.,Marginalization is summing the probability of a random variable X given the joint probability distribution of X with other variables. It is an application of the law of total probability.,A confusion matrix is a technique for summarizing the performance of a classification algorithm.,0
 What is a Confusion Matrix? ,Marginalisation is a method that requires summing over the possible values of one variable to determine the marginal contribution of another.,"A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes.",0
What is data augmentation? Can you give some examples?,"Data augmentation is a technique for synthesizing new data by modifying existing data in such a way that the target is not changed, or it is changed in a known way.
CV is one of the fields where data augmentation is very useful. There are many modifications that we can do to images: Resize, Horizontal or vertical flip, Rotate, Add noise, Deform, and Modify colors. Each problem needs a customized data augmentation pipeline. For example, on OCR, doing flips will change the text and won’t be beneficial; however, resizes and small rotations may help.",Data augmentation in data analysis are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. It acts as a regularizer and helps reduce overfitting when training a machine learning model.,1
What is data augmentation? Can you give some examples?,"Data augmentation is a technique for synthesizing new data by modifying existing data in such a way that the target is not changed, or it is changed in a known way.
CV is one of the fields where data augmentation is very useful. There are many modifications that we can do to images: Resize, Horizontal or vertical flip, Rotate, Add noise, Deform, and Modify colors. Each problem needs a customized data augmentation pipeline. For example, on OCR, doing flips will change the text and won’t be beneficial; however, resizes and small rotations may help.",predicitve models have a tradeoff between bias (how well the model fits the data) and variance (how much the model changes based on changes In the inputs). Simpler models are stable (low variance) but they don't get close to the truth (high bias) more complex models are more prone to overfitting (high variance) but they are expressive enough to get close to the truth (low bias) . The best model for a given problem usually lies somewhere in the middle.,0
what is the trade off between bias and variance ?,Data augmentation in data analysis are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. It acts as a regularizer and helps reduce overfitting when training a machine learning model.,"Bias is the simplifying assumptions made by the model to make the target function easier to approximate.
Variance is the amount that the estimate of the target function will change given different training data.
Trade-off is tension between the error introduced by the bias and the variance.",0
What is data augmentation? Can you give some examples?,"Data augmentation is a technique for synthesizing new data by modifying existing data in such a way that the target is not changed, or it is changed in a known way.
CV is one of the fields where data augmentation is very useful. There are many modifications that we can do to images: Resize, Horizontal or vertical flip, Rotate, Add noise, Deform, and Modify colors. Each problem needs a customized data augmentation pipeline. For example, on OCR, doing flips will change the text and won’t be beneficial; however, resizes and small rotations may help.",Data augmentation adds value to base data by adding information derived from internal and external sources within an enterprise.,1
What is data augmentation? Can you give some examples?,"Data augmentation is a technique for synthesizing new data by modifying existing data in such a way that the target is not changed, or it is changed in a known way.
CV is one of the fields where data augmentation is very useful. There are many modifications that we can do to images: Resize, Horizontal or vertical flip, Rotate, Add noise, Deform, and Modify colors. Each problem needs a customized data augmentation pipeline. For example, on OCR, doing flips will change the text and won’t be beneficial; however, resizes and small rotations may help.",The difference between inductive machine learning and deductive machine learning are as follows: machine-learning where the model learns by examples from a set of observed instances to draw a generalized conclusion whereas in deductive learning the model first draws the conclusion and then the conclusion is drawn.,0
What is the difference between inductive machine learning and deductive machine learning?,Data augmentation adds value to base data by adding information derived from internal and external sources within an enterprise.,"INDUCTIVE MACHINE LEARNING: From the perspective of inductive learning, we are given input samples (x) and output samples (f(x)) and the problem is to estimate the function (f). Specifically, the problem is to generalize from the samples and the mapping to be useful to estimate the output for new samples in the future.Deductive Machine Learning: A deductive approach to teaching language starts by giving learners rules, then examples, then practice. It is a teacher-centered approach to presenting new content. This is compared with an inductive approach, which starts with examples and asks learners to find rules and hence is more learner-centered.",0
Mention the difference between Data Mining and Machine learning?,"Machine learning relates to the study, design, and development of the algorithms that give computers the capability to learn without being explicitly programmed. While data mining can be defined as the process in which the unstructured data tries to extract knowledge or unknown interesting patterns. During this processing machine, learning algorithms are used","Data mining is used on an existing dataset (like a data warehouse) to find patterns. Machine learning, on the other hand, is trained on a ‘training’ data set, which teaches the computer how to make sense of data, and then to make predictions about new data sets.",1
Mention the difference between Data Mining and Machine learning?,"Machine learning relates to the study, design, and development of the algorithms that give computers the capability to learn without being explicitly programmed. While data mining can be defined as the process in which the unstructured data tries to extract knowledge or unknown interesting patterns. During this processing machine, learning algorithms are used","AUC is the area under the ROC curve, and it's a common performance metric for evaluating binary classification models.",0
what is AUC,"Data mining is used on an existing dataset (like a data warehouse) to find patterns. Machine learning, on the other hand, is trained on a ‘training’ data set, which teaches the computer how to make sense of data, and then to make predictions about new data sets.","AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.",0
Mention the difference between Data Mining and Machine learning?,"Machine learning relates to the study, design, and development of the algorithms that give computers the capability to learn without being explicitly programmed. While data mining can be defined as the process in which the unstructured data tries to extract knowledge or unknown interesting patterns. During this processing machine, learning algorithms are used","Data mining is considered the process of extracting useful information from a vast amount of data. It’s used to discover new, accurate, and useful patterns in the data, looking for meaning and relevant information for the organization or individual who needs it. It’s a tool used by humans.On the other hand, machine learning is the process of discovering algorithms that have improved courtesy of experience derived from data. It’s the design, study, and development of algorithms that permit machines to learn without human intervention. It’s a tool to make machines smarter, eliminating the human element (but not eliminating humans themselves; that would be wrong).",1
Mention the difference between Data Mining and Machine learning?,"Machine learning relates to the study, design, and development of the algorithms that give computers the capability to learn without being explicitly programmed. While data mining can be defined as the process in which the unstructured data tries to extract knowledge or unknown interesting patterns. During this processing machine, learning algorithms are used",PCA (Principal Components Analysis) is like KPCA ( Kernel-based Principal Component Analysis) and ICA ( Independent Component Analysis) are important feature extraction techniques used for dimensionality reduction.,0
"What are PCA, KPCA, and ICA used for?","Data mining is considered the process of extracting useful information from a vast amount of data. It’s used to discover new, accurate, and useful patterns in the data, looking for meaning and relevant information for the organization or individual who needs it. It’s a tool used by humans.On the other hand, machine learning is the process of discovering algorithms that have improved courtesy of experience derived from data. It’s the design, study, and development of algorithms that permit machines to learn without human intervention. It’s a tool to make machines smarter, eliminating the human element (but not eliminating humans themselves; that would be wrong).",they are commonly used for dimensionality reduction,0
Define entropy?,Entropy is the measure of uncertainty associated with random variable Y. It is the expected number of bits required to communicate the value of the variable.,Entropy is nothing but the measure of disorder.,1
Define entropy?,Entropy is the measure of uncertainty associated with random variable Y. It is the expected number of bits required to communicate the value of the variable.,"Machine learning (ML) is the study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, known as ""training data"", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.",0
what is the machine learning ?,Entropy is nothing but the measure of disorder.,"Machine learning is a form of AI that enables a system to learn from data rather than through explicit programming. However, machine learning is not a simple process. As the algorithms ingest training data, it is then possible to produce more precise models based on that data. A machine-learning model is the output generated when you train your machine-learning algorithm with data. After training, when you provide a model with an input, you will be given an output. For example, a predictive algorithm will create a predictive model. Then, when you provide the predictive model with data, you will receive a prediction based on the data that trained the model.",0
Define entropy?,Entropy is the measure of uncertainty associated with random variable Y. It is the expected number of bits required to communicate the value of the variable.,Entropy measures uncertainty.,1
Define entropy?,Entropy is the measure of uncertainty associated with random variable Y. It is the expected number of bits required to communicate the value of the variable.,"Parametric models are those with a finite number of parameters. To predict new data, you only need to know the parameters of the model. Examples include linear regression, logistic regression, and linear SVMs.",0
What are the parametric models? Give an example.,Entropy measures uncertainty.,"A Parametric Model is a concept used in statistics to describe a model in which all its information is represented within its parameters. In short, the only information needed to predict future or unknown values from the current value is the parameters. Parametric models often deal with discrete values,",0
Define entropy?,Entropy measures uncertainty.,Entropy is nothing but the measure of disorder.,1
Define entropy?,Entropy measures uncertainty.,"Machine learning relates to the study, design, and development of the algorithms that give computers the capability to learn without being explicitly programmed. While data mining can be defined as the process in which the unstructured data tries to extract knowledge or unknown interesting patterns. During this processing machine, learning algorithms are used",0
Mention the difference between Data Mining and Machine learning?,Entropy is nothing but the measure of disorder.,"Data mining is considered the process of extracting useful information from a vast amount of data. It’s used to discover new, accurate, and useful patterns in the data, looking for meaning and relevant information for the organization or individual who needs it. It’s a tool used by humans.On the other hand, machine learning is the process of discovering algorithms that have improved courtesy of experience derived from data. It’s the design, study, and development of algorithms that permit machines to learn without human intervention. It’s a tool to make machines smarter, eliminating the human element (but not eliminating humans themselves; that would be wrong).",0
What’s the F1 score? How would you use it?,"The F1 score is a measure of a model’s performance. It is a weighted average of the precision and recall of a model, with results tending to 1 being the best, and those tending to 0 being the worst. You would use it in classification tests where true negatives don’t matter much.","the F-score or F-measure is a measure of a test's accuracy. It is calculated from the precision and recall of the test,",1
What’s the F1 score? How would you use it?,"The F1 score is a measure of a model’s performance. It is a weighted average of the precision and recall of a model, with results tending to 1 being the best, and those tending to 0 being the worst. You would use it in classification tests where true negatives don’t matter much.",Support vector machines are supervised learning algorithms used for classification and regression analysis.,0
What are support vector machines?,"the F-score or F-measure is a measure of a test's accuracy. It is calculated from the precision and recall of the test,","support-vector machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.",0
What’s the F1 score? How would you use it?,"The F1 score is a measure of a model’s performance. It is a weighted average of the precision and recall of a model, with results tending to 1 being the best, and those tending to 0 being the worst. You would use it in classification tests where true negatives don’t matter much.","The F-score, also called the F1-score, is a measure of a model’s accuracy on a dataset. It is used to evaluate binary classification systems, which classify examples into ‘positive’ or ‘negative’.

The F-score is a way of combining the precision and recall of the model, and it is defined as the harmonic mean of the model’s precision and recall.

The F-score is commonly used for evaluating information retrieval systems such as search engines, and also for many kinds of machine learning models, in particular in natural language processing.",1
What’s the F1 score? How would you use it?,"The F1 score is a measure of a model’s performance. It is a weighted average of the precision and recall of a model, with results tending to 1 being the best, and those tending to 0 being the worst. You would use it in classification tests where true negatives don’t matter much.","Both algorithms are methods for finding a set of parameters that minimize a loss function by evaluating parameters against data and then making adjustments. In standard gradient descent, you'll evaluate all training samples for each set of parameters. This is akin to taking big, slow steps toward the solution. In stochastic gradient descent, you'll evaluate only 1 training sample for the set of parameters before updating them. This is akin to taking small, quick steps toward the solution.",0
What is the difference between stochastic gradient descent (SGD) and gradient descent (GD)?,"The F-score, also called the F1-score, is a measure of a model’s accuracy on a dataset. It is used to evaluate binary classification systems, which classify examples into ‘positive’ or ‘negative’.

The F-score is a way of combining the precision and recall of the model, and it is defined as the harmonic mean of the model’s precision and recall.

The F-score is commonly used for evaluating information retrieval systems such as search engines, and also for many kinds of machine learning models, in particular in natural language processing.","In both gradient descent (GD) and stochastic gradient descent (SGD), you update a set of parameters in an iterative manner to minimize an error function. While in GD, you have to run through ALL the samples in your training set to do a single update for a parameter in a particular iteration, in SGD, on the other hand, you use ONLY ONE or SUBSET of training sample from your training set to do the update for a parameter in a particular iteration. If you use SUBSET, it is called Minibatch Stochastic gradient Descent.",0
What’s the F1 score? How would you use it?,"The F-score, also called the F1-score, is a measure of a model’s accuracy on a dataset. It is used to evaluate binary classification systems, which classify examples into ‘positive’ or ‘negative’.

The F-score is a way of combining the precision and recall of the model, and it is defined as the harmonic mean of the model’s precision and recall.

The F-score is commonly used for evaluating information retrieval systems such as search engines, and also for many kinds of machine learning models, in particular in natural language processing.","the F-score or F-measure is a measure of a test's accuracy. It is calculated from the precision and recall of the test,",1
What’s the F1 score? How would you use it?,"The F-score, also called the F1-score, is a measure of a model’s accuracy on a dataset. It is used to evaluate binary classification systems, which classify examples into ‘positive’ or ‘negative’.

The F-score is a way of combining the precision and recall of the model, and it is defined as the harmonic mean of the model’s precision and recall.

The F-score is commonly used for evaluating information retrieval systems such as search engines, and also for many kinds of machine learning models, in particular in natural language processing.","precision is the ratio of serveral events you can correctly recall to the total number of events you recall , precision = (True Positive)/(True Positive + False Negative), recall is the ratio of a number of events you can recall the total events , recall = (True Positive)/(True Positive + False Negative)",0
Define precison and recall ?,"the F-score or F-measure is a measure of a test's accuracy. It is calculated from the precision and recall of the test,","precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances, while recall (also known as sensitivity) is the fraction of the total amount of relevant instances that were actually retrieved. Both precision and recall are therefore based on an understanding and measure of relevance.",0
what is the machine learning ?,"Machine learning (ML) is the study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, known as ""training data"", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.","Machine learning is a form of AI that enables a system to learn from data rather than through explicit programming. However, machine learning is not a simple process. As the algorithms ingest training data, it is then possible to produce more precise models based on that data. A machine-learning model is the output generated when you train your machine-learning algorithm with data. After training, when you provide a model with an input, you will be given an output. For example, a predictive algorithm will create a predictive model. Then, when you provide the predictive model with data, you will receive a prediction based on the data that trained the model.",1
what is the machine learning ?,"Machine learning (ML) is the study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, known as ""training data"", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.","While causation and correlation can exist at the same time, correlation does not imply causation. Causation explicitly applies to cases where action A Causation explicitly applies to cases where action A causes outcome B. causes outcome B. On the other hand, correlation is simply a relationship. Action A relates to Action B—but one event doesn’t necessarily cause the other event to happen.",0
State the differences between causality and correlation?,"Machine learning is a form of AI that enables a system to learn from data rather than through explicit programming. However, machine learning is not a simple process. As the algorithms ingest training data, it is then possible to produce more precise models based on that data. A machine-learning model is the output generated when you train your machine-learning algorithm with data. After training, when you provide a model with an input, you will be given an output. For example, a predictive algorithm will create a predictive model. Then, when you provide the predictive model with data, you will receive a prediction based on the data that trained the model.","Correlation means there is a relationship or pattern between the values of two variables. A scatterplot displays data about two variables as a set of points in the xyxyx, y-plane and is a useful tool for determining if there is a correlation between the variables.
Causation means that one event causes another event to occur. Causation can only be determined from an appropriately designed experiment. In such experiments, similar groups receive different treatments, and the outcomes of each group are studied. We can only conclude that a treatment causes an effect if the groups have noticeably different outcomes.",0
what is the machine learning ?,"Machine learning (ML) is the study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, known as ""training data"", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.","At a very high level, machine learning is the process of teaching a computer system how to make accurate predictions when fed data.",1
what is the machine learning ?,"Machine learning (ML) is the study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, known as ""training data"", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.","Classification is used to produce discrete results, classification is used to classify data into some specific categories. For example, classifying emails into spam and non-spam categories.
Whereas, We use regression analysis when we are dealing with continuous data, for example predicting stock prices at a certain point in time",0
what is the difference between classification and regression ?,"At a very high level, machine learning is the process of teaching a computer system how to make accurate predictions when fed data.","Classification is the process of finding or discovering a model or function which helps in separating the data into multiple categorical classes i.e. discrete values. In classification, data is categorized under different labels according to some parameters given in input and then the labels are predicted for the data.Regression is the process of finding a model or function for distinguishing the data into continuous real values instead of using classes or discrete values. It can also identify the distribution movement depending on the historical data. Because a regression predictive model predicts a quantity, therefore, the skill of the model must be reported as an error in those predictions",0
what is the machine learning ?,"Machine learning (ML) is the study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, known as ""training data"", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.",Machine learning is a branch of artificial intelligence (AI) focused on building applications that learn from data and improve their accuracy over time without being programmed to do so.,1
what is the machine learning ?,"Machine learning (ML) is the study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, known as ""training data"", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.","Supervised learning requires training labeled data.Unsupervised learning, in contrast, does not require labeling data explicitly.",0
what is the difference between supervised learning and unsupervised learning ?,Machine learning is a branch of artificial intelligence (AI) focused on building applications that learn from data and improve their accuracy over time without being programmed to do so.,"In Supervised learning, you train the machine using data which is well ""labeled."".Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",0
State the differences between causality and correlation?,"Causality applies to situations where one action, say X, causes an outcome, say Y, whereas Correlation is just relating one action (X) to another action(Y) but X does not necessarily cause Y.","Correlation means there is a relationship or pattern between the values of two variables. A scatterplot displays data about two variables as a set of points in the xyxyx, y-plane and is a useful tool for determining if there is a correlation between the variables.
Causation means that one event causes another event to occur. Causation can only be determined from an appropriately designed experiment. In such experiments, similar groups receive different treatments, and the outcomes of each group are studied. We can only conclude that a treatment causes an effect if the groups have noticeably different outcomes.",1
State the differences between causality and correlation?,"Causality applies to situations where one action, say X, causes an outcome, say Y, whereas Correlation is just relating one action (X) to another action(Y) but X does not necessarily cause Y.",Associative Rule Mining is one of the techniques to discover patterns in data like features (dimensions) which occur together and features (dimensions) which are correlated.,0
What do you mean by Associative Rule Mining (ARM)?,"Correlation means there is a relationship or pattern between the values of two variables. A scatterplot displays data about two variables as a set of points in the xyxyx, y-plane and is a useful tool for determining if there is a correlation between the variables.
Causation means that one event causes another event to occur. Causation can only be determined from an appropriately designed experiment. In such experiments, similar groups receive different treatments, and the outcomes of each group are studied. We can only conclude that a treatment causes an effect if the groups have noticeably different outcomes.",Association Rule Mining is one of the ways to find patterns in data. It finds: features (dimensions) which occur together and features (dimensions) which are “correlated”,0
State the differences between causality and correlation?,"Causality applies to situations where one action, say X, causes an outcome, say Y, whereas Correlation is just relating one action (X) to another action(Y) but X does not necessarily cause Y.","While causation and correlation can exist at the same time, correlation does not imply causation. Causation explicitly applies to cases where action A {quote:right}Causation explicitly applies to cases where action A causes outcome B.{/quote} causes outcome B. On the other hand, correlation is simply a relationship. Action A relates to Action B—but one event doesn’t necessarily cause the other event to happen.",1
State the differences between causality and correlation?,"Causality applies to situations where one action, say X, causes an outcome, say Y, whereas Correlation is just relating one action (X) to another action(Y) but X does not necessarily cause Y.","AUC is the area under the ROC curve, and it's a common performance metric for evaluating binary classification models.",0
what is AUC,"While causation and correlation can exist at the same time, correlation does not imply causation. Causation explicitly applies to cases where action A {quote:right}Causation explicitly applies to cases where action A causes outcome B.{/quote} causes outcome B. On the other hand, correlation is simply a relationship. Action A relates to Action B—but one event doesn’t necessarily cause the other event to happen.","AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.",0
State the differences between causality and correlation?,"Causality applies to situations where one action, say X, causes an outcome, say Y, whereas Correlation is just relating one action (X) to another action(Y) but X does not necessarily cause Y.","Correlation tests for a relationship between two variables. However, seeing two variables moving together does not necessarily mean we know whether one variable causes the other to occur. This is why we commonly say “correlation does not imply causation.”",1
What do you mean by Associative Rule Mining (ARM)?,"Correlation tests for a relationship between two variables. However, seeing two variables moving together does not necessarily mean we know whether one variable causes the other to occur. This is why we commonly say “correlation does not imply causation.”","Association rule mining is a procedure which is meant to find frequent patterns, correlations, associations, or causal structures from data sets found in various kinds of databases such as relational databases, transactional databases, and other forms of data repositories.",0
State the differences between causality and correlation?,"While causation and correlation can exist at the same time, correlation does not imply causation. Causation explicitly applies to cases where action A Causation explicitly applies to cases where action A causes outcome B. causes outcome B. On the other hand, correlation is simply a relationship. Action A relates to Action B—but one event doesn’t necessarily cause the other event to happen.","Correlation means there is a relationship or pattern between the values of two variables. A scatterplot displays data about two variables as a set of points in the xyxyx, y-plane and is a useful tool for determining if there is a correlation between the variables.
Causation means that one event causes another event to occur. Causation can only be determined from an appropriately designed experiment. In such experiments, similar groups receive different treatments, and the outcomes of each group are studied. We can only conclude that a treatment causes an effect if the groups have noticeably different outcomes.",1
State the differences between causality and correlation?,"While causation and correlation can exist at the same time, correlation does not imply causation. Causation explicitly applies to cases where action A Causation explicitly applies to cases where action A causes outcome B. causes outcome B. On the other hand, correlation is simply a relationship. Action A relates to Action B—but one event doesn’t necessarily cause the other event to happen.",Entropy is the measure of uncertainty associated with random variable Y. It is the expected number of bits required to communicate the value of the variable.,0
Define entropy?,"Correlation means there is a relationship or pattern between the values of two variables. A scatterplot displays data about two variables as a set of points in the xyxyx, y-plane and is a useful tool for determining if there is a correlation between the variables.
Causation means that one event causes another event to occur. Causation can only be determined from an appropriately designed experiment. In such experiments, similar groups receive different treatments, and the outcomes of each group are studied. We can only conclude that a treatment causes an effect if the groups have noticeably different outcomes.",Entropy is nothing but the measure of disorder.,0
State the differences between causality and correlation?,"While causation and correlation can exist at the same time, correlation does not imply causation. Causation explicitly applies to cases where action A Causation explicitly applies to cases where action A causes outcome B. causes outcome B. On the other hand, correlation is simply a relationship. Action A relates to Action B—but one event doesn’t necessarily cause the other event to happen.","Correlation tests for a relationship between two variables. However, seeing two variables moving together does not necessarily mean we know whether one variable causes the other to occur. This is why we commonly say “correlation does not imply causation.”",1
State the differences between causality and correlation?,"While causation and correlation can exist at the same time, correlation does not imply causation. Causation explicitly applies to cases where action A Causation explicitly applies to cases where action A causes outcome B. causes outcome B. On the other hand, correlation is simply a relationship. Action A relates to Action B—but one event doesn’t necessarily cause the other event to happen.",The difference between inductive machine learning and deductive machine learning are as follows: machine-learning where the model learns by examples from a set of observed instances to draw a generalized conclusion whereas in deductive learning the model first draws the conclusion and then the conclusion is drawn.,0
What is the difference between inductive machine learning and deductive machine learning?,"Correlation tests for a relationship between two variables. However, seeing two variables moving together does not necessarily mean we know whether one variable causes the other to occur. This is why we commonly say “correlation does not imply causation.”",inductive machine learning : Observe and learn from the set of instances and then draw the conclusion.It is Statistical machine learning like KNN (K-nearest neighbour) or SVM (Support Vector Machine).Deductive Machine Learning: Derives conclusion and then work on it based on the previous decision.Machine learning algorithm to deductive reasoning using a decision tree,0
What do you mean by Associative Rule Mining (ARM)?,Associative Rule Mining is one of the techniques to discover patterns in data like features (dimensions) which occur together and features (dimensions) which are correlated.,Association rule mining finds interesting associations and relationships among large sets of data items. This rule shows how frequently a itemset occurs in a transaction. A typical example is Market Based Analysis.,1
What do you mean by Associative Rule Mining (ARM)?,Associative Rule Mining is one of the techniques to discover patterns in data like features (dimensions) which occur together and features (dimensions) which are correlated.,"Machine learning (ML) is the study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, known as ""training data"", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.",0
what is the machine learning ?,Association rule mining finds interesting associations and relationships among large sets of data items. This rule shows how frequently a itemset occurs in a transaction. A typical example is Market Based Analysis.,"At a very high level, machine learning is the process of teaching a computer system how to make accurate predictions when fed data.",0
What do you mean by Associative Rule Mining (ARM)?,Associative Rule Mining is one of the techniques to discover patterns in data like features (dimensions) which occur together and features (dimensions) which are correlated.,Association Rule Mining is one of the ways to find patterns in data. It finds: features (dimensions) which occur together and features (dimensions) which are “correlated”,1
What do you mean by Associative Rule Mining (ARM)?,Associative Rule Mining is one of the techniques to discover patterns in data like features (dimensions) which occur together and features (dimensions) which are correlated.,"The F1 score is a measure of a model’s performance. It is a weighted average of the precision and recall of a model, with results tending to 1 being the best, and those tending to 0 being the worst. You would use it in classification tests where true negatives don’t matter much.",0
What’s the F1 score? How would you use it?,Association Rule Mining is one of the ways to find patterns in data. It finds: features (dimensions) which occur together and features (dimensions) which are “correlated”,"The F-score, also called the F1-score, is a measure of a model’s accuracy on a dataset. It is used to evaluate binary classification systems, which classify examples into ‘positive’ or ‘negative’.

The F-score is a way of combining the precision and recall of the model, and it is defined as the harmonic mean of the model’s precision and recall.

The F-score is commonly used for evaluating information retrieval systems such as search engines, and also for many kinds of machine learning models, in particular in natural language processing.",0
What do you mean by Associative Rule Mining (ARM)?,Associative Rule Mining is one of the techniques to discover patterns in data like features (dimensions) which occur together and features (dimensions) which are correlated.,"Association rule mining is a procedure which is meant to find frequent patterns, correlations, associations, or causal structures from data sets found in various kinds of databases such as relational databases, transactional databases, and other forms of data repositories.",1
What do you mean by Associative Rule Mining (ARM)?,Associative Rule Mining is one of the techniques to discover patterns in data like features (dimensions) which occur together and features (dimensions) which are correlated.,A generative model will learn categories of data while a discriminative model will simply learn the distinction between different categories of data. Discriminative models will generally outperform generative models on classification tasks.,0
What’s the difference between a generative and discriminative model?,"Association rule mining is a procedure which is meant to find frequent patterns, correlations, associations, or causal structures from data sets found in various kinds of databases such as relational databases, transactional databases, and other forms of data repositories.","Discriminative models learn the (hard or soft) boundary between classes
Generative models model the distribution of individual classes",0
Explain Ensemble learning,"In ensemble learning, many base models like classifiers and regressors are generated and combined together so that they give better results. It is used when we build component classifiers that are accurate and independent. There are sequential as well as parallel ensemble methods.","In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone. Unlike a statistical ensemble in statistical mechanics, which is usually infinite, a machine learning ensemble consists of only a concrete finite set of alternative models, but typically allows for much more flexible structure to exist among those alternatives.",1
Explain Ensemble learning,"In ensemble learning, many base models like classifiers and regressors are generated and combined together so that they give better results. It is used when we build component classifiers that are accurate and independent. There are sequential as well as parallel ensemble methods.","The F1 score is a measure of a model’s performance. It is a weighted average of the precision and recall of a model, with results tending to 1 being the best, and those tending to 0 being the worst. You would use it in classification tests where true negatives don’t matter much.",0
What’s the F1 score? How would you use it?,"In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone. Unlike a statistical ensemble in statistical mechanics, which is usually infinite, a machine learning ensemble consists of only a concrete finite set of alternative models, but typically allows for much more flexible structure to exist among those alternatives.","The F-score, also called the F1-score, is a measure of a model’s accuracy on a dataset. It is used to evaluate binary classification systems, which classify examples into ‘positive’ or ‘negative’.

The F-score is a way of combining the precision and recall of the model, and it is defined as the harmonic mean of the model’s precision and recall.

The F-score is commonly used for evaluating information retrieval systems such as search engines, and also for many kinds of machine learning models, in particular in natural language processing.",0
Explain Ensemble learning,"In ensemble learning, many base models like classifiers and regressors are generated and combined together so that they give better results. It is used when we build component classifiers that are accurate and independent. There are sequential as well as parallel ensemble methods.","Ensemble learning is the process by which multiple models, such as classifiers or experts, are strategically generated and combined to solve a particular computational intelligence problem. Ensemble learning is primarily used to improve the (classification, prediction, function approximation, etc.) performance of a model, or reduce the likelihood of an unfortunate selection of a poor one.",1
Explain Ensemble learning,"In ensemble learning, many base models like classifiers and regressors are generated and combined together so that they give better results. It is used when we build component classifiers that are accurate and independent. There are sequential as well as parallel ensemble methods.","L2 regularization tends to spread error among all the terms.while L1 is more binary/sparse, with many variables eithger being assigned a 1 or 0 in weighting L1 corresponds to setting a Laplacean prior to the terms , while L2 corresponds to a Gaussian error",0
Explain the difference between L1 and L2 regularization,"Ensemble learning is the process by which multiple models, such as classifiers or experts, are strategically generated and combined to solve a particular computational intelligence problem. Ensemble learning is primarily used to improve the (classification, prediction, function approximation, etc.) performance of a model, or reduce the likelihood of an unfortunate selection of a poor one.","From a practical standpoint, L1 tends to shrink coefficients to zero whereas L2 tends to shrink coefficients evenly. L1 is therefore useful for feature selection, as we can drop any variables associated with coefficients that go to zero. L2, on the other hand, is useful when you have collinear/codependent features.",0
Explain Ensemble learning,"In ensemble learning, many base models like classifiers and regressors are generated and combined together so that they give better results. It is used when we build component classifiers that are accurate and independent. There are sequential as well as parallel ensemble methods.",Ensemble methods is a machine learning technique that combines several base models in order to produce one optimal predictive model.,1
Explain Ensemble learning,"In ensemble learning, many base models like classifiers and regressors are generated and combined together so that they give better results. It is used when we build component classifiers that are accurate and independent. There are sequential as well as parallel ensemble methods.",If the algorithm is too simple (hypothesis with linear eq.) then it may be on high bias and low variance condition and thus is error-prone. If algorithms fit too complex ( hypothesis with high degree eq.) then it may be on high variance and low bias.,0
what is the trade off between bias and variance ?,Ensemble methods is a machine learning technique that combines several base models in order to produce one optimal predictive model.,the bias–variance tradeoff is the property of a model that the variance of the parameter estimates across samples can be reduced by increasing the bias in the estimated parameters.,0
What is the difference between stochastic gradient descent (SGD) and gradient descent (GD)?,"Both algorithms are methods for finding a set of parameters that minimize a loss function by evaluating parameters against data and then making adjustments. In standard gradient descent, you'll evaluate all training samples for each set of parameters. This is akin to taking big, slow steps toward the solution. In stochastic gradient descent, you'll evaluate only 1 training sample for the set of parameters before updating them. This is akin to taking small, quick steps toward the solution.","In both gradient descent (GD) and stochastic gradient descent (SGD), you update a set of parameters in an iterative manner to minimize an error function. While in GD, you have to run through ALL the samples in your training set to do a single update for a parameter in a particular iteration, in SGD, on the other hand, you use ONLY ONE or SUBSET of training sample from your training set to do the update for a parameter in a particular iteration. If you use SUBSET, it is called Minibatch Stochastic gradient Descent.",1
What is the difference between stochastic gradient descent (SGD) and gradient descent (GD)?,"Both algorithms are methods for finding a set of parameters that minimize a loss function by evaluating parameters against data and then making adjustments. In standard gradient descent, you'll evaluate all training samples for each set of parameters. This is akin to taking big, slow steps toward the solution. In stochastic gradient descent, you'll evaluate only 1 training sample for the set of parameters before updating them. This is akin to taking small, quick steps toward the solution.",A confusion matrix is a technique for summarizing the performance of a classification algorithm.,0
 What is a Confusion Matrix? ,"In both gradient descent (GD) and stochastic gradient descent (SGD), you update a set of parameters in an iterative manner to minimize an error function. While in GD, you have to run through ALL the samples in your training set to do a single update for a parameter in a particular iteration, in SGD, on the other hand, you use ONLY ONE or SUBSET of training sample from your training set to do the update for a parameter in a particular iteration. If you use SUBSET, it is called Minibatch Stochastic gradient Descent.","a confusion matrix, also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm,",0
What’s a Fourier transform?,"A Fourier transform is a generic method to decompose generic functions into a superposition of symmetric functions. Or as this more intuitive tutorial puts it, given a smoothie, it’s how we find the recipe. The Fourier transform finds the set of cycle speeds, amplitudes, and phases to match any time signal. A Fourier transform converts a signal from time to frequency domain — it’s a very common way to extract features from audio signals or other time series such as sensor data.","Fourier transform (FT) is capable of decomposing a complicated waveform into a sequence of simpler elemental waves (more specifically, a weighted sum of sines and cosines). This is analogous to how a wave representing a music chord (for example, one consisting of the notes C, D, and E) can be expressed in terms of the properties of its base notes (furthermore, if we graph these notes via the Fourier transform on a frequency-versus-intensity graph, there will be visible peaks corresponding to these music notes)",1
What’s a Fourier transform?,"A Fourier transform is a generic method to decompose generic functions into a superposition of symmetric functions. Or as this more intuitive tutorial puts it, given a smoothie, it’s how we find the recipe. The Fourier transform finds the set of cycle speeds, amplitudes, and phases to match any time signal. A Fourier transform converts a signal from time to frequency domain — it’s a very common way to extract features from audio signals or other time series such as sensor data.",A generative model will learn categories of data while a discriminative model will simply learn the distinction between different categories of data. Discriminative models will generally outperform generative models on classification tasks.,0
What’s the difference between a generative and discriminative model?,"Fourier transform (FT) is capable of decomposing a complicated waveform into a sequence of simpler elemental waves (more specifically, a weighted sum of sines and cosines). This is analogous to how a wave representing a music chord (for example, one consisting of the notes C, D, and E) can be expressed in terms of the properties of its base notes (furthermore, if we graph these notes via the Fourier transform on a frequency-versus-intensity graph, there will be visible peaks corresponding to these music notes)","Discriminative models learn the (hard or soft) boundary between classes
Generative models model the distribution of individual classes",0
what it the reinforcement learning ?,"Reinforcement learning is the training of machine learning models to make a sequence of decisions. The agent learns to achieve a goal in an uncertain, potentially complex environment. In reinforcement learning, an artificial intelligence faces a game-like situation. The computer employs trial and error to come up with a solution to the problem. To get the machine to do what the programmer wants, the artificial intelligence gets either rewards or penalties for the actions it performs. Its goal is to maximize the total reward.","Reinforcement learning (RL) is an area of machine learning concerned with how software agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.",1
what it the reinforcement learning ?,"Reinforcement learning is the training of machine learning models to make a sequence of decisions. The agent learns to achieve a goal in an uncertain, potentially complex environment. In reinforcement learning, an artificial intelligence faces a game-like situation. The computer employs trial and error to come up with a solution to the problem. To get the machine to do what the programmer wants, the artificial intelligence gets either rewards or penalties for the actions it performs. Its goal is to maximize the total reward.",The training set is examples given to the model to analyze and learn.The test set is used to test the accuracy of the hypothesis generated by the model,0
What is ‘training Set’ and ‘test Set’ in a Machine Learning Model?,"Reinforcement learning (RL) is an area of machine learning concerned with how software agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.",The actual dataset that we use to train the model (weights and biases in the case of a Neural Network). The model sees and learns from this data.,0
what it the reinforcement learning ?,"Reinforcement learning is the training of machine learning models to make a sequence of decisions. The agent learns to achieve a goal in an uncertain, potentially complex environment. In reinforcement learning, an artificial intelligence faces a game-like situation. The computer employs trial and error to come up with a solution to the problem. To get the machine to do what the programmer wants, the artificial intelligence gets either rewards or penalties for the actions it performs. Its goal is to maximize the total reward.",Reinforcement learning is an area of Machine Learning. It is about taking suitable action to maximize reward in a particular situation. It is employed by various software and machines to find the best possible behavior or path it should take in a specific situation.,1
what it the reinforcement learning ?,"Reinforcement learning is the training of machine learning models to make a sequence of decisions. The agent learns to achieve a goal in an uncertain, potentially complex environment. In reinforcement learning, an artificial intelligence faces a game-like situation. The computer employs trial and error to come up with a solution to the problem. To get the machine to do what the programmer wants, the artificial intelligence gets either rewards or penalties for the actions it performs. Its goal is to maximize the total reward.","Machine learning (ML) is the study of computer algorithms that improve automatically through experience. It is seen as a subset of artificial intelligence. Machine learning algorithms build a model based on sample data, known as ""training data"", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.",0
what is the machine learning ?,Reinforcement learning is an area of Machine Learning. It is about taking suitable action to maximize reward in a particular situation. It is employed by various software and machines to find the best possible behavior or path it should take in a specific situation.,"At a very high level, machine learning is the process of teaching a computer system how to make accurate predictions when fed data.",0
what it the reinforcement learning ?,"Reinforcement learning is the training of machine learning models to make a sequence of decisions. The agent learns to achieve a goal in an uncertain, potentially complex environment. In reinforcement learning, an artificial intelligence faces a game-like situation. The computer employs trial and error to come up with a solution to the problem. To get the machine to do what the programmer wants, the artificial intelligence gets either rewards or penalties for the actions it performs. Its goal is to maximize the total reward.",Reinforcement Learning is defined as a Machine Learning method that is concerned with how software agents should take actions in an environment. Reinforcement Learning is a part of the deep learning method that helps you to maximize some portion of the cumulative reward.,1
what it the reinforcement learning ?,"Reinforcement learning is the training of machine learning models to make a sequence of decisions. The agent learns to achieve a goal in an uncertain, potentially complex environment. In reinforcement learning, an artificial intelligence faces a game-like situation. The computer employs trial and error to come up with a solution to the problem. To get the machine to do what the programmer wants, the artificial intelligence gets either rewards or penalties for the actions it performs. Its goal is to maximize the total reward.","Classification is used to produce discrete results, classification is used to classify data into some specific categories. For example, classifying emails into spam and non-spam categories.
Whereas, We use regression analysis when we are dealing with continuous data, for example predicting stock prices at a certain point in time",0
what is the difference between classification and regression ?,Reinforcement Learning is defined as a Machine Learning method that is concerned with how software agents should take actions in an environment. Reinforcement Learning is a part of the deep learning method that helps you to maximize some portion of the cumulative reward.,"Fundamentally, classification is about predicting a label and regression is about predicting a quantity",0
what it the reinforcement learning ?,"Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.",Reinforcement Learning is defined as a Machine Learning method that is concerned with how software agents should take actions in an environment. Reinforcement Learning is a part of the deep learning method that helps you to maximize some portion of the cumulative reward.,1
what it the reinforcement learning ?,"Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.","In Supervised learning, you train the machine using data which is well ""labeled."".Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",0
what is the difference between supervised learning and unsupervised learning ?,Reinforcement Learning is defined as a Machine Learning method that is concerned with how software agents should take actions in an environment. Reinforcement Learning is a part of the deep learning method that helps you to maximize some portion of the cumulative reward.,"In supervised machine learning, a model makes predictions or decisions based on past or labeled data. Labeled data refers to sets of data that are given tags or labels, and thus made more meaningful.In unsupervised learning, we don't have labeled data. A model can identify patterns, anomalies, and relationships in the input data.",0
what it the reinforcement learning ?,"Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.",Reinforcement learning is an area of Machine Learning. It is about taking suitable action to maximize reward in a particular situation. It is employed by various software and machines to find the best possible behavior or path it should take in a specific situation.,1
what it the reinforcement learning ?,"Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.","L2 regularization tends to spread error among all the terms.while L1 is more binary/sparse, with many variables eithger being assigned a 1 or 0 in weighting L1 corresponds to setting a Laplacean prior to the terms , while L2 corresponds to a Gaussian error",0
Explain the difference between L1 and L2 regularization,Reinforcement learning is an area of Machine Learning. It is about taking suitable action to maximize reward in a particular situation. It is employed by various software and machines to find the best possible behavior or path it should take in a specific situation.,"From a practical standpoint, L1 tends to shrink coefficients to zero whereas L2 tends to shrink coefficients evenly. L1 is therefore useful for feature selection, as we can drop any variables associated with coefficients that go to zero. L2, on the other hand, is useful when you have collinear/codependent features.",0
Explain bagging.,"Bagging, or Bootstrap Aggregating, is an ensemble method in which the dataset is first divided into multiple subsets through resampling.
Then, each subset is used to train a model, and the final predictions are made through voting or averaging the component models.
Bagging is performed in parallel.","Bootstrap aggregating, also called bagging (from bootstrap aggregating), is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting.",1
Explain bagging.,"Bagging, or Bootstrap Aggregating, is an ensemble method in which the dataset is first divided into multiple subsets through resampling.
Then, each subset is used to train a model, and the final predictions are made through voting or averaging the component models.
Bagging is performed in parallel.",Overfitting is a situation that occurs when a model learns the training set too well,0
what is the overfitting ?,"Bootstrap aggregating, also called bagging (from bootstrap aggregating), is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting.",Overfitting is a modeling error that occurs when a function is too closely fit to a limited set of data points.,0
What is the ROC Curve,The ROC (receiver operating characteristic) the performance plot for binary classifiers of True Positive Rate (y axis) vs. False Positive Rate (x axis).,The ROC curve is a graphical representation of the contrast between true positive rates and the false positive rate at various thresholds. It’s often used as a proxy for the trade-off between the sensitivity of the model (true positives) vs the fall-out or the probability it will trigger a false alarm (false positives).,1
What is the ROC Curve,The ROC (receiver operating characteristic) the performance plot for binary classifiers of True Positive Rate (y axis) vs. False Positive Rate (x axis).,"A convex function is a continuous function, and the value of the midpoint at every interval in its given domain is less than the numerical mean of the values at the two ends of the interval.",0
What is the Convex Function?,The ROC curve is a graphical representation of the contrast between true positive rates and the false positive rate at various thresholds. It’s often used as a proxy for the trade-off between the sensitivity of the model (true positives) vs the fall-out or the probability it will trigger a false alarm (false positives).,"In mathematics, a real-valued function defined on an n-dimensional interval is called convex if the line segment between any two points on the graph of the function lies above the graph between the two points. Equivalently, a function is convex if its epigraph (the set of points on or above the graph of the function) is a convex set. A twice-differentiable function of a single variable is convex if and only if its second derivative is nonnegative on its entire domain. Well-known examples of convex functions of a single variable include the squaring function {\displaystyle x^{2}}x^{2} and the exponential function {\displaystyle e^{x}}e^{x}.",0
What is the ROC Curve,The ROC is the performance plot for binary classifiers of True Positive Rate (y axis) vs. False Positive Rate (x axis).,An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters: True Positive Rate and False Positive Rate,1
What is the ROC Curve,The ROC is the performance plot for binary classifiers of True Positive Rate (y axis) vs. False Positive Rate (x axis).,"Supervised learning requires training labeled data.Unsupervised learning, in contrast, does not require labeling data explicitly.",0
what is the difference between supervised learning and unsupervised learning ?,An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters: True Positive Rate and False Positive Rate,"In supervised machine learning algorithms, we have to provide labeled data, for example, prediction of stock market prices, whereas in unsupervised we need not have labeled data, for example, classification of emails into spam and non-spam.",0
What is the ROC Curve,An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters: True Positive Rate and False Positive Rate,The ROC curve is a graphical representation of the contrast between true positive rates and the false positive rate at various thresholds. It’s often used as a proxy for the trade-off between the sensitivity of the model (true positives) vs the fall-out or the probability it will trigger a false alarm (false positives).,1
What is the ROC Curve,An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters: True Positive Rate and False Positive Rate,"AUC is the area under the ROC curve, and it's a common performance metric for evaluating binary classification models.",0
what is AUC,The ROC curve is a graphical representation of the contrast between true positive rates and the false positive rate at various thresholds. It’s often used as a proxy for the trade-off between the sensitivity of the model (true positives) vs the fall-out or the probability it will trigger a false alarm (false positives).,"AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.",0
What is the ROC Curve,The ROC (receiver operating characteristic) the performance plot for binary classifiers of True Positive Rate (y axis) vs. False Positive Rate (x axis).,"ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The method was originally developed for operators of military radar receivers, which is why it is so named.",1
What is the ROC Curve,The ROC (receiver operating characteristic) the performance plot for binary classifiers of True Positive Rate (y axis) vs. False Positive Rate (x axis).,"AUC is the area under the ROC curve, and it's a common performance metric for evaluating binary classification models.",0
what is AUC,"ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The method was originally developed for operators of military radar receivers, which is why it is so named.","AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.",0
What is the ROC Curve,An ROC curve is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters: True Positive Rate and False Positive Rate,"ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The method was originally developed for operators of military radar receivers, which is why it is so named.",1
What is the ROC Curve,An ROC curve is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters: True Positive Rate and False Positive Rate,"Linear regression algorithm shows a linear relationship between a dependent (y) and one or more independent (y) variables, hence called as linear regression. Since linear regression shows the linear relationship, which means it finds how the value of the dependent variable is changing according to the value of the independent variable.",0
What is Linear Regression?,"ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The method was originally developed for operators of military radar receivers, which is why it is so named.",Simple linear regression is a type of regression analysis where the number of independent variables is one and there is a linear relationship between the independent(x) and dependent(y) variable.,0
what is AUC,"AUC is the area under the ROC curve, and it's a common performance metric for evaluating binary classification models.","AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.",1
what is AUC,"AUC is the area under the ROC curve, and it's a common performance metric for evaluating binary classification models.","In Supervised learning, you train the machine using data which is well ""labeled."".Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",0
what is the difference between supervised learning and unsupervised learning ?,"AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.","In supervised machine learning algorithms, we have to provide labeled data, for example, prediction of stock market prices, whereas in unsupervised we need not have labeled data, for example, classification of emails into spam and non-spam.",0
what is AUC,"AUC is the area under the ROC curve, and it's a common performance metric for evaluating binary classification models.","AUC stands for ""Area under the ROC Curve."" That is, AUC measures the entire two-dimensional area underneath the entire ROC curve (think integral calculus) from (0,0) to (1,1).",1
what is AUC,"AUC is the area under the ROC curve, and it's a common performance metric for evaluating binary classification models.","Kernel SVM is the abbreviated version of the kernel support vector machine. Kernel methods are a class of algorithms for pattern analysis, and the most common one is the kernel SVM.",0
What Is Kernel SVM?,"AUC stands for ""Area under the ROC Curve."" That is, AUC measures the entire two-dimensional area underneath the entire ROC curve (think integral calculus) from (0,0) to (1,1).","In machine learning, kernel machines are a class of algorithms for pattern analysis, whose best known member is the support vector machine (SVM).",0
"What are PCA, KPCA, and ICA used for?",PCA (Principal Components Analysis) is like KPCA ( Kernel-based Principal Component Analysis) and ICA ( Independent Component Analysis) are important feature extraction techniques used for dimensionality reduction.,they are commonly used for dimensionality reduction,1
"What are PCA, KPCA, and ICA used for?",PCA (Principal Components Analysis) is like KPCA ( Kernel-based Principal Component Analysis) and ICA ( Independent Component Analysis) are important feature extraction techniques used for dimensionality reduction.,"Causality applies to situations where one action, say X, causes an outcome, say Y, whereas Correlation is just relating one action (X) to another action(Y) but X does not necessarily cause Y.",0
State the differences between causality and correlation?,they are commonly used for dimensionality reduction,"While causation and correlation can exist at the same time, correlation does not imply causation. Causation explicitly applies to cases where action A {quote:right}Causation explicitly applies to cases where action A causes outcome B.{/quote} causes outcome B. On the other hand, correlation is simply a relationship. Action A relates to Action B—but one event doesn’t necessarily cause the other event to happen.",0
How do you handle outliers in the data?,"Outlier is an observation in the data set that is far away from other observations in the data set. We can discover outliers using tools and functions like box plot, scatter plot, Z-Score, IQR score etc. and then handle them based on the visualization we have got. To handle outliers, we can cap at some threshold, use transformations to reduce skewness of the data and remove outliers if they are anomalies or errors.","Univariate method: This method looks for data points with extreme values on one variable.
Multivariate method: Here, we look for unusual combinations of all the variables.
Minkowski error: This method reduces the contribution of potential outliers in the training process",1
How do you handle outliers in the data?,"Outlier is an observation in the data set that is far away from other observations in the data set. We can discover outliers using tools and functions like box plot, scatter plot, Z-Score, IQR score etc. and then handle them based on the visualization we have got. To handle outliers, we can cap at some threshold, use transformations to reduce skewness of the data and remove outliers if they are anomalies or errors.",False positives are those cases which wrongly get classified as True but are False.False negatives are those cases which wrongly get classified as False but are True.,0
What Is a False Positive and False Negative and How Are They Significant?,"Univariate method: This method looks for data points with extreme values on one variable.
Multivariate method: Here, we look for unusual combinations of all the variables.
Minkowski error: This method reduces the contribution of potential outliers in the training process",False negative: When a data point is classified as a negative example(say class 0) but it is actually a positive example(belongs to class 1).False positive: When a data point is classified as a positive example(say class 1) but it is actually a negative example(belongs to class 0).,0
How do you handle outliers in the data?,"Outlier is an observation in the data set that is far away from other observations in the data set. We can discover outliers using tools and functions like box plot, scatter plot, Z-Score, IQR score etc. and then handle them based on the visualization we have got. To handle outliers, we can cap at some threshold, use transformations to reduce skewness of the data and remove outliers if they are anomalies or errors.","1. Drop the outlier records. In the case of Bill Gates, or another true outlier, sometimes it’s best to completely remove that record from your dataset to keep that person or event from skewing your analysis.
2. Cap your outliers data. Another way to handle true outliers is to cap them. For example, if you are using income, you might find that people above a certain income level behave in the same way as those with a lower income. In this case, you can cap the income value at a level that keeps that intact.
3. Assign a new value. If an outlier seems to be due to a mistake in your data, you try imputing a value. Common imputation methods include using the mean of a variable or utilizing a regression model to predict the missing value.
4. Try a transformation. A different approach to true outliers could be to try creating a transformation of the data rather than using the data itself. For example, try creating a percentile version of your original field and working with that new field instead.",1
How do you handle outliers in the data?,"Outlier is an observation in the data set that is far away from other observations in the data set. We can discover outliers using tools and functions like box plot, scatter plot, Z-Score, IQR score etc. and then handle them based on the visualization we have got. To handle outliers, we can cap at some threshold, use transformations to reduce skewness of the data and remove outliers if they are anomalies or errors.","L2 regularization tends to spread error among all the terms.while L1 is more binary/sparse, with many variables eithger being assigned a 1 or 0 in weighting L1 corresponds to setting a Laplacean prior to the terms , while L2 corresponds to a Gaussian error",0
Explain the difference between L1 and L2 regularization,"1. Drop the outlier records. In the case of Bill Gates, or another true outlier, sometimes it’s best to completely remove that record from your dataset to keep that person or event from skewing your analysis.
2. Cap your outliers data. Another way to handle true outliers is to cap them. For example, if you’re using income, you might find that people above a certain income level behave in the same way as those with a lower income. In this case, you can cap the income value at a level that keeps that intact.
3. Assign a new value. If an outlier seems to be due to a mistake in your data, you try imputing a value. Common imputation methods include using the mean of a variable or utilizing a regression model to predict the missing value.
4. Try a transformation. A different approach to true outliers could be to try creating a transformation of the data rather than using the data itself. For example, try creating a percentile version of your original field and working with that new field instead.","From a practical standpoint, L1 tends to shrink coefficients to zero whereas L2 tends to shrink coefficients evenly. L1 is therefore useful for feature selection, as we can drop any variables associated with coefficients that go to zero. L2, on the other hand, is useful when you have collinear/codependent features.",0
What is the difference between inductive machine learning and deductive machine learning?,The difference between inductive machine learning and deductive machine learning are as follows: machine-learning where the model learns by examples from a set of observed instances to draw a generalized conclusion whereas in deductive learning the model first draws the conclusion and then the conclusion is drawn.,"Deductive reasoning moves from generalized statement to a valid conclusion, whereas Inductive reasoning moves from specific observation to a generalization.",1
What is the difference between inductive machine learning and deductive machine learning?,The difference between inductive machine learning and deductive machine learning are as follows: machine-learning where the model learns by examples from a set of observed instances to draw a generalized conclusion whereas in deductive learning the model first draws the conclusion and then the conclusion is drawn.,The training set is examples given to the model to analyze and learn.The test set is used to test the accuracy of the hypothesis generated by the model,0
What is ‘training Set’ and ‘test Set’ in a Machine Learning Model?,"Deductive reasoning moves from generalized statement to a valid conclusion, whereas Inductive reasoning moves from specific observation to a generalization.",The actual dataset that we use to train the model (weights and biases in the case of a Neural Network). The model sees and learns from this data.,0
What is the difference between inductive machine learning and deductive machine learning?,The difference between inductive machine learning and deductive machine learning are as follows: machine-learning where the model learns by examples from a set of observed instances to draw a generalized conclusion whereas in deductive learning the model first draws the conclusion and then the conclusion is drawn.,"INDUCTIVE MACHINE LEARNING: From the perspective of inductive learning, we are given input samples (x) and output samples (f(x)) and the problem is to estimate the function (f). Specifically, the problem is to generalize from the samples and the mapping to be useful to estimate the output for new samples in the future.Deductive Machine Learning: A deductive approach to teaching language starts by giving learners rules, then examples, then practice. It is a teacher-centered approach to presenting new content. This is compared with an inductive approach, which starts with examples and asks learners to find rules and hence is more learner-centered.",1
What is the difference between inductive machine learning and deductive machine learning?,The difference between inductive machine learning and deductive machine learning are as follows: machine-learning where the model learns by examples from a set of observed instances to draw a generalized conclusion whereas in deductive learning the model first draws the conclusion and then the conclusion is drawn.,"Machine learning relates to the study, design, and development of the algorithms that give computers the capability to learn without being explicitly programmed. While data mining can be defined as the process in which the unstructured data tries to extract knowledge or unknown interesting patterns. During this processing machine, learning algorithms are used",0
Mention the difference between Data Mining and Machine learning?,"INDUCTIVE MACHINE LEARNING: From the perspective of inductive learning, we are given input samples (x) and output samples (f(x)) and the problem is to estimate the function (f). Specifically, the problem is to generalize from the samples and the mapping to be useful to estimate the output for new samples in the future.Deductive Machine Learning: A deductive approach to teaching language starts by giving learners rules, then examples, then practice. It is a teacher-centered approach to presenting new content. This is compared with an inductive approach, which starts with examples and asks learners to find rules and hence is more learner-centered.","Data mining is used on an existing dataset (like a data warehouse) to find patterns. Machine learning, on the other hand, is trained on a ‘training’ data set, which teaches the computer how to make sense of data, and then to make predictions about new data sets.",0
What is the difference between inductive machine learning and deductive machine learning?,The difference between inductive machine learning and deductive machine learning are as follows: machine-learning where the model learns by examples from a set of observed instances to draw a generalized conclusion whereas in deductive learning the model first draws the conclusion and then the conclusion is drawn.,"Inductive reasoning includes making a simplification from specific facts, and observations. It uses a bottom-up method. It moves from precise observation to a generalization or simplification. In Inductive reasoning, the conclusions are probabilistic. An Inductive argument can be strong or weak, that means conclusion may be false even if premises(properties) are true. Usage of inductive reasoning is fast and easy, as we need evidence instead of true facts.
Deductive reasoning uses available facts, information, or knowledge to assume a valid conclusion. It uses a top-down approach or method. It moves from generalized statement to an effective conclusion. In deductive reasoning, the conclusions are sure. Deductive arguments can be valid or invalid, that means if premises or properties are true, the conclusion must be true. Usage of deductive reasoning is difficult, as we need facts which must be true.",1
What is the difference between inductive machine learning and deductive machine learning?,The difference between inductive machine learning and deductive machine learning are as follows: machine-learning where the model learns by examples from a set of observed instances to draw a generalized conclusion whereas in deductive learning the model first draws the conclusion and then the conclusion is drawn.,"L2 regularization tends to spread error among all the terms.while L1 is more binary/sparse, with many variables eithger being assigned a 1 or 0 in weighting L1 corresponds to setting a Laplacean prior to the terms , while L2 corresponds to a Gaussian error",0
Explain the difference between L1 and L2 regularization,"Inductive reasoning includes making a simplification from specific facts, and observations. It uses a bottom-up method. It moves from precise observation to a generalization or simplification. In Inductive reasoning, the conclusions are probabilistic. An Inductive argument can be strong or weak, that means conclusion may be false even if premises(properties) are true. Usage of inductive reasoning is fast and easy, as we need evidence instead of true facts.
Deductive reasoning uses available facts, information, or knowledge to assume a valid conclusion. It uses a top-down approach or method. It moves from generalized statement to an effective conclusion. In deductive reasoning, the conclusions are sure. Deductive arguments can be valid or invalid, that means if premises or properties are true, the conclusion must be true. Usage of deductive reasoning is difficult, as we need facts which must be true.","L1 regularization helps perform feature selection in sparse feature spaces, and that is a good practical reason to use L1 in some situations. However, beyond that particular reason I have never seen L1 to perform better than L2 in practice. And, to be clear, I don't think I am the only one to be in this situation. If you take a look at LIBLINEAR FAQ on this issue you will see how they have not seen a practical example where L1 beats L2 and encourage users of the library to contact them if they find one. Even in a situation where you might benefit from L1's sparsity in order to do feature selection, using L2 on the remaining variables is likely to give better results than L1 by itself.",0
What is the difference between inductive machine learning and deductive machine learning?,The difference between inductive machine learning and deductive machine learning are as follows: machine-learning where the model learns by examples from a set of observed instances to draw a generalized conclusion whereas in deductive learning the model first draws the conclusion and then the conclusion is drawn.,inductive machine learning : Observe and learn from the set of instances and then draw the conclusion.It is Statistical machine learning like KNN (K-nearest neighbour) or SVM (Support Vector Machine).Deductive Machine Learning: Derives conclusion and then work on it based on the previous decision.Machine learning algorithm to deductive reasoning using a decision tree,1
What is the difference between inductive machine learning and deductive machine learning?,The difference between inductive machine learning and deductive machine learning are as follows: machine-learning where the model learns by examples from a set of observed instances to draw a generalized conclusion whereas in deductive learning the model first draws the conclusion and then the conclusion is drawn.,"In Supervised learning, you train the machine using data which is well ""labeled."".Unsupervised learning is a machine learning technique, where you do not need to supervise the model.",0
what is the difference between supervised learning and unsupervised learning ?,inductive machine learning : Observe and learn from the set of instances and then draw the conclusion.It is Statistical machine learning like KNN (K-nearest neighbour) or SVM (Support Vector Machine).Deductive Machine Learning: Derives conclusion and then work on it based on the previous decision.Machine learning algorithm to deductive reasoning using a decision tree,"In supervised machine learning, a model makes predictions or decisions based on past or labeled data. Labeled data refers to sets of data that are given tags or labels, and thus made more meaningful.In unsupervised learning, we don't have labeled data. A model can identify patterns, anomalies, and relationships in the input data.",0
What do you understand by Natural Language Processing?,"Natural language processing is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.",Natural Language Processing is a field of computer science that deals with communication between computer systems and humans. It is a technique used in Artificial Intelligence and Machine Learning. It is used to create automated software that helps understand human spoken languages to extract useful information from the data it gets in the form of audio.,1
What do you understand by Natural Language Processing?,"Natural language processing is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.","stop words are words which are filtered out before or after processing of natural language data. The reason why stop words are critical to many applications is that, if we remove the words that are very commonly used in a given language, we can focus on the important words instead.",0
What are stop words?,Natural Language Processing is a field of computer science that deals with communication between computer systems and humans. It is a technique used in Artificial Intelligence and Machine Learning. It is used to create automated software that helps understand human spoken languages to extract useful information from the data it gets in the form of audio.,"A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.",0
What do you understand by Natural Language Processing?,"Natural language processing is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.","Natural language processing  is the relationship between computers and human language. More specifically, natural language processing is the computer understanding, analysis, manipulation, and/or generation of natural language.",1
What do you understand by Natural Language Processing?,"Natural language processing is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.","Text mining (also referred to as text analytics) is an artificial intelligence (AI) technology that uses natural language processing (NLP) to transform the free (unstructured) text in documents and databases into normalized, structured data suitable for analysis or to drive machine learning (ML) algorithms.",0
What is text mining ?,"Natural language processing  is the relationship between computers and human language. More specifically, natural language processing is the computer understanding, analysis, manipulation, and/or generation of natural language.","Text mining is the process of exploring and analyzing large amounts of unstructured text data aided by software that can identify concepts, patterns, topics, keywords and other attributes in the data.",0
What do you understand by Natural Language Processing?,"Natural language processing is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.",Natural language processing is the ability of a computer program to understand human language as it is spoken. NLP is a component of artificial intelligence. It allows machines to break down and interpret human language.,1
What do you understand by Natural Language Processing?,"Natural language processing is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.","regular expression is a sequence of characters that define a search pattern. Usually such patterns are used by string-searching algorithms for ""find"" or ""find and replace"" operations on strings, or for input validation. It is a technique developed in theoretical computer science and formal language theory.",0
What are Regular Expressions?,Natural language processing is the ability of a computer program to understand human language as it is spoken. NLP is a component of artificial intelligence. It allows machines to break down and interpret human language.,They are patterns used to match character combinations in strings.,0
What do you understand by Natural Language Processing?,"Natural language processing is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.",Natural Language Processing or NLP is an automated way to understand or analyze the natural languages and extract required information from such data by applying machine learning Algorithms,1
What do you understand by Natural Language Processing?,"Natural language processing is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.","it may be defined as the process of assigning one of the parts of speech to the given word. It is generally called POS tagging. In simple words, we can say that POS tagging is a task of labelling each word in a sentence with its appropriate part of speech. We know that parts of speech include nouns, verb, adverbs, adjectives, pronouns, conjunction and their sub-categories.",0
What is Parts-of-speech Tagging?,Natural Language Processing or NLP is an automated way to understand or analyze the natural languages and extract required information from such data by applying machine learning Algorithms,"A Part-Of-Speech Tagger (POS Tagger) is a piece of software that reads text in some language and assigns parts of speech to each word (and other token), such as noun, verb, adjective, etc.",0
What do you understand by Natural Language Processing?,Natural Language Processing is a field of computer science that deals with communication between computer systems and humans. It is a technique used in Artificial Intelligence and Machine Learning. It is used to create automated software that helps understand human spoken languages to extract useful information from the data it gets in the form of audio.,"Natural language processing  is the relationship between computers and human language. More specifically, natural language processing is the computer understanding, analysis, manipulation, and/or generation of natural language.",1
What do you understand by Natural Language Processing?,Natural Language Processing is a field of computer science that deals with communication between computer systems and humans. It is a technique used in Artificial Intelligence and Machine Learning. It is used to create automated software that helps understand human spoken languages to extract useful information from the data it gets in the form of audio.,Regular expressions are specially encoded text strings used as patterns for matching sets of strings.,0
What are Regular Expressions?,"Natural language processing  is the relationship between computers and human language. More specifically, natural language processing is the computer understanding, analysis, manipulation, and/or generation of natural language.",They are patterns used to match character combinations in strings.,0
What do you understand by Natural Language Processing?,Natural Language Processing is a field of computer science that deals with communication between computer systems and humans. It is a technique used in Artificial Intelligence and Machine Learning. It is used to create automated software that helps understand human spoken languages to extract useful information from the data it gets in the form of audio.,Natural language processing is the ability of a computer program to understand human language as it is spoken. NLP is a component of artificial intelligence. It allows machines to break down and interpret human language.,1
What do you understand by Natural Language Processing?,Natural Language Processing is a field of computer science that deals with communication between computer systems and humans. It is a technique used in Artificial Intelligence and Machine Learning. It is used to create automated software that helps understand human spoken languages to extract useful information from the data it gets in the form of audio.,"Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.",0
What is Pragmatic Ambiguity?,Natural language processing is the ability of a computer program to understand human language as it is spoken. NLP is a component of artificial intelligence. It allows machines to break down and interpret human language.,It can be defined as the words which have multiple interpretations. Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity.,0
What do you understand by Natural Language Processing?,Natural Language Processing is a field of computer science that deals with communication between computer systems and humans. It is a technique used in Artificial Intelligence and Machine Learning. It is used to create automated software that helps understand human spoken languages to extract useful information from the data it gets in the form of audio.,Natural Language Processing or NLP is an automated way to understand or analyze the natural languages and extract required information from such data by applying machine learning Algorithms,1
What do you understand by Natural Language Processing?,Natural Language Processing is a field of computer science that deals with communication between computer systems and humans. It is a technique used in Artificial Intelligence and Machine Learning. It is used to create automated software that helps understand human spoken languages to extract useful information from the data it gets in the form of audio.,"BatchNorm — Compute the mean and var at each layer for every minibatch
LayerNorm — Compute the mean and var for every single sample for each layer independently",0
Difference between BatchNorm and LayerNorm?,Natural Language Processing or NLP is an automated way to understand or analyze the natural languages and extract required information from such data by applying machine learning Algorithms,Batch normalization is applied on the neuron activation for all the samples in the mini-batch such that the mean of output lies close to 0 and the standard deviation lies close to 1. It also introduces two learning parameters gama and beta in its calculation which are all optimized during training. Layer Normalization is not dependent on batches and the normalization is applied on the neuron for a single instance across all features,0
What do you understand by Natural Language Processing?,"Natural language processing  is the relationship between computers and human language. More specifically, natural language processing is the computer understanding, analysis, manipulation, and/or generation of natural language.",Natural language processing is the ability of a computer program to understand human language as it is spoken. NLP is a component of artificial intelligence. It allows machines to break down and interpret human language.,1
What do you understand by Natural Language Processing?,"Natural language processing  is the relationship between computers and human language. More specifically, natural language processing is the computer understanding, analysis, manipulation, and/or generation of natural language.","N-gram in NLP is simply a sequence of n words, and we also conclude the sentences which appeared more frequently. for example, let us consider: New York consider as 2 gram and The Golden Compass is 3 gram",0
What is ngram in NLP?,Natural language processing is the ability of a computer program to understand human language as it is spoken. NLP is a component of artificial intelligence. It allows machines to break down and interpret human language.,They are basically a set of co-occurring words within a given window and when computing the n-grams you typically move one word forward,0
What do you understand by Natural Language Processing?,"Natural language processing  is the relationship between computers and human language. More specifically, natural language processing is the computer understanding, analysis, manipulation, and/or generation of natural language.",Natural Language Processing or NLP is an automated way to understand or analyze the natural languages and extract required information from such data by applying machine learning Algorithms,1
What do you understand by Natural Language Processing?,"Natural language processing  is the relationship between computers and human language. More specifically, natural language processing is the computer understanding, analysis, manipulation, and/or generation of natural language.","TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.",0
What is TF-IDF?,Natural Language Processing or NLP is an automated way to understand or analyze the natural languages and extract required information from such data by applying machine learning Algorithms,TF-IDF helps to establish how important a particular word is in the context of the document corpus. TF-IDF takes into account the number of times the word appears in the document and offset by the number of documents that appear in the corpus.,0
What do you understand by Natural Language Processing?,Natural language processing is the ability of a computer program to understand human language as it is spoken. NLP is a component of artificial intelligence. It allows machines to break down and interpret human language.,Natural Language Processing or NLP is an automated way to understand or analyze the natural languages and extract required information from such data by applying machine learning Algorithms,1
What do you understand by Natural Language Processing?,Natural language processing is the ability of a computer program to understand human language as it is spoken. NLP is a component of artificial intelligence. It allows machines to break down and interpret human language.,"regular expression is a sequence of characters that define a search pattern. Usually such patterns are used by string-searching algorithms for ""find"" or ""find and replace"" operations on strings, or for input validation. It is a technique developed in theoretical computer science and formal language theory.",0
What are Regular Expressions?,Natural Language Processing or NLP is an automated way to understand or analyze the natural languages and extract required information from such data by applying machine learning Algorithms,Regular expressions are specially encoded text strings used as patterns for matching sets of strings.,0
What are stop words?,"Stop words are said to be useless data for a search engine. There are stop words such as was, were, is, am, the, a, an, how, why, and many more. In Natural Language Processing, we eliminate the stop words to understand and analyze the meaning of a sentence.","stop words are words which are filtered out before or after processing of natural language data. The reason why stop words are critical to many applications is that, if we remove the words that are very commonly used in a given language, we can focus on the important words instead.",1
What are stop words?,"Stop words are said to be useless data for a search engine. There are stop words such as was, were, is, am, the, a, an, how, why, and many more. In Natural Language Processing, we eliminate the stop words to understand and analyze the meaning of a sentence.","Natural language processing is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.",0
What do you understand by Natural Language Processing?,"stop words are words which are filtered out before or after processing of natural language data. The reason why stop words are critical to many applications is that, if we remove the words that are very commonly used in a given language, we can focus on the important words instead.",Natural Language Processing is a field of computer science that deals with communication between computer systems and humans. It is a technique used in Artificial Intelligence and Machine Learning. It is used to create automated software that helps understand human spoken languages to extract useful information from the data it gets in the form of audio.,0
What are stop words?,"Stop words are said to be useless data for a search engine. There are stop words such as was, were, is, am, the, a, an, how, why, and many more. In Natural Language Processing, we eliminate the stop words to understand and analyze the meaning of a sentence.","A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.",1
What are stop words?,"Stop words are said to be useless data for a search engine. There are stop words such as was, were, is, am, the, a, an, how, why, and many more. In Natural Language Processing, we eliminate the stop words to understand and analyze the meaning of a sentence.",Latent Semantic Indexing (LSI) tries to overcome the problems of lexical matching by using statistically derived conceptual indices instead of individual words for retrieval. A better approach would allow users to retrieve information on the basis of a conceptual topic or meaning of a document,0
What is Latent Semantic Indexing (LSI)?,"A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.",It also called Latent semantic analysis is a mathematical method that was developed so that the accuracy of retrieving information can be improved. It helps in finding out the hidden(latent) relationship between the words(semantics) by producing a set of various concepts related to the terms of a sentence to improve the information understanding. The technique used for the purpose is called Singular value decomposition. It is generally useful for working on small sets of static documents.,0
What are stop words?,"Stop words are said to be useless data for a search engine. There are stop words such as was, were, is, am, the, a, an, how, why, and many more. In Natural Language Processing, we eliminate the stop words to understand and analyze the meaning of a sentence.","Common words that occur in sentences that add weight to the sentence are known as stop words. These stop words act as a bridge and ensure that sentences are grammatically correct. In simple terms, words that are filtered out before processing natural language data is known as a stop word and it is a common pre-processing method.",1
What are stop words?,"Stop words are said to be useless data for a search engine. There are stop words such as was, were, is, am, the, a, an, how, why, and many more. In Natural Language Processing, we eliminate the stop words to understand and analyze the meaning of a sentence.","Text mining, also referred to as text data mining, roughly equivalent to text analytics, is the process of deriving high-quality information from text. High-quality information is typically derived through the devising of patterns and trends through means such as statistical pattern learning.",0
What is text mining ?,"Common words that occur in sentences that add weight to the sentence are known as stop words. These stop words act as a bridge and ensure that sentences are grammatically correct. In simple terms, words that are filtered out before processing natural language data is known as a stop word and it is a common pre-processing method.","Text mining is the process of exploring and analyzing large amounts of unstructured text data aided by software that can identify concepts, patterns, topics, keywords and other attributes in the data.",0
What are stop words?,"stop words are words which are filtered out before or after processing of natural language data. The reason why stop words are critical to many applications is that, if we remove the words that are very commonly used in a given language, we can focus on the important words instead.","A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.",1
What are stop words?,"stop words are words which are filtered out before or after processing of natural language data. The reason why stop words are critical to many applications is that, if we remove the words that are very commonly used in a given language, we can focus on the important words instead.","The problem of Relu. First, Exploding gradient and this Solved by gradient clipping. Second, Dying ReLu — No learning if the activation is 0 (Solved by parametric relu). Third, Mean and variance of activations is not 0 and 1.(Partially solved by subtracting around 0.5 from activation. Better explained in fastai videos).",0
What is the problem with ReLu?,"A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.","ReLU units can be fragile during training and can ""die"". For example, a large gradient flowing through a ReLU neuron could cause the weights to update in such a way that the neuron will never activate on any datapoint again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. That is, the ReLU units can irreversibly die during training since they can get knocked off the data manifold.",0
What are stop words?,"stop words are words which are filtered out before or after processing of natural language data. The reason why stop words are critical to many applications is that, if we remove the words that are very commonly used in a given language, we can focus on the important words instead.","Common words that occur in sentences that add weight to the sentence are known as stop words. These stop words act as a bridge and ensure that sentences are grammatically correct. In simple terms, words that are filtered out before processing natural language data is known as a stop word and it is a common pre-processing method.",1
What are stop words?,"stop words are words which are filtered out before or after processing of natural language data. The reason why stop words are critical to many applications is that, if we remove the words that are very commonly used in a given language, we can focus on the important words instead.","BatchNorm — Compute the mean and var at each layer for every minibatch
LayerNorm — Compute the mean and var for every single sample for each layer independently",0
Difference between BatchNorm and LayerNorm?,"Common words that occur in sentences that add weight to the sentence are known as stop words. These stop words act as a bridge and ensure that sentences are grammatically correct. In simple terms, words that are filtered out before processing natural language data is known as a stop word and it is a common pre-processing method.","All the normalization is calculated using this equation x^=x minus mean of x¯ over std of x¯ . The difference is how to calculate the x¯ .
In layer normalization x¯ = all of the summed inputs to the neurons in a layer on a single training case And in batch normalization x¯ = all of the summed inputs of single neuron on single batch",0
What are stop words?,"A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.","Common words that occur in sentences that add weight to the sentence are known as stop words. These stop words act as a bridge and ensure that sentences are grammatically correct. In simple terms, words that are filtered out before processing natural language data is known as a stop word and it is a common pre-processing method.",1
What are stop words?,"A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.",Transformer models are essentially attention based models. They see the entire sentence as a whole unlike LSTMs (or in general RNNs) where the sentence is processed sequentially - one word per time step. During training LSTMs need to propagate the error back in time through words one word at a time. Transformer sees all words simultaneously - so there is no backpropagation through time.,0
Why transformer perform better than LSTM?,"Common words that occur in sentences that add weight to the sentence are known as stop words. These stop words act as a bridge and ensure that sentences are grammatically correct. In simple terms, words that are filtered out before processing natural language data is known as a stop word and it is a common pre-processing method.","Transformers are better than all the other architectures because they totally avoid recursion, by processing sentences as a whole and by learning relationships between words thank's to multi-head attention mechanisms and positional embeddings.",0
What is TF-IDF?,"TF-IDF or Term Frequency-Inverse Document Frequency indicates the importance of a word in a set. It helps in information retrieval with numerical statistics. For a specific document, TF-IDF shows a frequency that helps identify the keywords in a document.","TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.",1
What is TF-IDF?,"TF-IDF or Term Frequency-Inverse Document Frequency indicates the importance of a word in a set. It helps in information retrieval with numerical statistics. For a specific document, TF-IDF shows a frequency that helps identify the keywords in a document.","Text mining, also referred to as text data mining, roughly equivalent to text analytics, is the process of deriving high-quality information from text. High-quality information is typically derived through the devising of patterns and trends through means such as statistical pattern learning.",0
What is text mining ?,"TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.","Text mining is the process of exploring and analyzing large amounts of unstructured text data aided by software that can identify concepts, patterns, topics, keywords and other attributes in the data.",0
What is TF-IDF?,"TF-IDF or Term Frequency-Inverse Document Frequency indicates the importance of a word in a set. It helps in information retrieval with numerical statistics. For a specific document, TF-IDF shows a frequency that helps identify the keywords in a document.","TF-IDF, which stands for term frequency — inverse document frequency, is a scoring measure widely used in information retrieval (IR) or summarization. TF-IDF is intended to reflect how relevant a term is in a given document.",1
What is TF-IDF?,"TF-IDF or Term Frequency-Inverse Document Frequency indicates the importance of a word in a set. It helps in information retrieval with numerical statistics. For a specific document, TF-IDF shows a frequency that helps identify the keywords in a document.","Syntactic analysis is a technique of analyzing sentences to extract meaning from it. Using syntactic analysis, a machine can analyze and understand the order of words arranged in a sentence. NLP employs grammar rules of a language that helps in the syntactic analysis of the combination and order of words in documents.",0
What is Syntactic Analysis?,"TF-IDF, which stands for term frequency — inverse document frequency, is a scoring measure widely used in information retrieval (IR) or summarization. TF-IDF is intended to reflect how relevant a term is in a given document.",Syntactic analysis is defined as analysis that tells us the logical meaning of certain given sentences or parts of those sentences. We also need to consider rules of grammar in order to define the logical meaning as well as correctness of the sentences.,0
What is TF-IDF?,"TF-IDF or Term Frequency-Inverse Document Frequency indicates the importance of a word in a set. It helps in information retrieval with numerical statistics. For a specific document, TF-IDF shows a frequency that helps identify the keywords in a document.","Tf-idf weight is composed by two terms: the first computes the normalized Term Frequency. the number of times a word appears in a document, divided by the total number of words in that document; the second term is the Inverse Document Frequency, computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears",1
What is TF-IDF?,"TF-IDF or Term Frequency-Inverse Document Frequency indicates the importance of a word in a set. It helps in information retrieval with numerical statistics. For a specific document, TF-IDF shows a frequency that helps identify the keywords in a document.","The problem of Relu. First, Exploding gradient and this Solved by gradient clipping. Second, Dying ReLu — No learning if the activation is 0 (Solved by parametric relu). Third, Mean and variance of activations is not 0 and 1.(Partially solved by subtracting around 0.5 from activation. Better explained in fastai videos).",0
What is the problem with ReLu?,"Tf-idf weight is composed by two terms: the first computes the normalized Term Frequency. the number of times a word appears in a document, divided by the total number of words in that document; the second term is the Inverse Document Frequency, computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears","ReLU neurons output zero and have zero derivatives for all negative inputs. So, if the weights in your network always lead to negative inputs into a ReLU neuron, that neuron is effectively not contributing to the network's training. Mathematically, the gradient contribution to the weight updates coming from that neuron is always zero",0
What is TF-IDF?,"TF-IDF or Term Frequency-Inverse Document Frequency indicates the importance of a word in a set. It helps in information retrieval with numerical statistics. For a specific document, TF-IDF shows a frequency that helps identify the keywords in a document.",TF-IDF helps to establish how important a particular word is in the context of the document corpus. TF-IDF takes into account the number of times the word appears in the document and offset by the number of documents that appear in the corpus.,1
What is TF-IDF?,"TF-IDF or Term Frequency-Inverse Document Frequency indicates the importance of a word in a set. It helps in information retrieval with numerical statistics. For a specific document, TF-IDF shows a frequency that helps identify the keywords in a document.","Text mining is the process of transforming unstructured text into a structured format to identify meaningful patterns and new insights. By applying advanced analytical techniques, such as Naïve Bayes, Support Vector Machines (SVM), and other deep learning algorithms, companies are able to explore and discover hidden relationships within their unstructured data.",0
What is text mining ?,TF-IDF helps to establish how important a particular word is in the context of the document corpus. TF-IDF takes into account the number of times the word appears in the document and offset by the number of documents that appear in the corpus.,"Text mining is the process of exploring and analyzing large amounts of unstructured text data aided by software that can identify concepts, patterns, topics, keywords and other attributes in the data.",0
What is TF-IDF?,"TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.","TF-IDF, which stands for term frequency — inverse document frequency, is a scoring measure widely used in information retrieval (IR) or summarization. TF-IDF is intended to reflect how relevant a term is in a given document.",1
What is TF-IDF?,"TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.",Syntactic analysis is defined as analysis that tells us the logical meaning of certain given sentences or parts of those sentences. We also need to consider rules of grammar in order to define the logical meaning as well as correctness of the sentences.,0
What is Syntactic Analysis?,"TF-IDF, which stands for term frequency — inverse document frequency, is a scoring measure widely used in information retrieval (IR) or summarization. TF-IDF is intended to reflect how relevant a term is in a given document.","Syntactic Analysis is the process of analyzing natural language with the rules of a formal grammar. Grammatical rules are applied to categories and groups of words, not individual words. Syntactic analysis basically assigns a semantic structure to text.",0
What is TF-IDF?,"TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.","Tf-idf weight is composed by two terms: the first computes the normalized Term Frequency. the number of times a word appears in a document, divided by the total number of words in that document; the second term is the Inverse Document Frequency, computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears",1
What is TF-IDF?,"TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.",Natural language processing is the ability of a computer program to understand human language as it is spoken. NLP is a component of artificial intelligence. It allows machines to break down and interpret human language.,0
What do you understand by Natural Language Processing?,"Tf-idf weight is composed by two terms: the first computes the normalized Term Frequency. the number of times a word appears in a document, divided by the total number of words in that document; the second term is the Inverse Document Frequency, computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears",Natural Language Processing or NLP is an automated way to understand or analyze the natural languages and extract required information from such data by applying machine learning Algorithms,0
What is TF-IDF?,"TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.",TF-IDF helps to establish how important a particular word is in the context of the document corpus. TF-IDF takes into account the number of times the word appears in the document and offset by the number of documents that appear in the corpus.,1
What is TF-IDF?,"TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.","Text mining, also referred to as text data mining, roughly equivalent to text analytics, is the process of deriving high-quality information from text. High-quality information is typically derived through the devising of patterns and trends through means such as statistical pattern learning.",0
What is TF-IDF?,"TF-IDF, which stands for term frequency — inverse document frequency, is a scoring measure widely used in information retrieval (IR) or summarization. TF-IDF is intended to reflect how relevant a term is in a given document.","Tf-idf weight is composed by two terms: the first computes the normalized Term Frequency. the number of times a word appears in a document, divided by the total number of words in that document; the second term is the Inverse Document Frequency, computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears",1
What is TF-IDF?,"TF-IDF, which stands for term frequency — inverse document frequency, is a scoring measure widely used in information retrieval (IR) or summarization. TF-IDF is intended to reflect how relevant a term is in a given document.",Batch normalization is applied on the neuron activation for all the samples in the mini-batch such that the mean of output lies close to 0 and the standard deviation lies close to 1. It also introduces two learning parameters gama and beta in its calculation which are all optimized during training. Layer Normalization is not dependent on batches and the normalization is applied on the neuron for a single instance across all features,0
Difference between BatchNorm and LayerNorm?,"Tf-idf weight is composed by two terms: the first computes the normalized Term Frequency. the number of times a word appears in a document, divided by the total number of words in that document; the second term is the Inverse Document Frequency, computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears","All the normalization is calculated using this equation x^=x minus mean of x¯ over std of x¯ . The difference is how to calculate the x¯ .
In layer normalization x¯ = all of the summed inputs to the neurons in a layer on a single training case And in batch normalization x¯ = all of the summed inputs of single neuron on single batch",0
What is TF-IDF?,"TF-IDF, which stands for term frequency — inverse document frequency, is a scoring measure widely used in information retrieval (IR) or summarization. TF-IDF is intended to reflect how relevant a term is in a given document.",TF-IDF helps to establish how important a particular word is in the context of the document corpus. TF-IDF takes into account the number of times the word appears in the document and offset by the number of documents that appear in the corpus.,1
What is TF-IDF?,"TF-IDF, which stands for term frequency — inverse document frequency, is a scoring measure widely used in information retrieval (IR) or summarization. TF-IDF is intended to reflect how relevant a term is in a given document.","With named entity recognition, you can extract key information to understand what a text is about, or merely use it to collect important information to store in a database. Keys as names, organization, locations.",0
Explain Named Entity Recognition,TF-IDF helps to establish how important a particular word is in the context of the document corpus. TF-IDF takes into account the number of times the word appears in the document and offset by the number of documents that appear in the corpus.,"Named-entity recognition is the method of extracting information. It arranges and classifies named entity in the unstructured text in different categories like locations, time expressions, organizations, percentages, and monetary values. NER allows the users to properly understand the subject of the text.",0
What is TF-IDF?,"Tf-idf weight is composed by two terms: the first computes the normalized Term Frequency. the number of times a word appears in a document, divided by the total number of words in that document; the second term is the Inverse Document Frequency, computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears",TF-IDF helps to establish how important a particular word is in the context of the document corpus. TF-IDF takes into account the number of times the word appears in the document and offset by the number of documents that appear in the corpus.,1
What is TF-IDF?,"Tf-idf weight is composed by two terms: the first computes the normalized Term Frequency. the number of times a word appears in a document, divided by the total number of words in that document; the second term is the Inverse Document Frequency, computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears","Stop words are said to be useless data for a search engine. There are stop words such as was, were, is, am, the, a, an, how, why, and many more. In Natural Language Processing, we eliminate the stop words to understand and analyze the meaning of a sentence.",0
What are stop words?,TF-IDF helps to establish how important a particular word is in the context of the document corpus. TF-IDF takes into account the number of times the word appears in the document and offset by the number of documents that appear in the corpus.,"stop words are words which are filtered out before or after processing of natural language data. The reason why stop words are critical to many applications is that, if we remove the words that are very commonly used in a given language, we can focus on the important words instead.",0
What is Syntactic Analysis?,"Syntactic analysis is a technique of analyzing sentences to extract meaning from it. Using syntactic analysis, a machine can analyze and understand the order of words arranged in a sentence. NLP employs grammar rules of a language that helps in the syntactic analysis of the combination and order of words in documents.",Syntactic analysis is defined as analysis that tells us the logical meaning of certain given sentences or parts of those sentences. We also need to consider rules of grammar in order to define the logical meaning as well as correctness of the sentences.,1
What is Syntactic Analysis?,"Syntactic analysis is a technique of analyzing sentences to extract meaning from it. Using syntactic analysis, a machine can analyze and understand the order of words arranged in a sentence. NLP employs grammar rules of a language that helps in the syntactic analysis of the combination and order of words in documents.","Natural language processing  is the relationship between computers and human language. More specifically, natural language processing is the computer understanding, analysis, manipulation, and/or generation of natural language.",0
What do you understand by Natural Language Processing?,Syntactic analysis is defined as analysis that tells us the logical meaning of certain given sentences or parts of those sentences. We also need to consider rules of grammar in order to define the logical meaning as well as correctness of the sentences.,Natural Language Processing or NLP is an automated way to understand or analyze the natural languages and extract required information from such data by applying machine learning Algorithms,0
What is Syntactic Analysis?,"Syntactic analysis is a technique of analyzing sentences to extract meaning from it. Using syntactic analysis, a machine can analyze and understand the order of words arranged in a sentence. NLP employs grammar rules of a language that helps in the syntactic analysis of the combination and order of words in documents.","Syntactic Analysis is the process of analyzing natural language with the rules of a formal grammar. Grammatical rules are applied to categories and groups of words, not individual words. Syntactic analysis basically assigns a semantic structure to text.",1
What is Syntactic Analysis?,"Syntactic analysis is a technique of analyzing sentences to extract meaning from it. Using syntactic analysis, a machine can analyze and understand the order of words arranged in a sentence. NLP employs grammar rules of a language that helps in the syntactic analysis of the combination and order of words in documents.","NLP is a big field and covers things from very ML-like (classifiers with bag of words features) to not at all ML-like (machine translation). You need to spend some time on a survey of NLP problems, then zero in on the ones you care about, which may or may not involve the methods you're familiar with.",0
Why is NLP so hard?,"Syntactic Analysis is the process of analyzing natural language with the rules of a formal grammar. Grammatical rules are applied to categories and groups of words, not individual words. Syntactic analysis basically assigns a semantic structure to text.","Difficulties in Natural Language Processing are Some sentences in english can be parsed in different ways that human may understand while the computer systems not, and Some inputs can mean different meanings, while sometimes many inputs can mean the same thing. Word pronunciations are sometimes very hard for the computers to get it clearly.",0
What is Syntactic Analysis?,Syntactic analysis is defined as analysis that tells us the logical meaning of certain given sentences or parts of those sentences. We also need to consider rules of grammar in order to define the logical meaning as well as correctness of the sentences.,"Syntactic Analysis is the process of analyzing natural language with the rules of a formal grammar. Grammatical rules are applied to categories and groups of words, not individual words. Syntactic analysis basically assigns a semantic structure to text.",1
What is Syntactic Analysis?,Syntactic analysis is defined as analysis that tells us the logical meaning of certain given sentences or parts of those sentences. We also need to consider rules of grammar in order to define the logical meaning as well as correctness of the sentences.,"NLTK is a Python library, which stands for Natural Language Toolkit. We use NLTK to process data in human spoken languages. NLTK allows us to apply techniques such as parsing, tokenization, lemmatization, stemming, and more to understand natural languages.",0
What is NLTK?,"Syntactic Analysis is the process of analyzing natural language with the rules of a formal grammar. Grammatical rules are applied to categories and groups of words, not individual words. Syntactic analysis basically assigns a semantic structure to text.","NLTK is a leading platform for building Python programs to work with human language data. It provides a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.",0
What is Semantic Analysis?,Semantic analysis helps make a machine understand the meaning of a text. It uses various algorithms for the interpretation of words in sentences. It also helps understand the structure of a sentence.,"semantic analysis is the process of drawing meaning from text. It allows computers to understand and interpret sentences, paragraphs, or whole documents, by analyzing their grammatical structure, and identifying relationships between individual words in a particular context.",1
What is Semantic Analysis?,Semantic analysis helps make a machine understand the meaning of a text. It uses various algorithms for the interpretation of words in sentences. It also helps understand the structure of a sentence.,"Parsing allows the machine to understand the meaning of a word in a sentence and the grouping of words, phrases, nouns, subjects, and objects in a sentence.",0
What is Parsing in the context of NLP?,"semantic analysis is the process of drawing meaning from text. It allows computers to understand and interpret sentences, paragraphs, or whole documents, by analyzing their grammatical structure, and identifying relationships between individual words in a particular context.",It helps analyze the text or the document to extract useful insights from it.,0
What is Semantic Analysis?,Semantic analysis helps make a machine understand the meaning of a text. It uses various algorithms for the interpretation of words in sentences. It also helps understand the structure of a sentence.,Semantic analysis describes the process of understanding natural language. the way that humans communicate based on meaning and context. It starts by reading all of the words in content to capture the real meaning of any text. It identifies the text elements and assigns them to their logical and grammatical role.,1
What is Semantic Analysis?,Semantic analysis helps make a machine understand the meaning of a text. It uses various algorithms for the interpretation of words in sentences. It also helps understand the structure of a sentence.,"Pragmatic analysis deals with outside word knowledge, which means knowledge that is external to the documents and/or queries. Pragmatics analysis that focuses on what was described is reinterpreted by what it actually meant, deriving the various aspects of language that require real world knowledge.",0
What is Pragmatic Analysis?,Semantic analysis describes the process of understanding natural language. the way that humans communicate based on meaning and context. It starts by reading all of the words in content to capture the real meaning of any text. It identifies the text elements and assigns them to their logical and grammatical role.,"Pragmatic levels of NLP deal with the real-world meanings of communication. Not only can it breakdowns the meanings of individual words and sentences, but it can also decide what the purpose of those words and sentences are. Context is massively influential in this step, and it is something that computers only ever understand through deep learning.",0
What is Semantic Analysis?,"semantic analysis is the process of drawing meaning from text. It allows computers to understand and interpret sentences, paragraphs, or whole documents, by analyzing their grammatical structure, and identifying relationships between individual words in a particular context.",Semantic analysis describes the process of understanding natural language. the way that humans communicate based on meaning and context. It starts by reading all of the words in content to capture the real meaning of any text. It identifies the text elements and assigns them to their logical and grammatical role.,1
What is Semantic Analysis?,"semantic analysis is the process of drawing meaning from text. It allows computers to understand and interpret sentences, paragraphs, or whole documents, by analyzing their grammatical structure, and identifying relationships between individual words in a particular context.","stemming is the method to extract the root word by removing suffixes and prefixes from a word.
For example, we can reduce ‘stemming’ to ‘stem’ by removing ‘m’ and ‘ing.’",0
Explain Stemming with the help of an example.,Semantic analysis describes the process of understanding natural language. the way that humans communicate based on meaning and context. It starts by reading all of the words in content to capture the real meaning of any text. It identifies the text elements and assigns them to their logical and grammatical role.,"Stemming is the process of producing morphological variants of a root/base word. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”",0
What is NLTK?,"NLTK is a Python library, which stands for Natural Language Toolkit. We use NLTK to process data in human spoken languages. NLTK allows us to apply techniques such as parsing, tokenization, lemmatization, stemming, and more to understand natural languages.","NLTK is a leading platform for building Python programs to work with human language data. It provides a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.",1
What is NLTK?,"NLTK is a Python library, which stands for Natural Language Toolkit. We use NLTK to process data in human spoken languages. NLTK allows us to apply techniques such as parsing, tokenization, lemmatization, stemming, and more to understand natural languages.","While training with Adam helps in getting fast convergence, the resulting model will often have worse generalization performance than when training with SGD with momentum. Another issue is that even though Adam has adaptive learning rates its performance improves when using a good learning rate schedule. Especially early in the training, it is beneficial to use a lower learning rate to avoid divergence.",0
What are the limitation of Adam optimiser?,"NLTK is a leading platform for building Python programs to work with human language data. It provides a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.","We observe that the solutions found by adaptive methods like Adam generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.",0
Explain how we can do parsing,"Parsing is the method to identify and understand the syntactic structure of a text. It is done by analyzing the individual elements of the text. The machine parses the text one word at a time, then two at a time, further three, and so on.",parsing means analysis of an input to organize the data according to the rule of a grammar,1
Explain how we can do parsing,"Parsing is the method to identify and understand the syntactic structure of a text. It is done by analyzing the individual elements of the text. The machine parses the text one word at a time, then two at a time, further three, and so on.","Natural language processing  is the relationship between computers and human language. More specifically, natural language processing is the computer understanding, analysis, manipulation, and/or generation of natural language.",0
What do you understand by Natural Language Processing?,parsing means analysis of an input to organize the data according to the rule of a grammar,Natural language processing is the ability of a computer program to understand human language as it is spoken. NLP is a component of artificial intelligence. It allows machines to break down and interpret human language.,0
Explain how we can do parsing,"Parsing is the method to identify and understand the syntactic structure of a text. It is done by analyzing the individual elements of the text. The machine parses the text one word at a time, then two at a time, further three, and so on.",parsing in NLP is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),1
Explain how we can do parsing,"Parsing is the method to identify and understand the syntactic structure of a text. It is done by analyzing the individual elements of the text. The machine parses the text one word at a time, then two at a time, further three, and so on.",Topic modeling is a type of statistical modeling for discovering the abstract “topics” that occur in a collection of documents. Latent Dirichlet Allocation (LDA) is an example of topic model and is used to classify text in a document to a particular topic,0
What is Topic Modeling ? When we will do it ?,parsing in NLP is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),"Topic modeling is part of a class of text analysis methods that analyze “bags” or groups of words together—instead of counting them individually–in order to capture how the meaning of words is dependent upon the broader context in which they are used in natural language. Topic modeling is not the only method that does this– cluster analysis, latent semantic analysis, and other techniques have also been used to identify clustering within texts",0
Explain how we can do parsing,parsing means analysis of an input to organize the data according to the rule of a grammar,parsing in NLP is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),1
Explain how we can do parsing,parsing means analysis of an input to organize the data according to the rule of a grammar,"Text mining (also referred to as text analytics) is an artificial intelligence (AI) technology that uses natural language processing (NLP) to transform the free (unstructured) text in documents and databases into normalized, structured data suitable for analysis or to drive machine learning (ML) algorithms.",0
What is text mining ?,parsing in NLP is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),"Text mining is the process of exploring and analyzing large amounts of unstructured text data aided by software that can identify concepts, patterns, topics, keywords and other attributes in the data.",0
Explain Stemming with the help of an example.,"stemming is the method to extract the root word by removing suffixes and prefixes from a word.
For example, we can reduce ‘stemming’ to ‘stem’ by removing ‘m’ and ‘ing.’","Stemming is the process of producing morphological variants of a root/base word. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”",1
Explain Stemming with the help of an example.,"stemming is the method to extract the root word by removing suffixes and prefixes from a word.
For example, we can reduce ‘stemming’ to ‘stem’ by removing ‘m’ and ‘ing.’","stop words are words which are filtered out before or after processing of natural language data. The reason why stop words are critical to many applications is that, if we remove the words that are very commonly used in a given language, we can focus on the important words instead.",0
What are stop words?,"Stemming is the process of producing morphological variants of a root/base word. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”","A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.",0
Explain Stemming with the help of an example.,"stemming is the method to extract the root word by removing suffixes and prefixes from a word.
For example, we can reduce ‘stemming’ to ‘stem’ by removing ‘m’ and ‘ing.’","Stemming is one of the most common data pre-processing operations we do in almost all Natural Language Processing. It is the process of removing a part of a word, or reducing a word to its stem or root. For example, the stem of the words eating, eats, eaten is eat.",1
Explain Stemming with the help of an example.,"stemming is the method to extract the root word by removing suffixes and prefixes from a word.
For example, we can reduce ‘stemming’ to ‘stem’ by removing ‘m’ and ‘ing.’","it may be defined as the process of assigning one of the parts of speech to the given word. It is generally called POS tagging. In simple words, we can say that POS tagging is a task of labelling each word in a sentence with its appropriate part of speech. We know that parts of speech include nouns, verb, adverbs, adjectives, pronouns, conjunction and their sub-categories.",0
What is Parts-of-speech Tagging?,"Stemming is one of the most common data pre-processing operations we do in almost all Natural Language Processing. It is the process of removing a part of a word, or reducing a word to its stem or root. For example, the stem of the words eating, eats, eaten is eat.","A Part-Of-Speech Tagger (POS Tagger) is a piece of software that reads text in some language and assigns parts of speech to each word (and other token), such as noun, verb, adjective, etc.",0
Explain Stemming with the help of an example.,"stemming is the method to extract the root word by removing suffixes and prefixes from a word.
For example, we can reduce ‘stemming’ to ‘stem’ by removing ‘m’ and ‘ing.’","Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language. As converting the words Playing, played, plays to play.",1
Explain Stemming with the help of an example.,"stemming is the method to extract the root word by removing suffixes and prefixes from a word.
For example, we can reduce ‘stemming’ to ‘stem’ by removing ‘m’ and ‘ing.’","Lemmatization is the process of converting a word to its base form. The difference between stemming and lemmatization is, lemmatization considers the context and converts the word to its meaningful base form, whereas stemming just removes the last few characters, often leading to incorrect meanings and spelling errors. for example, ‘Caring’ -> Lemmatization -> ‘Care’.",0
Explain Lemmatization with the help of an example,"Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language. As converting the words Playing, played, plays to play.","I would explain lemmatization as returning different forms of a single word to its root form. It is not only applicable to nouns. Lemmatization works the same way for adjectives, action verbs, all the same. Such as: Constructing – (Lemmatization) -> Construct, Extracts – (Lemmatization) -> Extract",0
Explain Stemming with the help of an example.,"Stemming is the process of producing morphological variants of a root/base word. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”","Stemming is one of the most common data pre-processing operations we do in almost all Natural Language Processing. It is the process of removing a part of a word, or reducing a word to its stem or root. For example, the stem of the words eating, eats, eaten is eat.",1
Explain Stemming with the help of an example.,"Stemming is the process of producing morphological variants of a root/base word. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”","Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.",0
What is Pragmatic Ambiguity?,"Stemming is one of the most common data pre-processing operations we do in almost all Natural Language Processing. It is the process of removing a part of a word, or reducing a word to its stem or root. For example, the stem of the words eating, eats, eaten is eat.",Pragmatic ambiguity refers to a situation where the context of a phrase gives it multiple interpretation,0
Explain Stemming with the help of an example.,"Stemming is the process of producing morphological variants of a root/base word. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”","Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language. As converting the words Playing, played, plays to play.",1
Explain Stemming with the help of an example.,"Stemming is the process of producing morphological variants of a root/base word. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”","Named Entity Recognition (NER) is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text.",0
Explain Named Entity Recognition,"Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language. As converting the words Playing, played, plays to play.","Named Entity Recognition is a process where a sentence or a chunk of text is parsed through to find entities that can be put under categories like names, organizations, locations, quantities, monetary values, percentages, etc.",0
Explain Stemming with the help of an example.,"Stemming is one of the most common data pre-processing operations we do in almost all Natural Language Processing. It is the process of removing a part of a word, or reducing a word to its stem or root. For example, the stem of the words eating, eats, eaten is eat.","Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language. As converting the words Playing, played, plays to play.",1
Explain Stemming with the help of an example.,"Stemming is one of the most common data pre-processing operations we do in almost all Natural Language Processing. It is the process of removing a part of a word, or reducing a word to its stem or root. For example, the stem of the words eating, eats, eaten is eat.",It is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category,0
Explain Named Entity Recognition,"Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language. As converting the words Playing, played, plays to play.","Named-entity recognition is the method of extracting information. It arranges and classifies named entity in the unstructured text in different categories like locations, time expressions, organizations, percentages, and monetary values. NER allows the users to properly understand the subject of the text.",0
Explain Lemmatization with the help of an example,"We use stemming and lemmatization to extract root words. However, stemming may not give the actual word, whereas lemmatization generates a meaningful word. In lemmatization, rather than just removing the suffix and the prefix, the process tries to find out the root word with its proper meaning. for example, Bricks’ becomes ‘brick,’ ‘corpora’ becomes ‘corpus’.","Lemmatization is the process of converting a word to its base form. The difference between stemming and lemmatization is, lemmatization considers the context and converts the word to its meaningful base form, whereas stemming just removes the last few characters, often leading to incorrect meanings and spelling errors. for example, ‘Caring’ -> Lemmatization -> ‘Care’.",1
Explain Lemmatization with the help of an example,"We use stemming and lemmatization to extract root words. However, stemming may not give the actual word, whereas lemmatization generates a meaningful word. In lemmatization, rather than just removing the suffix and the prefix, the process tries to find out the root word with its proper meaning. for example, Bricks’ becomes ‘brick,’ ‘corpora’ becomes ‘corpus’.",Regular expressions are specially encoded text strings used as patterns for matching sets of strings.,0
What are Regular Expressions?,"Lemmatization is the process of converting a word to its base form. The difference between stemming and lemmatization is, lemmatization considers the context and converts the word to its meaningful base form, whereas stemming just removes the last few characters, often leading to incorrect meanings and spelling errors. for example, ‘Caring’ -> Lemmatization -> ‘Care’.",They are patterns used to match character combinations in strings.,0
Explain Lemmatization with the help of an example,"We use stemming and lemmatization to extract root words. However, stemming may not give the actual word, whereas lemmatization generates a meaningful word. In lemmatization, rather than just removing the suffix and the prefix, the process tries to find out the root word with its proper meaning. for example, Bricks’ becomes ‘brick,’ ‘corpora’ becomes ‘corpus’.","Lemmatization is closely related to stemming. In linguistics, it is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Putting an example to the definition, “computers” is an inflected form of “computer”, the same logic as “dogs” being an inflected form of “dog”",1
Explain Lemmatization with the help of an example,"We use stemming and lemmatization to extract root words. However, stemming may not give the actual word, whereas lemmatization generates a meaningful word. In lemmatization, rather than just removing the suffix and the prefix, the process tries to find out the root word with its proper meaning. for example, Bricks’ becomes ‘brick,’ ‘corpora’ becomes ‘corpus’.","Natural language processing is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.",0
What do you understand by Natural Language Processing?,"Lemmatization is closely related to stemming. In linguistics, it is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Putting an example to the definition, “computers” is an inflected form of “computer”, the same logic as “dogs” being an inflected form of “dog”","Natural language processing  is the relationship between computers and human language. More specifically, natural language processing is the computer understanding, analysis, manipulation, and/or generation of natural language.",0
Explain Lemmatization with the help of an example,"We use stemming and lemmatization to extract root words. However, stemming may not give the actual word, whereas lemmatization generates a meaningful word. In lemmatization, rather than just removing the suffix and the prefix, the process tries to find out the root word with its proper meaning. for example, Bricks’ becomes ‘brick,’ ‘corpora’ becomes ‘corpus’.","I would explain lemmatization as returning different forms of a single word to its root form. It is not only applicable to nouns. Lemmatization works the same way for adjectives, action verbs, all the same. Such as: Constructing – (Lemmatization) -> Construct, Extracts – (Lemmatization) -> Extract",1
Explain Lemmatization with the help of an example,"We use stemming and lemmatization to extract root words. However, stemming may not give the actual word, whereas lemmatization generates a meaningful word. In lemmatization, rather than just removing the suffix and the prefix, the process tries to find out the root word with its proper meaning. for example, Bricks’ becomes ‘brick,’ ‘corpora’ becomes ‘corpus’.","Text mining is the process of transforming unstructured text into a structured format to identify meaningful patterns and new insights. By applying advanced analytical techniques, such as Naïve Bayes, Support Vector Machines (SVM), and other deep learning algorithms, companies are able to explore and discover hidden relationships within their unstructured data.",0
What is text mining ?,"I would explain lemmatization as returning different forms of a single word to its root form. It is not only applicable to nouns. Lemmatization works the same way for adjectives, action verbs, all the same. Such as: Constructing – (Lemmatization) -> Construct, Extracts – (Lemmatization) -> Extract","Text mining is the process of exploring and analyzing large amounts of unstructured text data aided by software that can identify concepts, patterns, topics, keywords and other attributes in the data.",0
Explain Lemmatization with the help of an example,"We use stemming and lemmatization to extract root words. However, stemming may not give the actual word, whereas lemmatization generates a meaningful word. In lemmatization, rather than just removing the suffix and the prefix, the process tries to find out the root word with its proper meaning. for example, Bricks’ becomes ‘brick,’ ‘corpora’ becomes ‘corpus’.","It generally means to do the things properly with the use of vocabulary and morphological analysis of words. In this process, the endings of the words are removed to return the base word, which is also known as Lemma. Example: boy’s = boy, cars= car, colors= color.",1
Explain Lemmatization with the help of an example,"We use stemming and lemmatization to extract root words. However, stemming may not give the actual word, whereas lemmatization generates a meaningful word. In lemmatization, rather than just removing the suffix and the prefix, the process tries to find out the root word with its proper meaning. for example, Bricks’ becomes ‘brick,’ ‘corpora’ becomes ‘corpus’.","let's say the inputs to Relu are now distributed as a low-variance Gaussian centered at -0.1. we have that Most inputs to Relu are negative, thus Most inputs will cause the ReLU gate to be closed, thus Most inputs will cause gradients to fail to flow backwards through Relu thus Relu's inputs are usually not updated through SGD backprop.",0
What is the problem with ReLu?,"It generally means to do the things properly with the use of vocabulary and morphological analysis of words. In this process, the endings of the words are removed to return the base word, which is also known as Lemma. Example: boy’s = boy, cars= car, colors= color.","ReLU neurons output zero and have zero derivatives for all negative inputs. So, if the weights in your network always lead to negative inputs into a ReLU neuron, that neuron is effectively not contributing to the network's training. Mathematically, the gradient contribution to the weight updates coming from that neuron is always zero",0
Explain Lemmatization with the help of an example,"Lemmatization is the process of converting a word to its base form. The difference between stemming and lemmatization is, lemmatization considers the context and converts the word to its meaningful base form, whereas stemming just removes the last few characters, often leading to incorrect meanings and spelling errors. for example, ‘Caring’ -> Lemmatization -> ‘Care’.","Lemmatization is closely related to stemming. In linguistics, it is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Putting an example to the definition, “computers” is an inflected form of “computer”, the same logic as “dogs” being an inflected form of “dog”",1
Explain Lemmatization with the help of an example,"Lemmatization is the process of converting a word to its base form. The difference between stemming and lemmatization is, lemmatization considers the context and converts the word to its meaningful base form, whereas stemming just removes the last few characters, often leading to incorrect meanings and spelling errors. for example, ‘Caring’ -> Lemmatization -> ‘Care’.",Transformer models are essentially attention based models. They see the entire sentence as a whole unlike LSTMs (or in general RNNs) where the sentence is processed sequentially - one word per time step. During training LSTMs need to propagate the error back in time through words one word at a time. Transformer sees all words simultaneously - so there is no backpropagation through time.,0
Why transformer perform better than LSTM?,"Lemmatization is closely related to stemming. In linguistics, it is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Putting an example to the definition, “computers” is an inflected form of “computer”, the same logic as “dogs” being an inflected form of “dog”","For machine translation tasks, seq2seq models, consisting of encoder and decoder were used. This involved usage of Recurrent Neural Networks, both for constructing the encoder and the decoder. The architecture used to memorize the entire sentence from the source language and regurgitate it into the target language. This process works fine for shorter sentences, but as the length of the sentence increases the performance slumps. It is, therefore, difficult for a recurrent neural network to memorize a rather long sentence. The attention mechanism helps us overcome this difficulty",0
Explain Lemmatization with the help of an example,"Lemmatization is the process of converting a word to its base form. The difference between stemming and lemmatization is, lemmatization considers the context and converts the word to its meaningful base form, whereas stemming just removes the last few characters, often leading to incorrect meanings and spelling errors. for example, ‘Caring’ -> Lemmatization -> ‘Care’.","I would explain lemmatization as returning different forms of a single word to its root form. It is not only applicable to nouns. Lemmatization works the same way for adjectives, action verbs, all the same. Such as: Constructing – (Lemmatization) -> Construct, Extracts – (Lemmatization) -> Extract",1
Explain Lemmatization with the help of an example,"Lemmatization is the process of converting a word to its base form. The difference between stemming and lemmatization is, lemmatization considers the context and converts the word to its meaningful base form, whereas stemming just removes the last few characters, often leading to incorrect meanings and spelling errors. for example, ‘Caring’ -> Lemmatization -> ‘Care’.","Named Entity Recognition (NER) is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text.",0
Explain Named Entity Recognition,"I would explain lemmatization as returning different forms of a single word to its root form. It is not only applicable to nouns. Lemmatization works the same way for adjectives, action verbs, all the same. Such as: Constructing – (Lemmatization) -> Construct, Extracts – (Lemmatization) -> Extract","With named entity recognition, you can extract key information to understand what a text is about, or merely use it to collect important information to store in a database. Keys as names, organization, locations.",0
Explain Lemmatization with the help of an example,"Lemmatization is the process of converting a word to its base form. The difference between stemming and lemmatization is, lemmatization considers the context and converts the word to its meaningful base form, whereas stemming just removes the last few characters, often leading to incorrect meanings and spelling errors. for example, ‘Caring’ -> Lemmatization -> ‘Care’.","It generally means to do the things properly with the use of vocabulary and morphological analysis of words. In this process, the endings of the words are removed to return the base word, which is also known as Lemma. Example: boy’s = boy, cars= car, colors= color.",1
Explain Lemmatization with the help of an example,"Lemmatization is the process of converting a word to its base form. The difference between stemming and lemmatization is, lemmatization considers the context and converts the word to its meaningful base form, whereas stemming just removes the last few characters, often leading to incorrect meanings and spelling errors. for example, ‘Caring’ -> Lemmatization -> ‘Care’.","Dependency parsing helps assign a syntactic structure to a sentence. Therefore, it is also called syntactic parsing. Dependency parsing is one of the critical tasks in NLP. It allows the analysis of a sentence using parsing algorithms. Also, by using the parse tree in dependency parsing, we can check the grammar and analyze the semantic structure of a sentence",0
Explain Dependency Parsing in NLP,"It generally means to do the things properly with the use of vocabulary and morphological analysis of words. In this process, the endings of the words are removed to return the base word, which is also known as Lemma. Example: boy’s = boy, cars= car, colors= color.","Dependency parsing is the task of extracting a dependency parse of a sentence that represents its grammatical structure and defines the relationships between “head” words and words, which modify those heads.",0
Explain Lemmatization with the help of an example,"Lemmatization is closely related to stemming. In linguistics, it is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Putting an example to the definition, “computers” is an inflected form of “computer”, the same logic as “dogs” being an inflected form of “dog”","I would explain lemmatization as returning different forms of a single word to its root form. It is not only applicable to nouns. Lemmatization works the same way for adjectives, action verbs, all the same. Such as:
Constructing – (Lemmatization) -> Construct, Extracts – (Lemmatization) -> Extract",1
Explain Lemmatization with the help of an example,"Lemmatization is closely related to stemming. In linguistics, it is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Putting an example to the definition, “computers” is an inflected form of “computer”, the same logic as “dogs” being an inflected form of “dog”","It is an AI technique that automatically identifies named entities in a text and classifies them into predefined categories. Entities can be names of people, organizations, locations, times, quantities, monetary values, percentages, and more",0
Explain Named Entity Recognition,"I would explain lemmatization as returning different forms of a single word to its root form. It is not only applicable to nouns. Lemmatization works the same way for adjectives, action verbs, all the same. Such as:
Constructing – (Lemmatization) -> Construct, Extracts – (Lemmatization) -> Extract","With named entity recognition, you can extract key information to understand what a text is about, or merely use it to collect important information to store in a database. Keys as names, organization, locations.",0
Explain Lemmatization with the help of an example,"Lemmatization is closely related to stemming. In linguistics, it is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Putting an example to the definition, “computers” is an inflected form of “computer”, the same logic as “dogs” being an inflected form of “dog”","It generally means to do the things properly with the use of vocabulary and morphological analysis of words. In this process, the endings of the words are removed to return the base word, which is also known as Lemma. Example: boy’s = boy, cars= car, colors= color.",1
Explain Lemmatization with the help of an example,"Lemmatization is closely related to stemming. In linguistics, it is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Putting an example to the definition, “computers” is an inflected form of “computer”, the same logic as “dogs” being an inflected form of “dog”","Dependency parsing is the task of extracting a dependency parse of a sentence that represents its grammatical structure and defines the relationships between “head” words and words, which modify those heads.",0
Explain Dependency Parsing in NLP,"It generally means to do the things properly with the use of vocabulary and morphological analysis of words. In this process, the endings of the words are removed to return the base word, which is also known as Lemma. Example: boy’s = boy, cars= car, colors= color.",Dependency parsing is the process of analyzing the grammatical structure of a sentence based on the dependencies between the words in a sentence.,0
Explain Lemmatization with the help of an example,"I would explain lemmatization as returning different forms of a single word to its root form. It is not only applicable to nouns. Lemmatization works the same way for adjectives, action verbs, all the same. Such as: Constructing – (Lemmatization) -> Construct, Extracts – (Lemmatization) -> Extract","It generally means to do the things properly with the use of vocabulary and morphological analysis of words. In this process, the endings of the words are removed to return the base word, which is also known as Lemma. Example: boy’s = boy, cars= car, colors= color.",1
Explain Lemmatization with the help of an example,"I would explain lemmatization as returning different forms of a single word to its root form. It is not only applicable to nouns. Lemmatization works the same way for adjectives, action verbs, all the same. Such as: Constructing – (Lemmatization) -> Construct, Extracts – (Lemmatization) -> Extract",Regular expressions are specially encoded text strings used as patterns for matching sets of strings.,0
What are Regular Expressions?,"It generally means to do the things properly with the use of vocabulary and morphological analysis of words. In this process, the endings of the words are removed to return the base word, which is also known as Lemma. Example: boy’s = boy, cars= car, colors= color.",They are patterns used to match character combinations in strings.,0
What is Parts-of-speech Tagging?,"The parts-of-speech (POS) tagging is used to assign tags to words such as nouns, adjectives, verbs, and more. The software uses the POS tagging to first read the text and then differentiate the words by tagging. It helps in making the machine understand the meaning of a sentence.","it may be defined as the process of assigning one of the parts of speech to the given word. It is generally called POS tagging. In simple words, we can say that POS tagging is a task of labelling each word in a sentence with its appropriate part of speech. We know that parts of speech include nouns, verb, adverbs, adjectives, pronouns, conjunction and their sub-categories.",1
What is Parts-of-speech Tagging?,"The parts-of-speech (POS) tagging is used to assign tags to words such as nouns, adjectives, verbs, and more. The software uses the POS tagging to first read the text and then differentiate the words by tagging. It helps in making the machine understand the meaning of a sentence.","Bag of words is a way of extracting features from text for use in modeling, such as with machine learning algorithms.It is a representation of text that describes the occurrence of words within a document.",0
What is Bag of Words?,"it may be defined as the process of assigning one of the parts of speech to the given word. It is generally called POS tagging. In simple words, we can say that POS tagging is a task of labelling each word in a sentence with its appropriate part of speech. We know that parts of speech include nouns, verb, adverbs, adjectives, pronouns, conjunction and their sub-categories.","In this model, a text (such as a sentence or a document) is represented as the bag of its words, disregarding grammar and even word order but keeping multiplicity. The bag of words model is commonly used in methods of document classification where the (frequency of) occurrence of each word is used as a feature for training a classifier.",0
What is Parts-of-speech Tagging?,"The parts-of-speech (POS) tagging is used to assign tags to words such as nouns, adjectives, verbs, and more. The software uses the POS tagging to first read the text and then differentiate the words by tagging. It helps in making the machine understand the meaning of a sentence.","A Part-Of-Speech Tagger (POS Tagger) is a piece of software that reads text in some language and assigns parts of speech to each word (and other token), such as noun, verb, adjective, etc.",1
What is Parts-of-speech Tagging?,"The parts-of-speech (POS) tagging is used to assign tags to words such as nouns, adjectives, verbs, and more. The software uses the POS tagging to first read the text and then differentiate the words by tagging. It helps in making the machine understand the meaning of a sentence.","TF-IDF or Term Frequency-Inverse Document Frequency indicates the importance of a word in a set. It helps in information retrieval with numerical statistics. For a specific document, TF-IDF shows a frequency that helps identify the keywords in a document.",0
What is TF-IDF?,"A Part-Of-Speech Tagger (POS Tagger) is a piece of software that reads text in some language and assigns parts of speech to each word (and other token), such as noun, verb, adjective, etc.",TF-IDF helps to establish how important a particular word is in the context of the document corpus. TF-IDF takes into account the number of times the word appears in the document and offset by the number of documents that appear in the corpus.,0
What is Parts-of-speech Tagging?,"it may be defined as the process of assigning one of the parts of speech to the given word. It is generally called POS tagging. In simple words, we can say that POS tagging is a task of labelling each word in a sentence with its appropriate part of speech. We know that parts of speech include nouns, verb, adverbs, adjectives, pronouns, conjunction and their sub-categories.","A Part-Of-Speech Tagger (POS Tagger) is a piece of software that reads text in some language and assigns parts of speech to each word (and other token), such as noun, verb, adjective, etc.",1
What is Parts-of-speech Tagging?,"it may be defined as the process of assigning one of the parts of speech to the given word. It is generally called POS tagging. In simple words, we can say that POS tagging is a task of labelling each word in a sentence with its appropriate part of speech. We know that parts of speech include nouns, verb, adverbs, adjectives, pronouns, conjunction and their sub-categories.",Pragmatic analysis is an important task in NLP for interpreting knowledge that is lying outside a given document. The aim of implementing pragmatic analysis is to focus on exploring a different aspect of the document or text in a language. This requires a comprehensive knowledge of the real world. The pragmatic analysis allows software applications for the critical interpretation of the real-world data to know the actual meaning of sentences and words.,0
What is Pragmatic Analysis?,"A Part-Of-Speech Tagger (POS Tagger) is a piece of software that reads text in some language and assigns parts of speech to each word (and other token), such as noun, verb, adjective, etc.","Pragmatic analysis deals with outside word knowledge, which means knowledge that is external to the documents and/or queries. Pragmatics analysis that focuses on what was described is reinterpreted by what it actually meant, deriving the various aspects of language that require real world knowledge.",0
Explain Named Entity Recognition,"Named Entity Recognition (NER) is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text.",It is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category,1
Explain Named Entity Recognition,"Named Entity Recognition (NER) is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text.","TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.",0
What is TF-IDF?,It is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category,"Tf-idf weight is composed by two terms: the first computes the normalized Term Frequency. the number of times a word appears in a document, divided by the total number of words in that document; the second term is the Inverse Document Frequency, computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears",0
Explain Named Entity Recognition,"Named Entity Recognition (NER) is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text.","It is an AI technique that automatically identifies named entities in a text and classifies them into predefined categories. Entities can be names of people, organizations, locations, times, quantities, monetary values, percentages, and more",1
Explain Named Entity Recognition,"Named Entity Recognition (NER) is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text.",Parsing in NLP refers to the understanding of a sentence and its grammatical structure by a machine.,0
What is Parsing in the context of NLP?,"It is an AI technique that automatically identifies named entities in a text and classifies them into predefined categories. Entities can be names of people, organizations, locations, times, quantities, monetary values, percentages, and more",It helps analyze the text or the document to extract useful insights from it.,0
Explain Named Entity Recognition,"Named Entity Recognition (NER) is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text.","With named entity recognition, you can extract key information to understand what a text is about, or merely use it to collect important information to store in a database. Keys as names, organization, locations.",1
Explain Named Entity Recognition,"Named Entity Recognition (NER) is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text.","Natural language processing is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.",0
What do you understand by Natural Language Processing?,"With named entity recognition, you can extract key information to understand what a text is about, or merely use it to collect important information to store in a database. Keys as names, organization, locations.",Natural Language Processing or NLP is an automated way to understand or analyze the natural languages and extract required information from such data by applying machine learning Algorithms,0
Explain Named Entity Recognition,"Named Entity Recognition (NER) is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text.","Named Entity Recognition is a process where a sentence or a chunk of text is parsed through to find entities that can be put under categories like names, organizations, locations, quantities, monetary values, percentages, etc.",1
Explain Named Entity Recognition,"Named Entity Recognition (NER) is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text.","I would explain lemmatization as returning different forms of a single word to its root form. It is not only applicable to nouns. Lemmatization works the same way for adjectives, action verbs, all the same. Such as: Constructing – (Lemmatization) -> Construct, Extracts – (Lemmatization) -> Extract",0
Explain Lemmatization with the help of an example,"Named Entity Recognition is a process where a sentence or a chunk of text is parsed through to find entities that can be put under categories like names, organizations, locations, quantities, monetary values, percentages, etc.","It generally means to do the things properly with the use of vocabulary and morphological analysis of words. In this process, the endings of the words are removed to return the base word, which is also known as Lemma. Example: boy’s = boy, cars= car, colors= color.",0
Explain Named Entity Recognition,"Named Entity Recognition (NER) is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text.","Named-entity recognition is the method of extracting information. It arranges and classifies named entity in the unstructured text in different categories like locations, time expressions, organizations, percentages, and monetary values. NER allows the users to properly understand the subject of the text.",1
Explain Named Entity Recognition,"Named Entity Recognition (NER) is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text.","Pragmatic Analysis is part of the process of extracting information from text. Specifically, it’s the portion that focuses on taking structures set of text and figuring out what the actual meaning was. It actually comes from the field of linguistics (as a lot of NLP does), where the context is considered from the text.",0
What is Pragmatic Analysis?,"Named-entity recognition is the method of extracting information. It arranges and classifies named entity in the unstructured text in different categories like locations, time expressions, organizations, percentages, and monetary values. NER allows the users to properly understand the subject of the text.","Pragmatic analysis deals with outside word knowledge, which means knowledge that is external to the documents and/or queries. Pragmatics analysis that focuses on what was described is reinterpreted by what it actually meant, deriving the various aspects of language that require real world knowledge.",0
Explain Named Entity Recognition,It is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category,"It is an AI technique that automatically identifies named entities in a text and classifies them into predefined categories. Entities can be names of people, organizations, locations, times, quantities, monetary values, percentages, and more",1
Explain Named Entity Recognition,It is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category,"Parsing allows the machine to understand the meaning of a word in a sentence and the grouping of words, phrases, nouns, subjects, and objects in a sentence.",0
What is Parsing in the context of NLP?,"It is an AI technique that automatically identifies named entities in a text and classifies them into predefined categories. Entities can be names of people, organizations, locations, times, quantities, monetary values, percentages, and more",It is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),0
Explain Named Entity Recognition,It is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category,"With named entity recognition, you can extract key information to understand what a text is about, or merely use it to collect important information to store in a database. Keys as names, organization, locations.",1
Explain Named Entity Recognition,It is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category,"TF-IDF or Term Frequency-Inverse Document Frequency indicates the importance of a word in a set. It helps in information retrieval with numerical statistics. For a specific document, TF-IDF shows a frequency that helps identify the keywords in a document.",0
What is TF-IDF?,"With named entity recognition, you can extract key information to understand what a text is about, or merely use it to collect important information to store in a database. Keys as names, organization, locations.","TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.",0
Explain Named Entity Recognition,It is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category,"Named Entity Recognition is a process where a sentence or a chunk of text is parsed through to find entities that can be put under categories like names, organizations, locations, quantities, monetary values, percentages, etc.",1
Explain Named Entity Recognition,It is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category,Latent Semantic Indexing (LSI) tries to overcome the problems of lexical matching by using statistically derived conceptual indices instead of individual words for retrieval. A better approach would allow users to retrieve information on the basis of a conceptual topic or meaning of a document,0
What is Latent Semantic Indexing (LSI)?,"Named Entity Recognition is a process where a sentence or a chunk of text is parsed through to find entities that can be put under categories like names, organizations, locations, quantities, monetary values, percentages, etc.",It also called Latent semantic analysis is a mathematical method that was developed so that the accuracy of retrieving information can be improved. It helps in finding out the hidden(latent) relationship between the words(semantics) by producing a set of various concepts related to the terms of a sentence to improve the information understanding. The technique used for the purpose is called Singular value decomposition. It is generally useful for working on small sets of static documents.,0
Explain Named Entity Recognition,It is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category,"Named-entity recognition is the method of extracting information. It arranges and classifies named entity in the unstructured text in different categories like locations, time expressions, organizations, percentages, and monetary values. NER allows the users to properly understand the subject of the text.",1
Explain Named Entity Recognition,It is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category,"Latent semantic indexing is a mathematical technique used to improve the accuracy of the information retrieval process. The design of LSI algorithms allows machines to detect the hidden (latent) correlation between semantics (words). To enhance information understanding, machines generate various concepts that associate with the words of a sentence.",0
What is Latent Semantic Indexing (LSI)?,"Named-entity recognition is the method of extracting information. It arranges and classifies named entity in the unstructured text in different categories like locations, time expressions, organizations, percentages, and monetary values. NER allows the users to properly understand the subject of the text.",Latent Semantic Indexing is an indexing and retrieval method that uses a mathematical technique called Singular value decomposition (SVD) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text. LSI is based on the principle that words that are used in the same contexts tend to have similar meanings,0
Explain Named Entity Recognition,"It is an AI technique that automatically identifies named entities in a text and classifies them into predefined categories. Entities can be names of people, organizations, locations, times, quantities, monetary values, percentages, and more","With named entity recognition, you can extract key information to understand what a text is about, or merely use it to collect important information to store in a database. Keys as names, organization, locations.",1
Explain Named Entity Recognition,"It is an AI technique that automatically identifies named entities in a text and classifies them into predefined categories. Entities can be names of people, organizations, locations, times, quantities, monetary values, percentages, and more",Pragmatic analysis is an important task in NLP for interpreting knowledge that is lying outside a given document. The aim of implementing pragmatic analysis is to focus on exploring a different aspect of the document or text in a language. This requires a comprehensive knowledge of the real world. The pragmatic analysis allows software applications for the critical interpretation of the real-world data to know the actual meaning of sentences and words.,0
What is Pragmatic Analysis?,"With named entity recognition, you can extract key information to understand what a text is about, or merely use it to collect important information to store in a database. Keys as names, organization, locations.","Pragmatic analysis deals with outside word knowledge, which means knowledge that is external to the documents and/or queries. Pragmatics analysis that focuses on what was described is reinterpreted by what it actually meant, deriving the various aspects of language that require real world knowledge.",0
Explain Named Entity Recognition,"It is an AI technique that automatically identifies named entities in a text and classifies them into predefined categories. Entities can be names of people, organizations, locations, times, quantities, monetary values, percentages, and more","Named Entity Recognition is a process where a sentence or a chunk of text is parsed through to find entities that can be put under categories like names, organizations, locations, quantities, monetary values, percentages, etc.",1
Explain Named Entity Recognition,"It is an AI technique that automatically identifies named entities in a text and classifies them into predefined categories. Entities can be names of people, organizations, locations, times, quantities, monetary values, percentages, and more","stop words are words which are filtered out before or after processing of natural language data. The reason why stop words are critical to many applications is that, if we remove the words that are very commonly used in a given language, we can focus on the important words instead.",0
What are stop words?,"Named Entity Recognition is a process where a sentence or a chunk of text is parsed through to find entities that can be put under categories like names, organizations, locations, quantities, monetary values, percentages, etc.","Common words that occur in sentences that add weight to the sentence are known as stop words. These stop words act as a bridge and ensure that sentences are grammatically correct. In simple terms, words that are filtered out before processing natural language data is known as a stop word and it is a common pre-processing method.",0
Explain Named Entity Recognition,"It is an AI technique that automatically identifies named entities in a text and classifies them into predefined categories. Entities can be names of people, organizations, locations, times, quantities, monetary values, percentages, and more","Named-entity recognition is the method of extracting information. It arranges and classifies named entity in the unstructured text in different categories like locations, time expressions, organizations, percentages, and monetary values. NER allows the users to properly understand the subject of the text.",1
Explain Named Entity Recognition,"It is an AI technique that automatically identifies named entities in a text and classifies them into predefined categories. Entities can be names of people, organizations, locations, times, quantities, monetary values, percentages, and more","Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.",0
What is Pragmatic Ambiguity?,"Named-entity recognition is the method of extracting information. It arranges and classifies named entity in the unstructured text in different categories like locations, time expressions, organizations, percentages, and monetary values. NER allows the users to properly understand the subject of the text.",Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity,0
Explain Named Entity Recognition,"With named entity recognition, you can extract key information to understand what a text is about, or merely use it to collect important information to store in a database. Keys as names, organization, locations.","Named Entity Recognition is a process where a sentence or a chunk of text is parsed through to find entities that can be put under categories like names, organizations, locations, quantities, monetary values, percentages, etc.",1
Explain Named Entity Recognition,"With named entity recognition, you can extract key information to understand what a text is about, or merely use it to collect important information to store in a database. Keys as names, organization, locations.","Parsing allows the machine to understand the meaning of a word in a sentence and the grouping of words, phrases, nouns, subjects, and objects in a sentence.",0
What is Parsing in the context of NLP?,"Named Entity Recognition is a process where a sentence or a chunk of text is parsed through to find entities that can be put under categories like names, organizations, locations, quantities, monetary values, percentages, etc.",It is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),0
Explain Named Entity Recognition,"With named entity recognition, you can extract key information to understand what a text is about, or merely use it to collect important information to store in a database. Keys as names, organization, locations.","Named-entity recognition is the method of extracting information. It arranges and classifies named entity in the unstructured text in different categories like locations, time expressions, organizations, percentages, and monetary values. NER allows the users to properly understand the subject of the text.",1
Explain Named Entity Recognition,"With named entity recognition, you can extract key information to understand what a text is about, or merely use it to collect important information to store in a database. Keys as names, organization, locations.","Parsing is the method to identify and understand the syntactic structure of a text. It is done by analyzing the individual elements of the text. The machine parses the text one word at a time, then two at a time, further three, and so on.",0
Explain how we can do parsing,"Named-entity recognition is the method of extracting information. It arranges and classifies named entity in the unstructured text in different categories like locations, time expressions, organizations, percentages, and monetary values. NER allows the users to properly understand the subject of the text.",parsing in NLP is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),0
What is Latent Semantic Indexing (LSI)?,"Latent semantic indexing is a mathematical technique used to improve the accuracy of the information retrieval process. The design of LSI algorithms allows machines to detect the hidden (latent) correlation between semantics (words). To enhance information understanding, machines generate various concepts that associate with the words of a sentence.",Latent Semantic Indexing is an indexing and retrieval method that uses a mathematical technique called Singular value decomposition (SVD) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text. LSI is based on the principle that words that are used in the same contexts tend to have similar meanings,1
What is Latent Semantic Indexing (LSI)?,"Latent semantic indexing is a mathematical technique used to improve the accuracy of the information retrieval process. The design of LSI algorithms allows machines to detect the hidden (latent) correlation between semantics (words). To enhance information understanding, machines generate various concepts that associate with the words of a sentence.","Bag of words is a way of extracting features from text for use in modeling, such as with machine learning algorithms.It is a representation of text that describes the occurrence of words within a document.",0
What is Bag of Words?,Latent Semantic Indexing is an indexing and retrieval method that uses a mathematical technique called Singular value decomposition (SVD) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text. LSI is based on the principle that words that are used in the same contexts tend to have similar meanings,"The Bag of Words (BoW) model is the simplest form of text representation in numbers. Like the term itself, we can represent a sentence as a bag of words vector (a string of numbers).",0
What is Latent Semantic Indexing (LSI)?,"Latent semantic indexing is a mathematical technique used to improve the accuracy of the information retrieval process. The design of LSI algorithms allows machines to detect the hidden (latent) correlation between semantics (words). To enhance information understanding, machines generate various concepts that associate with the words of a sentence.",Latent Semantic Indexing (LSI) tries to overcome the problems of lexical matching by using statistically derived conceptual indices instead of individual words for retrieval. A better approach would allow users to retrieve information on the basis of a conceptual topic or meaning of a document,1
What is Latent Semantic Indexing (LSI)?,"Latent semantic indexing is a mathematical technique used to improve the accuracy of the information retrieval process. The design of LSI algorithms allows machines to detect the hidden (latent) correlation between semantics (words). To enhance information understanding, machines generate various concepts that associate with the words of a sentence.","N-gram in NLP is simply a sequence of n words, and we also conclude the sentences which appeared more frequently. for example, let us consider: New York consider as 2 gram and The Golden Compass is 3 gram",0
What is ngram in NLP?,Latent Semantic Indexing (LSI) tries to overcome the problems of lexical matching by using statistically derived conceptual indices instead of individual words for retrieval. A better approach would allow users to retrieve information on the basis of a conceptual topic or meaning of a document,They are basically a set of co-occurring words within a given window and when computing the n-grams you typically move one word forward,0
What is Latent Semantic Indexing (LSI)?,"Latent semantic indexing is a mathematical technique used to improve the accuracy of the information retrieval process. The design of LSI algorithms allows machines to detect the hidden (latent) correlation between semantics (words). To enhance information understanding, machines generate various concepts that associate with the words of a sentence.",It also called Latent semantic analysis is a mathematical method that was developed so that the accuracy of retrieving information can be improved. It helps in finding out the hidden(latent) relationship between the words(semantics) by producing a set of various concepts related to the terms of a sentence to improve the information understanding. The technique used for the purpose is called Singular value decomposition. It is generally useful for working on small sets of static documents.,1
What is Latent Semantic Indexing (LSI)?,"Latent semantic indexing is a mathematical technique used to improve the accuracy of the information retrieval process. The design of LSI algorithms allows machines to detect the hidden (latent) correlation between semantics (words). To enhance information understanding, machines generate various concepts that associate with the words of a sentence.","In NLP, perplexity is a way of evaluating language models. Perplexity can be high and low; Low perplexity is ethical because the inability to deal with any complicated problem is less while high perplexity is terrible because the failure to deal with a complicated is high.",0
What is perplexity in NLP?,It also called Latent semantic analysis is a mathematical method that was developed so that the accuracy of retrieving information can be improved. It helps in finding out the hidden(latent) relationship between the words(semantics) by producing a set of various concepts related to the terms of a sentence to improve the information understanding. The technique used for the purpose is called Singular value decomposition. It is generally useful for working on small sets of static documents.,"perplexity metric in NLP is a way to capture the degree of 'uncertainty' a model has in predicting (assigning probabilities to) some text. If a model, which is trained on good blogs and is being evaluated on similarly looking good blogs, assigns higher probability, we say the model has lower perplexity than a model which assigns lower probability.",0
What is Latent Semantic Indexing (LSI)?,Latent Semantic Indexing is an indexing and retrieval method that uses a mathematical technique called Singular value decomposition (SVD) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text. LSI is based on the principle that words that are used in the same contexts tend to have similar meanings,Latent Semantic Indexing (LSI) tries to overcome the problems of lexical matching by using statistically derived conceptual indices instead of individual words for retrieval. A better approach would allow users to retrieve information on the basis of a conceptual topic or meaning of a document,1
What is Latent Semantic Indexing (LSI)?,Latent Semantic Indexing is an indexing and retrieval method that uses a mathematical technique called Singular value decomposition (SVD) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text. LSI is based on the principle that words that are used in the same contexts tend to have similar meanings,"In general, perplexity is a measurement of how well a probability model predicts a sample. In the context of Natural Language Processing, perplexity is one way to evaluate language models.",0
What is perplexity in NLP?,Latent Semantic Indexing (LSI) tries to overcome the problems of lexical matching by using statistically derived conceptual indices instead of individual words for retrieval. A better approach would allow users to retrieve information on the basis of a conceptual topic or meaning of a document,it is a process to th behavior of the model. Low perplexity is good and high perplexity is bad since the perplexity is the exponentiation of the entropy,0
What is Latent Semantic Indexing (LSI)?,Latent Semantic Indexing is an indexing and retrieval method that uses a mathematical technique called Singular value decomposition (SVD) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text. LSI is based on the principle that words that are used in the same contexts tend to have similar meanings,It also called Latent semantic analysis is a mathematical method that was developed so that the accuracy of retrieving information can be improved. It helps in finding out the hidden(latent) relationship between the words(semantics) by producing a set of various concepts related to the terms of a sentence to improve the information understanding. The technique used for the purpose is called Singular value decomposition. It is generally useful for working on small sets of static documents.,1
What is Latent Semantic Indexing (LSI)?,Latent Semantic Indexing is an indexing and retrieval method that uses a mathematical technique called Singular value decomposition (SVD) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text. LSI is based on the principle that words that are used in the same contexts tend to have similar meanings,"Pragmatic Analysis is part of the process of extracting information from text. Specifically, it’s the portion that focuses on taking structures set of text and figuring out what the actual meaning was. It actually comes from the field of linguistics (as a lot of NLP does), where the context is considered from the text.",0
What is Pragmatic Analysis?,It also called Latent semantic analysis is a mathematical method that was developed so that the accuracy of retrieving information can be improved. It helps in finding out the hidden(latent) relationship between the words(semantics) by producing a set of various concepts related to the terms of a sentence to improve the information understanding. The technique used for the purpose is called Singular value decomposition. It is generally useful for working on small sets of static documents.,"Pragmatic levels of NLP deal with the real-world meanings of communication. Not only can it breakdowns the meanings of individual words and sentences, but it can also decide what the purpose of those words and sentences are. Context is massively influential in this step, and it is something that computers only ever understand through deep learning.",0
What is Latent Semantic Indexing (LSI)?,Latent Semantic Indexing (LSI) tries to overcome the problems of lexical matching by using statistically derived conceptual indices instead of individual words for retrieval. A better approach would allow users to retrieve information on the basis of a conceptual topic or meaning of a document,It also called Latent semantic analysis is a mathematical method that was developed so that the accuracy of retrieving information can be improved. It helps in finding out the hidden(latent) relationship between the words(semantics) by producing a set of various concepts related to the terms of a sentence to improve the information understanding. The technique used for the purpose is called Singular value decomposition. It is generally useful for working on small sets of static documents.,1
What is Latent Semantic Indexing (LSI)?,Latent Semantic Indexing (LSI) tries to overcome the problems of lexical matching by using statistically derived conceptual indices instead of individual words for retrieval. A better approach would allow users to retrieve information on the basis of a conceptual topic or meaning of a document,Dependency Parsing is the task of recognizing a sentence and assigning a syntactic structure to it. The most widely used syntactic structure is the parse tree which can be generated using some parsing algorithms. These parse trees are useful in various applications like grammar checking or more importantly it plays a critical role in the semantic analysis stage.,0
Explain Dependency Parsing in NLP,It also called Latent semantic analysis is a mathematical method that was developed so that the accuracy of retrieving information can be improved. It helps in finding out the hidden(latent) relationship between the words(semantics) by producing a set of various concepts related to the terms of a sentence to improve the information understanding. The technique used for the purpose is called Singular value decomposition. It is generally useful for working on small sets of static documents.,Dependency parsing is the process of analyzing the grammatical structure of a sentence based on the dependencies between the words in a sentence.,0
What are Regular Expressions?,A regular expression is used to match and tag words. It consists of a series of characters for matching strings.,"regular expression is a sequence of characters that define a search pattern. Usually such patterns are used by string-searching algorithms for ""find"" or ""find and replace"" operations on strings, or for input validation. It is a technique developed in theoretical computer science and formal language theory.",1
What are Regular Expressions?,A regular expression is used to match and tag words. It consists of a series of characters for matching strings.,"Stemming is the process of producing morphological variants of a root/base word. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”",0
Explain Stemming with the help of an example.,"regular expression is a sequence of characters that define a search pattern. Usually such patterns are used by string-searching algorithms for ""find"" or ""find and replace"" operations on strings, or for input validation. It is a technique developed in theoretical computer science and formal language theory.","Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language. As converting the words Playing, played, plays to play.",0
What are Regular Expressions?,A regular expression is used to match and tag words. It consists of a series of characters for matching strings.,Regular expressions are specially encoded text strings used as patterns for matching sets of strings.,1
What are Regular Expressions?,A regular expression is used to match and tag words. It consists of a series of characters for matching strings.,"All the normalization is calculated using this equation x^=x minus mean of x¯ over std of x¯ . The difference is how to calculate the x¯ .
In layer normalization x¯ = all of the summed inputs to the neurons in a layer on a single training case And in batch normalization x¯ = all of the summed inputs of single neuron on single batch",0
Difference between BatchNorm and LayerNorm?,Regular expressions are specially encoded text strings used as patterns for matching sets of strings.,"BatchNorm: Normalize the batch direction and count The mean value of W is not good for small batchsize; the main disadvantage of BN is that it is more sensitive to the size of batchsize. Since the mean and variance are calculated on one batch each time, if the batchsize is too small, the calculated mean and variance are not enough to represent The entire data distribution.
LayerNorm: Normalize the channel direction and count as CHThe mean value of W is mainly effective for RNN;",0
What are Regular Expressions?,A regular expression is used to match and tag words. It consists of a series of characters for matching strings.,They are patterns used to match character combinations in strings.,1
What are Regular Expressions?,A regular expression is used to match and tag words. It consists of a series of characters for matching strings.,"Naive Bayes algorithm is a collection of classifiers which works on the principles of the Bayes’ theorem. This series of NLP model forms a family of algorithms that can be used for a wide range of classification tasks including sentiment prediction, filtering of spam, classifying documents and more.",0
What is Naive Bayes algorithm?,They are patterns used to match character combinations in strings.,"Naive Bayes is a family of algorithms that take advantage of probability theory and Bayes’ Theorem to predict the tag of a text (like a piece of news or a customer review). They are probabilistic, which means that they calculate the probability of each tag for a given text, and then output the tag with the highest one. The way they get these probabilities is by using Bayes’ Theorem, which describes the probability of a feature, based on prior knowledge of conditions that might be related to that feature.",0
What are Regular Expressions?,"regular expression is a sequence of characters that define a search pattern. Usually such patterns are used by string-searching algorithms for ""find"" or ""find and replace"" operations on strings, or for input validation. It is a technique developed in theoretical computer science and formal language theory.",Regular expressions are specially encoded text strings used as patterns for matching sets of strings.,1
What are Regular Expressions?,"regular expression is a sequence of characters that define a search pattern. Usually such patterns are used by string-searching algorithms for ""find"" or ""find and replace"" operations on strings, or for input validation. It is a technique developed in theoretical computer science and formal language theory.","In this model, a text (such as a sentence or a document) is represented as the bag of its words, disregarding grammar and even word order but keeping multiplicity. The bag of words model is commonly used in methods of document classification where the (frequency of) occurrence of each word is used as a feature for training a classifier.",0
What is Bag of Words?,Regular expressions are specially encoded text strings used as patterns for matching sets of strings.,"The Bag of Words (BoW) model is the simplest form of text representation in numbers. Like the term itself, we can represent a sentence as a bag of words vector (a string of numbers).",0
What are Regular Expressions?,"regular expression is a sequence of characters that define a search pattern. Usually such patterns are used by string-searching algorithms for ""find"" or ""find and replace"" operations on strings, or for input validation. It is a technique developed in theoretical computer science and formal language theory.",They are patterns used to match character combinations in strings.,1
What are Regular Expressions?,"regular expression is a sequence of characters that define a search pattern. Usually such patterns are used by string-searching algorithms for ""find"" or ""find and replace"" operations on strings, or for input validation. It is a technique developed in theoretical computer science and formal language theory.","BatchNorm — Compute the mean and var at each layer for every minibatch
LayerNorm — Compute the mean and var for every single sample for each layer independently",0
Difference between BatchNorm and LayerNorm?,They are patterns used to match character combinations in strings.,Batch normalization is applied on the neuron activation for all the samples in the mini-batch such that the mean of output lies close to 0 and the standard deviation lies close to 1. It also introduces two learning parameters gama and beta in its calculation which are all optimized during training. Layer Normalization is not dependent on batches and the normalization is applied on the neuron for a single instance across all features,0
What are Regular Expressions?,Regular expressions are specially encoded text strings used as patterns for matching sets of strings.,They are patterns used to match character combinations in strings.,1
What are Regular Expressions?,Regular expressions are specially encoded text strings used as patterns for matching sets of strings.,A grammar is regular if it has rules of form A -> a or A -> aB or A -> ɛ where ɛ is a special symbol called NULL.,0
What is Regular Grammar?,They are patterns used to match character combinations in strings.,"There are 4 tuples in Regular Grammars (N, ∑, P, S € N). In this formula, N stands for the non-terminals’ sets, ∑ means the set of terminals, P is the set of productions to change the start symbol, P has its productions from one of the types and lastly S is the start non-terminal.",0
What is Regular Grammar?,"Regular grammar is used to represent a regular language. A regular grammar comprises rules in the form of A -> a, A -> aB, and many more. The rules help detect and analyze strings by automated computation.",A grammar is regular if it has rules of form A -> a or A -> aB or A -> ɛ where ɛ is a special symbol called NULL.,1
What is Regular Grammar?,"Regular grammar is used to represent a regular language. A regular grammar comprises rules in the form of A -> a, A -> aB, and many more. The rules help detect and analyze strings by automated computation.","Stemming is the process of producing morphological variants of a root/base word. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”",0
Explain Stemming with the help of an example.,A grammar is regular if it has rules of form A -> a or A -> aB or A -> ɛ where ɛ is a special symbol called NULL.,"Stemming is one of the most common data pre-processing operations we do in almost all Natural Language Processing. It is the process of removing a part of a word, or reducing a word to its stem or root. For example, the stem of the words eating, eats, eaten is eat.",0
What is Regular Grammar?,"Regular grammar is used to represent a regular language. A regular grammar comprises rules in the form of A -> a, A -> aB, and many more. The rules help detect and analyze strings by automated computation.","There are 4 tuples in Regular Grammars (N, ∑, P, S € N). In this formula, N stands for the non-terminals’ sets, ∑ means the set of terminals, P is the set of productions to change the start symbol, P has its productions from one of the types and lastly S is the start non-terminal.",1
What is Regular Grammar?,"Regular grammar is used to represent a regular language. A regular grammar comprises rules in the form of A -> a, A -> aB, and many more. The rules help detect and analyze strings by automated computation.","For machine translation tasks, seq2seq models, consisting of encoder and decoder were used. This involved usage of Recurrent Neural Networks, both for constructing the encoder and the decoder. The architecture used to memorize the entire sentence from the source language and regurgitate it into the target language. This process works fine for shorter sentences, but as the length of the sentence increases the performance slumps. It is, therefore, difficult for a recurrent neural network to memorize a rather long sentence. The attention mechanism helps us overcome this difficulty",0
Why transformer perform better than LSTM?,"There are 4 tuples in Regular Grammars (N, ∑, P, S € N). In this formula, N stands for the non-terminals’ sets, ∑ means the set of terminals, P is the set of productions to change the start symbol, P has its productions from one of the types and lastly S is the start non-terminal.","RNN is not very efficient in handling long sequences. The model tends to forget the contents of the distant position or, in some cases, mixes the contents of adjacent positions: the more the steps, the more challenging for the recurrent network to make decisions. The Long Short Term Memory (LSTM) offers a slight improvement over conventional RNN. It can also eliminate the vanishing gradient problem that RNN suffers from. Transformer avoids recursion by processing sentences as whole using attention mechanisms and positional embeddings.",0
What is Regular Grammar?,A grammar is regular if it has rules of form A -> a or A -> aB or A -> ɛ where ɛ is a special symbol called NULL.,"There are 4 tuples in Regular Grammars (N, ∑, P, S € N). In this formula, N stands for the non-terminals’ sets, ∑ means the set of terminals, P is the set of productions to change the start symbol, P has its productions from one of the types and lastly S is the start non-terminal.",1
What is Regular Grammar?,A grammar is regular if it has rules of form A -> a or A -> aB or A -> ɛ where ɛ is a special symbol called NULL.,"NLP is a big field and covers things from very ML-like (classifiers with bag of words features) to not at all ML-like (machine translation). You need to spend some time on a survey of NLP problems, then zero in on the ones you care about, which may or may not involve the methods you're familiar with.",0
Why is NLP so hard?,"There are 4 tuples in Regular Grammars (N, ∑, P, S € N). In this formula, N stands for the non-terminals’ sets, ∑ means the set of terminals, P is the set of productions to change the start symbol, P has its productions from one of the types and lastly S is the start non-terminal.","NLP is so hard because of many reasons. For example, Knowledge of the world is still difficult for computers to acquire, It is hard to understand whether two sentences or two concepts are equal, and Optimizing the wrong metrics",0
Explain Dependency Parsing in NLP,"Dependency parsing helps assign a syntactic structure to a sentence. Therefore, it is also called syntactic parsing. Dependency parsing is one of the critical tasks in NLP. It allows the analysis of a sentence using parsing algorithms. Also, by using the parse tree in dependency parsing, we can check the grammar and analyze the semantic structure of a sentence","Dependency parsing is the task of extracting a dependency parse of a sentence that represents its grammatical structure and defines the relationships between “head” words and words, which modify those heads.",1
Explain Dependency Parsing in NLP,"Dependency parsing helps assign a syntactic structure to a sentence. Therefore, it is also called syntactic parsing. Dependency parsing is one of the critical tasks in NLP. It allows the analysis of a sentence using parsing algorithms. Also, by using the parse tree in dependency parsing, we can check the grammar and analyze the semantic structure of a sentence","In general, perplexity is a measurement of how well a probability model predicts a sample. In the context of Natural Language Processing, perplexity is one way to evaluate language models.",0
What is perplexity in NLP?,"Dependency parsing is the task of extracting a dependency parse of a sentence that represents its grammatical structure and defines the relationships between “head” words and words, which modify those heads.",it is a process to th behavior of the model. Low perplexity is good and high perplexity is bad since the perplexity is the exponentiation of the entropy,0
Explain Dependency Parsing in NLP,"Dependency parsing helps assign a syntactic structure to a sentence. Therefore, it is also called syntactic parsing. Dependency parsing is one of the critical tasks in NLP. It allows the analysis of a sentence using parsing algorithms. Also, by using the parse tree in dependency parsing, we can check the grammar and analyze the semantic structure of a sentence",Dependency Parsing is the task of recognizing a sentence and assigning a syntactic structure to it. The most widely used syntactic structure is the parse tree which can be generated using some parsing algorithms. These parse trees are useful in various applications like grammar checking or more importantly it plays a critical role in the semantic analysis stage.,1
Explain Dependency Parsing in NLP,"Dependency parsing helps assign a syntactic structure to a sentence. Therefore, it is also called syntactic parsing. Dependency parsing is one of the critical tasks in NLP. It allows the analysis of a sentence using parsing algorithms. Also, by using the parse tree in dependency parsing, we can check the grammar and analyze the semantic structure of a sentence","The problem of Relu. First, Exploding gradient and this Solved by gradient clipping. Second, Dying ReLu — No learning if the activation is 0 (Solved by parametric relu). Third, Mean and variance of activations is not 0 and 1.(Partially solved by subtracting around 0.5 from activation. Better explained in fastai videos).",0
What is the problem with ReLu?,Dependency Parsing is the task of recognizing a sentence and assigning a syntactic structure to it. The most widely used syntactic structure is the parse tree which can be generated using some parsing algorithms. These parse trees are useful in various applications like grammar checking or more importantly it plays a critical role in the semantic analysis stage.,"let's say the inputs to Relu are now distributed as a low-variance Gaussian centered at -0.1. we have that Most inputs to Relu are negative, thus Most inputs will cause the ReLU gate to be closed, thus Most inputs will cause gradients to fail to flow backwards through Relu thus Relu's inputs are usually not updated through SGD backprop.",0
Explain Dependency Parsing in NLP,"Dependency parsing helps assign a syntactic structure to a sentence. Therefore, it is also called syntactic parsing. Dependency parsing is one of the critical tasks in NLP. It allows the analysis of a sentence using parsing algorithms. Also, by using the parse tree in dependency parsing, we can check the grammar and analyze the semantic structure of a sentence",Dependency parsing is the process of analyzing the grammatical structure of a sentence based on the dependencies between the words in a sentence.,1
Explain Dependency Parsing in NLP,"Dependency parsing helps assign a syntactic structure to a sentence. Therefore, it is also called syntactic parsing. Dependency parsing is one of the critical tasks in NLP. It allows the analysis of a sentence using parsing algorithms. Also, by using the parse tree in dependency parsing, we can check the grammar and analyze the semantic structure of a sentence","Parsing is the method to identify and understand the syntactic structure of a text. It is done by analyzing the individual elements of the text. The machine parses the text one word at a time, then two at a time, further three, and so on.",0
Explain how we can do parsing,Dependency parsing is the process of analyzing the grammatical structure of a sentence based on the dependencies between the words in a sentence.,parsing means analysis of an input to organize the data according to the rule of a grammar,0
Explain Dependency Parsing in NLP,"Dependency parsing is the task of extracting a dependency parse of a sentence that represents its grammatical structure and defines the relationships between “head” words and words, which modify those heads.",Dependency Parsing is the task of recognizing a sentence and assigning a syntactic structure to it. The most widely used syntactic structure is the parse tree which can be generated using some parsing algorithms. These parse trees are useful in various applications like grammar checking or more importantly it plays a critical role in the semantic analysis stage.,1
Explain Dependency Parsing in NLP,"Dependency parsing is the task of extracting a dependency parse of a sentence that represents its grammatical structure and defines the relationships between “head” words and words, which modify those heads.","Topic modeling is part of a class of text analysis methods that analyze “bags” or groups of words together—instead of counting them individually–in order to capture how the meaning of words is dependent upon the broader context in which they are used in natural language. Topic modeling is not the only method that does this– cluster analysis, latent semantic analysis, and other techniques have also been used to identify clustering within texts",0
What is Topic Modeling ? When we will do it ?,Dependency Parsing is the task of recognizing a sentence and assigning a syntactic structure to it. The most widely used syntactic structure is the parse tree which can be generated using some parsing algorithms. These parse trees are useful in various applications like grammar checking or more importantly it plays a critical role in the semantic analysis stage.,"Topic modeling is a branch of unsupervised natural language processing which is used to represent a text document with the help of several topics, that can best explain the underlying information in a particular document. This can be thought in terms of clustering, but with a difference.",0
Explain Dependency Parsing in NLP,"Dependency parsing is the task of extracting a dependency parse of a sentence that represents its grammatical structure and defines the relationships between “head” words and words, which modify those heads.",Dependency parsing is the process of analyzing the grammatical structure of a sentence based on the dependencies between the words in a sentence.,1
Explain Dependency Parsing in NLP,"Dependency parsing is the task of extracting a dependency parse of a sentence that represents its grammatical structure and defines the relationships between “head” words and words, which modify those heads.","Such kind of ambiguity refers to the situation where the context of a phrase gives it multiple interpretations. In simple words, we can say that pragmatic ambiguity arises when the statement is not specific. For example, the sentence “I like you too” can have multiple interpretations as I like you (just like you like me), I like you (just like someone else does).",0
What is Pragmatic Ambiguity?,Dependency parsing is the process of analyzing the grammatical structure of a sentence based on the dependencies between the words in a sentence.,Pragmatic ambiguity refers to a situation where the context of a phrase gives it multiple interpretation,0
Explain Dependency Parsing in NLP,Dependency Parsing is the task of recognizing a sentence and assigning a syntactic structure to it. The most widely used syntactic structure is the parse tree which can be generated using some parsing algorithms. These parse trees are useful in various applications like grammar checking or more importantly it plays a critical role in the semantic analysis stage.,Dependency parsing is the process of analyzing the grammatical structure of a sentence based on the dependencies between the words in a sentence.,1
Explain Dependency Parsing in NLP,Dependency Parsing is the task of recognizing a sentence and assigning a syntactic structure to it. The most widely used syntactic structure is the parse tree which can be generated using some parsing algorithms. These parse trees are useful in various applications like grammar checking or more importantly it plays a critical role in the semantic analysis stage.,Pragmatic analysis is an important task in NLP for interpreting knowledge that is lying outside a given document. The aim of implementing pragmatic analysis is to focus on exploring a different aspect of the document or text in a language. This requires a comprehensive knowledge of the real world. The pragmatic analysis allows software applications for the critical interpretation of the real-world data to know the actual meaning of sentences and words.,0
What is Pragmatic Analysis?,Dependency parsing is the process of analyzing the grammatical structure of a sentence based on the dependencies between the words in a sentence.,"Pragmatic Analysis is part of the process of extracting information from text. Specifically, it’s the portion that focuses on taking structures set of text and figuring out what the actual meaning was. It actually comes from the field of linguistics (as a lot of NLP does), where the context is considered from the text.",0
What is Pragmatic Analysis?,Pragmatic analysis is an important task in NLP for interpreting knowledge that is lying outside a given document. The aim of implementing pragmatic analysis is to focus on exploring a different aspect of the document or text in a language. This requires a comprehensive knowledge of the real world. The pragmatic analysis allows software applications for the critical interpretation of the real-world data to know the actual meaning of sentences and words.,"Pragmatic Analysis is part of the process of extracting information from text. Specifically, it’s the portion that focuses on taking structures set of text and figuring out what the actual meaning was. It actually comes from the field of linguistics (as a lot of NLP does), where the context is considered from the text.",1
What is Pragmatic Analysis?,Pragmatic analysis is an important task in NLP for interpreting knowledge that is lying outside a given document. The aim of implementing pragmatic analysis is to focus on exploring a different aspect of the document or text in a language. This requires a comprehensive knowledge of the real world. The pragmatic analysis allows software applications for the critical interpretation of the real-world data to know the actual meaning of sentences and words.,"Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.",0
What is Pragmatic Ambiguity?,"Pragmatic Analysis is part of the process of extracting information from text. Specifically, it’s the portion that focuses on taking structures set of text and figuring out what the actual meaning was. It actually comes from the field of linguistics (as a lot of NLP does), where the context is considered from the text.","Such kind of ambiguity refers to the situation where the context of a phrase gives it multiple interpretations. In simple words, we can say that pragmatic ambiguity arises when the statement is not specific. For example, the sentence “I like you too” can have multiple interpretations as I like you (just like you like me), I like you (just like someone else does).",0
What is Pragmatic Analysis?,Pragmatic analysis is an important task in NLP for interpreting knowledge that is lying outside a given document. The aim of implementing pragmatic analysis is to focus on exploring a different aspect of the document or text in a language. This requires a comprehensive knowledge of the real world. The pragmatic analysis allows software applications for the critical interpretation of the real-world data to know the actual meaning of sentences and words.,"Pragmatic analysis deals with outside word knowledge, which means knowledge that is external to the documents and/or queries. Pragmatics analysis that focuses on what was described is reinterpreted by what it actually meant, deriving the various aspects of language that require real world knowledge.",1
What is Pragmatic Analysis?,Pragmatic analysis is an important task in NLP for interpreting knowledge that is lying outside a given document. The aim of implementing pragmatic analysis is to focus on exploring a different aspect of the document or text in a language. This requires a comprehensive knowledge of the real world. The pragmatic analysis allows software applications for the critical interpretation of the real-world data to know the actual meaning of sentences and words.,"We use stemming and lemmatization to extract root words. However, stemming may not give the actual word, whereas lemmatization generates a meaningful word. In lemmatization, rather than just removing the suffix and the prefix, the process tries to find out the root word with its proper meaning. for example, Bricks’ becomes ‘brick,’ ‘corpora’ becomes ‘corpus’.",0
Explain Lemmatization with the help of an example,"Pragmatic analysis deals with outside word knowledge, which means knowledge that is external to the documents and/or queries. Pragmatics analysis that focuses on what was described is reinterpreted by what it actually meant, deriving the various aspects of language that require real world knowledge.","I would explain lemmatization as returning different forms of a single word to its root form. It is not only applicable to nouns. Lemmatization works the same way for adjectives, action verbs, all the same. Such as: Constructing – (Lemmatization) -> Construct, Extracts – (Lemmatization) -> Extract",0
What is Pragmatic Analysis?,Pragmatic analysis is an important task in NLP for interpreting knowledge that is lying outside a given document. The aim of implementing pragmatic analysis is to focus on exploring a different aspect of the document or text in a language. This requires a comprehensive knowledge of the real world. The pragmatic analysis allows software applications for the critical interpretation of the real-world data to know the actual meaning of sentences and words.,pramatic Analysis is the structure representing what was said is reinterpreted to determine what was actually meant,1
What is Pragmatic Analysis?,Pragmatic analysis is an important task in NLP for interpreting knowledge that is lying outside a given document. The aim of implementing pragmatic analysis is to focus on exploring a different aspect of the document or text in a language. This requires a comprehensive knowledge of the real world. The pragmatic analysis allows software applications for the critical interpretation of the real-world data to know the actual meaning of sentences and words.,"Stemming is the process of producing morphological variants of a root/base word. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”",0
Explain Stemming with the help of an example.,pramatic Analysis is the structure representing what was said is reinterpreted to determine what was actually meant,"Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language. As converting the words Playing, played, plays to play.",0
What is Pragmatic Analysis?,Pragmatic analysis is an important task in NLP for interpreting knowledge that is lying outside a given document. The aim of implementing pragmatic analysis is to focus on exploring a different aspect of the document or text in a language. This requires a comprehensive knowledge of the real world. The pragmatic analysis allows software applications for the critical interpretation of the real-world data to know the actual meaning of sentences and words.,"Pragmatic levels of NLP deal with the real-world meanings of communication. Not only can it breakdowns the meanings of individual words and sentences, but it can also decide what the purpose of those words and sentences are. Context is massively influential in this step, and it is something that computers only ever understand through deep learning.",1
What is Pragmatic Ambiguity?,"Pragmatic levels of NLP deal with the real-world meanings of communication. Not only can it breakdowns the meanings of individual words and sentences, but it can also decide what the purpose of those words and sentences are. Context is massively influential in this step, and it is something that computers only ever understand through deep learning.","Such kind of ambiguity refers to the situation where the context of a phrase gives it multiple interpretations. In simple words, we can say that pragmatic ambiguity arises when the statement is not specific. For example, the sentence “I like you too” can have multiple interpretations as I like you (just like you like me), I like you (just like someone else does).",0
What is Pragmatic Analysis?,"Pragmatic Analysis is part of the process of extracting information from text. Specifically, it’s the portion that focuses on taking structures set of text and figuring out what the actual meaning was. It actually comes from the field of linguistics (as a lot of NLP does), where the context is considered from the text.","Pragmatic analysis deals with outside word knowledge, which means knowledge that is external to the documents and/or queries. Pragmatics analysis that focuses on what was described is reinterpreted by what it actually meant, deriving the various aspects of language that require real world knowledge.",1
What is Pragmatic Analysis?,"Pragmatic Analysis is part of the process of extracting information from text. Specifically, it’s the portion that focuses on taking structures set of text and figuring out what the actual meaning was. It actually comes from the field of linguistics (as a lot of NLP does), where the context is considered from the text.",Transformer models are essentially attention based models. They see the entire sentence as a whole unlike LSTMs (or in general RNNs) where the sentence is processed sequentially - one word per time step. During training LSTMs need to propagate the error back in time through words one word at a time. Transformer sees all words simultaneously - so there is no backpropagation through time.,0
Why transformer perform better than LSTM?,"Pragmatic analysis deals with outside word knowledge, which means knowledge that is external to the documents and/or queries. Pragmatics analysis that focuses on what was described is reinterpreted by what it actually meant, deriving the various aspects of language that require real world knowledge.","RNN is not very efficient in handling long sequences. The model tends to forget the contents of the distant position or, in some cases, mixes the contents of adjacent positions: the more the steps, the more challenging for the recurrent network to make decisions. The Long Short Term Memory (LSTM) offers a slight improvement over conventional RNN. It can also eliminate the vanishing gradient problem that RNN suffers from. Transformer avoids recursion by processing sentences as whole using attention mechanisms and positional embeddings.",0
What is Pragmatic Analysis?,"Pragmatic Analysis is part of the process of extracting information from text. Specifically, it’s the portion that focuses on taking structures set of text and figuring out what the actual meaning was. It actually comes from the field of linguistics (as a lot of NLP does), where the context is considered from the text.",pramatic Analysis is the structure representing what was said is reinterpreted to determine what was actually meant,1
What is Pragmatic Analysis?,"Pragmatic Analysis is part of the process of extracting information from text. Specifically, it’s the portion that focuses on taking structures set of text and figuring out what the actual meaning was. It actually comes from the field of linguistics (as a lot of NLP does), where the context is considered from the text.","In NLP, perplexity is a way of evaluating language models. Perplexity can be high and low; Low perplexity is ethical because the inability to deal with any complicated problem is less while high perplexity is terrible because the failure to deal with a complicated is high.",0
What is perplexity in NLP?,pramatic Analysis is the structure representing what was said is reinterpreted to determine what was actually meant,"perplexity metric in NLP is a way to capture the degree of 'uncertainty' a model has in predicting (assigning probabilities to) some text. If a model, which is trained on good blogs and is being evaluated on similarly looking good blogs, assigns higher probability, we say the model has lower perplexity than a model which assigns lower probability.",0
What is Pragmatic Analysis?,"Pragmatic Analysis is part of the process of extracting information from text. Specifically, it’s the portion that focuses on taking structures set of text and figuring out what the actual meaning was. It actually comes from the field of linguistics (as a lot of NLP does), where the context is considered from the text.","Pragmatic levels of NLP deal with the real-world meanings of communication. Not only can it breakdowns the meanings of individual words and sentences, but it can also decide what the purpose of those words and sentences are. Context is massively influential in this step, and it is something that computers only ever understand through deep learning.",1
What is Pragmatic Analysis?,"Pragmatic Analysis is part of the process of extracting information from text. Specifically, it’s the portion that focuses on taking structures set of text and figuring out what the actual meaning was. It actually comes from the field of linguistics (as a lot of NLP does), where the context is considered from the text.","Stop words are said to be useless data for a search engine. There are stop words such as was, were, is, am, the, a, an, how, why, and many more. In Natural Language Processing, we eliminate the stop words to understand and analyze the meaning of a sentence.",0
What are stop words?,"Pragmatic levels of NLP deal with the real-world meanings of communication. Not only can it breakdowns the meanings of individual words and sentences, but it can also decide what the purpose of those words and sentences are. Context is massively influential in this step, and it is something that computers only ever understand through deep learning.","A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.",0
What is Pragmatic Analysis?,"Pragmatic analysis deals with outside word knowledge, which means knowledge that is external to the documents and/or queries. Pragmatics analysis that focuses on what was described is reinterpreted by what it actually meant, deriving the various aspects of language that require real world knowledge.",pramatic Analysis is the structure representing what was said is reinterpreted to determine what was actually meant,1
What is Pragmatic Analysis?,"Pragmatic analysis deals with outside word knowledge, which means knowledge that is external to the documents and/or queries. Pragmatics analysis that focuses on what was described is reinterpreted by what it actually meant, deriving the various aspects of language that require real world knowledge.","Natural language processing is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.",0
What do you understand by Natural Language Processing?,pramatic Analysis is the structure representing what was said is reinterpreted to determine what was actually meant,Natural Language Processing or NLP is an automated way to understand or analyze the natural languages and extract required information from such data by applying machine learning Algorithms,0
What is Pragmatic Analysis?,"Pragmatic analysis deals with outside word knowledge, which means knowledge that is external to the documents and/or queries. Pragmatics analysis that focuses on what was described is reinterpreted by what it actually meant, deriving the various aspects of language that require real world knowledge.","Pragmatic levels of NLP deal with the real-world meanings of communication. Not only can it breakdowns the meanings of individual words and sentences, but it can also decide what the purpose of those words and sentences are. Context is massively influential in this step, and it is something that computers only ever understand through deep learning.",1
What is Pragmatic Analysis?,"Pragmatic analysis deals with outside word knowledge, which means knowledge that is external to the documents and/or queries. Pragmatics analysis that focuses on what was described is reinterpreted by what it actually meant, deriving the various aspects of language that require real world knowledge.",Parsing in NLP refers to the understanding of a sentence and its grammatical structure by a machine.,0
What is Parsing in the context of NLP?,"Pragmatic levels of NLP deal with the real-world meanings of communication. Not only can it breakdowns the meanings of individual words and sentences, but it can also decide what the purpose of those words and sentences are. Context is massively influential in this step, and it is something that computers only ever understand through deep learning.",It is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),0
What is Pragmatic Analysis?,pramatic Analysis is the structure representing what was said is reinterpreted to determine what was actually meant,"Pragmatic levels of NLP deal with the real-world meanings of communication. Not only can it breakdowns the meanings of individual words and sentences, but it can also decide what the purpose of those words and sentences are. Context is massively influential in this step, and it is something that computers only ever understand through deep learning.",1
What is Pragmatic Analysis?,pramatic Analysis is the structure representing what was said is reinterpreted to determine what was actually meant,"The parts-of-speech (POS) tagging is used to assign tags to words such as nouns, adjectives, verbs, and more. The software uses the POS tagging to first read the text and then differentiate the words by tagging. It helps in making the machine understand the meaning of a sentence.",0
What is Parts-of-speech Tagging?,"Pragmatic levels of NLP deal with the real-world meanings of communication. Not only can it breakdowns the meanings of individual words and sentences, but it can also decide what the purpose of those words and sentences are. Context is massively influential in this step, and it is something that computers only ever understand through deep learning.","it may be defined as the process of assigning one of the parts of speech to the given word. It is generally called POS tagging. In simple words, we can say that POS tagging is a task of labelling each word in a sentence with its appropriate part of speech. We know that parts of speech include nouns, verb, adverbs, adjectives, pronouns, conjunction and their sub-categories.",0
What is Pragmatic Ambiguity?,"Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.","Such kind of ambiguity refers to the situation where the context of a phrase gives it multiple interpretations. In simple words, we can say that pragmatic ambiguity arises when the statement is not specific. For example, the sentence “I like you too” can have multiple interpretations as I like you (just like you like me), I like you (just like someone else does).",1
What is Pragmatic Ambiguity?,"Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.","perplexity metric in NLP is a way to capture the degree of 'uncertainty' a model has in predicting (assigning probabilities to) some text. If a model, which is trained on good blogs and is being evaluated on similarly looking good blogs, assigns higher probability, we say the model has lower perplexity than a model which assigns lower probability.",0
What is perplexity in NLP?,"Such kind of ambiguity refers to the situation where the context of a phrase gives it multiple interpretations. In simple words, we can say that pragmatic ambiguity arises when the statement is not specific. For example, the sentence “I like you too” can have multiple interpretations as I like you (just like you like me), I like you (just like someone else does).",it is a process to th behavior of the model. Low perplexity is good and high perplexity is bad since the perplexity is the exponentiation of the entropy,0
What is Pragmatic Ambiguity?,"Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.",It can be defined as the words which have multiple interpretations. Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity.,1
What is Pragmatic Ambiguity?,"Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.",parsing means analysis of an input to organize the data according to the rule of a grammar,0
Explain how we can do parsing,It can be defined as the words which have multiple interpretations. Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity.,parsing in NLP is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),0
What is Pragmatic Ambiguity?,"Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.",Pragmatic ambiguity refers to a situation where the context of a phrase gives it multiple interpretation,1
What is Pragmatic Ambiguity?,"Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.","ReLU units can be fragile during training and can ""die"". For example, a large gradient flowing through a ReLU neuron could cause the weights to update in such a way that the neuron will never activate on any datapoint again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. That is, the ReLU units can irreversibly die during training since they can get knocked off the data manifold.",0
What is the problem with ReLu?,Pragmatic ambiguity refers to a situation where the context of a phrase gives it multiple interpretation,"ReLU neurons output zero and have zero derivatives for all negative inputs. So, if the weights in your network always lead to negative inputs into a ReLU neuron, that neuron is effectively not contributing to the network's training. Mathematically, the gradient contribution to the weight updates coming from that neuron is always zero",0
What is Pragmatic Ambiguity?,"Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.",Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity,1
What is Pragmatic Ambiguity?,"Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.","Dependency parsing is the task of extracting a dependency parse of a sentence that represents its grammatical structure and defines the relationships between “head” words and words, which modify those heads.",0
Explain Dependency Parsing in NLP,Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity,Dependency Parsing is the task of recognizing a sentence and assigning a syntactic structure to it. The most widely used syntactic structure is the parse tree which can be generated using some parsing algorithms. These parse trees are useful in various applications like grammar checking or more importantly it plays a critical role in the semantic analysis stage.,0
What is Pragmatic Ambiguity?,"Such kind of ambiguity refers to the situation where the context of a phrase gives it multiple interpretations. In simple words, we can say that pragmatic ambiguity arises when the statement is not specific. For example, the sentence “I like you too” can have multiple interpretations as I like you (just like you like me), I like you (just like someone else does).",It can be defined as the words which have multiple interpretations. Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity.,1
What is Pragmatic Ambiguity?,"Such kind of ambiguity refers to the situation where the context of a phrase gives it multiple interpretations. In simple words, we can say that pragmatic ambiguity arises when the statement is not specific. For example, the sentence “I like you too” can have multiple interpretations as I like you (just like you like me), I like you (just like someone else does).","Dependency parsing is the task of extracting a dependency parse of a sentence that represents its grammatical structure and defines the relationships between “head” words and words, which modify those heads.",0
Explain Dependency Parsing in NLP,It can be defined as the words which have multiple interpretations. Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity.,Dependency Parsing is the task of recognizing a sentence and assigning a syntactic structure to it. The most widely used syntactic structure is the parse tree which can be generated using some parsing algorithms. These parse trees are useful in various applications like grammar checking or more importantly it plays a critical role in the semantic analysis stage.,0
What is Pragmatic Ambiguity?,"Such kind of ambiguity refers to the situation where the context of a phrase gives it multiple interpretations. In simple words, we can say that pragmatic ambiguity arises when the statement is not specific. For example, the sentence “I like you too” can have multiple interpretations as I like you (just like you like me), I like you (just like someone else does).",Pragmatic ambiguity refers to a situation where the context of a phrase gives it multiple interpretation,1
What is Pragmatic Ambiguity?,"Such kind of ambiguity refers to the situation where the context of a phrase gives it multiple interpretations. In simple words, we can say that pragmatic ambiguity arises when the statement is not specific. For example, the sentence “I like you too” can have multiple interpretations as I like you (just like you like me), I like you (just like someone else does).","N-gram in NLP is simply a sequence of n words, and we also conclude the sentences which appeared more frequently. for example, let us consider: New York consider as 2 gram and The Golden Compass is 3 gram",0
What is ngram in NLP?,Pragmatic ambiguity refers to a situation where the context of a phrase gives it multiple interpretation,They are basically a set of co-occurring words within a given window and when computing the n-grams you typically move one word forward,0
What is Pragmatic Ambiguity?,"Such kind of ambiguity refers to the situation where the context of a phrase gives it multiple interpretations. In simple words, we can say that pragmatic ambiguity arises when the statement is not specific. For example, the sentence “I like you too” can have multiple interpretations as I like you (just like you like me), I like you (just like someone else does).",Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity,1
What is Pragmatic Ambiguity?,"Such kind of ambiguity refers to the situation where the context of a phrase gives it multiple interpretations. In simple words, we can say that pragmatic ambiguity arises when the statement is not specific. For example, the sentence “I like you too” can have multiple interpretations as I like you (just like you like me), I like you (just like someone else does).",Parsing in NLP refers to the understanding of a sentence and its grammatical structure by a machine.,0
What is Parsing in the context of NLP?,Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity,"Parsing allows the machine to understand the meaning of a word in a sentence and the grouping of words, phrases, nouns, subjects, and objects in a sentence.",0
What is Pragmatic Ambiguity?,It can be defined as the words which have multiple interpretations. Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity.,Pragmatic ambiguity refers to a situation where the context of a phrase gives it multiple interpretation,1
What is Pragmatic Ambiguity?,It can be defined as the words which have multiple interpretations. Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity.,Transformer models are essentially attention based models. They see the entire sentence as a whole unlike LSTMs (or in general RNNs) where the sentence is processed sequentially - one word per time step. During training LSTMs need to propagate the error back in time through words one word at a time. Transformer sees all words simultaneously - so there is no backpropagation through time.,0
Why transformer perform better than LSTM?,Pragmatic ambiguity refers to a situation where the context of a phrase gives it multiple interpretation,"For machine translation tasks, seq2seq models, consisting of encoder and decoder were used. This involved usage of Recurrent Neural Networks, both for constructing the encoder and the decoder. The architecture used to memorize the entire sentence from the source language and regurgitate it into the target language. This process works fine for shorter sentences, but as the length of the sentence increases the performance slumps. It is, therefore, difficult for a recurrent neural network to memorize a rather long sentence. The attention mechanism helps us overcome this difficulty",0
What is Pragmatic Ambiguity?,It can be defined as the words which have multiple interpretations. Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity.,Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity,1
What is Pragmatic Ambiguity?,It can be defined as the words which have multiple interpretations. Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity.,"I would explain lemmatization as returning different forms of a single word to its root form. It is not only applicable to nouns. Lemmatization works the same way for adjectives, action verbs, all the same. Such as: Constructing – (Lemmatization) -> Construct, Extracts – (Lemmatization) -> Extract",0
Explain Lemmatization with the help of an example,Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity,"It generally means to do the things properly with the use of vocabulary and morphological analysis of words. In this process, the endings of the words are removed to return the base word, which is also known as Lemma. Example: boy’s = boy, cars= car, colors= color.",0
What is Pragmatic Ambiguity?,Pragmatic ambiguity refers to a situation where the context of a phrase gives it multiple interpretation,Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity,1
What is Pragmatic Ambiguity?,Pragmatic ambiguity refers to a situation where the context of a phrase gives it multiple interpretation,"Natural language processing  is the relationship between computers and human language. More specifically, natural language processing is the computer understanding, analysis, manipulation, and/or generation of natural language.",0
What do you understand by Natural Language Processing?,Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity,Natural language processing is the ability of a computer program to understand human language as it is spoken. NLP is a component of artificial intelligence. It allows machines to break down and interpret human language.,0
What is Parsing in the context of NLP?,Parsing in NLP refers to the understanding of a sentence and its grammatical structure by a machine.,"Parsing allows the machine to understand the meaning of a word in a sentence and the grouping of words, phrases, nouns, subjects, and objects in a sentence.",1
What is Parsing in the context of NLP?,Parsing in NLP refers to the understanding of a sentence and its grammatical structure by a machine.,"All the normalization is calculated using this equation x^=x minus mean of x¯ over std of x¯ . The difference is how to calculate the x¯ .
In layer normalization x¯ = all of the summed inputs to the neurons in a layer on a single training case And in batch normalization x¯ = all of the summed inputs of single neuron on single batch",0
Difference between BatchNorm and LayerNorm?,"Parsing allows the machine to understand the meaning of a word in a sentence and the grouping of words, phrases, nouns, subjects, and objects in a sentence.","BatchNorm: Normalize the batch direction and count The mean value of W is not good for small batchsize; the main disadvantage of BN is that it is more sensitive to the size of batchsize. Since the mean and variance are calculated on one batch each time, if the batchsize is too small, the calculated mean and variance are not enough to represent The entire data distribution.
LayerNorm: Normalize the channel direction and count as CHThe mean value of W is mainly effective for RNN;",0
What is Parsing in the context of NLP?,Parsing in NLP refers to the understanding of a sentence and its grammatical structure by a machine.,It helps analyze the text or the document to extract useful insights from it.,1
What is Parsing in the context of NLP?,Parsing in NLP refers to the understanding of a sentence and its grammatical structure by a machine.,"TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.",0
What is TF-IDF?,It helps analyze the text or the document to extract useful insights from it.,"Tf-idf weight is composed by two terms: the first computes the normalized Term Frequency. the number of times a word appears in a document, divided by the total number of words in that document; the second term is the Inverse Document Frequency, computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears",0
What is Parsing in the context of NLP?,Parsing in NLP refers to the understanding of a sentence and its grammatical structure by a machine.,It is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),1
What is Parsing in the context of NLP?,Parsing in NLP refers to the understanding of a sentence and its grammatical structure by a machine.,"We use stemming and lemmatization to extract root words. However, stemming may not give the actual word, whereas lemmatization generates a meaningful word. In lemmatization, rather than just removing the suffix and the prefix, the process tries to find out the root word with its proper meaning. for example, Bricks’ becomes ‘brick,’ ‘corpora’ becomes ‘corpus’.",0
Explain Lemmatization with the help of an example,It is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),"I would explain lemmatization as returning different forms of a single word to its root form. It is not only applicable to nouns. Lemmatization works the same way for adjectives, action verbs, all the same. Such as: Constructing – (Lemmatization) -> Construct, Extracts – (Lemmatization) -> Extract",0
What is Parsing in the context of NLP?,"Parsing allows the machine to understand the meaning of a word in a sentence and the grouping of words, phrases, nouns, subjects, and objects in a sentence.",It helps analyze the text or the document to extract useful insights from it.,1
What is Parsing in the context of NLP?,"Parsing allows the machine to understand the meaning of a word in a sentence and the grouping of words, phrases, nouns, subjects, and objects in a sentence.",It can be defined as the words which have multiple interpretations. Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity.,0
What is Pragmatic Ambiguity?,It helps analyze the text or the document to extract useful insights from it.,Pragmatic ambiguity refers to a situation where the context of a phrase gives it multiple interpretation,0
What is Parsing in the context of NLP?,"Parsing allows the machine to understand the meaning of a word in a sentence and the grouping of words, phrases, nouns, subjects, and objects in a sentence.",It is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),1
What is Parsing in the context of NLP?,"Parsing allows the machine to understand the meaning of a word in a sentence and the grouping of words, phrases, nouns, subjects, and objects in a sentence.","ReLU neurons output zero and have zero derivatives for all negative inputs. So, if the weights in your network always lead to negative inputs into a ReLU neuron, that neuron is effectively not contributing to the network's training. Mathematically, the gradient contribution to the weight updates coming from that neuron is always zero",0
What is the problem with ReLu?,It is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),"The dying ReLU refers to the problem when ReLU neurons become inactive and only output 0 for any input. So, once a neuron gets negative input, it will always output zero and is unlikely for it to recover. It will become inactive forever. Such neurons will not play any role in discriminating the input and become useless in the neural network. If this process continues, over the time you may end up with a large part of your network doing nothing.",0
What is Parsing in the context of NLP?,It helps analyze the text or the document to extract useful insights from it.,It is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),1
What is Parsing in the context of NLP?,It helps analyze the text or the document to extract useful insights from it.,"Text mining, also referred to as text data mining, roughly equivalent to text analytics, is the process of deriving high-quality information from text. High-quality information is typically derived through the devising of patterns and trends through means such as statistical pattern learning.",0
What is text mining ?,It is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),"Text mining (also referred to as text analytics) is an artificial intelligence (AI) technology that uses natural language processing (NLP) to transform the free (unstructured) text in documents and databases into normalized, structured data suitable for analysis or to drive machine learning (ML) algorithms.",0
What is Bag of Words?,Bag of Words is a commonly used model that depends on word frequencies or occurrences to train a classifier. This model creates an occurrence matrix for documents or sentences irrespective of its grammatical structure or word order.,"Bag of words is a way of extracting features from text for use in modeling, such as with machine learning algorithms.It is a representation of text that describes the occurrence of words within a document.",1
What is Bag of Words?,Bag of Words is a commonly used model that depends on word frequencies or occurrences to train a classifier. This model creates an occurrence matrix for documents or sentences irrespective of its grammatical structure or word order.,Masked language models help learners to understand deep representations in downstream tasks by taking an output from the corrupt input. This model is often used to predict the words to be used in a sentence.,0
What is Masked Language Model,"Bag of words is a way of extracting features from text for use in modeling, such as with machine learning algorithms.It is a representation of text that describes the occurrence of words within a document.","Masked Language Modeling is a fill-in-the-blank task, where a model uses the context words surrounding a mask token to try to predict what the masked word should be. For an input that contains one or more mask tokens, the model will generate the most likely substitution for each.",0
What is Bag of Words?,Bag of Words is a commonly used model that depends on word frequencies or occurrences to train a classifier. This model creates an occurrence matrix for documents or sentences irrespective of its grammatical structure or word order.,"In this model, a text (such as a sentence or a document) is represented as the bag of its words, disregarding grammar and even word order but keeping multiplicity. The bag of words model is commonly used in methods of document classification where the (frequency of) occurrence of each word is used as a feature for training a classifier.",1
What is Bag of Words?,Bag of Words is a commonly used model that depends on word frequencies or occurrences to train a classifier. This model creates an occurrence matrix for documents or sentences irrespective of its grammatical structure or word order.,Semantic analysis helps make a machine understand the meaning of a text. It uses various algorithms for the interpretation of words in sentences. It also helps understand the structure of a sentence.,0
What is Semantic Analysis?,"In this model, a text (such as a sentence or a document) is represented as the bag of its words, disregarding grammar and even word order but keeping multiplicity. The bag of words model is commonly used in methods of document classification where the (frequency of) occurrence of each word is used as a feature for training a classifier.","semantic analysis is the process of drawing meaning from text. It allows computers to understand and interpret sentences, paragraphs, or whole documents, by analyzing their grammatical structure, and identifying relationships between individual words in a particular context.",0
What is Bag of Words?,Bag of Words is a commonly used model that depends on word frequencies or occurrences to train a classifier. This model creates an occurrence matrix for documents or sentences irrespective of its grammatical structure or word order.,"The Bag of Words (BoW) model is the simplest form of text representation in numbers. Like the term itself, we can represent a sentence as a bag of words vector (a string of numbers).",1
What is Bag of Words?,Bag of Words is a commonly used model that depends on word frequencies or occurrences to train a classifier. This model creates an occurrence matrix for documents or sentences irrespective of its grammatical structure or word order.,"Pragmatic analysis deals with outside word knowledge, which means knowledge that is external to the documents and/or queries. Pragmatics analysis that focuses on what was described is reinterpreted by what it actually meant, deriving the various aspects of language that require real world knowledge.",0
What is Pragmatic Analysis?,"The Bag of Words (BoW) model is the simplest form of text representation in numbers. Like the term itself, we can represent a sentence as a bag of words vector (a string of numbers).",pramatic Analysis is the structure representing what was said is reinterpreted to determine what was actually meant,0
What is Bag of Words?,"Bag of words is a way of extracting features from text for use in modeling, such as with machine learning algorithms.It is a representation of text that describes the occurrence of words within a document.","In this model, a text (such as a sentence or a document) is represented as the bag of its words, disregarding grammar and even word order but keeping multiplicity. The bag of words model is commonly used in methods of document classification where the (frequency of) occurrence of each word is used as a feature for training a classifier.",1
What is Bag of Words?,"Bag of words is a way of extracting features from text for use in modeling, such as with machine learning algorithms.It is a representation of text that describes the occurrence of words within a document.","Topic modeling is part of a class of text analysis methods that analyze “bags” or groups of words together—instead of counting them individually–in order to capture how the meaning of words is dependent upon the broader context in which they are used in natural language. Topic modeling is not the only method that does this– cluster analysis, latent semantic analysis, and other techniques have also been used to identify clustering within texts",0
What is Topic Modeling ? When we will do it ?,"In this model, a text (such as a sentence or a document) is represented as the bag of its words, disregarding grammar and even word order but keeping multiplicity. The bag of words model is commonly used in methods of document classification where the (frequency of) occurrence of each word is used as a feature for training a classifier.","Topic modeling is a branch of unsupervised natural language processing which is used to represent a text document with the help of several topics, that can best explain the underlying information in a particular document. This can be thought in terms of clustering, but with a difference.",0
What is Bag of Words?,"Bag of words is a way of extracting features from text for use in modeling, such as with machine learning algorithms.It is a representation of text that describes the occurrence of words within a document.","The Bag of Words (BoW) model is the simplest form of text representation in numbers. Like the term itself, we can represent a sentence as a bag of words vector (a string of numbers).",1
What is Bag of Words?,"Bag of words is a way of extracting features from text for use in modeling, such as with machine learning algorithms.It is a representation of text that describes the occurrence of words within a document.","perplexity metric in NLP is a way to capture the degree of 'uncertainty' a model has in predicting (assigning probabilities to) some text. If a model, which is trained on good blogs and is being evaluated on similarly looking good blogs, assigns higher probability, we say the model has lower perplexity than a model which assigns lower probability.",0
What is perplexity in NLP?,"The Bag of Words (BoW) model is the simplest form of text representation in numbers. Like the term itself, we can represent a sentence as a bag of words vector (a string of numbers).",Perplexity is a way to express a degree of confusion a model has in predicting. More entropy equal to more confusion. Perplexity is used to evaluate language models in NLP. A good language model assigns a higher probability to the right prediction.,0
What is Bag of Words?,"In this model, a text (such as a sentence or a document) is represented as the bag of its words, disregarding grammar and even word order but keeping multiplicity. The bag of words model is commonly used in methods of document classification where the (frequency of) occurrence of each word is used as a feature for training a classifier.","The Bag of Words (BoW) model is the simplest form of text representation in numbers. Like the term itself, we can represent a sentence as a bag of words vector (a string of numbers).",1
What is Bag of Words?,"In this model, a text (such as a sentence or a document) is represented as the bag of its words, disregarding grammar and even word order but keeping multiplicity. The bag of words model is commonly used in methods of document classification where the (frequency of) occurrence of each word is used as a feature for training a classifier.",They are basically a set of co-occurring words within a given window and when computing the n-grams you typically move one word forward,0
What is ngram in NLP?,"The Bag of Words (BoW) model is the simplest form of text representation in numbers. Like the term itself, we can represent a sentence as a bag of words vector (a string of numbers).","An N-gram language model predicts the probability of a given N-gram within any sequence of words in the language. If we have a good N-gram model, we can predict p(w | h) – what is the probability of seeing the word w given a history of previous words h – where the history contains n-1 words.",0
What is Masked Language Model,Masked language models help learners to understand deep representations in downstream tasks by taking an output from the corrupt input. This model is often used to predict the words to be used in a sentence.,"Masked Language Modeling is a fill-in-the-blank task, where a model uses the context words surrounding a mask token to try to predict what the masked word should be. For an input that contains one or more mask tokens, the model will generate the most likely substitution for each.",1
What is Masked Language Model,Masked language models help learners to understand deep representations in downstream tasks by taking an output from the corrupt input. This model is often used to predict the words to be used in a sentence.,"Stop words are said to be useless data for a search engine. There are stop words such as was, were, is, am, the, a, an, how, why, and many more. In Natural Language Processing, we eliminate the stop words to understand and analyze the meaning of a sentence.",0
What are stop words?,"Masked Language Modeling is a fill-in-the-blank task, where a model uses the context words surrounding a mask token to try to predict what the masked word should be. For an input that contains one or more mask tokens, the model will generate the most likely substitution for each.","A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.",0
What is Masked Language Model,Masked language models help learners to understand deep representations in downstream tasks by taking an output from the corrupt input. This model is often used to predict the words to be used in a sentence.,It is the process in which the output is taken from the corrupted input. This model helps the learners to master the deep representations in downstream tasks. You can predict a word from the other words of the sentence using this model.,1
What is Masked Language Model,Masked language models help learners to understand deep representations in downstream tasks by taking an output from the corrupt input. This model is often used to predict the words to be used in a sentence.,"Latent semantic indexing is a mathematical technique used to improve the accuracy of the information retrieval process. The design of LSI algorithms allows machines to detect the hidden (latent) correlation between semantics (words). To enhance information understanding, machines generate various concepts that associate with the words of a sentence.",0
What is Latent Semantic Indexing (LSI)?,It is the process in which the output is taken from the corrupted input. This model helps the learners to master the deep representations in downstream tasks. You can predict a word from the other words of the sentence using this model.,Latent Semantic Indexing (LSI) tries to overcome the problems of lexical matching by using statistically derived conceptual indices instead of individual words for retrieval. A better approach would allow users to retrieve information on the basis of a conceptual topic or meaning of a document,0
What is Masked Language Model,Masked language models help learners to understand deep representations in downstream tasks by taking an output from the corrupt input. This model is often used to predict the words to be used in a sentence.,It is a mission of completing a missed word of the sentence or many words in the sentence.,1
What is Masked Language Model,Masked language models help learners to understand deep representations in downstream tasks by taking an output from the corrupt input. This model is often used to predict the words to be used in a sentence.,"Transformers are better than all the other architectures because they totally avoid recursion, by processing sentences as a whole and by learning relationships between words thank's to multi-head attention mechanisms and positional embeddings.",0
Why transformer perform better than LSTM?,It is a mission of completing a missed word of the sentence or many words in the sentence.,"RNN is not very efficient in handling long sequences. The model tends to forget the contents of the distant position or, in some cases, mixes the contents of adjacent positions: the more the steps, the more challenging for the recurrent network to make decisions. The Long Short Term Memory (LSTM) offers a slight improvement over conventional RNN. It can also eliminate the vanishing gradient problem that RNN suffers from. Transformer avoids recursion by processing sentences as whole using attention mechanisms and positional embeddings.",0
What is Masked Language Model,"Masked Language Modeling is a fill-in-the-blank task, where a model uses the context words surrounding a mask token to try to predict what the masked word should be. For an input that contains one or more mask tokens, the model will generate the most likely substitution for each.",It is the process in which the output is taken from the corrupted input. This model helps the learners to master the deep representations in downstream tasks. You can predict a word from the other words of the sentence using this model.,1
What is Masked Language Model,"Masked Language Modeling is a fill-in-the-blank task, where a model uses the context words surrounding a mask token to try to predict what the masked word should be. For an input that contains one or more mask tokens, the model will generate the most likely substitution for each.",It can be defined as the words which have multiple interpretations. Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity.,0
What is Pragmatic Ambiguity?,It is the process in which the output is taken from the corrupted input. This model helps the learners to master the deep representations in downstream tasks. You can predict a word from the other words of the sentence using this model.,Pragmatic Ambiguity arises when the meaning of words of a sentence is not specific; it concludes different meanings. There are various sentences in which the proper sense is not understood due to the grammar formation of the sentence; this multi interpretation of the sentence gives rise to ambiguity,0
What is Masked Language Model,"Masked Language Modeling is a fill-in-the-blank task, where a model uses the context words surrounding a mask token to try to predict what the masked word should be. For an input that contains one or more mask tokens, the model will generate the most likely substitution for each.",It is a mission of completing a missed word of the sentence or many words in the sentence.,1
What is Masked Language Model,"Masked Language Modeling is a fill-in-the-blank task, where a model uses the context words surrounding a mask token to try to predict what the masked word should be. For an input that contains one or more mask tokens, the model will generate the most likely substitution for each.",Batch normalization is applied on the neuron activation for all the samples in the mini-batch such that the mean of output lies close to 0 and the standard deviation lies close to 1. It also introduces two learning parameters gama and beta in its calculation which are all optimized during training. Layer Normalization is not dependent on batches and the normalization is applied on the neuron for a single instance across all features,0
Difference between BatchNorm and LayerNorm?,It is a mission of completing a missed word of the sentence or many words in the sentence.,"All the normalization is calculated using this equation x^=x minus mean of x¯ over std of x¯ . The difference is how to calculate the x¯ .
In layer normalization x¯ = all of the summed inputs to the neurons in a layer on a single training case And in batch normalization x¯ = all of the summed inputs of single neuron on single batch",0
What is Masked Language Model,It is the process in which the output is taken from the corrupted input. This model helps the learners to master the deep representations in downstream tasks. You can predict a word from the other words of the sentence using this model.,It is a mission of completing a missed word of the sentence or many words in the sentence.,1
What is Masked Language Model,It is the process in which the output is taken from the corrupted input. This model helps the learners to master the deep representations in downstream tasks. You can predict a word from the other words of the sentence using this model.,Hidden stores all the information till that time step and cell state stores particular information that might be needed in the future time step.,0
What is the information in hidden and cell state of LSTM?,It is a mission of completing a missed word of the sentence or many words in the sentence.,"Cell state is a memory of LSTM cell, hidden state is an output of this cell. Hidden state and cell input are used to control what to do with memory: to forget or to write new information. We decide what to do with memory knowing about previous output (hidden state) and current input.",0
Why is NLP so hard?,"There are several factors that make the process of Natural Language Processing difficult. There are hundreds of natural languages all over the world, words can be ambiguous in their meaning, each natural language has a different script and syntax, the meaning of words can change depending on the context, and so the process of NLP can be difficult.","NLP is a big field and covers things from very ML-like (classifiers with bag of words features) to not at all ML-like (machine translation). You need to spend some time on a survey of NLP problems, then zero in on the ones you care about, which may or may not involve the methods you're familiar with.",1
Why is NLP so hard?,"There are several factors that make the process of Natural Language Processing difficult. There are hundreds of natural languages all over the world, words can be ambiguous in their meaning, each natural language has a different script and syntax, the meaning of words can change depending on the context, and so the process of NLP can be difficult.","Information extraction in the context of Natural Language Processing refers to the technique of extracting structured information automatically from unstructured sources to ascribe meaning to it. This can include extracting information regarding attributes of entities, relationship between different entities and more",0
What is information extraction?,"NLP is a big field and covers things from very ML-like (classifiers with bag of words features) to not at all ML-like (machine translation). You need to spend some time on a survey of NLP problems, then zero in on the ones you care about, which may or may not involve the methods you're familiar with.","Information Extraction systems takes natural language text as input and produces structured information specified by certain criteria, that is relevant to a particular application.",0
Why is NLP so hard?,"There are several factors that make the process of Natural Language Processing difficult. There are hundreds of natural languages all over the world, words can be ambiguous in their meaning, each natural language has a different script and syntax, the meaning of words can change depending on the context, and so the process of NLP can be difficult.","NLP is so hard because of many reasons. For example, Knowledge of the world is still difficult for computers to acquire, It is hard to understand whether two sentences or two concepts are equal, and Optimizing the wrong metrics",1
Why is NLP so hard?,"There are several factors that make the process of Natural Language Processing difficult. There are hundreds of natural languages all over the world, words can be ambiguous in their meaning, each natural language has a different script and syntax, the meaning of words can change depending on the context, and so the process of NLP can be difficult.",Information extraction (IE) is the automated retrieval of specific information related to a selected topic from a body or bodies of text.,0
What is information extraction?,"NLP is so hard because of many reasons. For example, Knowledge of the world is still difficult for computers to acquire, It is hard to understand whether two sentences or two concepts are equal, and Optimizing the wrong metrics","Information Extraction systems takes natural language text as input and produces structured information specified by certain criteria, that is relevant to a particular application.",0
Why is NLP so hard?,"There are several factors that make the process of Natural Language Processing difficult. There are hundreds of natural languages all over the world, words can be ambiguous in their meaning, each natural language has a different script and syntax, the meaning of words can change depending on the context, and so the process of NLP can be difficult.","Difficulties in Natural Language Processing are Some sentences in english can be parsed in different ways that human may understand while the computer systems not, and Some inputs can mean different meanings, while sometimes many inputs can mean the same thing. Word pronunciations are sometimes very hard for the computers to get it clearly.",1
Why is NLP so hard?,"There are several factors that make the process of Natural Language Processing difficult. There are hundreds of natural languages all over the world, words can be ambiguous in their meaning, each natural language has a different script and syntax, the meaning of words can change depending on the context, and so the process of NLP can be difficult.","Parsing allows the machine to understand the meaning of a word in a sentence and the grouping of words, phrases, nouns, subjects, and objects in a sentence.",0
What is Parsing in the context of NLP?,"Difficulties in Natural Language Processing are Some sentences in english can be parsed in different ways that human may understand while the computer systems not, and Some inputs can mean different meanings, while sometimes many inputs can mean the same thing. Word pronunciations are sometimes very hard for the computers to get it clearly.",It is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),0
Why is NLP so hard?,"NLP is a big field and covers things from very ML-like (classifiers with bag of words features) to not at all ML-like (machine translation). You need to spend some time on a survey of NLP problems, then zero in on the ones you care about, which may or may not involve the methods you're familiar with.","NLP is so hard because of many reasons. For example, Knowledge of the world is still difficult for computers to acquire, It is hard to understand whether two sentences or two concepts are equal, and Optimizing the wrong metrics",1
Why is NLP so hard?,"NLP is a big field and covers things from very ML-like (classifiers with bag of words features) to not at all ML-like (machine translation). You need to spend some time on a survey of NLP problems, then zero in on the ones you care about, which may or may not involve the methods you're familiar with.","The parts-of-speech (POS) tagging is used to assign tags to words such as nouns, adjectives, verbs, and more. The software uses the POS tagging to first read the text and then differentiate the words by tagging. It helps in making the machine understand the meaning of a sentence.",0
What is Parts-of-speech Tagging?,"NLP is so hard because of many reasons. For example, Knowledge of the world is still difficult for computers to acquire, It is hard to understand whether two sentences or two concepts are equal, and Optimizing the wrong metrics","A Part-Of-Speech Tagger (POS Tagger) is a piece of software that reads text in some language and assigns parts of speech to each word (and other token), such as noun, verb, adjective, etc.",0
Why is NLP so hard?,"NLP is a big field and covers things from very ML-like (classifiers with bag of words features) to not at all ML-like (machine translation). You need to spend some time on a survey of NLP problems, then zero in on the ones you care about, which may or may not involve the methods you're familiar with.","Difficulties in Natural Language Processing are Some sentences in english can be parsed in different ways that human may understand while the computer systems not, and Some inputs can mean different meanings, while sometimes many inputs can mean the same thing. Word pronunciations are sometimes very hard for the computers to get it clearly.",1
Why is NLP so hard?,"NLP is a big field and covers things from very ML-like (classifiers with bag of words features) to not at all ML-like (machine translation). You need to spend some time on a survey of NLP problems, then zero in on the ones you care about, which may or may not involve the methods you're familiar with.","Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.",0
What is Pragmatic Ambiguity?,"Difficulties in Natural Language Processing are Some sentences in english can be parsed in different ways that human may understand while the computer systems not, and Some inputs can mean different meanings, while sometimes many inputs can mean the same thing. Word pronunciations are sometimes very hard for the computers to get it clearly.",Pragmatic ambiguity refers to a situation where the context of a phrase gives it multiple interpretation,0
Why is NLP so hard?,"NLP is so hard because of many reasons. For example, Knowledge of the world is still difficult for computers to acquire, It is hard to understand whether two sentences or two concepts are equal, and Optimizing the wrong metrics","Difficulties in Natural Language Processing are Some sentences in english can be parsed in different ways that human may understand while the computer systems not, and Some inputs can mean different meanings, while sometimes many inputs can mean the same thing. Word pronunciations are sometimes very hard for the computers to get it clearly.",1
Why is NLP so hard?,"NLP is so hard because of many reasons. For example, Knowledge of the world is still difficult for computers to acquire, It is hard to understand whether two sentences or two concepts are equal, and Optimizing the wrong metrics","TF-IDF, which stands for term frequency — inverse document frequency, is a scoring measure widely used in information retrieval (IR) or summarization. TF-IDF is intended to reflect how relevant a term is in a given document.",0
What is TF-IDF?,"Difficulties in Natural Language Processing are Some sentences in english can be parsed in different ways that human may understand while the computer systems not, and Some inputs can mean different meanings, while sometimes many inputs can mean the same thing. Word pronunciations are sometimes very hard for the computers to get it clearly.","Tf-idf weight is composed by two terms: the first computes the normalized Term Frequency. the number of times a word appears in a document, divided by the total number of words in that document; the second term is the Inverse Document Frequency, computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears",0
What is information extraction?,"Information extraction in the context of Natural Language Processing refers to the technique of extracting structured information automatically from unstructured sources to ascribe meaning to it. This can include extracting information regarding attributes of entities, relationship between different entities and more",Information extraction (IE) is the automated retrieval of specific information related to a selected topic from a body or bodies of text.,1
What is information extraction?,"Information extraction in the context of Natural Language Processing refers to the technique of extracting structured information automatically from unstructured sources to ascribe meaning to it. This can include extracting information regarding attributes of entities, relationship between different entities and more",Transformer models are essentially attention based models. They see the entire sentence as a whole unlike LSTMs (or in general RNNs) where the sentence is processed sequentially - one word per time step. During training LSTMs need to propagate the error back in time through words one word at a time. Transformer sees all words simultaneously - so there is no backpropagation through time.,0
Why transformer perform better than LSTM?,Information extraction (IE) is the automated retrieval of specific information related to a selected topic from a body or bodies of text.,"RNN is not very efficient in handling long sequences. The model tends to forget the contents of the distant position or, in some cases, mixes the contents of adjacent positions: the more the steps, the more challenging for the recurrent network to make decisions. The Long Short Term Memory (LSTM) offers a slight improvement over conventional RNN. It can also eliminate the vanishing gradient problem that RNN suffers from. Transformer avoids recursion by processing sentences as whole using attention mechanisms and positional embeddings.",0
What is information extraction?,"Information extraction in the context of Natural Language Processing refers to the technique of extracting structured information automatically from unstructured sources to ascribe meaning to it. This can include extracting information regarding attributes of entities, relationship between different entities and more","Information Extraction systems takes natural language text as input and produces structured information specified by certain criteria, that is relevant to a particular application.",1
What is information extraction?,"Information extraction in the context of Natural Language Processing refers to the technique of extracting structured information automatically from unstructured sources to ascribe meaning to it. This can include extracting information regarding attributes of entities, relationship between different entities and more","stemming is the method to extract the root word by removing suffixes and prefixes from a word.
For example, we can reduce ‘stemming’ to ‘stem’ by removing ‘m’ and ‘ing.’",0
Explain Stemming with the help of an example.,"Information Extraction systems takes natural language text as input and produces structured information specified by certain criteria, that is relevant to a particular application.","Stemming is the process of producing morphological variants of a root/base word. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”",0
What is information extraction?,Information extraction (IE) is the automated retrieval of specific information related to a selected topic from a body or bodies of text.,"Information Extraction systems takes natural language text as input and produces structured information specified by certain criteria, that is relevant to a particular application.",1
What is information extraction?,Information extraction (IE) is the automated retrieval of specific information related to a selected topic from a body or bodies of text.,"Naive Bayes algorithm is a collection of classifiers which works on the principles of the Bayes’ theorem. This series of NLP model forms a family of algorithms that can be used for a wide range of classification tasks including sentiment prediction, filtering of spam, classifying documents and more.",0
What is Naive Bayes algorithm?,"Information Extraction systems takes natural language text as input and produces structured information specified by certain criteria, that is relevant to a particular application.","Naive Bayes Classifier Algorithm is a family of probabilistic algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of a feature.
Bayes theorem calculates probability P(c|x) where c is the class of the possible outcomes and x is the given instance which has to be classified, representing some certain features.",0
What is Naive Bayes algorithm?,"Naive Bayes algorithm is a collection of classifiers which works on the principles of the Bayes’ theorem. This series of NLP model forms a family of algorithms that can be used for a wide range of classification tasks including sentiment prediction, filtering of spam, classifying documents and more.","Naive Bayes Classifier Algorithm is a family of probabilistic algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of a feature.
Bayes theorem calculates probability P(c|x) where c is the class of the possible outcomes and x is the given instance which has to be classified, representing some certain features.",1
What is Naive Bayes algorithm?,"Naive Bayes algorithm is a collection of classifiers which works on the principles of the Bayes’ theorem. This series of NLP model forms a family of algorithms that can be used for a wide range of classification tasks including sentiment prediction, filtering of spam, classifying documents and more.","Latent semantic indexing is a mathematical technique used to improve the accuracy of the information retrieval process. The design of LSI algorithms allows machines to detect the hidden (latent) correlation between semantics (words). To enhance information understanding, machines generate various concepts that associate with the words of a sentence.",0
What is Latent Semantic Indexing (LSI)?,"Naive Bayes Classifier Algorithm is a family of probabilistic algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of a feature.
Bayes theorem calculates probability P(c|x) where c is the class of the possible outcomes and x is the given instance which has to be classified, representing some certain features.",Latent Semantic Indexing is an indexing and retrieval method that uses a mathematical technique called Singular value decomposition (SVD) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text. LSI is based on the principle that words that are used in the same contexts tend to have similar meanings,0
What is Naive Bayes algorithm?,"Naive Bayes algorithm is a collection of classifiers which works on the principles of the Bayes’ theorem. This series of NLP model forms a family of algorithms that can be used for a wide range of classification tasks including sentiment prediction, filtering of spam, classifying documents and more.","Naive Bayes is a family of algorithms that take advantage of probability theory and Bayes’ Theorem to predict the tag of a text (like a piece of news or a customer review). They are probabilistic, which means that they calculate the probability of each tag for a given text, and then output the tag with the highest one. The way they get these probabilities is by using Bayes’ Theorem, which describes the probability of a feature, based on prior knowledge of conditions that might be related to that feature.",1
What is Naive Bayes algorithm?,"Naive Bayes algorithm is a collection of classifiers which works on the principles of the Bayes’ theorem. This series of NLP model forms a family of algorithms that can be used for a wide range of classification tasks including sentiment prediction, filtering of spam, classifying documents and more.","Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.",0
What is Pragmatic Ambiguity?,"Naive Bayes is a family of algorithms that take advantage of probability theory and Bayes’ Theorem to predict the tag of a text (like a piece of news or a customer review). They are probabilistic, which means that they calculate the probability of each tag for a given text, and then output the tag with the highest one. The way they get these probabilities is by using Bayes’ Theorem, which describes the probability of a feature, based on prior knowledge of conditions that might be related to that feature.",Pragmatic ambiguity refers to a situation where the context of a phrase gives it multiple interpretation,0
What is Naive Bayes algorithm?,"Naive Bayes Classifier Algorithm is a family of probabilistic algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of a feature.
Bayes theorem calculates probability P(c|x) where c is the class of the possible outcomes and x is the given instance which has to be classified, representing some certain features.","Naive Bayes is a family of algorithms that take advantage of probability theory and Bayes’ Theorem to predict the tag of a text (like a piece of news or a customer review). They are probabilistic, which means that they calculate the probability of each tag for a given text, and then output the tag with the highest one. The way they get these probabilities is by using Bayes’ Theorem, which describes the probability of a feature, based on prior knowledge of conditions that might be related to that feature.",1
What is Naive Bayes algorithm?,"Naive Bayes Classifier Algorithm is a family of probabilistic algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of a feature.
Bayes theorem calculates probability P(c|x) where c is the class of the possible outcomes and x is the given instance which has to be classified, representing some certain features.","Text mining, also referred to as text data mining, roughly equivalent to text analytics, is the process of deriving high-quality information from text. High-quality information is typically derived through the devising of patterns and trends through means such as statistical pattern learning.",0
What is text mining ?,"Naive Bayes is a family of algorithms that take advantage of probability theory and Bayes’ Theorem to predict the tag of a text (like a piece of news or a customer review). They are probabilistic, which means that they calculate the probability of each tag for a given text, and then output the tag with the highest one. The way they get these probabilities is by using Bayes’ Theorem, which describes the probability of a feature, based on prior knowledge of conditions that might be related to that feature.","Text mining (also referred to as text analytics) is an artificial intelligence (AI) technology that uses natural language processing (NLP) to transform the free (unstructured) text in documents and databases into normalized, structured data suitable for analysis or to drive machine learning (ML) algorithms.",0
What is perplexity in NLP?,"In NLP, perplexity is a way of evaluating language models. Perplexity can be high and low; Low perplexity is ethical because the inability to deal with any complicated problem is less while high perplexity is terrible because the failure to deal with a complicated is high.","In general, perplexity is a measurement of how well a probability model predicts a sample. In the context of Natural Language Processing, perplexity is one way to evaluate language models.",1
What is perplexity in NLP?,"In NLP, perplexity is a way of evaluating language models. Perplexity can be high and low; Low perplexity is ethical because the inability to deal with any complicated problem is less while high perplexity is terrible because the failure to deal with a complicated is high.",Pragmatic analysis is an important task in NLP for interpreting knowledge that is lying outside a given document. The aim of implementing pragmatic analysis is to focus on exploring a different aspect of the document or text in a language. This requires a comprehensive knowledge of the real world. The pragmatic analysis allows software applications for the critical interpretation of the real-world data to know the actual meaning of sentences and words.,0
What is Pragmatic Analysis?,"In general, perplexity is a measurement of how well a probability model predicts a sample. In the context of Natural Language Processing, perplexity is one way to evaluate language models.",pramatic Analysis is the structure representing what was said is reinterpreted to determine what was actually meant,0
What is perplexity in NLP?,"In NLP, perplexity is a way of evaluating language models. Perplexity can be high and low; Low perplexity is ethical because the inability to deal with any complicated problem is less while high perplexity is terrible because the failure to deal with a complicated is high.","perplexity metric in NLP is a way to capture the degree of 'uncertainty' a model has in predicting (assigning probabilities to) some text. If a model, which is trained on good blogs and is being evaluated on similarly looking good blogs, assigns higher probability, we say the model has lower perplexity than a model which assigns lower probability.",1
What is perplexity in NLP?,"In NLP, perplexity is a way of evaluating language models. Perplexity can be high and low; Low perplexity is ethical because the inability to deal with any complicated problem is less while high perplexity is terrible because the failure to deal with a complicated is high.","We use stemming and lemmatization to extract root words. However, stemming may not give the actual word, whereas lemmatization generates a meaningful word. In lemmatization, rather than just removing the suffix and the prefix, the process tries to find out the root word with its proper meaning. for example, Bricks’ becomes ‘brick,’ ‘corpora’ becomes ‘corpus’.",0
Explain Lemmatization with the help of an example,"perplexity metric in NLP is a way to capture the degree of 'uncertainty' a model has in predicting (assigning probabilities to) some text. If a model, which is trained on good blogs and is being evaluated on similarly looking good blogs, assigns higher probability, we say the model has lower perplexity than a model which assigns lower probability.","I would explain lemmatization as returning different forms of a single word to its root form. It is not only applicable to nouns. Lemmatization works the same way for adjectives, action verbs, all the same. Such as: Constructing – (Lemmatization) -> Construct, Extracts – (Lemmatization) -> Extract",0
What is perplexity in NLP?,"In NLP, perplexity is a way of evaluating language models. Perplexity can be high and low; Low perplexity is ethical because the inability to deal with any complicated problem is less while high perplexity is terrible because the failure to deal with a complicated is high.",it is a process to th behavior of the model. Low perplexity is good and high perplexity is bad since the perplexity is the exponentiation of the entropy,1
What is perplexity in NLP?,"In NLP, perplexity is a way of evaluating language models. Perplexity can be high and low; Low perplexity is ethical because the inability to deal with any complicated problem is less while high perplexity is terrible because the failure to deal with a complicated is high.","Natural language processing is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.",0
What do you understand by Natural Language Processing?,it is a process to th behavior of the model. Low perplexity is good and high perplexity is bad since the perplexity is the exponentiation of the entropy,"Natural language processing  is the relationship between computers and human language. More specifically, natural language processing is the computer understanding, analysis, manipulation, and/or generation of natural language.",0
What is perplexity in NLP?,"In NLP, perplexity is a way of evaluating language models. Perplexity can be high and low; Low perplexity is ethical because the inability to deal with any complicated problem is less while high perplexity is terrible because the failure to deal with a complicated is high.",Perplexity is a way to express a degree of confusion a model has in predicting. More entropy equal to more confusion. Perplexity is used to evaluate language models in NLP. A good language model assigns a higher probability to the right prediction.,1
What is perplexity in NLP?,"In NLP, perplexity is a way of evaluating language models. Perplexity can be high and low; Low perplexity is ethical because the inability to deal with any complicated problem is less while high perplexity is terrible because the failure to deal with a complicated is high.","Latent semantic indexing is a mathematical technique used to improve the accuracy of the information retrieval process. The design of LSI algorithms allows machines to detect the hidden (latent) correlation between semantics (words). To enhance information understanding, machines generate various concepts that associate with the words of a sentence.",0
What is Latent Semantic Indexing (LSI)?,Perplexity is a way to express a degree of confusion a model has in predicting. More entropy equal to more confusion. Perplexity is used to evaluate language models in NLP. A good language model assigns a higher probability to the right prediction.,Latent Semantic Indexing is an indexing and retrieval method that uses a mathematical technique called Singular value decomposition (SVD) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text. LSI is based on the principle that words that are used in the same contexts tend to have similar meanings,0
What is perplexity in NLP?,"In general, perplexity is a measurement of how well a probability model predicts a sample. In the context of Natural Language Processing, perplexity is one way to evaluate language models.","perplexity metric in NLP is a way to capture the degree of 'uncertainty' a model has in predicting (assigning probabilities to) some text. If a model, which is trained on good blogs and is being evaluated on similarly looking good blogs, assigns higher probability, we say the model has lower perplexity than a model which assigns lower probability.",1
What is perplexity in NLP?,"In general, perplexity is a measurement of how well a probability model predicts a sample. In the context of Natural Language Processing, perplexity is one way to evaluate language models.",Transformer models are essentially attention based models. They see the entire sentence as a whole unlike LSTMs (or in general RNNs) where the sentence is processed sequentially - one word per time step. During training LSTMs need to propagate the error back in time through words one word at a time. Transformer sees all words simultaneously - so there is no backpropagation through time.,0
Why transformer perform better than LSTM?,"perplexity metric in NLP is a way to capture the degree of 'uncertainty' a model has in predicting (assigning probabilities to) some text. If a model, which is trained on good blogs and is being evaluated on similarly looking good blogs, assigns higher probability, we say the model has lower perplexity than a model which assigns lower probability.","RNN is not very efficient in handling long sequences. The model tends to forget the contents of the distant position or, in some cases, mixes the contents of adjacent positions: the more the steps, the more challenging for the recurrent network to make decisions. The Long Short Term Memory (LSTM) offers a slight improvement over conventional RNN. It can also eliminate the vanishing gradient problem that RNN suffers from. Transformer avoids recursion by processing sentences as whole using attention mechanisms and positional embeddings.",0
What is perplexity in NLP?,"In general, perplexity is a measurement of how well a probability model predicts a sample. In the context of Natural Language Processing, perplexity is one way to evaluate language models.",it is a process to th behavior of the model. Low perplexity is good and high perplexity is bad since the perplexity is the exponentiation of the entropy,1
What is perplexity in NLP?,"In general, perplexity is a measurement of how well a probability model predicts a sample. In the context of Natural Language Processing, perplexity is one way to evaluate language models.","Parsing allows the machine to understand the meaning of a word in a sentence and the grouping of words, phrases, nouns, subjects, and objects in a sentence.",0
What is Parsing in the context of NLP?,it is a process to th behavior of the model. Low perplexity is good and high perplexity is bad since the perplexity is the exponentiation of the entropy,It helps analyze the text or the document to extract useful insights from it.,0
What is perplexity in NLP?,"In general, perplexity is a measurement of how well a probability model predicts a sample. In the context of Natural Language Processing, perplexity is one way to evaluate language models.",Perplexity is a way to express a degree of confusion a model has in predicting. More entropy equal to more confusion. Perplexity is used to evaluate language models in NLP. A good language model assigns a higher probability to the right prediction.,1
What is perplexity in NLP?,"In general, perplexity is a measurement of how well a probability model predicts a sample. In the context of Natural Language Processing, perplexity is one way to evaluate language models.","Transformers are better than all the other architectures because they totally avoid recursion, by processing sentences as a whole and by learning relationships between words thank's to multi-head attention mechanisms and positional embeddings.",0
Why transformer perform better than LSTM?,Perplexity is a way to express a degree of confusion a model has in predicting. More entropy equal to more confusion. Perplexity is used to evaluate language models in NLP. A good language model assigns a higher probability to the right prediction.,"RNN is not very efficient in handling long sequences. The model tends to forget the contents of the distant position or, in some cases, mixes the contents of adjacent positions: the more the steps, the more challenging for the recurrent network to make decisions. The Long Short Term Memory (LSTM) offers a slight improvement over conventional RNN. It can also eliminate the vanishing gradient problem that RNN suffers from. Transformer avoids recursion by processing sentences as whole using attention mechanisms and positional embeddings.",0
What is perplexity in NLP?,"perplexity metric in NLP is a way to capture the degree of 'uncertainty' a model has in predicting (assigning probabilities to) some text. If a model, which is trained on good blogs and is being evaluated on similarly looking good blogs, assigns higher probability, we say the model has lower perplexity than a model which assigns lower probability.",it is a process to th behavior of the model. Low perplexity is good and high perplexity is bad since the perplexity is the exponentiation of the entropy,1
What is perplexity in NLP?,"perplexity metric in NLP is a way to capture the degree of 'uncertainty' a model has in predicting (assigning probabilities to) some text. If a model, which is trained on good blogs and is being evaluated on similarly looking good blogs, assigns higher probability, we say the model has lower perplexity than a model which assigns lower probability.","Stemming is one of the most common data pre-processing operations we do in almost all Natural Language Processing. It is the process of removing a part of a word, or reducing a word to its stem or root. For example, the stem of the words eating, eats, eaten is eat.",0
Explain Stemming with the help of an example.,it is a process to th behavior of the model. Low perplexity is good and high perplexity is bad since the perplexity is the exponentiation of the entropy,"Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language. As converting the words Playing, played, plays to play.",0
What is perplexity in NLP?,"perplexity metric in NLP is a way to capture the degree of 'uncertainty' a model has in predicting (assigning probabilities to) some text. If a model, which is trained on good blogs and is being evaluated on similarly looking good blogs, assigns higher probability, we say the model has lower perplexity than a model which assigns lower probability.",Perplexity is a way to express a degree of confusion a model has in predicting. More entropy equal to more confusion. Perplexity is used to evaluate language models in NLP. A good language model assigns a higher probability to the right prediction.,1
What is perplexity in NLP?,"perplexity metric in NLP is a way to capture the degree of 'uncertainty' a model has in predicting (assigning probabilities to) some text. If a model, which is trained on good blogs and is being evaluated on similarly looking good blogs, assigns higher probability, we say the model has lower perplexity than a model which assigns lower probability.",It helps analyze the text or the document to extract useful insights from it.,0
What is Parsing in the context of NLP?,Perplexity is a way to express a degree of confusion a model has in predicting. More entropy equal to more confusion. Perplexity is used to evaluate language models in NLP. A good language model assigns a higher probability to the right prediction.,It is the process of determining the syntactic structure of a text by analyzing its constituent words based on an underlying grammar (of the language),0
What is ngram in NLP?,"N-gram in NLP is simply a sequence of n words, and we also conclude the sentences which appeared more frequently. for example, let us consider: New York consider as 2 gram and The Golden Compass is 3 gram",They are basically a set of co-occurring words within a given window and when computing the n-grams you typically move one word forward,1
What is ngram in NLP?,"N-gram in NLP is simply a sequence of n words, and we also conclude the sentences which appeared more frequently. for example, let us consider: New York consider as 2 gram and The Golden Compass is 3 gram",It is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category,0
Explain Named Entity Recognition,They are basically a set of co-occurring words within a given window and when computing the n-grams you typically move one word forward,"It is an AI technique that automatically identifies named entities in a text and classifies them into predefined categories. Entities can be names of people, organizations, locations, times, quantities, monetary values, percentages, and more",0
What is ngram in NLP?,"N-gram in NLP is simply a sequence of n words, and we also conclude the sentences which appeared more frequently. for example, let us consider: New York consider as 2 gram and The Golden Compass is 3 gram","An N-gram language model predicts the probability of a given N-gram within any sequence of words in the language. If we have a good N-gram model, we can predict p(w | h) – what is the probability of seeing the word w given a history of previous words h – where the history contains n-1 words.",1
What is ngram in NLP?,"N-gram in NLP is simply a sequence of n words, and we also conclude the sentences which appeared more frequently. for example, let us consider: New York consider as 2 gram and The Golden Compass is 3 gram","Named Entity Recognition (NER) is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text.",0
Explain Named Entity Recognition,"An N-gram language model predicts the probability of a given N-gram within any sequence of words in the language. If we have a good N-gram model, we can predict p(w | h) – what is the probability of seeing the word w given a history of previous words h – where the history contains n-1 words.","Named Entity Recognition is a process where a sentence or a chunk of text is parsed through to find entities that can be put under categories like names, organizations, locations, quantities, monetary values, percentages, etc.",0
What is ngram in NLP?,"N-gram in NLP is simply a sequence of n words, and we also conclude the sentences which appeared more frequently. for example, let us consider: New York consider as 2 gram and The Golden Compass is 3 gram","The basic point of n-grams is that they capture the language structure from the statistical point of view, like what letter or word is likely to follow the given one. The longer the n-gram (the higher the n), the more context you have to work with.",1
What is ngram in NLP?,"N-gram in NLP is simply a sequence of n words, and we also conclude the sentences which appeared more frequently. for example, let us consider: New York consider as 2 gram and The Golden Compass is 3 gram","Cell state is a memory of LSTM cell, hidden state is an output of this cell. Hidden state and cell input are used to control what to do with memory: to forget or to write new information. We decide what to do with memory knowing about previous output (hidden state) and current input.",0
What is the information in hidden and cell state of LSTM?,"The basic point of n-grams is that they capture the language structure from the statistical point of view, like what letter or word is likely to follow the given one. The longer the n-gram (the higher the n), the more context you have to work with.","hidden state is Working memory capability that carries information from immediately previous events and overwrites at every step uncontrollably -present at RNNs and LSTMs
cell state is long term memory capability that stores and loads information of not necessarily immediately previous events
present in LSTMs",0
What is ngram in NLP?,They are basically a set of co-occurring words within a given window and when computing the n-grams you typically move one word forward,"An N-gram language model predicts the probability of a given N-gram within any sequence of words in the language. If we have a good N-gram model, we can predict p(w | h) – what is the probability of seeing the word w given a history of previous words h – where the history contains n-1 words.",1
What is ngram in NLP?,They are basically a set of co-occurring words within a given window and when computing the n-grams you typically move one word forward,"Named Entity Recognition (NER) is an information retrieval process. NER helps classify named entities such as monetary figures, location, things, people, time, and more. It allows the software to analyze and understand the meaning of the text.",0
What is ngram in NLP?,They are basically a set of co-occurring words within a given window and when computing the n-grams you typically move one word forward,"The basic point of n-grams is that they capture the language structure from the statistical point of view, like what letter or word is likely to follow the given one. The longer the n-gram (the higher the n), the more context you have to work with.",1
What is ngram in NLP?,They are basically a set of co-occurring words within a given window and when computing the n-grams you typically move one word forward,"The problem of Relu. First, Exploding gradient and this Solved by gradient clipping. Second, Dying ReLu — No learning if the activation is 0 (Solved by parametric relu). Third, Mean and variance of activations is not 0 and 1.(Partially solved by subtracting around 0.5 from activation. Better explained in fastai videos).",0
What is the problem with ReLu?,"The basic point of n-grams is that they capture the language structure from the statistical point of view, like what letter or word is likely to follow the given one. The longer the n-gram (the higher the n), the more context you have to work with.","ReLU units can be fragile during training and can ""die"". For example, a large gradient flowing through a ReLU neuron could cause the weights to update in such a way that the neuron will never activate on any datapoint again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. That is, the ReLU units can irreversibly die during training since they can get knocked off the data manifold.",0
What is ngram in NLP?,"An N-gram language model predicts the probability of a given N-gram within any sequence of words in the language. If we have a good N-gram model, we can predict p(w | h) – what is the probability of seeing the word w given a history of previous words h – where the history contains n-1 words.","The basic point of n-grams is that they capture the language structure from the statistical point of view, like what letter or word is likely to follow the given one. The longer the n-gram (the higher the n), the more context you have to work with.",1
What is ngram in NLP?,"An N-gram language model predicts the probability of a given N-gram within any sequence of words in the language. If we have a good N-gram model, we can predict p(w | h) – what is the probability of seeing the word w given a history of previous words h – where the history contains n-1 words.","We use stemming and lemmatization to extract root words. However, stemming may not give the actual word, whereas lemmatization generates a meaningful word. In lemmatization, rather than just removing the suffix and the prefix, the process tries to find out the root word with its proper meaning. for example, Bricks’ becomes ‘brick,’ ‘corpora’ becomes ‘corpus’.",0
Explain Lemmatization with the help of an example,"The basic point of n-grams is that they capture the language structure from the statistical point of view, like what letter or word is likely to follow the given one. The longer the n-gram (the higher the n), the more context you have to work with.","It generally means to do the things properly with the use of vocabulary and morphological analysis of words. In this process, the endings of the words are removed to return the base word, which is also known as Lemma. Example: boy’s = boy, cars= car, colors= color.",0
What is the problem with ReLu?,"The problem of Relu. First, Exploding gradient and this Solved by gradient clipping. Second, Dying ReLu — No learning if the activation is 0 (Solved by parametric relu). Third, Mean and variance of activations is not 0 and 1.(Partially solved by subtracting around 0.5 from activation. Better explained in fastai videos).","ReLU units can be fragile during training and can ""die"". For example, a large gradient flowing through a ReLU neuron could cause the weights to update in such a way that the neuron will never activate on any datapoint again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. That is, the ReLU units can irreversibly die during training since they can get knocked off the data manifold.",1
What is the problem with ReLu?,"The problem of Relu. First, Exploding gradient and this Solved by gradient clipping. Second, Dying ReLu — No learning if the activation is 0 (Solved by parametric relu). Third, Mean and variance of activations is not 0 and 1.(Partially solved by subtracting around 0.5 from activation. Better explained in fastai videos).","Natural language processing is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.",0
What do you understand by Natural Language Processing?,"ReLU units can be fragile during training and can ""die"". For example, a large gradient flowing through a ReLU neuron could cause the weights to update in such a way that the neuron will never activate on any datapoint again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. That is, the ReLU units can irreversibly die during training since they can get knocked off the data manifold.",Natural language processing is the ability of a computer program to understand human language as it is spoken. NLP is a component of artificial intelligence. It allows machines to break down and interpret human language.,0
What is the problem with ReLu?,"The problem of Relu. First, Exploding gradient and this Solved by gradient clipping. Second, Dying ReLu — No learning if the activation is 0 (Solved by parametric relu). Third, Mean and variance of activations is not 0 and 1.(Partially solved by subtracting around 0.5 from activation. Better explained in fastai videos).","let's say the inputs to Relu are now distributed as a low-variance Gaussian centered at -0.1. we have that Most inputs to Relu are negative, thus Most inputs will cause the ReLU gate to be closed, thus Most inputs will cause gradients to fail to flow backwards through Relu thus Relu's inputs are usually not updated through SGD backprop.",1
What is the problem with ReLu?,"The problem of Relu. First, Exploding gradient and this Solved by gradient clipping. Second, Dying ReLu — No learning if the activation is 0 (Solved by parametric relu). Third, Mean and variance of activations is not 0 and 1.(Partially solved by subtracting around 0.5 from activation. Better explained in fastai videos).","In terms of computational complexity, self-attention layers are faster than recurrent layers when the sequence length n is smaller than the representation dimensionality d, which is most often the case with sentence representations used by state-of-the-art models in machine translations, such as word-piece and byte-pair representations.",0
Why self-attention is awesome?,"let's say the inputs to Relu are now distributed as a low-variance Gaussian centered at -0.1. we have that Most inputs to Relu are negative, thus Most inputs will cause the ReLU gate to be closed, thus Most inputs will cause gradients to fail to flow backwards through Relu thus Relu's inputs are usually not updated through SGD backprop.","self-attention Minimizes total computational complexity per layer. Maximizes amount of parallelizable computations, measured by minimum number of sequential operations required. Minimizes maximum path length between any two input and output positions in network composed of the different layer types . The shorter the path between any combination of positions in the input and output sequences, the easier to learn long-range dependencies.",0
What is the problem with ReLu?,"The problem of Relu. First, Exploding gradient and this Solved by gradient clipping. Second, Dying ReLu — No learning if the activation is 0 (Solved by parametric relu). Third, Mean and variance of activations is not 0 and 1.(Partially solved by subtracting around 0.5 from activation. Better explained in fastai videos).","ReLU neurons output zero and have zero derivatives for all negative inputs. So, if the weights in your network always lead to negative inputs into a ReLU neuron, that neuron is effectively not contributing to the network's training. Mathematically, the gradient contribution to the weight updates coming from that neuron is always zero",1
What is the problem with ReLu?,"The problem of Relu. First, Exploding gradient and this Solved by gradient clipping. Second, Dying ReLu — No learning if the activation is 0 (Solved by parametric relu). Third, Mean and variance of activations is not 0 and 1.(Partially solved by subtracting around 0.5 from activation. Better explained in fastai videos).","NLP is a big field and covers things from very ML-like (classifiers with bag of words features) to not at all ML-like (machine translation). You need to spend some time on a survey of NLP problems, then zero in on the ones you care about, which may or may not involve the methods you're familiar with.",0
Why is NLP so hard?,"ReLU neurons output zero and have zero derivatives for all negative inputs. So, if the weights in your network always lead to negative inputs into a ReLU neuron, that neuron is effectively not contributing to the network's training. Mathematically, the gradient contribution to the weight updates coming from that neuron is always zero","NLP is so hard because of many reasons. For example, Knowledge of the world is still difficult for computers to acquire, It is hard to understand whether two sentences or two concepts are equal, and Optimizing the wrong metrics",0
What is the problem with ReLu?,"The problem of Relu. First, Exploding gradient and this Solved by gradient clipping. Second, Dying ReLu — No learning if the activation is 0 (Solved by parametric relu). Third, Mean and variance of activations is not 0 and 1.(Partially solved by subtracting around 0.5 from activation. Better explained in fastai videos).","The dying ReLU refers to the problem when ReLU neurons become inactive and only output 0 for any input. So, once a neuron gets negative input, it will always output zero and is unlikely for it to recover. It will become inactive forever. Such neurons will not play any role in discriminating the input and become useless in the neural network. If this process continues, over the time you may end up with a large part of your network doing nothing.",1
What is the problem with ReLu?,"The problem of Relu. First, Exploding gradient and this Solved by gradient clipping. Second, Dying ReLu — No learning if the activation is 0 (Solved by parametric relu). Third, Mean and variance of activations is not 0 and 1.(Partially solved by subtracting around 0.5 from activation. Better explained in fastai videos).","With named entity recognition, you can extract key information to understand what a text is about, or merely use it to collect important information to store in a database. Keys as names, organization, locations.",0
Explain Named Entity Recognition,"The dying ReLU refers to the problem when ReLU neurons become inactive and only output 0 for any input. So, once a neuron gets negative input, it will always output zero and is unlikely for it to recover. It will become inactive forever. Such neurons will not play any role in discriminating the input and become useless in the neural network. If this process continues, over the time you may end up with a large part of your network doing nothing.","Named Entity Recognition is a process where a sentence or a chunk of text is parsed through to find entities that can be put under categories like names, organizations, locations, quantities, monetary values, percentages, etc.",0
What is the problem with ReLu?,"ReLU units can be fragile during training and can ""die"". For example, a large gradient flowing through a ReLU neuron could cause the weights to update in such a way that the neuron will never activate on any datapoint again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. That is, the ReLU units can irreversibly die during training since they can get knocked off the data manifold.","let's say the inputs to Relu are now distributed as a low-variance Gaussian centered at -0.1. we have that Most inputs to Relu are negative, thus Most inputs will cause the ReLU gate to be closed, thus Most inputs will cause gradients to fail to flow backwards through Relu thus Relu's inputs are usually not updated through SGD backprop.",1
What is the problem with ReLu?,"ReLU units can be fragile during training and can ""die"". For example, a large gradient flowing through a ReLU neuron could cause the weights to update in such a way that the neuron will never activate on any datapoint again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. That is, the ReLU units can irreversibly die during training since they can get knocked off the data manifold.","Bag of words is a way of extracting features from text for use in modeling, such as with machine learning algorithms.It is a representation of text that describes the occurrence of words within a document.",0
What is Bag of Words?,"let's say the inputs to Relu are now distributed as a low-variance Gaussian centered at -0.1. we have that Most inputs to Relu are negative, thus Most inputs will cause the ReLU gate to be closed, thus Most inputs will cause gradients to fail to flow backwards through Relu thus Relu's inputs are usually not updated through SGD backprop.","In this model, a text (such as a sentence or a document) is represented as the bag of its words, disregarding grammar and even word order but keeping multiplicity. The bag of words model is commonly used in methods of document classification where the (frequency of) occurrence of each word is used as a feature for training a classifier.",0
What is the problem with ReLu?,"ReLU units can be fragile during training and can ""die"". For example, a large gradient flowing through a ReLU neuron could cause the weights to update in such a way that the neuron will never activate on any datapoint again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. That is, the ReLU units can irreversibly die during training since they can get knocked off the data manifold.","ReLU neurons output zero and have zero derivatives for all negative inputs. So, if the weights in your network always lead to negative inputs into a ReLU neuron, that neuron is effectively not contributing to the network's training. Mathematically, the gradient contribution to the weight updates coming from that neuron is always zero",1
What is the problem with ReLu?,"ReLU units can be fragile during training and can ""die"". For example, a large gradient flowing through a ReLU neuron could cause the weights to update in such a way that the neuron will never activate on any datapoint again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. That is, the ReLU units can irreversibly die during training since they can get knocked off the data manifold.","Pragmatic analysis deals with outside word knowledge, which means knowledge that is external to the documents and/or queries. Pragmatics analysis that focuses on what was described is reinterpreted by what it actually meant, deriving the various aspects of language that require real world knowledge.",0
What is Pragmatic Analysis?,"ReLU neurons output zero and have zero derivatives for all negative inputs. So, if the weights in your network always lead to negative inputs into a ReLU neuron, that neuron is effectively not contributing to the network's training. Mathematically, the gradient contribution to the weight updates coming from that neuron is always zero","Pragmatic levels of NLP deal with the real-world meanings of communication. Not only can it breakdowns the meanings of individual words and sentences, but it can also decide what the purpose of those words and sentences are. Context is massively influential in this step, and it is something that computers only ever understand through deep learning.",0
What is the problem with ReLu?,"ReLU units can be fragile during training and can ""die"". For example, a large gradient flowing through a ReLU neuron could cause the weights to update in such a way that the neuron will never activate on any datapoint again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. That is, the ReLU units can irreversibly die during training since they can get knocked off the data manifold.","The dying ReLU refers to the problem when ReLU neurons become inactive and only output 0 for any input. So, once a neuron gets negative input, it will always output zero and is unlikely for it to recover. It will become inactive forever. Such neurons will not play any role in discriminating the input and become useless in the neural network. If this process continues, over the time you may end up with a large part of your network doing nothing.",1
What is the problem with ReLu?,"ReLU units can be fragile during training and can ""die"". For example, a large gradient flowing through a ReLU neuron could cause the weights to update in such a way that the neuron will never activate on any datapoint again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. That is, the ReLU units can irreversibly die during training since they can get knocked off the data manifold.","Stop words are said to be useless data for a search engine. There are stop words such as was, were, is, am, the, a, an, how, why, and many more. In Natural Language Processing, we eliminate the stop words to understand and analyze the meaning of a sentence.",0
What are stop words?,"The dying ReLU refers to the problem when ReLU neurons become inactive and only output 0 for any input. So, once a neuron gets negative input, it will always output zero and is unlikely for it to recover. It will become inactive forever. Such neurons will not play any role in discriminating the input and become useless in the neural network. If this process continues, over the time you may end up with a large part of your network doing nothing.","A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.",0
What is the problem with ReLu?,"let's say the inputs to Relu are now distributed as a low-variance Gaussian centered at -0.1. we have that Most inputs to Relu are negative, thus Most inputs will cause the ReLU gate to be closed, thus Most inputs will cause gradients to fail to flow backwards through Relu thus Relu's inputs are usually not updated through SGD backprop.","ReLU neurons output zero and have zero derivatives for all negative inputs. So, if the weights in your network always lead to negative inputs into a ReLU neuron, that neuron is effectively not contributing to the network's training. Mathematically, the gradient contribution to the weight updates coming from that neuron is always zero",1
What is the problem with ReLu?,"let's say the inputs to Relu are now distributed as a low-variance Gaussian centered at -0.1. we have that Most inputs to Relu are negative, thus Most inputs will cause the ReLU gate to be closed, thus Most inputs will cause gradients to fail to flow backwards through Relu thus Relu's inputs are usually not updated through SGD backprop.",It is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category,0
Explain Named Entity Recognition,"ReLU neurons output zero and have zero derivatives for all negative inputs. So, if the weights in your network always lead to negative inputs into a ReLU neuron, that neuron is effectively not contributing to the network's training. Mathematically, the gradient contribution to the weight updates coming from that neuron is always zero","It is an AI technique that automatically identifies named entities in a text and classifies them into predefined categories. Entities can be names of people, organizations, locations, times, quantities, monetary values, percentages, and more",0
What is the problem with ReLu?,"let's say the inputs to Relu are now distributed as a low-variance Gaussian centered at -0.1. we have that Most inputs to Relu are negative, thus Most inputs will cause the ReLU gate to be closed, thus Most inputs will cause gradients to fail to flow backwards through Relu thus Relu's inputs are usually not updated through SGD backprop.","The dying ReLU refers to the problem when ReLU neurons become inactive and only output 0 for any input. So, once a neuron gets negative input, it will always output zero and is unlikely for it to recover. It will become inactive forever. Such neurons will not play any role in discriminating the input and become useless in the neural network. If this process continues, over the time you may end up with a large part of your network doing nothing.",1
What is the problem with ReLu?,"let's say the inputs to Relu are now distributed as a low-variance Gaussian centered at -0.1. we have that Most inputs to Relu are negative, thus Most inputs will cause the ReLU gate to be closed, thus Most inputs will cause gradients to fail to flow backwards through Relu thus Relu's inputs are usually not updated through SGD backprop.","We use stemming and lemmatization to extract root words. However, stemming may not give the actual word, whereas lemmatization generates a meaningful word. In lemmatization, rather than just removing the suffix and the prefix, the process tries to find out the root word with its proper meaning. for example, Bricks’ becomes ‘brick,’ ‘corpora’ becomes ‘corpus’.",0
Explain Lemmatization with the help of an example,"The dying ReLU refers to the problem when ReLU neurons become inactive and only output 0 for any input. So, once a neuron gets negative input, it will always output zero and is unlikely for it to recover. It will become inactive forever. Such neurons will not play any role in discriminating the input and become useless in the neural network. If this process continues, over the time you may end up with a large part of your network doing nothing.","I would explain lemmatization as returning different forms of a single word to its root form. It is not only applicable to nouns. Lemmatization works the same way for adjectives, action verbs, all the same. Such as: Constructing – (Lemmatization) -> Construct, Extracts – (Lemmatization) -> Extract",0
What is the problem with ReLu?,"ReLU neurons output zero and have zero derivatives for all negative inputs. So, if the weights in your network always lead to negative inputs into a ReLU neuron, that neuron is effectively not contributing to the network's training. Mathematically, the gradient contribution to the weight updates coming from that neuron is always zero","The dying ReLU refers to the problem when ReLU neurons become inactive and only output 0 for any input. So, once a neuron gets negative input, it will always output zero and is unlikely for it to recover. It will become inactive forever. Such neurons will not play any role in discriminating the input and become useless in the neural network. If this process continues, over the time you may end up with a large part of your network doing nothing.",1
What is the problem with ReLu?,"ReLU neurons output zero and have zero derivatives for all negative inputs. So, if the weights in your network always lead to negative inputs into a ReLU neuron, that neuron is effectively not contributing to the network's training. Mathematically, the gradient contribution to the weight updates coming from that neuron is always zero","Regular grammar is used to represent a regular language. A regular grammar comprises rules in the form of A -> a, A -> aB, and many more. The rules help detect and analyze strings by automated computation.",0
What is Regular Grammar?,"The dying ReLU refers to the problem when ReLU neurons become inactive and only output 0 for any input. So, once a neuron gets negative input, it will always output zero and is unlikely for it to recover. It will become inactive forever. Such neurons will not play any role in discriminating the input and become useless in the neural network. If this process continues, over the time you may end up with a large part of your network doing nothing.",A grammar is regular if it has rules of form A -> a or A -> aB or A -> ɛ where ɛ is a special symbol called NULL.,0
Why self-attention is awesome?,"In terms of computational complexity, self-attention layers are faster than recurrent layers when the sequence length n is smaller than the representation dimensionality d, which is most often the case with sentence representations used by state-of-the-art models in machine translations, such as word-piece and byte-pair representations.","self-attention Minimizes total computational complexity per layer. Maximizes amount of parallelizable computations, measured by minimum number of sequential operations required. Minimizes maximum path length between any two input and output positions in network composed of the different layer types . The shorter the path between any combination of positions in the input and output sequences, the easier to learn long-range dependencies.",1
Why self-attention is awesome?,"In terms of computational complexity, self-attention layers are faster than recurrent layers when the sequence length n is smaller than the representation dimensionality d, which is most often the case with sentence representations used by state-of-the-art models in machine translations, such as word-piece and byte-pair representations.","BatchNorm — Compute the mean and var at each layer for every minibatch
LayerNorm — Compute the mean and var for every single sample for each layer independently",0
Difference between BatchNorm and LayerNorm?,"self-attention Minimizes total computational complexity per layer. Maximizes amount of parallelizable computations, measured by minimum number of sequential operations required. Minimizes maximum path length between any two input and output positions in network composed of the different layer types . The shorter the path between any combination of positions in the input and output sequences, the easier to learn long-range dependencies.","BatchNorm: Normalize the batch direction and count The mean value of W is not good for small batchsize; the main disadvantage of BN is that it is more sensitive to the size of batchsize. Since the mean and variance are calculated on one batch each time, if the batchsize is too small, the calculated mean and variance are not enough to represent The entire data distribution.
LayerNorm: Normalize the channel direction and count as CHThe mean value of W is mainly effective for RNN;",0
What are the limitation of Adam optimiser?,"While training with Adam helps in getting fast convergence, the resulting model will often have worse generalization performance than when training with SGD with momentum. Another issue is that even though Adam has adaptive learning rates its performance improves when using a good learning rate schedule. Especially early in the training, it is beneficial to use a lower learning rate to avoid divergence.","There are few disadvantages as the Adam optimizer tends to converge faster, but other algorithms like the Stochastic gradient descent focus on the datapoints and generalize in a better manner. Thus, the performance depends on the type of data being provided and the speed/generalization trade-off.",1
What are the limitation of Adam optimiser?,"While training with Adam helps in getting fast convergence, the resulting model will often have worse generalization performance than when training with SGD with momentum. Another issue is that even though Adam has adaptive learning rates its performance improves when using a good learning rate schedule. Especially early in the training, it is beneficial to use a lower learning rate to avoid divergence.","In NLP, perplexity is a way of evaluating language models. Perplexity can be high and low; Low perplexity is ethical because the inability to deal with any complicated problem is less while high perplexity is terrible because the failure to deal with a complicated is high.",0
What is perplexity in NLP?,"There are few disadvantages as the Adam optimizer tends to converge faster, but other algorithms like the Stochastic gradient descent focus on the datapoints and generalize in a better manner. Thus, the performance depends on the type of data being provided and the speed/generalization trade-off.",Perplexity is a way to express a degree of confusion a model has in predicting. More entropy equal to more confusion. Perplexity is used to evaluate language models in NLP. A good language model assigns a higher probability to the right prediction.,0
What are the limitation of Adam optimiser?,"While training with Adam helps in getting fast convergence, the resulting model will often have worse generalization performance than when training with SGD with momentum. Another issue is that even though Adam has adaptive learning rates its performance improves when using a good learning rate schedule. Especially early in the training, it is beneficial to use a lower learning rate to avoid divergence.","We observe that the solutions found by adaptive methods like Adam generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.",1
What are the limitation of Adam optimiser?,"While training with Adam helps in getting fast convergence, the resulting model will often have worse generalization performance than when training with SGD with momentum. Another issue is that even though Adam has adaptive learning rates its performance improves when using a good learning rate schedule. Especially early in the training, it is beneficial to use a lower learning rate to avoid divergence.","BatchNorm — Compute the mean and var at each layer for every minibatch
LayerNorm — Compute the mean and var for every single sample for each layer independently",0
Difference between BatchNorm and LayerNorm?,"We observe that the solutions found by adaptive methods like Adam generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.",Batch normalization is applied on the neuron activation for all the samples in the mini-batch such that the mean of output lies close to 0 and the standard deviation lies close to 1. It also introduces two learning parameters gama and beta in its calculation which are all optimized during training. Layer Normalization is not dependent on batches and the normalization is applied on the neuron for a single instance across all features,0
What are the limitation of Adam optimiser?,"While training with Adam helps in getting fast convergence, the resulting model will often have worse generalization performance than when training with SGD with momentum. Another issue is that even though Adam has adaptive learning rates its performance improves when using a good learning rate schedule. Especially early in the training, it is beneficial to use a lower learning rate to avoid divergence.","Adam/Nadam have lowest training error/loss, but not val. error/loss. So, SGD is a better generalized adapter than ADAM.",1
What are the limitation of Adam optimiser?,"While training with Adam helps in getting fast convergence, the resulting model will often have worse generalization performance than when training with SGD with momentum. Another issue is that even though Adam has adaptive learning rates its performance improves when using a good learning rate schedule. Especially early in the training, it is beneficial to use a lower learning rate to avoid divergence.","Text mining (also referred to as text analytics) is an artificial intelligence (AI) technology that uses natural language processing (NLP) to transform the free (unstructured) text in documents and databases into normalized, structured data suitable for analysis or to drive machine learning (ML) algorithms.",0
What is text mining ?,"Adam/Nadam have lowest training error/loss, but not val. error/loss. So, SGD is a better generalized adapter than ADAM.","Text mining is the process of transforming unstructured text into a structured format to identify meaningful patterns and new insights. By applying advanced analytical techniques, such as Naïve Bayes, Support Vector Machines (SVM), and other deep learning algorithms, companies are able to explore and discover hidden relationships within their unstructured data.",0
What are the limitation of Adam optimiser?,"There are few disadvantages as the Adam optimizer tends to converge faster, but other algorithms like the Stochastic gradient descent focus on the datapoints and generalize in a better manner. Thus, the performance depends on the type of data being provided and the speed/generalization trade-off.","We observe that the solutions found by adaptive methods like Adam generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.",1
What are the limitation of Adam optimiser?,"There are few disadvantages as the Adam optimizer tends to converge faster, but other algorithms like the Stochastic gradient descent focus on the datapoints and generalize in a better manner. Thus, the performance depends on the type of data being provided and the speed/generalization trade-off.",Pragmatic analysis is an important task in NLP for interpreting knowledge that is lying outside a given document. The aim of implementing pragmatic analysis is to focus on exploring a different aspect of the document or text in a language. This requires a comprehensive knowledge of the real world. The pragmatic analysis allows software applications for the critical interpretation of the real-world data to know the actual meaning of sentences and words.,0
What is Pragmatic Analysis?,"We observe that the solutions found by adaptive methods like Adam generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.","Pragmatic analysis deals with outside word knowledge, which means knowledge that is external to the documents and/or queries. Pragmatics analysis that focuses on what was described is reinterpreted by what it actually meant, deriving the various aspects of language that require real world knowledge.",0
What are the limitation of Adam optimiser?,"There are few disadvantages as the Adam optimizer tends to converge faster, but other algorithms like the Stochastic gradient descent focus on the datapoints and generalize in a better manner. Thus, the performance depends on the type of data being provided and the speed/generalization trade-off.","Adam/Nadam have lowest training error/loss, but not val. error/loss. So, SGD is a better generalized adapter than ADAM.",1
What are the limitation of Adam optimiser?,"There are few disadvantages as the Adam optimizer tends to converge faster, but other algorithms like the Stochastic gradient descent focus on the datapoints and generalize in a better manner. Thus, the performance depends on the type of data being provided and the speed/generalization trade-off.",Batch normalization is applied on the neuron activation for all the samples in the mini-batch such that the mean of output lies close to 0 and the standard deviation lies close to 1. It also introduces two learning parameters gama and beta in its calculation which are all optimized during training. Layer Normalization is not dependent on batches and the normalization is applied on the neuron for a single instance across all features,0
Difference between BatchNorm and LayerNorm?,"Adam/Nadam have lowest training error/loss, but not val. error/loss. So, SGD is a better generalized adapter than ADAM.","All the normalization is calculated using this equation x^=x minus mean of x¯ over std of x¯ . The difference is how to calculate the x¯ .
In layer normalization x¯ = all of the summed inputs to the neurons in a layer on a single training case And in batch normalization x¯ = all of the summed inputs of single neuron on single batch",0
What are the limitation of Adam optimiser?,"We observe that the solutions found by adaptive methods like Adam generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.","Adam/Nadam have lowest training error/loss, but not val. error/loss. So, SGD is a better generalized adapter than ADAM.",1
What are the limitation of Adam optimiser?,"We observe that the solutions found by adaptive methods like Adam generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.","An N-gram language model predicts the probability of a given N-gram within any sequence of words in the language. If we have a good N-gram model, we can predict p(w | h) – what is the probability of seeing the word w given a history of previous words h – where the history contains n-1 words.",0
What is ngram in NLP?,"Adam/Nadam have lowest training error/loss, but not val. error/loss. So, SGD is a better generalized adapter than ADAM.","The basic point of n-grams is that they capture the language structure from the statistical point of view, like what letter or word is likely to follow the given one. The longer the n-gram (the higher the n), the more context you have to work with.",0
Difference between BatchNorm and LayerNorm?,"BatchNorm — Compute the mean and var at each layer for every minibatch
LayerNorm — Compute the mean and var for every single sample for each layer independently",Batch normalization is applied on the neuron activation for all the samples in the mini-batch such that the mean of output lies close to 0 and the standard deviation lies close to 1. It also introduces two learning parameters gama and beta in its calculation which are all optimized during training. Layer Normalization is not dependent on batches and the normalization is applied on the neuron for a single instance across all features,1
Difference between BatchNorm and LayerNorm?,"BatchNorm — Compute the mean and var at each layer for every minibatch
LayerNorm — Compute the mean and var for every single sample for each layer independently","There are several factors that make the process of Natural Language Processing difficult. There are hundreds of natural languages all over the world, words can be ambiguous in their meaning, each natural language has a different script and syntax, the meaning of words can change depending on the context, and so the process of NLP can be difficult.",0
Why is NLP so hard?,Batch normalization is applied on the neuron activation for all the samples in the mini-batch such that the mean of output lies close to 0 and the standard deviation lies close to 1. It also introduces two learning parameters gama and beta in its calculation which are all optimized during training. Layer Normalization is not dependent on batches and the normalization is applied on the neuron for a single instance across all features,"NLP is so hard because of many reasons. For example, Knowledge of the world is still difficult for computers to acquire, It is hard to understand whether two sentences or two concepts are equal, and Optimizing the wrong metrics",0
Difference between BatchNorm and LayerNorm?,"BatchNorm — Compute the mean and var at each layer for every minibatch
LayerNorm — Compute the mean and var for every single sample for each layer independently","All the normalization is calculated using this equation x^=x minus mean of x¯ over std of x¯ . The difference is how to calculate the x¯ .
In layer normalization x¯ = all of the summed inputs to the neurons in a layer on a single training case And in batch normalization x¯ = all of the summed inputs of single neuron on single batch",1
Difference between BatchNorm and LayerNorm?,"BatchNorm — Compute the mean and var at each layer for every minibatch
LayerNorm — Compute the mean and var for every single sample for each layer independently","Latent semantic indexing is a mathematical technique used to improve the accuracy of the information retrieval process. The design of LSI algorithms allows machines to detect the hidden (latent) correlation between semantics (words). To enhance information understanding, machines generate various concepts that associate with the words of a sentence.",0
What is Latent Semantic Indexing (LSI)?,"All the normalization is calculated using this equation x^=x minus mean of x¯ over std of x¯ . The difference is how to calculate the x¯ .
In layer normalization x¯ = all of the summed inputs to the neurons in a layer on a single training case And in batch normalization x¯ = all of the summed inputs of single neuron on single batch",Latent Semantic Indexing (LSI) tries to overcome the problems of lexical matching by using statistically derived conceptual indices instead of individual words for retrieval. A better approach would allow users to retrieve information on the basis of a conceptual topic or meaning of a document,0
Difference between BatchNorm and LayerNorm?,"BatchNorm — Compute the mean and var at each layer for every minibatch
LayerNorm — Compute the mean and var for every single sample for each layer independently","BatchNorm: Normalize the batch direction and count The mean value of W is not good for small batchsize; the main disadvantage of BN is that it is more sensitive to the size of batchsize. Since the mean and variance are calculated on one batch each time, if the batchsize is too small, the calculated mean and variance are not enough to represent The entire data distribution.
LayerNorm: Normalize the channel direction and count as CHThe mean value of W is mainly effective for RNN;",1
Difference between BatchNorm and LayerNorm?,"BatchNorm — Compute the mean and var at each layer for every minibatch
LayerNorm — Compute the mean and var for every single sample for each layer independently","For machine translation tasks, seq2seq models, consisting of encoder and decoder were used. This involved usage of Recurrent Neural Networks, both for constructing the encoder and the decoder. The architecture used to memorize the entire sentence from the source language and regurgitate it into the target language. This process works fine for shorter sentences, but as the length of the sentence increases the performance slumps. It is, therefore, difficult for a recurrent neural network to memorize a rather long sentence. The attention mechanism helps us overcome this difficulty",0
Why transformer perform better than LSTM?,"BatchNorm: Normalize the batch direction and count The mean value of W is not good for small batchsize; the main disadvantage of BN is that it is more sensitive to the size of batchsize. Since the mean and variance are calculated on one batch each time, if the batchsize is too small, the calculated mean and variance are not enough to represent The entire data distribution.
LayerNorm: Normalize the channel direction and count as CHThe mean value of W is mainly effective for RNN;","RNN is not very efficient in handling long sequences. The model tends to forget the contents of the distant position or, in some cases, mixes the contents of adjacent positions: the more the steps, the more challenging for the recurrent network to make decisions. The Long Short Term Memory (LSTM) offers a slight improvement over conventional RNN. It can also eliminate the vanishing gradient problem that RNN suffers from. Transformer avoids recursion by processing sentences as whole using attention mechanisms and positional embeddings.",0
Difference between BatchNorm and LayerNorm?,Batch normalization is applied on the neuron activation for all the samples in the mini-batch such that the mean of output lies close to 0 and the standard deviation lies close to 1. It also introduces two learning parameters gama and beta in its calculation which are all optimized during training. Layer Normalization is not dependent on batches and the normalization is applied on the neuron for a single instance across all features,"All the normalization is calculated using this equation x^=x minus mean of x¯ over std of x¯ . The difference is how to calculate the x¯ .
In layer normalization x¯ = all of the summed inputs to the neurons in a layer on a single training case And in batch normalization x¯ = all of the summed inputs of single neuron on single batch",1
Difference between BatchNorm and LayerNorm?,Batch normalization is applied on the neuron activation for all the samples in the mini-batch such that the mean of output lies close to 0 and the standard deviation lies close to 1. It also introduces two learning parameters gama and beta in its calculation which are all optimized during training. Layer Normalization is not dependent on batches and the normalization is applied on the neuron for a single instance across all features,"let's say the inputs to Relu are now distributed as a low-variance Gaussian centered at -0.1. we have that Most inputs to Relu are negative, thus Most inputs will cause the ReLU gate to be closed, thus Most inputs will cause gradients to fail to flow backwards through Relu thus Relu's inputs are usually not updated through SGD backprop.",0
What is the problem with ReLu?,"All the normalization is calculated using this equation x^=x minus mean of x¯ over std of x¯ . The difference is how to calculate the x¯ .
In layer normalization x¯ = all of the summed inputs to the neurons in a layer on a single training case And in batch normalization x¯ = all of the summed inputs of single neuron on single batch","The dying ReLU refers to the problem when ReLU neurons become inactive and only output 0 for any input. So, once a neuron gets negative input, it will always output zero and is unlikely for it to recover. It will become inactive forever. Such neurons will not play any role in discriminating the input and become useless in the neural network. If this process continues, over the time you may end up with a large part of your network doing nothing.",0
Difference between BatchNorm and LayerNorm?,Batch normalization is applied on the neuron activation for all the samples in the mini-batch such that the mean of output lies close to 0 and the standard deviation lies close to 1. It also introduces two learning parameters gama and beta in its calculation which are all optimized during training. Layer Normalization is not dependent on batches and the normalization is applied on the neuron for a single instance across all features,"BatchNorm: Normalize the batch direction and count The mean value of W is not good for small batchsize; the main disadvantage of BN is that it is more sensitive to the size of batchsize. Since the mean and variance are calculated on one batch each time, if the batchsize is too small, the calculated mean and variance are not enough to represent The entire data distribution.
LayerNorm: Normalize the channel direction and count as CHThe mean value of W is mainly effective for RNN;",1
Difference between BatchNorm and LayerNorm?,Batch normalization is applied on the neuron activation for all the samples in the mini-batch such that the mean of output lies close to 0 and the standard deviation lies close to 1. It also introduces two learning parameters gama and beta in its calculation which are all optimized during training. Layer Normalization is not dependent on batches and the normalization is applied on the neuron for a single instance across all features,Hidden stores all the information till that time step and cell state stores particular information that might be needed in the future time step.,0
What is the information in hidden and cell state of LSTM?,"BatchNorm: Normalize the batch direction and count The mean value of W is not good for small batchsize; the main disadvantage of BN is that it is more sensitive to the size of batchsize. Since the mean and variance are calculated on one batch each time, if the batchsize is too small, the calculated mean and variance are not enough to represent The entire data distribution.
LayerNorm: Normalize the channel direction and count as CHThe mean value of W is mainly effective for RNN;","Cell state is a memory of LSTM cell, hidden state is an output of this cell. Hidden state and cell input are used to control what to do with memory: to forget or to write new information. We decide what to do with memory knowing about previous output (hidden state) and current input.",0
Difference between BatchNorm and LayerNorm?,"All the normalization is calculated using this equation x^=x minus mean of x¯ over std of x¯ . The difference is how to calculate the x¯ .
In layer normalization x¯ = all of the summed inputs to the neurons in a layer on a single training case And in batch normalization x¯ = all of the summed inputs of single neuron on single batch","BatchNorm: Normalize the batch direction and count The mean value of W is not good for small batchsize; the main disadvantage of BN is that it is more sensitive to the size of batchsize. Since the mean and variance are calculated on one batch each time, if the batchsize is too small, the calculated mean and variance are not enough to represent The entire data distribution.
LayerNorm: Normalize the channel direction and count as CHThe mean value of W is mainly effective for RNN;",1
Difference between BatchNorm and LayerNorm?,"All the normalization is calculated using this equation x^=x minus mean of x¯ over std of x¯ . The difference is how to calculate the x¯ .
In layer normalization x¯ = all of the summed inputs to the neurons in a layer on a single training case And in batch normalization x¯ = all of the summed inputs of single neuron on single batch","NLP is a big field and covers things from very ML-like (classifiers with bag of words features) to not at all ML-like (machine translation). You need to spend some time on a survey of NLP problems, then zero in on the ones you care about, which may or may not involve the methods you're familiar with.",0
Why is NLP so hard?,"BatchNorm: Normalize the batch direction and count The mean value of W is not good for small batchsize; the main disadvantage of BN is that it is more sensitive to the size of batchsize. Since the mean and variance are calculated on one batch each time, if the batchsize is too small, the calculated mean and variance are not enough to represent The entire data distribution.
LayerNorm: Normalize the channel direction and count as CHThe mean value of W is mainly effective for RNN;","NLP is so hard because of many reasons. For example, Knowledge of the world is still difficult for computers to acquire, It is hard to understand whether two sentences or two concepts are equal, and Optimizing the wrong metrics",0
What is the information in hidden and cell state of LSTM?,Hidden stores all the information till that time step and cell state stores particular information that might be needed in the future time step.,"Cell state is a memory of LSTM cell, hidden state is an output of this cell. Hidden state and cell input are used to control what to do with memory: to forget or to write new information. We decide what to do with memory knowing about previous output (hidden state) and current input.",1
What is the information in hidden and cell state of LSTM?,Hidden stores all the information till that time step and cell state stores particular information that might be needed in the future time step.,"Dependency parsing is the task of extracting a dependency parse of a sentence that represents its grammatical structure and defines the relationships between “head” words and words, which modify those heads.",0
Explain Dependency Parsing in NLP,"Cell state is a memory of LSTM cell, hidden state is an output of this cell. Hidden state and cell input are used to control what to do with memory: to forget or to write new information. We decide what to do with memory knowing about previous output (hidden state) and current input.",Dependency Parsing is the task of recognizing a sentence and assigning a syntactic structure to it. The most widely used syntactic structure is the parse tree which can be generated using some parsing algorithms. These parse trees are useful in various applications like grammar checking or more importantly it plays a critical role in the semantic analysis stage.,0
What is the information in hidden and cell state of LSTM?,Hidden stores all the information till that time step and cell state stores particular information that might be needed in the future time step.,"hidden state is Working memory capability that carries information from immediately previous events and overwrites at every step uncontrollably -present at RNNs and LSTMs
cell state is long term memory capability that stores and loads information of not necessarily immediately previous events
present in LSTMs",1
What is the information in hidden and cell state of LSTM?,Hidden stores all the information till that time step and cell state stores particular information that might be needed in the future time step.,"We observe that the solutions found by adaptive methods like Adam generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.",0
What are the limitation of Adam optimiser?,"hidden state is Working memory capability that carries information from immediately previous events and overwrites at every step uncontrollably -present at RNNs and LSTMs
cell state is long term memory capability that stores and loads information of not necessarily immediately previous events
present in LSTMs","Adam/Nadam have lowest training error/loss, but not val. error/loss. So, SGD is a better generalized adapter than ADAM.",0
What is the information in hidden and cell state of LSTM?,"Cell state is a memory of LSTM cell, hidden state is an output of this cell. Hidden state and cell input are used to control what to do with memory: to forget or to write new information. We decide what to do with memory knowing about previous output (hidden state) and current input.","hidden state is Working memory capability that carries information from immediately previous events and overwrites at every step uncontrollably -present at RNNs and LSTMs
cell state is long term memory capability that stores and loads information of not necessarily immediately previous events
present in LSTMs",1
What is the information in hidden and cell state of LSTM?,"Cell state is a memory of LSTM cell, hidden state is an output of this cell. Hidden state and cell input are used to control what to do with memory: to forget or to write new information. We decide what to do with memory knowing about previous output (hidden state) and current input.",Latent Semantic Indexing is an indexing and retrieval method that uses a mathematical technique called Singular value decomposition (SVD) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text. LSI is based on the principle that words that are used in the same contexts tend to have similar meanings,0
What is Latent Semantic Indexing (LSI)?,"hidden state is Working memory capability that carries information from immediately previous events and overwrites at every step uncontrollably -present at RNNs and LSTMs
cell state is long term memory capability that stores and loads information of not necessarily immediately previous events
present in LSTMs",It also called Latent semantic analysis is a mathematical method that was developed so that the accuracy of retrieving information can be improved. It helps in finding out the hidden(latent) relationship between the words(semantics) by producing a set of various concepts related to the terms of a sentence to improve the information understanding. The technique used for the purpose is called Singular value decomposition. It is generally useful for working on small sets of static documents.,0
Why transformer perform better than LSTM?,Transformer models are essentially attention based models. They see the entire sentence as a whole unlike LSTMs (or in general RNNs) where the sentence is processed sequentially - one word per time step. During training LSTMs need to propagate the error back in time through words one word at a time. Transformer sees all words simultaneously - so there is no backpropagation through time.,"Transformers are better than all the other architectures because they totally avoid recursion, by processing sentences as a whole and by learning relationships between words thank's to multi-head attention mechanisms and positional embeddings.",1
Why transformer perform better than LSTM?,Transformer models are essentially attention based models. They see the entire sentence as a whole unlike LSTMs (or in general RNNs) where the sentence is processed sequentially - one word per time step. During training LSTMs need to propagate the error back in time through words one word at a time. Transformer sees all words simultaneously - so there is no backpropagation through time.,"Topic modeling is part of a class of text analysis methods that analyze “bags” or groups of words together—instead of counting them individually–in order to capture how the meaning of words is dependent upon the broader context in which they are used in natural language. Topic modeling is not the only method that does this– cluster analysis, latent semantic analysis, and other techniques have also been used to identify clustering within texts",0
What is Topic Modeling ? When we will do it ?,"Transformers are better than all the other architectures because they totally avoid recursion, by processing sentences as a whole and by learning relationships between words thank's to multi-head attention mechanisms and positional embeddings.","Topic modeling is a branch of unsupervised natural language processing which is used to represent a text document with the help of several topics, that can best explain the underlying information in a particular document. This can be thought in terms of clustering, but with a difference.",0
Why transformer perform better than LSTM?,Transformer models are essentially attention based models. They see the entire sentence as a whole unlike LSTMs (or in general RNNs) where the sentence is processed sequentially - one word per time step. During training LSTMs need to propagate the error back in time through words one word at a time. Transformer sees all words simultaneously - so there is no backpropagation through time.,"For machine translation tasks, seq2seq models, consisting of encoder and decoder were used. This involved usage of Recurrent Neural Networks, both for constructing the encoder and the decoder. The architecture used to memorize the entire sentence from the source language and regurgitate it into the target language. This process works fine for shorter sentences, but as the length of the sentence increases the performance slumps. It is, therefore, difficult for a recurrent neural network to memorize a rather long sentence. The attention mechanism helps us overcome this difficulty",1
Why transformer perform better than LSTM?,Transformer models are essentially attention based models. They see the entire sentence as a whole unlike LSTMs (or in general RNNs) where the sentence is processed sequentially - one word per time step. During training LSTMs need to propagate the error back in time through words one word at a time. Transformer sees all words simultaneously - so there is no backpropagation through time.,"Natural language processing  is the relationship between computers and human language. More specifically, natural language processing is the computer understanding, analysis, manipulation, and/or generation of natural language.",0
What do you understand by Natural Language Processing?,"For machine translation tasks, seq2seq models, consisting of encoder and decoder were used. This involved usage of Recurrent Neural Networks, both for constructing the encoder and the decoder. The architecture used to memorize the entire sentence from the source language and regurgitate it into the target language. This process works fine for shorter sentences, but as the length of the sentence increases the performance slumps. It is, therefore, difficult for a recurrent neural network to memorize a rather long sentence. The attention mechanism helps us overcome this difficulty",Natural language processing is the ability of a computer program to understand human language as it is spoken. NLP is a component of artificial intelligence. It allows machines to break down and interpret human language.,0
Why transformer perform better than LSTM?,Transformer models are essentially attention based models. They see the entire sentence as a whole unlike LSTMs (or in general RNNs) where the sentence is processed sequentially - one word per time step. During training LSTMs need to propagate the error back in time through words one word at a time. Transformer sees all words simultaneously - so there is no backpropagation through time.,"RNN is not very efficient in handling long sequences. The model tends to forget the contents of the distant position or, in some cases, mixes the contents of adjacent positions: the more the steps, the more challenging for the recurrent network to make decisions. The Long Short Term Memory (LSTM) offers a slight improvement over conventional RNN. It can also eliminate the vanishing gradient problem that RNN suffers from. Transformer avoids recursion by processing sentences as whole using attention mechanisms and positional embeddings.",1
Why transformer perform better than LSTM?,Transformer models are essentially attention based models. They see the entire sentence as a whole unlike LSTMs (or in general RNNs) where the sentence is processed sequentially - one word per time step. During training LSTMs need to propagate the error back in time through words one word at a time. Transformer sees all words simultaneously - so there is no backpropagation through time.,Latent Semantic Indexing is an indexing and retrieval method that uses a mathematical technique called Singular value decomposition (SVD) to identify patterns in the relationships between the terms and concepts contained in an unstructured collection of text. LSI is based on the principle that words that are used in the same contexts tend to have similar meanings,0
What is Latent Semantic Indexing (LSI)?,"RNN is not very efficient in handling long sequences. The model tends to forget the contents of the distant position or, in some cases, mixes the contents of adjacent positions: the more the steps, the more challenging for the recurrent network to make decisions. The Long Short Term Memory (LSTM) offers a slight improvement over conventional RNN. It can also eliminate the vanishing gradient problem that RNN suffers from. Transformer avoids recursion by processing sentences as whole using attention mechanisms and positional embeddings.",It also called Latent semantic analysis is a mathematical method that was developed so that the accuracy of retrieving information can be improved. It helps in finding out the hidden(latent) relationship between the words(semantics) by producing a set of various concepts related to the terms of a sentence to improve the information understanding. The technique used for the purpose is called Singular value decomposition. It is generally useful for working on small sets of static documents.,0
Why transformer perform better than LSTM?,"Transformers are better than all the other architectures because they totally avoid recursion, by processing sentences as a whole and by learning relationships between words thank's to multi-head attention mechanisms and positional embeddings.","For machine translation tasks, seq2seq models, consisting of encoder and decoder were used. This involved usage of Recurrent Neural Networks, both for constructing the encoder and the decoder. The architecture used to memorize the entire sentence from the source language and regurgitate it into the target language. This process works fine for shorter sentences, but as the length of the sentence increases the performance slumps. It is, therefore, difficult for a recurrent neural network to memorize a rather long sentence. The attention mechanism helps us overcome this difficulty",1
Why transformer perform better than LSTM?,"Transformers are better than all the other architectures because they totally avoid recursion, by processing sentences as a whole and by learning relationships between words thank's to multi-head attention mechanisms and positional embeddings.",Parsing in NLP refers to the understanding of a sentence and its grammatical structure by a machine.,0
What is Parsing in the context of NLP?,"For machine translation tasks, seq2seq models, consisting of encoder and decoder were used. This involved usage of Recurrent Neural Networks, both for constructing the encoder and the decoder. The architecture used to memorize the entire sentence from the source language and regurgitate it into the target language. This process works fine for shorter sentences, but as the length of the sentence increases the performance slumps. It is, therefore, difficult for a recurrent neural network to memorize a rather long sentence. The attention mechanism helps us overcome this difficulty","Parsing allows the machine to understand the meaning of a word in a sentence and the grouping of words, phrases, nouns, subjects, and objects in a sentence.",0
Why transformer perform better than LSTM?,"Transformers are better than all the other architectures because they totally avoid recursion, by processing sentences as a whole and by learning relationships between words thank's to multi-head attention mechanisms and positional embeddings.","RNN is not very efficient in handling long sequences. The model tends to forget the contents of the distant position or, in some cases, mixes the contents of adjacent positions: the more the steps, the more challenging for the recurrent network to make decisions. The Long Short Term Memory (LSTM) offers a slight improvement over conventional RNN. It can also eliminate the vanishing gradient problem that RNN suffers from. Transformer avoids recursion by processing sentences as whole using attention mechanisms and positional embeddings.",1
Why transformer perform better than LSTM?,"Transformers are better than all the other architectures because they totally avoid recursion, by processing sentences as a whole and by learning relationships between words thank's to multi-head attention mechanisms and positional embeddings.","While training with Adam helps in getting fast convergence, the resulting model will often have worse generalization performance than when training with SGD with momentum. Another issue is that even though Adam has adaptive learning rates its performance improves when using a good learning rate schedule. Especially early in the training, it is beneficial to use a lower learning rate to avoid divergence.",0
What are the limitation of Adam optimiser?,"RNN is not very efficient in handling long sequences. The model tends to forget the contents of the distant position or, in some cases, mixes the contents of adjacent positions: the more the steps, the more challenging for the recurrent network to make decisions. The Long Short Term Memory (LSTM) offers a slight improvement over conventional RNN. It can also eliminate the vanishing gradient problem that RNN suffers from. Transformer avoids recursion by processing sentences as whole using attention mechanisms and positional embeddings.","There are few disadvantages as the Adam optimizer tends to converge faster, but other algorithms like the Stochastic gradient descent focus on the datapoints and generalize in a better manner. Thus, the performance depends on the type of data being provided and the speed/generalization trade-off.",0
Why transformer perform better than LSTM?,"For machine translation tasks, seq2seq models, consisting of encoder and decoder were used. This involved usage of Recurrent Neural Networks, both for constructing the encoder and the decoder. The architecture used to memorize the entire sentence from the source language and regurgitate it into the target language. This process works fine for shorter sentences, but as the length of the sentence increases the performance slumps. It is, therefore, difficult for a recurrent neural network to memorize a rather long sentence. The attention mechanism helps us overcome this difficulty","RNN is not very efficient in handling long sequences. The model tends to forget the contents of the distant position or, in some cases, mixes the contents of adjacent positions: the more the steps, the more challenging for the recurrent network to make decisions. The Long Short Term Memory (LSTM) offers a slight improvement over conventional RNN. It can also eliminate the vanishing gradient problem that RNN suffers from. Transformer avoids recursion by processing sentences as whole using attention mechanisms and positional embeddings.",1
Why transformer perform better than LSTM?,"For machine translation tasks, seq2seq models, consisting of encoder and decoder were used. This involved usage of Recurrent Neural Networks, both for constructing the encoder and the decoder. The architecture used to memorize the entire sentence from the source language and regurgitate it into the target language. This process works fine for shorter sentences, but as the length of the sentence increases the performance slumps. It is, therefore, difficult for a recurrent neural network to memorize a rather long sentence. The attention mechanism helps us overcome this difficulty","There are several factors that make the process of Natural Language Processing difficult. There are hundreds of natural languages all over the world, words can be ambiguous in their meaning, each natural language has a different script and syntax, the meaning of words can change depending on the context, and so the process of NLP can be difficult.",0
Why is NLP so hard?,"RNN is not very efficient in handling long sequences. The model tends to forget the contents of the distant position or, in some cases, mixes the contents of adjacent positions: the more the steps, the more challenging for the recurrent network to make decisions. The Long Short Term Memory (LSTM) offers a slight improvement over conventional RNN. It can also eliminate the vanishing gradient problem that RNN suffers from. Transformer avoids recursion by processing sentences as whole using attention mechanisms and positional embeddings.","NLP is a big field and covers things from very ML-like (classifiers with bag of words features) to not at all ML-like (machine translation). You need to spend some time on a survey of NLP problems, then zero in on the ones you care about, which may or may not involve the methods you're familiar with.",0
What is text mining ?,"Text mining, also referred to as text data mining, roughly equivalent to text analytics, is the process of deriving high-quality information from text. High-quality information is typically derived through the devising of patterns and trends through means such as statistical pattern learning.","Text mining (also referred to as text analytics) is an artificial intelligence (AI) technology that uses natural language processing (NLP) to transform the free (unstructured) text in documents and databases into normalized, structured data suitable for analysis or to drive machine learning (ML) algorithms.",1
What is text mining ?,"Text mining, also referred to as text data mining, roughly equivalent to text analytics, is the process of deriving high-quality information from text. High-quality information is typically derived through the devising of patterns and trends through means such as statistical pattern learning.","It is an AI technique that automatically identifies named entities in a text and classifies them into predefined categories. Entities can be names of people, organizations, locations, times, quantities, monetary values, percentages, and more",0
Explain Named Entity Recognition,"Text mining (also referred to as text analytics) is an artificial intelligence (AI) technology that uses natural language processing (NLP) to transform the free (unstructured) text in documents and databases into normalized, structured data suitable for analysis or to drive machine learning (ML) algorithms.","Named-entity recognition is the method of extracting information. It arranges and classifies named entity in the unstructured text in different categories like locations, time expressions, organizations, percentages, and monetary values. NER allows the users to properly understand the subject of the text.",0
What is text mining ?,"Text mining, also referred to as text data mining, roughly equivalent to text analytics, is the process of deriving high-quality information from text. High-quality information is typically derived through the devising of patterns and trends through means such as statistical pattern learning.","Text mining is the process of transforming unstructured text into a structured format to identify meaningful patterns and new insights. By applying advanced analytical techniques, such as Naïve Bayes, Support Vector Machines (SVM), and other deep learning algorithms, companies are able to explore and discover hidden relationships within their unstructured data.",1
What is text mining ?,"Text mining, also referred to as text data mining, roughly equivalent to text analytics, is the process of deriving high-quality information from text. High-quality information is typically derived through the devising of patterns and trends through means such as statistical pattern learning.","Naive Bayes Classifier Algorithm is a family of probabilistic algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of a feature.
Bayes theorem calculates probability P(c|x) where c is the class of the possible outcomes and x is the given instance which has to be classified, representing some certain features.",0
What is Naive Bayes algorithm?,"Text mining is the process of transforming unstructured text into a structured format to identify meaningful patterns and new insights. By applying advanced analytical techniques, such as Naïve Bayes, Support Vector Machines (SVM), and other deep learning algorithms, companies are able to explore and discover hidden relationships within their unstructured data.","Naive Bayes is a family of algorithms that take advantage of probability theory and Bayes’ Theorem to predict the tag of a text (like a piece of news or a customer review). They are probabilistic, which means that they calculate the probability of each tag for a given text, and then output the tag with the highest one. The way they get these probabilities is by using Bayes’ Theorem, which describes the probability of a feature, based on prior knowledge of conditions that might be related to that feature.",0
What is text mining ?,"Text mining, also referred to as text data mining, roughly equivalent to text analytics, is the process of deriving high-quality information from text. High-quality information is typically derived through the devising of patterns and trends through means such as statistical pattern learning.","Text mining is the process of exploring and analyzing large amounts of unstructured text data aided by software that can identify concepts, patterns, topics, keywords and other attributes in the data.",1
What is text mining ?,"Text mining, also referred to as text data mining, roughly equivalent to text analytics, is the process of deriving high-quality information from text. High-quality information is typically derived through the devising of patterns and trends through means such as statistical pattern learning.",Syntactic analysis is defined as analysis that tells us the logical meaning of certain given sentences or parts of those sentences. We also need to consider rules of grammar in order to define the logical meaning as well as correctness of the sentences.,0
What is Syntactic Analysis?,"Text mining is the process of exploring and analyzing large amounts of unstructured text data aided by software that can identify concepts, patterns, topics, keywords and other attributes in the data.","Syntactic Analysis is the process of analyzing natural language with the rules of a formal grammar. Grammatical rules are applied to categories and groups of words, not individual words. Syntactic analysis basically assigns a semantic structure to text.",0
What is text mining ?,"Text mining (also referred to as text analytics) is an artificial intelligence (AI) technology that uses natural language processing (NLP) to transform the free (unstructured) text in documents and databases into normalized, structured data suitable for analysis or to drive machine learning (ML) algorithms.","Text mining is the process of transforming unstructured text into a structured format to identify meaningful patterns and new insights. By applying advanced analytical techniques, such as Naïve Bayes, Support Vector Machines (SVM), and other deep learning algorithms, companies are able to explore and discover hidden relationships within their unstructured data.",1
What is text mining ?,"Text mining (also referred to as text analytics) is an artificial intelligence (AI) technology that uses natural language processing (NLP) to transform the free (unstructured) text in documents and databases into normalized, structured data suitable for analysis or to drive machine learning (ML) algorithms.","TF-IDF or Term Frequency-Inverse Document Frequency indicates the importance of a word in a set. It helps in information retrieval with numerical statistics. For a specific document, TF-IDF shows a frequency that helps identify the keywords in a document.",0
What is TF-IDF?,"Text mining is the process of transforming unstructured text into a structured format to identify meaningful patterns and new insights. By applying advanced analytical techniques, such as Naïve Bayes, Support Vector Machines (SVM), and other deep learning algorithms, companies are able to explore and discover hidden relationships within their unstructured data.","TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.",0
What is text mining ?,"Text mining (also referred to as text analytics) is an artificial intelligence (AI) technology that uses natural language processing (NLP) to transform the free (unstructured) text in documents and databases into normalized, structured data suitable for analysis or to drive machine learning (ML) algorithms.","Text mining is the process of exploring and analyzing large amounts of unstructured text data aided by software that can identify concepts, patterns, topics, keywords and other attributes in the data.",1
What is text mining ?,"Text mining (also referred to as text analytics) is an artificial intelligence (AI) technology that uses natural language processing (NLP) to transform the free (unstructured) text in documents and databases into normalized, structured data suitable for analysis or to drive machine learning (ML) algorithms.",Hidden stores all the information till that time step and cell state stores particular information that might be needed in the future time step.,0
What is the information in hidden and cell state of LSTM?,"Text mining is the process of exploring and analyzing large amounts of unstructured text data aided by software that can identify concepts, patterns, topics, keywords and other attributes in the data.","Cell state is a memory of LSTM cell, hidden state is an output of this cell. Hidden state and cell input are used to control what to do with memory: to forget or to write new information. We decide what to do with memory knowing about previous output (hidden state) and current input.",0
What is text mining ?,"Text mining is the process of transforming unstructured text into a structured format to identify meaningful patterns and new insights. By applying advanced analytical techniques, such as Naïve Bayes, Support Vector Machines (SVM), and other deep learning algorithms, companies are able to explore and discover hidden relationships within their unstructured data.","Text mining is the process of exploring and analyzing large amounts of unstructured text data aided by software that can identify concepts, patterns, topics, keywords and other attributes in the data.",1
What is text mining ?,"Text mining is the process of transforming unstructured text into a structured format to identify meaningful patterns and new insights. By applying advanced analytical techniques, such as Naïve Bayes, Support Vector Machines (SVM), and other deep learning algorithms, companies are able to explore and discover hidden relationships within their unstructured data.",Bag of Words is a commonly used model that depends on word frequencies or occurrences to train a classifier. This model creates an occurrence matrix for documents or sentences irrespective of its grammatical structure or word order.,0
What is Bag of Words?,"Text mining is the process of exploring and analyzing large amounts of unstructured text data aided by software that can identify concepts, patterns, topics, keywords and other attributes in the data.","In this model, a text (such as a sentence or a document) is represented as the bag of its words, disregarding grammar and even word order but keeping multiplicity. The bag of words model is commonly used in methods of document classification where the (frequency of) occurrence of each word is used as a feature for training a classifier.",0
What is Topic Modeling ? When we will do it ?,"Topic modeling is an unsupervised machine learning technique that’s capable of scanning a set of documents, detecting word and phrase patterns within them, and automatically clustering word groups and similar expressions that best characterize a set of documents.",Topic modeling is a type of statistical modeling for discovering the abstract “topics” that occur in a collection of documents. Latent Dirichlet Allocation (LDA) is an example of topic model and is used to classify text in a document to a particular topic,1
What is Topic Modeling ? When we will do it ?,"Topic modeling is an unsupervised machine learning technique that’s capable of scanning a set of documents, detecting word and phrase patterns within them, and automatically clustering word groups and similar expressions that best characterize a set of documents.","In general, perplexity is a measurement of how well a probability model predicts a sample. In the context of Natural Language Processing, perplexity is one way to evaluate language models.",0
What is perplexity in NLP?,Topic modeling is a type of statistical modeling for discovering the abstract “topics” that occur in a collection of documents. Latent Dirichlet Allocation (LDA) is an example of topic model and is used to classify text in a document to a particular topic,Perplexity is a way to express a degree of confusion a model has in predicting. More entropy equal to more confusion. Perplexity is used to evaluate language models in NLP. A good language model assigns a higher probability to the right prediction.,0
What is Topic Modeling ? When we will do it ?,"Topic modeling is an unsupervised machine learning technique that’s capable of scanning a set of documents, detecting word and phrase patterns within them, and automatically clustering word groups and similar expressions that best characterize a set of documents.","Topic modeling is part of a class of text analysis methods that analyze “bags” or groups of words together—instead of counting them individually–in order to capture how the meaning of words is dependent upon the broader context in which they are used in natural language. Topic modeling is not the only method that does this– cluster analysis, latent semantic analysis, and other techniques have also been used to identify clustering within texts",1
What is Topic Modeling ? When we will do it ?,"Topic modeling is an unsupervised machine learning technique that’s capable of scanning a set of documents, detecting word and phrase patterns within them, and automatically clustering word groups and similar expressions that best characterize a set of documents.","While training with Adam helps in getting fast convergence, the resulting model will often have worse generalization performance than when training with SGD with momentum. Another issue is that even though Adam has adaptive learning rates its performance improves when using a good learning rate schedule. Especially early in the training, it is beneficial to use a lower learning rate to avoid divergence.",0
What are the limitation of Adam optimiser?,"Topic modeling is part of a class of text analysis methods that analyze “bags” or groups of words together—instead of counting them individually–in order to capture how the meaning of words is dependent upon the broader context in which they are used in natural language. Topic modeling is not the only method that does this– cluster analysis, latent semantic analysis, and other techniques have also been used to identify clustering within texts","Adam/Nadam have lowest training error/loss, but not val. error/loss. So, SGD is a better generalized adapter than ADAM.",0
What is Topic Modeling ? When we will do it ?,"Topic modeling is an unsupervised machine learning technique that’s capable of scanning a set of documents, detecting word and phrase patterns within them, and automatically clustering word groups and similar expressions that best characterize a set of documents.","Topic modeling is a branch of unsupervised natural language processing which is used to represent a text document with the help of several topics, that can best explain the underlying information in a particular document. This can be thought in terms of clustering, but with a difference.",1
What is Topic Modeling ? When we will do it ?,"Topic modeling is an unsupervised machine learning technique that’s capable of scanning a set of documents, detecting word and phrase patterns within them, and automatically clustering word groups and similar expressions that best characterize a set of documents.","Lemmatization is closely related to stemming. In linguistics, it is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Putting an example to the definition, “computers” is an inflected form of “computer”, the same logic as “dogs” being an inflected form of “dog”",0
Explain Lemmatization with the help of an example,"Topic modeling is a branch of unsupervised natural language processing which is used to represent a text document with the help of several topics, that can best explain the underlying information in a particular document. This can be thought in terms of clustering, but with a difference.","I would explain lemmatization as returning different forms of a single word to its root form. It is not only applicable to nouns. Lemmatization works the same way for adjectives, action verbs, all the same. Such as:
Constructing – (Lemmatization) -> Construct, Extracts – (Lemmatization) -> Extract",0
What is Topic Modeling ? When we will do it ?,Topic modeling is a type of statistical modeling for discovering the abstract “topics” that occur in a collection of documents. Latent Dirichlet Allocation (LDA) is an example of topic model and is used to classify text in a document to a particular topic,"Topic modeling is part of a class of text analysis methods that analyze “bags” or groups of words together—instead of counting them individually–in order to capture how the meaning of words is dependent upon the broader context in which they are used in natural language. Topic modeling is not the only method that does this– cluster analysis, latent semantic analysis, and other techniques have also been used to identify clustering within texts",1
What is Topic Modeling ? When we will do it ?,Topic modeling is a type of statistical modeling for discovering the abstract “topics” that occur in a collection of documents. Latent Dirichlet Allocation (LDA) is an example of topic model and is used to classify text in a document to a particular topic,"Pragmatic ambiguity refers to the multiple descriptions of a word or a sentence. An ambiguity arises when the meaning of the sentence is not clear. The words of the sentence may have different meanings. Therefore, in practical situations, it becomes a challenging task for a machine to understand the meaning of a sentence. This leads to pragmatic ambiguity.",0
What is Pragmatic Ambiguity?,"Topic modeling is part of a class of text analysis methods that analyze “bags” or groups of words together—instead of counting them individually–in order to capture how the meaning of words is dependent upon the broader context in which they are used in natural language. Topic modeling is not the only method that does this– cluster analysis, latent semantic analysis, and other techniques have also been used to identify clustering within texts","Such kind of ambiguity refers to the situation where the context of a phrase gives it multiple interpretations. In simple words, we can say that pragmatic ambiguity arises when the statement is not specific. For example, the sentence “I like you too” can have multiple interpretations as I like you (just like you like me), I like you (just like someone else does).",0
What is Topic Modeling ? When we will do it ?,Topic modeling is a type of statistical modeling for discovering the abstract “topics” that occur in a collection of documents. Latent Dirichlet Allocation (LDA) is an example of topic model and is used to classify text in a document to a particular topic,"Topic modeling is a branch of unsupervised natural language processing which is used to represent a text document with the help of several topics, that can best explain the underlying information in a particular document. This can be thought in terms of clustering, but with a difference.",1
What is Topic Modeling ? When we will do it ?,Topic modeling is a type of statistical modeling for discovering the abstract “topics” that occur in a collection of documents. Latent Dirichlet Allocation (LDA) is an example of topic model and is used to classify text in a document to a particular topic,"Natural language processing is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics, in its pursuit to fill the gap between human communication and computer understanding.",0
What do you understand by Natural Language Processing?,"Topic modeling is a branch of unsupervised natural language processing which is used to represent a text document with the help of several topics, that can best explain the underlying information in a particular document. This can be thought in terms of clustering, but with a difference.",Natural Language Processing or NLP is an automated way to understand or analyze the natural languages and extract required information from such data by applying machine learning Algorithms,0
What is Topic Modeling ? When we will do it ?,"Topic modeling is part of a class of text analysis methods that analyze “bags” or groups of words together—instead of counting them individually–in order to capture how the meaning of words is dependent upon the broader context in which they are used in natural language. Topic modeling is not the only method that does this– cluster analysis, latent semantic analysis, and other techniques have also been used to identify clustering within texts","Topic modeling is a branch of unsupervised natural language processing which is used to represent a text document with the help of several topics, that can best explain the underlying information in a particular document. This can be thought in terms of clustering, but with a difference.",1
What is Topic Modeling ? When we will do it ?,"Topic modeling is part of a class of text analysis methods that analyze “bags” or groups of words together—instead of counting them individually–in order to capture how the meaning of words is dependent upon the broader context in which they are used in natural language. Topic modeling is not the only method that does this– cluster analysis, latent semantic analysis, and other techniques have also been used to identify clustering within texts","Latent semantic indexing is a mathematical technique used to improve the accuracy of the information retrieval process. The design of LSI algorithms allows machines to detect the hidden (latent) correlation between semantics (words). To enhance information understanding, machines generate various concepts that associate with the words of a sentence.",0
What is Latent Semantic Indexing (LSI)?,"Topic modeling is a branch of unsupervised natural language processing which is used to represent a text document with the help of several topics, that can best explain the underlying information in a particular document. This can be thought in terms of clustering, but with a difference.",It also called Latent semantic analysis is a mathematical method that was developed so that the accuracy of retrieving information can be improved. It helps in finding out the hidden(latent) relationship between the words(semantics) by producing a set of various concepts related to the terms of a sentence to improve the information understanding. The technique used for the purpose is called Singular value decomposition. It is generally useful for working on small sets of static documents.,0
What is a class?,A class is simply a representation of a type of object. It is the blueprint/plan/template that describes the details of an object.,A Class in object oriented programming is a blueprint or prototype that defines the variables and the methods (functions) common to all Java Objects of a certain kind.,1
What is a class?,A class is simply a representation of a type of object. It is the blueprint/plan/template that describes the details of an object.,"An interface is a collection of an abstract method. If the class implements an interface, it thereby inherits all the abstract methods of an interface.Java uses Interface to implement multiple inheritances.",0
What is an interface?,A Class in object oriented programming is a blueprint or prototype that defines the variables and the methods (functions) common to all Java Objects of a certain kind.,"An interface is an abstract ""class"" that is used to group related methods with ""empty"" bodies",0
What is a class?,A class is simply a representation of a type of object. It is the blueprint/plan/template that describes the details of an object.,A class is a program-code-template that allows developers to create an object that has both variables (data) and behaviors (functions or methods).,1
What is a class?,A class is simply a representation of a type of object. It is the blueprint/plan/template that describes the details of an object.,"Function overloading is a regular function, but it can perform different tasks. It allows the creation of several methods with the same name which differ from each other by the type of input and output of the function.",0
What is function overloading?,A class is a program-code-template that allows developers to create an object that has both variables (data) and behaviors (functions or methods).,Overloading occurs when two or more methods in one class have the same method name but different parameters.,0
What is a class?,A Class in object oriented programming is a blueprint or prototype that defines the variables and the methods (functions) common to all Java Objects of a certain kind.,A class is a program-code-template that allows developers to create an object that has both variables (data) and behaviors (functions or methods).,1
What is a class?,A Class in object oriented programming is a blueprint or prototype that defines the variables and the methods (functions) common to all Java Objects of a certain kind.,"A constructor is a special method of a class or structure in object-oriented programming that initializes a newly created object of that type. Whenever an object is created, the constructor is called automatically.",0
Explain the term constructor,A class is a program-code-template that allows developers to create an object that has both variables (data) and behaviors (functions or methods).,"A constructor is a member function of a class which initializes objects of a class. In C++, Constructor is automatically called when object(instance of class) create. It is special member function of the class.J",0
What is an Object?,"An object is an instance of a class. It has its own state, behavior, and identity.","An Object is an instance of a Class. When a class is defined, no memory is allocated but when it is instantiated (i.e. an object is created) memory is allocated.",1
What is an Object?,"An object is an instance of a class. It has its own state, behavior, and identity.",is a mechanism in which one object acquires all the properties and behaviors of a parent object.,0
What is Inheritance?,"An Object is an instance of a Class. When a class is defined, no memory is allocated but when it is instantiated (i.e. an object is created) memory is allocated.",The capability of a class to derive properties and characteristics from another class is called Inheritance,0
What is an Object?,"An object is an instance of a class. It has its own state, behavior, and identity.",an object is an element of a class; objects have the behaviors of their class. The object is the actual component of programs,1
What is an Object?,"An object is an instance of a class. It has its own state, behavior, and identity.","operator that takes three operands: a condition followed by a question mark ( ? ), then an expression to execute if the condition is truthy or not.",0
What is a ternary operator?,an object is an element of a class; objects have the behaviors of their class. The object is the actual component of programs,a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,0
What is an Object?,"An Object is an instance of a Class. When a class is defined, no memory is allocated but when it is instantiated (i.e. an object is created) memory is allocated.",an object is an element of a class; objects have the behaviors of their class. The object is the actual component of programs,1
What is an Object?,"An Object is an instance of a Class. When a class is defined, no memory is allocated but when it is instantiated (i.e. an object is created) memory is allocated.","Encapsulation is an attribute of an object, and it contains all data which is hidden. That hidden data can be restricted to the members of that class.Levels are Public, Protected, Private, Internal, and Protected Internal.",0
What is Encapsulation?,an object is an element of a class; objects have the behaviors of their class. The object is the actual component of programs,"Encapsulation is used to hide the values or state of a structured data object inside a class, preventing unauthorized parties' direct access to them.",0
What is Encapsulation?,"Encapsulation is an attribute of an object, and it contains all data which is hidden. That hidden data can be restricted to the members of that class.Levels are Public, Protected, Private, Internal, and Protected Internal.","Encapsulation is used to hide the values or state of a structured data object inside a class, preventing unauthorized parties' direct access to them.",1
What is Encapsulation?,"Encapsulation is an attribute of an object, and it contains all data which is hidden. That hidden data can be restricted to the members of that class.Levels are Public, Protected, Private, Internal, and Protected Internal.","An object is an instance of a class. It has its own state, behavior, and identity.",0
What is an Object?,"Encapsulation is used to hide the values or state of a structured data object inside a class, preventing unauthorized parties' direct access to them.",an object is an element of a class; objects have the behaviors of their class. The object is the actual component of programs,0
What is Encapsulation?,"Encapsulation is an attribute of an object, and it contains all data which is hidden. That hidden data can be restricted to the members of that class.Levels are Public, Protected, Private, Internal, and Protected Internal.","This concept is often used to hide the internal representation, or state, of an object from the outside.",1
What is Encapsulation?,"Encapsulation is an attribute of an object, and it contains all data which is hidden. That hidden data can be restricted to the members of that class.Levels are Public, Protected, Private, Internal, and Protected Internal.",A constructor is called automatically when we create an object of a class.,0
Explain the term constructor,"This concept is often used to hide the internal representation, or state, of an object from the outside.","A constructor is a member function of a class which initializes objects of a class. In C++, Constructor is automatically called when object(instance of class) create. It is special member function of the class.J",0
What is Encapsulation?,"Encapsulation is an attribute of an object, and it contains all data which is hidden. That hidden data can be restricted to the members of that class.Levels are Public, Protected, Private, Internal, and Protected Internal.",encapsulation is the inclusion of one thing within another thing so that the included thing is not apparent.,1
What is Encapsulation?,"Encapsulation is an attribute of an object, and it contains all data which is hidden. That hidden data can be restricted to the members of that class.Levels are Public, Protected, Private, Internal, and Protected Internal.",A class is simply a representation of a type of object. It is the blueprint/plan/template that describes the details of an object.,0
What is a class?,encapsulation is the inclusion of one thing within another thing so that the included thing is not apparent.,A class is a program-code-template that allows developers to create an object that has both variables (data) and behaviors (functions or methods).,0
What is Encapsulation?,"Encapsulation is used to hide the values or state of a structured data object inside a class, preventing unauthorized parties' direct access to them.","This concept is often used to hide the internal representation, or state, of an object from the outside.",1
What is Encapsulation?,"Encapsulation is used to hide the values or state of a structured data object inside a class, preventing unauthorized parties' direct access to them.","programming feature that allows us to have more than one function having same name but different parameter list,",0
What is function overloading?,"This concept is often used to hide the internal representation, or state, of an object from the outside.",function overloading or method overloading is the ability to create multiple functions of the same name with different implementations.,0
What is Encapsulation?,"Encapsulation is used to hide the values or state of a structured data object inside a class, preventing unauthorized parties' direct access to them.",encapsulation is the inclusion of one thing within another thing so that the included thing is not apparent.,1
What is Encapsulation?,"Encapsulation is used to hide the values or state of a structured data object inside a class, preventing unauthorized parties' direct access to them.","operator that takes three operands: a condition followed by a question mark ( ? ), then an expression to execute if the condition is truthy or not.",0
What is a ternary operator?,encapsulation is the inclusion of one thing within another thing so that the included thing is not apparent.,"The ternary operator is an operator that exists in some programming languages, which takes three operands rather than the typical one or two and is used to evaluate Boolean expressions.",0
What is Encapsulation?,"This concept is often used to hide the internal representation, or state, of an object from the outside.",encapsulation is the inclusion of one thing within another thing so that the included thing is not apparent.,1
What is Encapsulation?,"This concept is often used to hide the internal representation, or state, of an object from the outside.",A destructor is a special method that gets called automatically as soon as the life-cycle of an object is finished. A destructor is called to de-allocate and free memory.,0
Define Destructor?,encapsulation is the inclusion of one thing within another thing so that the included thing is not apparent.,A destructor is a special method called automatically during the destruction of an object.,0
What is Polymorphism?,"Polymorphism is nothing but assigning behavior or value in a subclass to something that was already declared in the main class. Simply, polymorphism takes more than one form.",The word polymorphism is used in various contexts and describes situations in which something occurs in several different forms.,1
What is Polymorphism?,"Polymorphism is nothing but assigning behavior or value in a subclass to something that was already declared in the main class. Simply, polymorphism takes more than one form.",A destructor is a method which is automatically called when the object is made of scope or destroyed. Destructor name is also same as class name but with the tilde symbol before the name.,0
Define Destructor?,The word polymorphism is used in various contexts and describes situations in which something occurs in several different forms.,A destructor is a special method called automatically during the destruction of an object.,0
What is Polymorphism?,"Polymorphism is nothing but assigning behavior or value in a subclass to something that was already declared in the main class. Simply, polymorphism takes more than one form.",The word polymorphism means having many forms.,1
What is Polymorphism?,"Polymorphism is nothing but assigning behavior or value in a subclass to something that was already declared in the main class. Simply, polymorphism takes more than one form.","Inheritance is a mechanism in which one class acquires the property of another class. For example, a child inherits the traits of his/her parents.",0
What is Inheritance?,The word polymorphism means having many forms.,The capability of a class to derive properties and characteristics from another class is called Inheritance,0
What is Polymorphism?,"Polymorphism is nothing but assigning behavior or value in a subclass to something that was already declared in the main class. Simply, polymorphism takes more than one form.",polymorphism is that which can be defined in multiple forms,1
What is Polymorphism?,"Polymorphism is nothing but assigning behavior or value in a subclass to something that was already declared in the main class. Simply, polymorphism takes more than one form.",a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,0
What is a ternary operator?,polymorphism is that which can be defined in multiple forms,"The ternary operator is an operator that exists in some programming languages, which takes three operands rather than the typical one or two and is used to evaluate Boolean expressions.",0
What is Polymorphism?,The word polymorphism means having many forms.,polymorphism is that which can be defined in multiple forms,1
What is Polymorphism?,The word polymorphism means having many forms.,"Inheritance is a mechanism in which one class acquires the property of another class. For example, a child inherits the traits of his/her parents.",0
What is Inheritance?,polymorphism is that which can be defined in multiple forms,is a mechanism in which one object acquires all the properties and behaviors of a parent object.,0
What is Inheritance?,"Inheritance is a mechanism in which one class acquires the property of another class. For example, a child inherits the traits of his/her parents.",is a mechanism in which one object acquires all the properties and behaviors of a parent object.,1
What is Inheritance?,"Inheritance is a mechanism in which one class acquires the property of another class. For example, a child inherits the traits of his/her parents.",A virtual function is a member function which is declared within a base class and is re-defined(Overriden) by a derived class.,0
What is a virtual function?,is a mechanism in which one object acquires all the properties and behaviors of a parent object.,A virtual function is a member function that you expect to be redefined in derived classes.,0
What is Inheritance?,"Inheritance is a mechanism in which one class acquires the property of another class. For example, a child inherits the traits of his/her parents.",The capability of a class to derive properties and characteristics from another class is called Inheritance,1
What is Inheritance?,"Inheritance is a mechanism in which one class acquires the property of another class. For example, a child inherits the traits of his/her parents.",A pure virtual function is a function that must be overridden in a derived class and need not be defined. A virtual function is declared to bepure using the curious =0 syntax.,0
What is a pure virtual function?,The capability of a class to derive properties and characteristics from another class is called Inheritance,"A pure virtual function (or abstract function) in C++ is a virtual function for which we don't have an implementation, we only declare it. A pure virtual function is declared by assigning 0 in the declaration.",0
What is Inheritance?,is a mechanism in which one object acquires all the properties and behaviors of a parent object.,The capability of a class to derive properties and characteristics from another class is called Inheritance,1
What is Inheritance?,is a mechanism in which one object acquires all the properties and behaviors of a parent object.,"A constructor is a special method of a class or structure in object-oriented programming that initializes a newly created object of that type. Whenever an object is created, the constructor is called automatically.",0
Explain the term constructor,The capability of a class to derive properties and characteristics from another class is called Inheritance,"Constructors have the same name as the class or struct, and they usually initialize the data members of the new object.",0
What are manipulators?,Manipulators are the functions which can be used in conjunction with the insertion (<<) and extraction (>>) operators on an object. Examples are endl and setw.,"are functions specifically designed to be used in conjunction with the insertion (<<) and extraction (>>) operators on stream objects,",1
What are manipulators?,Manipulators are the functions which can be used in conjunction with the insertion (<<) and extraction (>>) operators on an object. Examples are endl and setw.,Function overloading is a feature in C++ where two or more functions can have the same name but different parameters.,0
What is function overloading?,"are functions specifically designed to be used in conjunction with the insertion (<<) and extraction (>>) operators on stream objects,",Overloading occurs when two or more methods in one class have the same method name but different parameters.,0
Explain the term constructor,"A constructor is a method used to initialize the state of an object, and it gets invoked automatically at the time of object creation. Rules for constructor are:Constructor Name should be the same as a class name.A constructor must have no return type.","A constructor is a special method of a class or structure in object-oriented programming that initializes a newly created object of that type. Whenever an object is created, the constructor is called automatically.",1
Explain the term constructor,"A constructor is a method used to initialize the state of an object, and it gets invoked automatically at the time of object creation. Rules for constructor are:Constructor Name should be the same as a class name.A constructor must have no return type.","Polymorphism is nothing but assigning behavior or value in a subclass to something that was already declared in the main class. Simply, polymorphism takes more than one form.",0
What is Polymorphism?,"A constructor is a special method of a class or structure in object-oriented programming that initializes a newly created object of that type. Whenever an object is created, the constructor is called automatically.",The word polymorphism means having many forms.,0
Explain the term constructor,"A constructor is a method used to initialize the state of an object, and it gets invoked automatically at the time of object creation. Rules for constructor are:Constructor Name should be the same as a class name.A constructor must have no return type.","Constructors have the same name as the class or struct, and they usually initialize the data members of the new object.",1
Explain the term constructor,"A constructor is a method used to initialize the state of an object, and it gets invoked automatically at the time of object creation. Rules for constructor are:Constructor Name should be the same as a class name.A constructor must have no return type.","Function overloading is a regular function, but it can perform different tasks. It allows the creation of several methods with the same name which differ from each other by the type of input and output of the function.",0
What is function overloading?,"Constructors have the same name as the class or struct, and they usually initialize the data members of the new object.","programming feature that allows us to have more than one function having same name but different parameter list,",0
Explain the term constructor,"A constructor is a method used to initialize the state of an object, and it gets invoked automatically at the time of object creation. Rules for constructor are:Constructor Name should be the same as a class name.A constructor must have no return type.","A class constructor is a special member function of a class that is executed whenever we create new objects of that class. A constructor will have exact same name as the class and it does not have any return type at all,",1
Explain the term constructor,"A constructor is a method used to initialize the state of an object, and it gets invoked automatically at the time of object creation. Rules for constructor are:Constructor Name should be the same as a class name.A constructor must have no return type.",A destructor is a method which is automatically called when the object is made of scope or destroyed. Destructor name is also same as class name but with the tilde symbol before the name.,0
Define Destructor?,"A class constructor is a special member function of a class that is executed whenever we create new objects of that class. A constructor will have exact same name as the class and it does not have any return type at all,","A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",0
Explain the term constructor,"A constructor is a method used to initialize the state of an object, and it gets invoked automatically at the time of object creation. Rules for constructor are:Constructor Name should be the same as a class name.A constructor must have no return type.",A constructor is called automatically when we create an object of a class.,1
Explain the term constructor,"A constructor is a method used to initialize the state of an object, and it gets invoked automatically at the time of object creation. Rules for constructor are:Constructor Name should be the same as a class name.A constructor must have no return type.","An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code",0
What is an Inline function?,A constructor is called automatically when we create an object of a class.,"An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code,",0
Explain the term constructor,"A constructor is a method used to initialize the state of an object, and it gets invoked automatically at the time of object creation. Rules for constructor are:Constructor Name should be the same as a class name.A constructor must have no return type.","A constructor is a member function of a class which initializes objects of a class. In C++, Constructor is automatically called when object(instance of class) create. It is special member function of the class.J",1
Define Destructor?,"A constructor is a member function of a class which initializes objects of a class. In C++, Constructor is automatically called when object(instance of class) create. It is special member function of the class.J",A destructor is a special method that gets called automatically as soon as the life-cycle of an object is finished. A destructor is called to de-allocate and free memory.,0
Explain the term constructor,"A constructor is a special method of a class or structure in object-oriented programming that initializes a newly created object of that type. Whenever an object is created, the constructor is called automatically.","Constructors have the same name as the class or struct, and they usually initialize the data members of the new object.",1
Explain the term constructor,"A constructor is a special method of a class or structure in object-oriented programming that initializes a newly created object of that type. Whenever an object is created, the constructor is called automatically.","An interface is a collection of an abstract method. If the class implements an interface, it thereby inherits all the abstract methods of an interface.Java uses Interface to implement multiple inheritances.",0
What is an interface?,"Constructors have the same name as the class or struct, and they usually initialize the data members of the new object.","An interface is an abstract ""class"" that is used to group related methods with ""empty"" bodies",0
Explain the term constructor,"A constructor is a special method of a class or structure in object-oriented programming that initializes a newly created object of that type. Whenever an object is created, the constructor is called automatically.","A class constructor is a special member function of a class that is executed whenever we create new objects of that class. A constructor will have exact same name as the class and it does not have any return type at all,",1
Explain the term constructor,"A constructor is a special method of a class or structure in object-oriented programming that initializes a newly created object of that type. Whenever an object is created, the constructor is called automatically.","Function overloading is a regular function, but it can perform different tasks. It allows the creation of several methods with the same name which differ from each other by the type of input and output of the function.",0
What is function overloading?,"A class constructor is a special member function of a class that is executed whenever we create new objects of that class. A constructor will have exact same name as the class and it does not have any return type at all,","programming feature that allows us to have more than one function having same name but different parameter list,",0
Explain the term constructor,"A constructor is a special method of a class or structure in object-oriented programming that initializes a newly created object of that type. Whenever an object is created, the constructor is called automatically.",A constructor is called automatically when we create an object of a class.,1
Explain the term constructor,"A constructor is a special method of a class or structure in object-oriented programming that initializes a newly created object of that type. Whenever an object is created, the constructor is called automatically.",The ternary operator is also known as the conditional operator. This operator consists of three operands and is used to evaluate Boolean expressions.,0
What is a ternary operator?,A constructor is called automatically when we create an object of a class.,a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,0
Explain the term constructor,"A constructor is a special method of a class or structure in object-oriented programming that initializes a newly created object of that type. Whenever an object is created, the constructor is called automatically.","A constructor is a member function of a class which initializes objects of a class. In C++, Constructor is automatically called when object(instance of class) create. It is special member function of the class.J",1
Explain the term constructor,"A constructor is a special method of a class or structure in object-oriented programming that initializes a newly created object of that type. Whenever an object is created, the constructor is called automatically.",Inline function is a function that is expanded in line when it is called. When the inline function is called whole code of the inline function gets inserted or substituted at the point of inline function call.,0
What is an Inline function?,"A constructor is a member function of a class which initializes objects of a class. In C++, Constructor is automatically called when object(instance of class) create. It is special member function of the class.J","An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code",0
Explain the term constructor,"Constructors have the same name as the class or struct, and they usually initialize the data members of the new object.","A class constructor is a special member function of a class that is executed whenever we create new objects of that class. A constructor will have exact same name as the class and it does not have any return type at all,",1
Explain the term constructor,"Constructors have the same name as the class or struct, and they usually initialize the data members of the new object.","programming feature that allows us to have more than one function having same name but different parameter list,",0
What is function overloading?,"A class constructor is a special member function of a class that is executed whenever we create new objects of that class. A constructor will have exact same name as the class and it does not have any return type at all,",Overloading occurs when two or more methods in one class have the same method name but different parameters.,0
Explain the term constructor,"Constructors have the same name as the class or struct, and they usually initialize the data members of the new object.",A constructor is called automatically when we create an object of a class.,1
Explain the term constructor,"Constructors have the same name as the class or struct, and they usually initialize the data members of the new object.",The ternary operator is also known as the conditional operator. This operator consists of three operands and is used to evaluate Boolean expressions.,0
Explain the term constructor,"Constructors have the same name as the class or struct, and they usually initialize the data members of the new object.","A constructor is a member function of a class which initializes objects of a class. In C++, Constructor is automatically called when object(instance of class) create. It is special member function of the class.J",1
Explain the term constructor,"Constructors have the same name as the class or struct, and they usually initialize the data members of the new object.",Overloading occurs when two or more methods in one class have the same method name but different parameters.,0
What is function overloading?,"A constructor is a member function of a class which initializes objects of a class. In C++, Constructor is automatically called when object(instance of class) create. It is special member function of the class.J",function overloading or method overloading is the ability to create multiple functions of the same name with different implementations.,0
Explain the term constructor,"A class constructor is a special member function of a class that is executed whenever we create new objects of that class. A constructor will have exact same name as the class and it does not have any return type at all,",A constructor is called automatically when we create an object of a class.,1
Explain the term constructor,"A class constructor is a special member function of a class that is executed whenever we create new objects of that class. A constructor will have exact same name as the class and it does not have any return type at all,","Encapsulation is used to hide the values or state of a structured data object inside a class, preventing unauthorized parties' direct access to them.",0
What is Encapsulation?,A constructor is called automatically when we create an object of a class.,"This concept is often used to hide the internal representation, or state, of an object from the outside.",0
Explain the term constructor,"A class constructor is a special member function of a class that is executed whenever we create new objects of that class. A constructor will have exact same name as the class and it does not have any return type at all,","A constructor is a member function of a class which initializes objects of a class. In C++, Constructor is automatically called when object(instance of class) create. It is special member function of the class.J",1
Explain the term constructor,"A class constructor is a special member function of a class that is executed whenever we create new objects of that class. A constructor will have exact same name as the class and it does not have any return type at all,",A virtual function is a member function which is declared within a base class and is re-defined(Overriden) by a derived class.,0
What is a virtual function?,"A constructor is a member function of a class which initializes objects of a class. In C++, Constructor is automatically called when object(instance of class) create. It is special member function of the class.J",virtual function is a member function in the base class that you redefine in a derived class.,0
Explain the term constructor,A constructor is called automatically when we create an object of a class.,"A constructor is a member function of a class which initializes objects of a class. In C++, Constructor is automatically called when object(instance of class) create. It is special member function of the class.J",1
Explain the term constructor,A constructor is called automatically when we create an object of a class.,"An interface is a collection of an abstract method. If the class implements an interface, it thereby inherits all the abstract methods of an interface.Java uses Interface to implement multiple inheritances.",0
What is an interface?,"A constructor is a member function of a class which initializes objects of a class. In C++, Constructor is automatically called when object(instance of class) create. It is special member function of the class.J","An interface is an abstract ""class"" that is used to group related methods with ""empty"" bodies",0
Define Destructor?,A destructor is a method which is automatically called when the object is made of scope or destroyed. Destructor name is also same as class name but with the tilde symbol before the name.,"A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",1
Define Destructor?,A destructor is a method which is automatically called when the object is made of scope or destroyed. Destructor name is also same as class name but with the tilde symbol before the name.,Inline function is a function that is expanded in line when it is called. When the inline function is called whole code of the inline function gets inserted or substituted at the point of inline function call.,0
What is an Inline function?,"A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde","An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code,",0
Define Destructor?,A destructor is a method which is automatically called when the object is made of scope or destroyed. Destructor name is also same as class name but with the tilde symbol before the name.,A destructor is a special method that gets called automatically as soon as the life-cycle of an object is finished. A destructor is called to de-allocate and free memory.,1
Define Destructor?,A destructor is a method which is automatically called when the object is made of scope or destroyed. Destructor name is also same as class name but with the tilde symbol before the name.,"A virtual function is a member function of a class, and its functionality can be overridden in its derived class. This function can be implemented by using a keyword called virtual, and it can be given during function declaration.",0
What is a virtual function?,A destructor is a special method that gets called automatically as soon as the life-cycle of an object is finished. A destructor is called to de-allocate and free memory.,A virtual function is a member function that you expect to be redefined in derived classes.,0
Define Destructor?,A destructor is a method which is automatically called when the object is made of scope or destroyed. Destructor name is also same as class name but with the tilde symbol before the name.,"programming feature that allows us to have more than one function having same name but different parameter list,",0
What is function overloading?,"A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",Overloading occurs when two or more methods in one class have the same method name but different parameters.,0
Define Destructor?,A destructor is a method which is automatically called when the object is made of scope or destroyed. Destructor name is also same as class name but with the tilde symbol before the name.,A destructor is a special method called automatically during the destruction of an object.,1
What is an Inline function?,A destructor is a special method called automatically during the destruction of an object.,"An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code",0
Define Destructor?,"A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",A destructor is a special method that gets called automatically as soon as the life-cycle of an object is finished. A destructor is called to de-allocate and free memory.,1
Define Destructor?,"A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",Inline function is a function that is expanded in line when it is called. When the inline function is called whole code of the inline function gets inserted or substituted at the point of inline function call.,0
What is an Inline function?,A destructor is a special method that gets called automatically as soon as the life-cycle of an object is finished. A destructor is called to de-allocate and free memory.,"An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code",0
Define Destructor?,"A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde","A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",1
What is an Inline function?,"A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde","An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code",0
Define Destructor?,"A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",A destructor is a special method called automatically during the destruction of an object.,1
Define Destructor?,"A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde","The new modifier instructs the compiler to use the new implementation instead of the base class function. Whereas, Override modifier helps to override the base class function.",0
What is the difference between new and override?,A destructor is a special method called automatically during the destruction of an object.,"verride: overrides the functionality of a virtual method in a base class, providing different functionality. new: hides the original method (which doesn't have to be virtual), providing different functionality.",0
Define Destructor?,A destructor is a special method that gets called automatically as soon as the life-cycle of an object is finished. A destructor is called to de-allocate and free memory.,"A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",1
Define Destructor?,A destructor is a special method that gets called automatically as soon as the life-cycle of an object is finished. A destructor is called to de-allocate and free memory.,"Encapsulation is used to hide the values or state of a structured data object inside a class, preventing unauthorized parties' direct access to them.",0
What is Encapsulation?,"A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",encapsulation is the inclusion of one thing within another thing so that the included thing is not apparent.,0
Define Destructor?,A destructor is a special method that gets called automatically as soon as the life-cycle of an object is finished. A destructor is called to de-allocate and free memory.,A destructor is a special method called automatically during the destruction of an object.,1
Define Destructor?,A destructor is a special method that gets called automatically as soon as the life-cycle of an object is finished. A destructor is called to de-allocate and free memory.,The ternary operator is also known as the conditional operator. This operator consists of three operands and is used to evaluate Boolean expressions.,0
What is a ternary operator?,A destructor is a special method called automatically during the destruction of an object.,"The ternary operator is an operator that exists in some programming languages, which takes three operands rather than the typical one or two and is used to evaluate Boolean expressions.",0
Define Destructor?,"A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",Manipulators are the functions which can be used in conjunction with the insertion (<<) and extraction (>>) operators on an object. Examples are endl and setw.,0
What are manipulators?,A destructor is a special method called automatically during the destruction of an object.,"are functions specifically designed to be used in conjunction with the insertion (<<) and extraction (>>) operators on stream objects,",0
What is an Inline function?,Inline function is a function that is expanded in line when it is called. When the inline function is called whole code of the inline function gets inserted or substituted at the point of inline function call.,"An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code",1
What is an Inline function?,Inline function is a function that is expanded in line when it is called. When the inline function is called whole code of the inline function gets inserted or substituted at the point of inline function call.,A Class in object oriented programming is a blueprint or prototype that defines the variables and the methods (functions) common to all Java Objects of a certain kind.,0
What is a class?,"An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code",A class is a program-code-template that allows developers to create an object that has both variables (data) and behaviors (functions or methods).,0
What is an Inline function?,Inline function is a function that is expanded in line when it is called. When the inline function is called whole code of the inline function gets inserted or substituted at the point of inline function call.,enhancement feature to increase the execution time of a program. Functions can be instructed to compiler to make them inline so that compiler can replace those function definition wherever those are being called.,1
What is an Inline function?,Inline function is a function that is expanded in line when it is called. When the inline function is called whole code of the inline function gets inserted or substituted at the point of inline function call.,"The ternary operator is said to be an operator which takes three arguments. Arguments and results are of different data types, and it depends on the function. The ternary operator is also called a conditional operator.",0
What is a ternary operator?,enhancement feature to increase the execution time of a program. Functions can be instructed to compiler to make them inline so that compiler can replace those function definition wherever those are being called.,a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,0
What is an Inline function?,Inline function is a function that is expanded in line when it is called. When the inline function is called whole code of the inline function gets inserted or substituted at the point of inline function call.,"An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code,",1
What is an Inline function?,Inline function is a function that is expanded in line when it is called. When the inline function is called whole code of the inline function gets inserted or substituted at the point of inline function call.,"A virtual function is a member function of a class, and its functionality can be overridden in its derived class. This function can be implemented by using a keyword called virtual, and it can be given during function declaration.",0
What is a virtual function?,"An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code,",virtual function is a member function in the base class that you redefine in a derived class.,0
What is an Inline function?,"An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code",enhancement feature to increase the execution time of a program. Functions can be instructed to compiler to make them inline so that compiler can replace those function definition wherever those are being called.,1
What is an Inline function?,"An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code",this is a keyword that refers to the current instance of the class.,0
What is this pointer?,enhancement feature to increase the execution time of a program. Functions can be instructed to compiler to make them inline so that compiler can replace those function definition wherever those are being called.,"this pointer holds the address of current object, in simple words you can say that this pointer points to the current object of the class.",0
What is an Inline function?,"An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code","An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code,",1
What is an Inline function?,"An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code","operator that takes three operands: a condition followed by a question mark ( ? ), then an expression to execute if the condition is truthy or not.",0
What is a ternary operator?,"An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code,","The ternary operator is an operator that exists in some programming languages, which takes three operands rather than the typical one or two and is used to evaluate Boolean expressions.",0
What is an Inline function?,enhancement feature to increase the execution time of a program. Functions can be instructed to compiler to make them inline so that compiler can replace those function definition wherever those are being called.,"An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code,",1
What is an Inline function?,enhancement feature to increase the execution time of a program. Functions can be instructed to compiler to make them inline so that compiler can replace those function definition wherever those are being called.,A virtual function is a member function which is declared within a base class and is re-defined(Overriden) by a derived class.,0
What is a virtual function?,"An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code,",A virtual function is a member function that you expect to be redefined in derived classes.,0
What is a virtual function?,A virtual function is a member function which is declared within a base class and is re-defined(Overriden) by a derived class.,"A virtual function is a member function of a class, and its functionality can be overridden in its derived class. This function can be implemented by using a keyword called virtual, and it can be given during function declaration.",1
What is a virtual function?,A virtual function is a member function which is declared within a base class and is re-defined(Overriden) by a derived class.,"operator that takes three operands: a condition followed by a question mark ( ? ), then an expression to execute if the condition is truthy or not.",0
What is a ternary operator?,"A virtual function is a member function of a class, and its functionality can be overridden in its derived class. This function can be implemented by using a keyword called virtual, and it can be given during function declaration.",a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,0
What is a virtual function?,A virtual function is a member function which is declared within a base class and is re-defined(Overriden) by a derived class.,A virtual function is a member function that you expect to be redefined in derived classes.,1
What is a virtual function?,A virtual function is a member function which is declared within a base class and is re-defined(Overriden) by a derived class.,"The ternary operator is said to be an operator which takes three arguments. Arguments and results are of different data types, and it depends on the function. The ternary operator is also called a conditional operator.",0
What is a ternary operator?,A virtual function is a member function that you expect to be redefined in derived classes.,a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,0
What is a virtual function?,A virtual function is a member function which is declared within a base class and is re-defined(Overriden) by a derived class.,virtual function is a member function in the base class that you redefine in a derived class.,1
What is a virtual function?,A virtual function is a member function which is declared within a base class and is re-defined(Overriden) by a derived class.,"A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",0
Define Destructor?,virtual function is a member function in the base class that you redefine in a derived class.,"A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",0
What is a virtual function?,"A virtual function is a member function of a class, and its functionality can be overridden in its derived class. This function can be implemented by using a keyword called virtual, and it can be given during function declaration.",A virtual function is a member function that you expect to be redefined in derived classes.,1
What is a virtual function?,"A virtual function is a member function of a class, and its functionality can be overridden in its derived class. This function can be implemented by using a keyword called virtual, and it can be given during function declaration.",A class is simply a representation of a type of object. It is the blueprint/plan/template that describes the details of an object.,0
What is a class?,A virtual function is a member function that you expect to be redefined in derived classes.,A class is a program-code-template that allows developers to create an object that has both variables (data) and behaviors (functions or methods).,0
What is a virtual function?,"A virtual function is a member function of a class, and its functionality can be overridden in its derived class. This function can be implemented by using a keyword called virtual, and it can be given during function declaration.",virtual function is a member function in the base class that you redefine in a derived class.,1
What is a virtual function?,"A virtual function is a member function of a class, and its functionality can be overridden in its derived class. This function can be implemented by using a keyword called virtual, and it can be given during function declaration.",The ternary operator is also known as the conditional operator. This operator consists of three operands and is used to evaluate Boolean expressions.,0
What is a ternary operator?,virtual function is a member function in the base class that you redefine in a derived class.,a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,0
What is a virtual function?,A virtual function is a member function that you expect to be redefined in derived classes.,virtual function is a member function in the base class that you redefine in a derived class.,1
What is a virtual function?,A virtual function is a member function that you expect to be redefined in derived classes.,Function overloading is a feature in C++ where two or more functions can have the same name but different parameters.,0
What is function overloading?,virtual function is a member function in the base class that you redefine in a derived class.,"programming feature that allows us to have more than one function having same name but different parameter list,",0
What is a friend function?,"A friend function is a friend of a class that is allowed to access to Public, private, or protected data in that same class. If the function is defined outside the class cannot access such information.A friend can be declared anywhere in the class declaration, and it cannot be affected by access control keywords like private, public, or protected.",A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,1
What is a friend function?,"A friend function is a friend of a class that is allowed to access to Public, private, or protected data in that same class. If the function is defined outside the class cannot access such information.A friend can be declared anywhere in the class declaration, and it cannot be affected by access control keywords like private, public, or protected.","Encapsulation is used to hide the values or state of a structured data object inside a class, preventing unauthorized parties' direct access to them.",0
What is Encapsulation?,A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,"This concept is often used to hide the internal representation, or state, of an object from the outside.",0
What is a friend function?,"A friend function is a friend of a class that is allowed to access to Public, private, or protected data in that same class. If the function is defined outside the class cannot access such information.A friend can be declared anywhere in the class declaration, and it cannot be affected by access control keywords like private, public, or protected.",A friend function can access the private and protected data of a class.,1
What is a friend function?,"A friend function is a friend of a class that is allowed to access to Public, private, or protected data in that same class. If the function is defined outside the class cannot access such information.A friend can be declared anywhere in the class declaration, and it cannot be affected by access control keywords like private, public, or protected.",A virtual function is a member function which is declared within a base class and is re-defined(Overriden) by a derived class.,0
What is a virtual function?,A friend function can access the private and protected data of a class.,A virtual function is a member function that you expect to be redefined in derived classes.,0
What is a friend function?,"A friend function is a friend of a class that is allowed to access to Public, private, or protected data in that same class. If the function is defined outside the class cannot access such information.A friend can be declared anywhere in the class declaration, and it cannot be affected by access control keywords like private, public, or protected.","that is a ""friend"" of a given class, is a function that is given the same access as methods to private and protected data.",1
What is a friend function?,"A friend function is a friend of a class that is allowed to access to Public, private, or protected data in that same class. If the function is defined outside the class cannot access such information.A friend can be declared anywhere in the class declaration, and it cannot be affected by access control keywords like private, public, or protected.","An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code",0
What is an Inline function?,"that is a ""friend"" of a given class, is a function that is given the same access as methods to private and protected data.",enhancement feature to increase the execution time of a program. Functions can be instructed to compiler to make them inline so that compiler can replace those function definition wherever those are being called.,0
What is a friend function?,"A friend function is a friend of a class that is allowed to access to Public, private, or protected data in that same class. If the function is defined outside the class cannot access such information.A friend can be declared anywhere in the class declaration, and it cannot be affected by access control keywords like private, public, or protected.",The ternary operator is also known as the conditional operator. This operator consists of three operands and is used to evaluate Boolean expressions.,0
What is a ternary operator?,A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,0
What is a friend function?,A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,A friend function can access the private and protected data of a class.,1
What is a friend function?,A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,"Encapsulation is an attribute of an object, and it contains all data which is hidden. That hidden data can be restricted to the members of that class.Levels are Public, Protected, Private, Internal, and Protected Internal.",0
What is Encapsulation?,A friend function can access the private and protected data of a class.,"This concept is often used to hide the internal representation, or state, of an object from the outside.",0
What is a friend function?,A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,"that is a ""friend"" of a given class, is a function that is given the same access as methods to private and protected data.",1
What is a friend function?,A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,"An interface is a collection of an abstract method. If the class implements an interface, it thereby inherits all the abstract methods of an interface.Java uses Interface to implement multiple inheritances.",0
What is an interface?,"that is a ""friend"" of a given class, is a function that is given the same access as methods to private and protected data.","An interface is a reference type in Java. It is similar to class. It is a collection of abstract methods. A class implements an interface, thereby inheriting the abstract methods of the interface.",0
What is a friend function?,A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,1
What is a friend function?,A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,"A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",0
Define Destructor?,A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,A destructor is a special method called automatically during the destruction of an object.,0
What is a friend function?,A friend function can access the private and protected data of a class.,"that is a ""friend"" of a given class, is a function that is given the same access as methods to private and protected data.",1
What is a friend function?,A friend function can access the private and protected data of a class.,"An interface is a collection of an abstract method. If the class implements an interface, it thereby inherits all the abstract methods of an interface.Java uses Interface to implement multiple inheritances.",0
What is an interface?,"that is a ""friend"" of a given class, is a function that is given the same access as methods to private and protected data.","An interface is a completely ""abstract class"" that is used to group related methods with empty bodies:",0
What is a friend function?,A friend function can access the private and protected data of a class.,A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,1
What is a friend function?,A friend function can access the private and protected data of a class.,Manipulators are the functions which can be used in conjunction with the insertion (<<) and extraction (>>) operators on an object. Examples are endl and setw.,0
What are manipulators?,A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,"are functions specifically designed to be used in conjunction with the insertion (<<) and extraction (>>) operators on stream objects,",0
What is a friend function?,"that is a ""friend"" of a given class, is a function that is given the same access as methods to private and protected data.",A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,1
What is a friend function?,"that is a ""friend"" of a given class, is a function that is given the same access as methods to private and protected data.","Polymorphism is nothing but assigning behavior or value in a subclass to something that was already declared in the main class. Simply, polymorphism takes more than one form.",0
What is Polymorphism?,A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,The word polymorphism is used in various contexts and describes situations in which something occurs in several different forms.,0
What is function overloading?,"Function overloading is a regular function, but it can perform different tasks. It allows the creation of several methods with the same name which differ from each other by the type of input and output of the function.",Function overloading is a feature in C++ where two or more functions can have the same name but different parameters.,1
What is function overloading?,"Function overloading is a regular function, but it can perform different tasks. It allows the creation of several methods with the same name which differ from each other by the type of input and output of the function.",A Class in object oriented programming is a blueprint or prototype that defines the variables and the methods (functions) common to all Java Objects of a certain kind.,0
What is a class?,Function overloading is a feature in C++ where two or more functions can have the same name but different parameters.,A class is a program-code-template that allows developers to create an object that has both variables (data) and behaviors (functions or methods).,0
What is function overloading?,"Function overloading is a regular function, but it can perform different tasks. It allows the creation of several methods with the same name which differ from each other by the type of input and output of the function.","programming feature that allows us to have more than one function having same name but different parameter list,",1
What is function overloading?,"Function overloading is a regular function, but it can perform different tasks. It allows the creation of several methods with the same name which differ from each other by the type of input and output of the function.",The ternary operator is also known as the conditional operator. This operator consists of three operands and is used to evaluate Boolean expressions.,0
What is a ternary operator?,"programming feature that allows us to have more than one function having same name but different parameter list,",a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,0
What is function overloading?,"Function overloading is a regular function, but it can perform different tasks. It allows the creation of several methods with the same name which differ from each other by the type of input and output of the function.",Overloading occurs when two or more methods in one class have the same method name but different parameters.,1
What is function overloading?,"Function overloading is a regular function, but it can perform different tasks. It allows the creation of several methods with the same name which differ from each other by the type of input and output of the function.",enhancement feature to increase the execution time of a program. Functions can be instructed to compiler to make them inline so that compiler can replace those function definition wherever those are being called.,0
What is an Inline function?,Overloading occurs when two or more methods in one class have the same method name but different parameters.,"An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code,",0
What is function overloading?,"Function overloading is a regular function, but it can perform different tasks. It allows the creation of several methods with the same name which differ from each other by the type of input and output of the function.",function overloading or method overloading is the ability to create multiple functions of the same name with different implementations.,1
What is function overloading?,"Function overloading is a regular function, but it can perform different tasks. It allows the creation of several methods with the same name which differ from each other by the type of input and output of the function.","Encapsulation is an attribute of an object, and it contains all data which is hidden. That hidden data can be restricted to the members of that class.Levels are Public, Protected, Private, Internal, and Protected Internal.",0
What is Encapsulation?,function overloading or method overloading is the ability to create multiple functions of the same name with different implementations.,encapsulation is the inclusion of one thing within another thing so that the included thing is not apparent.,0
What is function overloading?,Function overloading is a feature in C++ where two or more functions can have the same name but different parameters.,"programming feature that allows us to have more than one function having same name but different parameter list,",1
What is function overloading?,Function overloading is a feature in C++ where two or more functions can have the same name but different parameters.,A Class in object oriented programming is a blueprint or prototype that defines the variables and the methods (functions) common to all Java Objects of a certain kind.,0
What is a class?,"programming feature that allows us to have more than one function having same name but different parameter list,",A class is a program-code-template that allows developers to create an object that has both variables (data) and behaviors (functions or methods).,0
What is function overloading?,Function overloading is a feature in C++ where two or more functions can have the same name but different parameters.,Overloading occurs when two or more methods in one class have the same method name but different parameters.,1
What is function overloading?,Function overloading is a feature in C++ where two or more functions can have the same name but different parameters.,A friend function can access the private and protected data of a class.,0
What is a friend function?,Overloading occurs when two or more methods in one class have the same method name but different parameters.,"that is a ""friend"" of a given class, is a function that is given the same access as methods to private and protected data.",0
What is function overloading?,Function overloading is a feature in C++ where two or more functions can have the same name but different parameters.,function overloading or method overloading is the ability to create multiple functions of the same name with different implementations.,1
What is function overloading?,Function overloading is a feature in C++ where two or more functions can have the same name but different parameters.,A virtual function is a member function which is declared within a base class and is re-defined(Overriden) by a derived class.,0
What is a virtual function?,function overloading or method overloading is the ability to create multiple functions of the same name with different implementations.,A virtual function is a member function that you expect to be redefined in derived classes.,0
What is function overloading?,"programming feature that allows us to have more than one function having same name but different parameter list,",Overloading occurs when two or more methods in one class have the same method name but different parameters.,1
What is function overloading?,"programming feature that allows us to have more than one function having same name but different parameter list,",Manipulators are the functions which can be used in conjunction with the insertion (<<) and extraction (>>) operators on an object. Examples are endl and setw.,0
What are manipulators?,Overloading occurs when two or more methods in one class have the same method name but different parameters.,"are functions specifically designed to be used in conjunction with the insertion (<<) and extraction (>>) operators on stream objects,",0
What is function overloading?,"programming feature that allows us to have more than one function having same name but different parameter list,",function overloading or method overloading is the ability to create multiple functions of the same name with different implementations.,1
What is function overloading?,"programming feature that allows us to have more than one function having same name but different parameter list,","The ternary operator is said to be an operator which takes three arguments. Arguments and results are of different data types, and it depends on the function. The ternary operator is also called a conditional operator.",0
What is a ternary operator?,function overloading or method overloading is the ability to create multiple functions of the same name with different implementations.,"The ternary operator is an operator that exists in some programming languages, which takes three operands rather than the typical one or two and is used to evaluate Boolean expressions.",0
What is function overloading?,Overloading occurs when two or more methods in one class have the same method name but different parameters.,function overloading or method overloading is the ability to create multiple functions of the same name with different implementations.,1
What is function overloading?,Overloading occurs when two or more methods in one class have the same method name but different parameters.,"An abstract class is a class which cannot be instantiated. Creation of an object is not possible with an abstract class, but it can be inherited. An abstract class can contain only an Abstract method. Java allows only abstract method in abstract class while other languages allow non-abstract method as well.",0
What is an abstract class?,function overloading or method overloading is the ability to create multiple functions of the same name with different implementations.,"it may or may not include abstract methods. Abstract classes cannot be instantiated, but they can be subclassed.",0
What is an abstract class?,"An abstract class is a class which cannot be instantiated. Creation of an object is not possible with an abstract class, but it can be inherited. An abstract class can contain only an Abstract method. Java allows only abstract method in abstract class while other languages allow non-abstract method as well.","it may or may not include abstract methods. Abstract classes cannot be instantiated, but they can be subclassed.",1
What is an abstract class?,"An abstract class is a class which cannot be instantiated. Creation of an object is not possible with an abstract class, but it can be inherited. An abstract class can contain only an Abstract method. Java allows only abstract method in abstract class while other languages allow non-abstract method as well.",The ternary operator is also known as the conditional operator. This operator consists of three operands and is used to evaluate Boolean expressions.,0
What is a ternary operator?,"it may or may not include abstract methods. Abstract classes cannot be instantiated, but they can be subclassed.",a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,0
What is a ternary operator?,"The ternary operator is said to be an operator which takes three arguments. Arguments and results are of different data types, and it depends on the function. The ternary operator is also called a conditional operator.","operator that takes three operands: a condition followed by a question mark ( ? ), then an expression to execute if the condition is truthy or not.",1
What is a ternary operator?,"The ternary operator is said to be an operator which takes three arguments. Arguments and results are of different data types, and it depends on the function. The ternary operator is also called a conditional operator.","that is a ""friend"" of a given class, is a function that is given the same access as methods to private and protected data.",0
What is a friend function?,"operator that takes three operands: a condition followed by a question mark ( ? ), then an expression to execute if the condition is truthy or not.",A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,0
What is a ternary operator?,"The ternary operator is said to be an operator which takes three arguments. Arguments and results are of different data types, and it depends on the function. The ternary operator is also called a conditional operator.",The ternary operator is also known as the conditional operator. This operator consists of three operands and is used to evaluate Boolean expressions.,1
What is a ternary operator?,"The ternary operator is said to be an operator which takes three arguments. Arguments and results are of different data types, and it depends on the function. The ternary operator is also called a conditional operator.","Function overloading is a regular function, but it can perform different tasks. It allows the creation of several methods with the same name which differ from each other by the type of input and output of the function.",0
What is function overloading?,The ternary operator is also known as the conditional operator. This operator consists of three operands and is used to evaluate Boolean expressions.,function overloading or method overloading is the ability to create multiple functions of the same name with different implementations.,0
What is a ternary operator?,"The ternary operator is said to be an operator which takes three arguments. Arguments and results are of different data types, and it depends on the function. The ternary operator is also called a conditional operator.",a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,1
What is a ternary operator?,"The ternary operator is said to be an operator which takes three arguments. Arguments and results are of different data types, and it depends on the function. The ternary operator is also called a conditional operator.","An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code",0
What is an Inline function?,a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,"An inline function is a function that is expanded inline when it is invoked, thus saving time. The compiler replaces the function call with the corresponding function code,",0
What is a ternary operator?,"The ternary operator is said to be an operator which takes three arguments. Arguments and results are of different data types, and it depends on the function. The ternary operator is also called a conditional operator.","The ternary operator is an operator that exists in some programming languages, which takes three operands rather than the typical one or two and is used to evaluate Boolean expressions.",1
What is a ternary operator?,"The ternary operator is said to be an operator which takes three arguments. Arguments and results are of different data types, and it depends on the function. The ternary operator is also called a conditional operator.",A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,0
What is a friend function?,"The ternary operator is an operator that exists in some programming languages, which takes three operands rather than the typical one or two and is used to evaluate Boolean expressions.",A friend function of a class is defined outside that class' scope but it has the right to access all private and protected members of the class.,0
What is a ternary operator?,"operator that takes three operands: a condition followed by a question mark ( ? ), then an expression to execute if the condition is truthy or not.",The ternary operator is also known as the conditional operator. This operator consists of three operands and is used to evaluate Boolean expressions.,1
What is a ternary operator?,"operator that takes three operands: a condition followed by a question mark ( ? ), then an expression to execute if the condition is truthy or not.","Constructors have the same name as the class or struct, and they usually initialize the data members of the new object.",0
Explain the term constructor,The ternary operator is also known as the conditional operator. This operator consists of three operands and is used to evaluate Boolean expressions.,"A class constructor is a special member function of a class that is executed whenever we create new objects of that class. A constructor will have exact same name as the class and it does not have any return type at all,",0
What is a ternary operator?,"operator that takes three operands: a condition followed by a question mark ( ? ), then an expression to execute if the condition is truthy or not.",a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,1
What is a ternary operator?,"operator that takes three operands: a condition followed by a question mark ( ? ), then an expression to execute if the condition is truthy or not.","A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",0
Define Destructor?,a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,"A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",0
What is a ternary operator?,"operator that takes three operands: a condition followed by a question mark ( ? ), then an expression to execute if the condition is truthy or not.","The ternary operator is an operator that exists in some programming languages, which takes three operands rather than the typical one or two and is used to evaluate Boolean expressions.",1
What is a ternary operator?,"operator that takes three operands: a condition followed by a question mark ( ? ), then an expression to execute if the condition is truthy or not.",A destructor is a special method that gets called automatically as soon as the life-cycle of an object is finished. A destructor is called to de-allocate and free memory.,0
Define Destructor?,"The ternary operator is an operator that exists in some programming languages, which takes three operands rather than the typical one or two and is used to evaluate Boolean expressions.","A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",0
What is a ternary operator?,The ternary operator is also known as the conditional operator. This operator consists of three operands and is used to evaluate Boolean expressions.,a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,1
What is a ternary operator?,The ternary operator is also known as the conditional operator. This operator consists of three operands and is used to evaluate Boolean expressions.,A destructor is a method which is automatically called when the object is made of scope or destroyed. Destructor name is also same as class name but with the tilde symbol before the name.,0
Define Destructor?,a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,A destructor is a special method called automatically during the destruction of an object.,0
What is a ternary operator?,The ternary operator is also known as the conditional operator. This operator consists of three operands and is used to evaluate Boolean expressions.,"The ternary operator is an operator that exists in some programming languages, which takes three operands rather than the typical one or two and is used to evaluate Boolean expressions.",1
What is a ternary operator?,The ternary operator is also known as the conditional operator. This operator consists of three operands and is used to evaluate Boolean expressions.,"A class constructor is a special member function of a class that is executed whenever we create new objects of that class. A constructor will have exact same name as the class and it does not have any return type at all,",0
Explain the term constructor,"The ternary operator is an operator that exists in some programming languages, which takes three operands rather than the typical one or two and is used to evaluate Boolean expressions.",A constructor is called automatically when we create an object of a class.,0
What is a ternary operator?,a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,"The ternary operator is an operator that exists in some programming languages, which takes three operands rather than the typical one or two and is used to evaluate Boolean expressions.",1
What is a ternary operator?,a ternary operator is an operator that takes three arguments (or operands) which defines a conditional expression.,"An interface is a collection of an abstract method. If the class implements an interface, it thereby inherits all the abstract methods of an interface.Java uses Interface to implement multiple inheritances.",0
What is an interface?,"The ternary operator is an operator that exists in some programming languages, which takes three operands rather than the typical one or two and is used to evaluate Boolean expressions.","An interface is an abstract ""class"" that is used to group related methods with ""empty"" bodies",0
What is an interface?,"An interface is a collection of an abstract method. If the class implements an interface, it thereby inherits all the abstract methods of an interface.Java uses Interface to implement multiple inheritances.","An interface is a completely ""abstract class"" that is used to group related methods with empty bodies:",1
What is an interface?,"An interface is a collection of an abstract method. If the class implements an interface, it thereby inherits all the abstract methods of an interface.Java uses Interface to implement multiple inheritances.","Encapsulation is an attribute of an object, and it contains all data which is hidden. That hidden data can be restricted to the members of that class.Levels are Public, Protected, Private, Internal, and Protected Internal.",0
What is Encapsulation?,"An interface is a completely ""abstract class"" that is used to group related methods with empty bodies:",encapsulation is the inclusion of one thing within another thing so that the included thing is not apparent.,0
What is an interface?,"An interface is a collection of an abstract method. If the class implements an interface, it thereby inherits all the abstract methods of an interface.Java uses Interface to implement multiple inheritances.","An interface is an abstract ""class"" that is used to group related methods with ""empty"" bodies",1
What is an interface?,"An interface is a collection of an abstract method. If the class implements an interface, it thereby inherits all the abstract methods of an interface.Java uses Interface to implement multiple inheritances.",A pure virtual function is a function which can be overridden in the derived class but cannot be defined. A virtual function can be declared as Pure by using the operator =0.,0
What is a pure virtual function?,"An interface is an abstract ""class"" that is used to group related methods with ""empty"" bodies",A pure virtual function is a function that must be overridden in a derived class and need not be defined. A virtual function is declared to be pure using the curious =0 syntax.,0
What is an interface?,"An interface is a collection of an abstract method. If the class implements an interface, it thereby inherits all the abstract methods of an interface.Java uses Interface to implement multiple inheritances.","An interface is a reference type in Java. It is similar to class. It is a collection of abstract methods. A class implements an interface, thereby inheriting the abstract methods of the interface.",1
What is an interface?,"An interface is a collection of an abstract method. If the class implements an interface, it thereby inherits all the abstract methods of an interface.Java uses Interface to implement multiple inheritances.","Inheritance is a mechanism in which one class acquires the property of another class. For example, a child inherits the traits of his/her parents.",0
What is Inheritance?,"An interface is a reference type in Java. It is similar to class. It is a collection of abstract methods. A class implements an interface, thereby inheriting the abstract methods of the interface.",is a mechanism in which one object acquires all the properties and behaviors of a parent object.,0
What is an interface?,"An interface is a completely ""abstract class"" that is used to group related methods with empty bodies:","An interface is an abstract ""class"" that is used to group related methods with ""empty"" bodies",1
What is an interface?,"An interface is a completely ""abstract class"" that is used to group related methods with empty bodies:","programming feature that allows us to have more than one function having same name but different parameter list,",0
What is function overloading?,"An interface is an abstract ""class"" that is used to group related methods with ""empty"" bodies",function overloading or method overloading is the ability to create multiple functions of the same name with different implementations.,0
What is an interface?,"An interface is a completely ""abstract class"" that is used to group related methods with empty bodies:","An interface is a reference type in Java. It is similar to class. It is a collection of abstract methods. A class implements an interface, thereby inheriting the abstract methods of the interface.",1
What is an interface?,"An interface is a completely ""abstract class"" that is used to group related methods with empty bodies:","Encapsulation is an attribute of an object, and it contains all data which is hidden. That hidden data can be restricted to the members of that class.Levels are Public, Protected, Private, Internal, and Protected Internal.",0
What is Encapsulation?,"An interface is a reference type in Java. It is similar to class. It is a collection of abstract methods. A class implements an interface, thereby inheriting the abstract methods of the interface.","Encapsulation is used to hide the values or state of a structured data object inside a class, preventing unauthorized parties' direct access to them.",0
What is an interface?,"An interface is an abstract ""class"" that is used to group related methods with ""empty"" bodies","An interface is a reference type in Java. It is similar to class. It is a collection of abstract methods. A class implements an interface, thereby inheriting the abstract methods of the interface.",1
What is an interface?,"An interface is an abstract ""class"" that is used to group related methods with ""empty"" bodies",A destructor is a method which is automatically called when the object is made of scope or destroyed. Destructor name is also same as class name but with the tilde symbol before the name.,0
Define Destructor?,"An interface is a reference type in Java. It is similar to class. It is a collection of abstract methods. A class implements an interface, thereby inheriting the abstract methods of the interface.","A destructor is a member function that is invoked automatically when the object goes out of scope or is explicitly destroyed by a call to delete . A destructor has the same name as the class, preceded by a tilde",0
What is the difference between new and override?,"The new modifier instructs the compiler to use the new implementation instead of the base class function. Whereas, Override modifier helps to override the base class function.","verride: overrides the functionality of a virtual method in a base class, providing different functionality. new: hides the original method (which doesn't have to be virtual), providing different functionality.",1
What is the difference between new and override?,"The new modifier instructs the compiler to use the new implementation instead of the base class function. Whereas, Override modifier helps to override the base class function.","A class constructor is a special member function of a class that is executed whenever we create new objects of that class. A constructor will have exact same name as the class and it does not have any return type at all,",0
Explain the term constructor,"verride: overrides the functionality of a virtual method in a base class, providing different functionality. new: hides the original method (which doesn't have to be virtual), providing different functionality.",A constructor is called automatically when we create an object of a class.,0
What is this pointer?,THIS pointer refers to the current object of a class. THIS keyword is used as a pointer which differentiates between the current object with the global object. It refers to the current object.,this is a keyword that refers to the current instance of the class.,1
What is this pointer?,THIS pointer refers to the current object of a class. THIS keyword is used as a pointer which differentiates between the current object with the global object. It refers to the current object.,A destructor is a method which is automatically called when the object is made of scope or destroyed. Destructor name is also same as class name but with the tilde symbol before the name.,0
Define Destructor?,this is a keyword that refers to the current instance of the class.,A destructor is a special method called automatically during the destruction of an object.,0
What is this pointer?,THIS pointer refers to the current object of a class. THIS keyword is used as a pointer which differentiates between the current object with the global object. It refers to the current object.,"this pointer holds the address of current object, in simple words you can say that this pointer points to the current object of the class.",1
What is this pointer?,THIS pointer refers to the current object of a class. THIS keyword is used as a pointer which differentiates between the current object with the global object. It refers to the current object.,"Encapsulation is used to hide the values or state of a structured data object inside a class, preventing unauthorized parties' direct access to them.",0
What is Encapsulation?,"this pointer holds the address of current object, in simple words you can say that this pointer points to the current object of the class.",encapsulation is the inclusion of one thing within another thing so that the included thing is not apparent.,0
What is this pointer?,this is a keyword that refers to the current instance of the class.,"this pointer holds the address of current object, in simple words you can say that this pointer points to the current object of the class.",1
What is this pointer?,this is a keyword that refers to the current instance of the class.,"An interface is a completely ""abstract class"" that is used to group related methods with empty bodies:",0
What is an interface?,"this pointer holds the address of current object, in simple words you can say that this pointer points to the current object of the class.","An interface is a reference type in Java. It is similar to class. It is a collection of abstract methods. A class implements an interface, thereby inheriting the abstract methods of the interface.",0
What is a pure virtual function?,A pure virtual function is a function which can be overridden in the derived class but cannot be defined. A virtual function can be declared as Pure by using the operator =0.,A pure virtual function is a function that must be overridden in a derived class and need not be defined. A virtual function is declared to be pure using the curious =0 syntax.,1
What is a pure virtual function?,A pure virtual function is a function which can be overridden in the derived class but cannot be defined. A virtual function can be declared as Pure by using the operator =0.,this is a keyword that refers to the current instance of the class.,0
What is this pointer?,A pure virtual function is a function that must be overridden in a derived class and need not be defined. A virtual function is declared to be pure using the curious =0 syntax.,"this pointer holds the address of current object, in simple words you can say that this pointer points to the current object of the class.",0
What is a pure virtual function?,A pure virtual function is a function which can be overridden in the derived class but cannot be defined. A virtual function can be declared as Pure by using the operator =0.,"A pure virtual function (or abstract function) in C++ is a virtual function for which we don't have an implementation, we only declare it. A pure virtual function is declared by assigning 0 in the declaration.",1
What is a pure virtual function?,A pure virtual function is a function which can be overridden in the derived class but cannot be defined. A virtual function can be declared as Pure by using the operator =0.,"A friend function is a friend of a class that is allowed to access to Public, private, or protected data in that same class. If the function is defined outside the class cannot access such information.A friend can be declared anywhere in the class declaration, and it cannot be affected by access control keywords like private, public, or protected.",0
What is a friend function?,"A pure virtual function (or abstract function) in C++ is a virtual function for which we don't have an implementation, we only declare it. A pure virtual function is declared by assigning 0 in the declaration.","that is a ""friend"" of a given class, is a function that is given the same access as methods to private and protected data.",0
What is a pure virtual function?,A pure virtual function is a function that must be overridden in a derived class and need not be defined. A virtual function is declared to bepure using the curious =0 syntax.,"A pure virtual function (or abstract function) in C++ is a virtual function for which we don't have an implementation, we only declare it. A pure virtual function is declared by assigning 0 in the declaration.",1
What is a pure virtual function?,A pure virtual function is a function that must be overridden in a derived class and need not be defined. A virtual function is declared to bepure using the curious =0 syntax.,"A virtual function is a member function of a class, and its functionality can be overridden in its derived class. This function can be implemented by using a keyword called virtual, and it can be given during function declaration.",0
What is a virtual function?,"A pure virtual function (or abstract function) in C++ is a virtual function for which we don't have an implementation, we only declare it. A pure virtual function is declared by assigning 0 in the declaration.",A virtual function is a member function that you expect to be redefined in derived classes.,0
What is the main difference between a computer program and computer software?,"PROGRAMS-A computer program is a collection of instructions that performs a specific task when executed by a computer. A set of instruction telling a computer what to do(instruction is in the form code .binary.) while SOFTWARE-Software are made up of two or more than two programs.
It instruct computer processor to perform specific operation .
(In simple words it give instruction or data to computer processor(CPU))","A program consists of a set of instructions which are coded in a programming language like C, C++, PHP, Java etc. and A software consists of bundles of programs and data files. Programs in a specific software use these data files to perform a dedicated type of tasks.",1
What is the main difference between a computer program and computer software?,PROGRAMS-A computer program is a collection of instructions that performs a specific task when executed by a computer. A set of instruction telling a computer what to do(instruction is in the form code .binary.) while SOFTWARE-Software are made up of two or more than two programs. It instruct computer processor to perform specific operation . (In simple words it give instruction or data to computer processor(CPU)),Process means any program is in execution and Thread is the segment of a process means a process can have multiple threads and these multiple threads are contained within a process.,0
What is the main difference between a computer program and computer software?,"PROGRAMS-A computer program is a collection of instructions that performs a specific task when executed by a computer. A set of instruction telling a computer what to do(instruction is in the form code .binary.) while SOFTWARE-Software are made up of two or more than two programs.

It instruct computer processor to perform specific operation .

(In simple words it give instruction or data to computer processor(CPU))",Software- the programs and other operating information used by a computer. Software can be made up of more than one program. All-encompassing term that is often used in contrast to hardware (the tangible parts of a computer) but Program- A set of instructions telling a computer what to do.,1
What is the main difference between a computer program and computer software?,Software- the programs and other operating information used by a computer. Software can be made up of more than one program. All-encompassing term that is often used in contrast to hardware (the tangible parts of a computer) but Program- A set of instructions telling a computer what to do.,A program in execution is often referred as process. A thread is a part of the process.,0
What is the main difference between a computer program and computer software?,PROGRAMS-A computer program is a collection of instructions that performs a specific task when executed by a computer. A set of instruction telling a computer what to do(instruction is in the form code .binary.) while SOFTWARE-Software are made up of two or more than two programs. It instruct computer processor to perform specific operation . (In simple words it give instruction or data to computer processor(CPU)),"A Software is a super set of a program, in which one or many programs are executed sequentially or simultaneously to perform a particular job. It is the end of product of a set of programs. And A Program is a combination of lines of code, which takes input, working on the instructions on the computer to generate an output. A program is a group of instructions which when performed will generate a logical output.",1
What is the main difference between a computer program and computer software?,PROGRAMS-A computer program is a collection of instructions that performs a specific task when executed by a computer. A set of instruction telling a computer what to do(instruction is in the form code .binary.) while SOFTWARE-Software are made up of two or more than two programs. It instruct computer processor to perform specific operation . (In simple words it give instruction or data to computer processor(CPU)),"A computer program is a set or sequential sequence of operations that will automatically execute on a computer medium, such as a computer. Indeed, everything that is a computer program supports automatic executions related to the work of different calculations. Software is a set of instructions intended to be interpreted by a machine to perform different tasks on the computer device",1
What is the main difference between a computer program and computer software?,"A computer program is a set or sequential sequence of operations that will automatically execute on a computer medium, such as a computer. Indeed, everything that is a computer program supports automatic executions related to the work of different calculations. Software is a set of instructions intended to be interpreted by a machine to perform different tasks on the computer device",An executing instance of a program is called a process. A thread is a subset of the process.,0
What is the main difference between a computer program and computer software?,"A program consists of a set of instructions which are coded in a programming language like C, C++, PHP, Java etc. and A software consists of bundles of programs and data files. Programs in a specific software use these data files to perform a dedicated type of tasks.",Software- the programs and other operating information used by a computer. Software can be made up of more than one program. All-encompassing term that is often used in contrast to hardware (the tangible parts of a computer) but Program- A set of instructions telling a computer what to do.,1
What is the main difference between a computer program and computer software?,"A program consists of a set of instructions which are coded in a programming language like C, C++, PHP, Java etc. and A software consists of bundles of programs and data files. Programs in a specific software use these data files to perform a dedicated type of tasks.",Software ReEngineering is the examination and alteration of a system to reconstitute it in a new form. The principles of Re-Engineering when applied to the software development process,0
What is the main difference between a computer program and computer software?,"A program consists of a set of instructions which are coded in a programming language like C, C++, PHP, Java etc. and A software consists of bundles of programs and data files. Programs in a specific software use these data files to perform a dedicated type of tasks.","A Software is a super set of a program, in which one or many programs are executed sequentially or simultaneously to perform a particular job. It is the end of product of a set of programs. And A Program is a combination of lines of code, which takes input, working on the instructions on the computer to generate an output. A program is a group of instructions which when performed will generate a logical output.",1
What is the main difference between a computer program and computer software?,"A Software is a super set of a program, in which one or many programs are executed sequentially or simultaneously to perform a particular job. It is the end of product of a set of programs. And A Program is a combination of lines of code, which takes input, working on the instructions on the computer to generate an output. A program is a group of instructions which when performed will generate a logical output.",Polymorphism is used when there is a need for override functionality when inheriting class. It is about shared classes,0
What is the main difference between a computer program and computer software?,"A program consists of a set of instructions which are coded in a programming language like C, C++, PHP, Java etc. and A software consists of bundles of programs and data files. Programs in a specific software use these data files to perform a dedicated type of tasks.","A computer program is a set or sequential sequence of operations that will automatically execute on a computer medium, such as a computer. Indeed, everything that is a computer program supports automatic executions related to the work of different calculations. Software is a set of instructions intended to be interpreted by a machine to perform different tasks on the computer device",1
What is the main difference between a computer program and computer software?,Software- the programs and other operating information used by a computer. Software can be made up of more than one program. All-encompassing term that is often used in contrast to hardware (the tangible parts of a computer) but Program- A set of instructions telling a computer what to do.,"A Software is a super set of a program, in which one or many programs are executed sequentially or simultaneously to perform a particular job. It is the end of product of a set of programs. And A Program is a combination of lines of code, which takes input, working on the instructions on the computer to generate an output. A program is a group of instructions which when performed will generate a logical output.",1
What is the main difference between a computer program and computer software?,Software- the programs and other operating information used by a computer. Software can be made up of more than one program. All-encompassing term that is often used in contrast to hardware (the tangible parts of a computer) but Program- A set of instructions telling a computer what to do.,"A computer program is a set or sequential sequence of operations that will automatically execute on a computer medium, such as a computer. Indeed, everything that is a computer program supports automatic executions related to the work of different calculations. Software is a set of instructions intended to be interpreted by a machine to perform different tasks on the computer device",1
What is the main difference between a computer program and computer software?,"A Software is a super set of a program, in which one or many programs are executed sequentially or simultaneously to perform a particular job. It is the end of product of a set of programs. And A Program is a combination of lines of code, which takes input, working on the instructions on the computer to generate an output. A program is a group of instructions which when performed will generate a logical output.","A computer program is a set or sequential sequence of operations that will automatically execute on a computer medium, such as a computer. Indeed, everything that is a computer program supports automatic executions related to the work of different calculations. Software is a set of instructions intended to be interpreted by a machine to perform different tasks on the computer device",1
What is software re-engineering?,Software ReEngineering is the examination and alteration of a system to reconstitute it in a new form. The principles of Re-Engineering when applied to the software development process,"Software reengineering enables the examination and modification of legacy software code, which helps to maintain, reuse and alter it in the future.",1
What is software re-engineering?,Software ReEngineering is the examination and alteration of a system to reconstitute it in a new form. The principles of Re-Engineering when applied to the software development process,Debugging is the process that results in the removal of error,0
What is software re-engineering?,Software ReEngineering is the examination and alteration of a system to reconstitute it in a new form. The principles of Re-Engineering when applied to the software development process,A software reengineering is a software upgrading procedure or its migration to a more advanced technology platform.,1
What is software re-engineering?,A software reengineering is a software upgrading procedure or its migration to a more advanced technology platform.,It is the process of detecting and removing of existing and potential errors,0
What is software re-engineering?,Software ReEngineering is the examination and alteration of a system to reconstitute it in a new form. The principles of Re-Engineering when applied to the software development process,"software reengineering a complex procedure aimed at modernizing software. It is typically used to increase system's maintainability, enhance performance, scalability, security.",1
What is software re-engineering?,Software ReEngineering is the examination and alteration of a system to reconstitute it in a new form. The principles of Re-Engineering when applied to the software development process,"Software reengineering is used to update the existing software in the new form product so that software product will provide high performance, and improve the functionality of the system.",1
What is software re-engineering?,"Software reengineering is used to update the existing software in the new form product so that software product will provide high performance, and improve the functionality of the system.",It is the process of detecting and removing of existing and potential errors,0
What is software re-engineering?,"Software reengineering enables the examination and modification of legacy software code, which helps to maintain, reuse and alter it in the future.",A software reengineering is a software upgrading procedure or its migration to a more advanced technology platform.,1
What is software re-engineering?,"Software reengineering enables the examination and modification of legacy software code, which helps to maintain, reuse and alter it in the future.",Debugging is the process that results in the removal of error,0
What is software re-engineering?,"Software reengineering enables the examination and modification of legacy software code, which helps to maintain, reuse and alter it in the future.","software reengineering a complex procedure aimed at modernizing software. It is typically used to increase system's maintainability, enhance performance, scalability, security.",1
What is software re-engineering?,"software reengineering a complex procedure aimed at modernizing software. It is typically used to increase system's maintainability, enhance performance, scalability, security.",It is the process of detecting and removing of existing and potential errors,0
What is software re-engineering?,"Software reengineering enables the examination and modification of legacy software code, which helps to maintain, reuse and alter it in the future.","Software reengineering is used to update the existing software in the new form product so that software product will provide high performance, and improve the functionality of the system.",1
What is software re-engineering?,A software reengineering is a software upgrading procedure or its migration to a more advanced technology platform.,"software reengineering a complex procedure aimed at modernizing software. It is typically used to increase system's maintainability, enhance performance, scalability, security.",1
What is software re-engineering?,A software reengineering is a software upgrading procedure or its migration to a more advanced technology platform.,"Software reengineering is used to update the existing software in the new form product so that software product will provide high performance, and improve the functionality of the system.",1
What is software re-engineering?,A software reengineering is a software upgrading procedure or its migration to a more advanced technology platform.,Debugging is the process that results in the removal of error,0
What is software re-engineering?,"software reengineering a complex procedure aimed at modernizing software. It is typically used to increase system's maintainability, enhance performance, scalability, security.","Software reengineering is used to update the existing software in the new form product so that software product will provide high performance, and improve the functionality of the system.",1
In software development process what is the meaning of debugging?,Debugging is the process that results in the removal of error,It is the process of detecting and removing of existing and potential errors,1
In software development process what is the meaning of debugging?,Debugging is the process that results in the removal of error,"I'd program for security first, and then if it's slow, I'd try to identify the bottleneck and then find a way to improve its time complexity.",0
In software development process what is the meaning of debugging?,Debugging is the process that results in the removal of error,Debugging is the process that eliminate faults in the software,1
In software development process what is the meaning of debugging?,Debugging is the process that eliminate faults in the software,"In the software, development security is always first. So if the execution of the program is slow then, I will try to identify the reason out ways to its time complexity.",0
In software development process what is the meaning of debugging?,Debugging is the process that results in the removal of error,"Debugging is the routine process of locating and removing computer program bugs, errors or abnormalities",1
In software development process what is the meaning of debugging?,Debugging is the process that results in the removal of error,"debugging is the process of finding and resolving bugs (defects or problems that prevent correct operation) within computer programs, software, or systems.",1
In software development process what is the meaning of debugging?,"debugging is the process of finding and resolving bugs (defects or problems that prevent correct operation) within computer programs, software, or systems.","In the software, development security is always first. So if the execution of the program is slow then, I will try to identify the reason out ways to its time complexity.",0
In software development process what is the meaning of debugging?,It is the process of detecting and removing of existing and potential errors,Debugging is the process that eliminate faults in the software,1
In software development process what is the meaning of debugging?,It is the process of detecting and removing of existing and potential errors,"I'd program for security first, and then if it's slow, I'd try to identify the bottleneck and then find a way to improve its time complexity.",0
In software development process what is the meaning of debugging?,It is the process of detecting and removing of existing and potential errors,"Debugging is the routine process of locating and removing computer program bugs, errors or abnormalities",1
In software development process what is the meaning of debugging?,"Debugging is the routine process of locating and removing computer program bugs, errors or abnormalities","In the software, development security is always first. So if the execution of the program is slow then, I will try to identify the reason out ways to its time complexity.",0
In software development process what is the meaning of debugging?,It is the process of detecting and removing of existing and potential errors,"debugging is the process of finding and resolving bugs (defects or problems that prevent correct operation) within computer programs, software, or systems.",1
In software development process what is the meaning of debugging?,Debugging is the process that eliminate faults in the software,"Debugging is the routine process of locating and removing computer program bugs, errors or abnormalities",1
In software development process what is the meaning of debugging?,Debugging is the process that eliminate faults in the software,"debugging is the process of finding and resolving bugs (defects or problems that prevent correct operation) within computer programs, software, or systems.",1
In software development process what is the meaning of debugging?,Debugging is the process that eliminate faults in the software,"I'd program for security first, and then if it's slow, I'd try to identify the bottleneck and then find a way to improve its time complexity.",0
In software development process what is the meaning of debugging?,"Debugging is the routine process of locating and removing computer program bugs, errors or abnormalities","debugging is the process of finding and resolving bugs (defects or problems that prevent correct operation) within computer programs, software, or systems.",1
How can you make sure that your code is both safe and fast?,"I'd program for security first, and then if it's slow, I'd try to identify the bottleneck and then find a way to improve its time complexity.","In the software, development security is always first. So if the execution of the program is slow then, I will try to identify the reason out ways to its time complexity.",1
How can you make sure that your code is both safe and fast?,"I'd program for security first, and then if it's slow, I'd try to identify the bottleneck and then find a way to improve its time complexity.",A stub is a minimal implementation of an interface which generally returns hardcoded data while mock usually verifies outputs against expectations. Those expectations are set in the test.,0
"What is the main difference between a stubs, a mock?",A stub is a minimal implementation of an interface which generally returns hardcoded data while mock usually verifies outputs against expectations. Those expectations are set in the test.,"verride methods to return hard-coded values, also referred to as state-based.and A mock is something that as part of your test you have to setup with your expectations.",1
"What is the main difference between a stubs, a mock?","verride methods to return hard-coded values, also referred to as state-based.and A mock is something that as part of your test you have to setup with your expectations.",Software- the programs and other operating information used by a computer. Software can be made up of more than one program. All-encompassing term that is often used in contrast to hardware (the tangible parts of a computer) but Program- A set of instructions telling a computer what to do.,0
What is computer software?,Software is a collection of data or computer instructions that tell the computer how to work.,Software is a program that enables a computer to perform a specific task,1
What is computer software?,Software is a collection of data or computer instructions that tell the computer how to work.,Software configuration management is a process of tracking and controlling changes that happen in the software.Change control is a function which ensures that all changes made into the software system are consistent and created using organizational rules and regulations.,0
What is computer software?,Software is a collection of data or computer instructions that tell the computer how to work.,"Software, instructions that tell a computer what to do",1
What is computer software?,"Software, instructions that tell a computer what to do","It is a process to systematically manage, organize, and control the changes in the documents, codes, and other entities during the Software Development Life Cycle",0
What is computer software?,Software is a collection of data or computer instructions that tell the computer how to work.,"Software is a set of programs, which is designed to perform a well-defined function.",1
What is computer software?,Software is a collection of data or computer instructions that tell the computer how to work.,"software is a collection of instructions that enable the user to interact with a computer, its hardware, or perform jobs.",1
What is computer software?,"software is a collection of instructions that enable the user to interact with a computer, its hardware, or perform jobs.","It is a process to systematically manage, organize, and control the changes in the documents, codes, and other entities during the Software Development Life Cycle",0
What is computer software?,Software is a program that enables a computer to perform a specific task,"Software, instructions that tell a computer what to do",1
What is computer software?,Software is a program that enables a computer to perform a specific task,Software configuration management is a process of tracking and controlling changes that happen in the software.Change control is a function which ensures that all changes made into the software system are consistent and created using organizational rules and regulations.,0
What is computer software?,Software is a program that enables a computer to perform a specific task,"Software is a set of programs, which is designed to perform a well-defined function.",1
What is computer software?,"Software is a set of programs, which is designed to perform a well-defined function.","It is a process to systematically manage, organize, and control the changes in the documents, codes, and other entities during the Software Development Life Cycle",0
What is computer software?,Software is a program that enables a computer to perform a specific task,"software is a collection of instructions that enable the user to interact with a computer, its hardware, or perform jobs.",1
What is computer software?,"Software, instructions that tell a computer what to do","Software is a set of programs, which is designed to perform a well-defined function.",1
What is computer software?,"Software, instructions that tell a computer what to do","software is a collection of instructions that enable the user to interact with a computer, its hardware, or perform jobs.",1
What is computer software?,"Software, instructions that tell a computer what to do",Software configuration management is a process of tracking and controlling changes that happen in the software.Change control is a function which ensures that all changes made into the software system are consistent and created using organizational rules and regulations.,0
What is computer software?,"Software is a set of programs, which is designed to perform a well-defined function.","software is a collection of instructions that enable the user to interact with a computer, its hardware, or perform jobs.",1
What is Software configuration management?,Software configuration management is a process of tracking and controlling changes that happen in the software.Change control is a function which ensures that all changes made into the software system are consistent and created using organizational rules and regulations.,"It is a process to systematically manage, organize, and control the changes in the documents, codes, and other entities during the Software Development Life Cycle",1
What is Software configuration management?,Software configuration management is a process of tracking and controlling changes that happen in the software.Change control is a function which ensures that all changes made into the software system are consistent and created using organizational rules and regulations.,"Software requirements are a functional description of a proposed software system. It is assumed to be the description of the target system, its functionalities, and features.",0
What is Software configuration management?,Software configuration management is a process of tracking and controlling changes that happen in the software.Change control is a function which ensures that all changes made into the software system are consistent and created using organizational rules and regulations.,"It is a technic of identifying, organizing, and controlling modification to software being built by a programming team.",1
What is Software configuration management?,"It is a technic of identifying, organizing, and controlling modification to software being built by a programming team.",are all of the requirements at the system level that describe the functions which the system as a whole should fulfill to satisfy.,0
What is Software configuration management?,Software configuration management is a process of tracking and controlling changes that happen in the software.Change control is a function which ensures that all changes made into the software system are consistent and created using organizational rules and regulations.,"It is the process of identifying and defining the software configuration items in a system, controlling the release and change of these items throughout the system lifecycle, recording and reporting the status of configuration items and change requests, and verifying the completeness",1
What is Software configuration management?,Software configuration management is a process of tracking and controlling changes that happen in the software.Change control is a function which ensures that all changes made into the software system are consistent and created using organizational rules and regulations.,"It is a software engineering discipline consisting of standard processes and techniques often used by organizations to manage the changes introduced to its software products. SCM helps in identifying individual elements and configurations, tracking changes,",1
What is Software configuration management?,"It is a software engineering discipline consisting of standard processes and techniques often used by organizations to manage the changes introduced to its software products. SCM helps in identifying individual elements and configurations, tracking changes,",are all of the requirements at the system level that describe the functions which the system as a whole should fulfill to satisfy.,0
What is Software configuration management?,"It is a process to systematically manage, organize, and control the changes in the documents, codes, and other entities during the Software Development Life Cycle","It is a technic of identifying, organizing, and controlling modification to software being built by a programming team.",1
What is Software configuration management?,"It is a process to systematically manage, organize, and control the changes in the documents, codes, and other entities during the Software Development Life Cycle","Software requirements are a functional description of a proposed software system. It is assumed to be the description of the target system, its functionalities, and features.",0
What is Software configuration management?,"It is a process to systematically manage, organize, and control the changes in the documents, codes, and other entities during the Software Development Life Cycle","It is the process of identifying and defining the software configuration items in a system, controlling the release and change of these items throughout the system lifecycle, recording and reporting the status of configuration items and change requests, and verifying the completeness",1
What is Software configuration management?,"It is the process of identifying and defining the software configuration items in a system, controlling the release and change of these items throughout the system lifecycle, recording and reporting the status of configuration items and change requests, and verifying the completeness",are all of the requirements at the system level that describe the functions which the system as a whole should fulfill to satisfy.,0
What is Software configuration management?,"It is a process to systematically manage, organize, and control the changes in the documents, codes, and other entities during the Software Development Life Cycle","It is a software engineering discipline consisting of standard processes and techniques often used by organizations to manage the changes introduced to its software products. SCM helps in identifying individual elements and configurations, tracking changes,",1
What is Software configuration management?,"It is a technic of identifying, organizing, and controlling modification to software being built by a programming team.","It is the process of identifying and defining the software configuration items in a system, controlling the release and change of these items throughout the system lifecycle, recording and reporting the status of configuration items and change requests, and verifying the completeness",1
What is Software configuration management?,"It is the process of identifying and defining the software configuration items in a system, controlling the release and change of these items throughout the system lifecycle, recording and reporting the status of configuration items and change requests, and verifying the completeness",are all of the requirements at the system level that describe the functions which the system as a whole should fulfill to satisfy.,0
What is Software configuration management?,"It is a technic of identifying, organizing, and controlling modification to software being built by a programming team.","It is a software engineering discipline consisting of standard processes and techniques often used by organizations to manage the changes introduced to its software products. SCM helps in identifying individual elements and configurations, tracking changes,",1
What is Software configuration management?,"It is a technic of identifying, organizing, and controlling modification to software being built by a programming team.","Software requirements are a functional description of a proposed software system. It is assumed to be the description of the target system, its functionalities, and features.",0
What is Software configuration management?,"It is the process of identifying and defining the software configuration items in a system, controlling the release and change of these items throughout the system lifecycle, recording and reporting the status of configuration items and change requests, and verifying the completeness","It is a software engineering discipline consisting of standard processes and techniques often used by organizations to manage the changes introduced to its software products. SCM helps in identifying individual elements and configurations, tracking changes,",1
What are software requirements?,"Software requirements are a functional description of a proposed software system. It is assumed to be the description of the target system, its functionalities, and features.",are all of the requirements at the system level that describe the functions which the system as a whole should fulfill to satisfy.,1
What are software requirements?,"Software requirements are a functional description of a proposed software system. It is assumed to be the description of the target system, its functionalities, and features.","Functional Requirements: These are the requirements that the end user specifically demands as basic facilities that the system should offer. And Non-functional requirements: These are basically the quality constraints that the system must satisfy according to the project contract as Security,Maintainability,Reliability,Scalability,Performance,Reusability,Flexibility",0
What are software requirements?,"Software requirements are a functional description of a proposed software system. It is assumed to be the description of the target system, its functionalities, and features.",The software requirements are description of features and functionalities of the target system.,1
What are software requirements?,The software requirements are description of features and functionalities of the target system.,"Functional requirements are functional features which are expected by users from the proposed software product. Non-functional requirements are related to security, performance, look, and feel of the user interface.",0
What are software requirements?,"Software requirements are a functional description of a proposed software system. It is assumed to be the description of the target system, its functionalities, and features.",Requirements can range from high-level abstract statements of services or system constraints to detailed mathematical functional specifications,1
What are software requirements?,are all of the requirements at the system level that describe the functions which the system as a whole should fulfill to satisfy.,The software requirements are description of features and functionalities of the target system.,1
What are software requirements?,are all of the requirements at the system level that describe the functions which the system as a whole should fulfill to satisfy.,Requirements can range from high-level abstract statements of services or system constraints to detailed mathematical functional specifications,1
What are software requirements?,are all of the requirements at the system level that describe the functions which the system as a whole should fulfill to satisfy.,"Functional Requirements: These are the requirements that the end user specifically demands as basic facilities that the system should offer. And Non-functional requirements: These are basically the quality constraints that the system must satisfy according to the project contract as Security,Maintainability,Reliability,Scalability,Performance,Reusability,Flexibility",0
What are software requirements?,The software requirements are description of features and functionalities of the target system.,Requirements can range from high-level abstract statements of services or system constraints to detailed mathematical functional specifications,1
What are software requirements?,Requirements can range from high-level abstract statements of services or system constraints to detailed mathematical functional specifications,"Functional requirements are functional features which are expected by users from the proposed software product. Non-functional requirements are related to security, performance, look, and feel of the user interface.",0
What are functional and non-functional requirements?,"Functional Requirements: These are the requirements that the end user specifically demands as basic facilities that the system should offer. And Non-functional requirements: These are basically the quality constraints that the system must satisfy according to the project contract as Security,Maintainability,Reliability,Scalability,Performance,Reusability,Flexibility","Functional requirements are functional features which are expected by users from the proposed software product. Non-functional requirements are related to security, performance, look, and feel of the user interface.",1
What are functional and non-functional requirements?,"Functional Requirements: These are the requirements that the end user specifically demands as basic facilities that the system should offer. And Non-functional requirements: These are basically the quality constraints that the system must satisfy according to the project contract as Security,Maintainability,Reliability,Scalability,Performance,Reusability,Flexibility",Modularization is a technique which is used for dividing a software system into various discrete modules. That is expected to carry out the tasks independently.,0
What are functional and non-functional requirements?,"Functional Requirements: These are the requirements that the end user specifically demands as basic facilities that the system should offer. And Non-functional requirements: These are basically the quality constraints that the system must satisfy according to the project contract as Security,Maintainability,Reliability,Scalability,Performance,Reusability,Flexibility","A functional requirement describes what a software system should do, while non-functional requirements place constraints on how the system will do so as Accessibility Capacity, current and forecast, Compliance,Documentation",1
What are functional and non-functional requirements?,"A functional requirement describes what a software system should do, while non-functional requirements place constraints on how the system will do so as Accessibility Capacity, current and forecast, Compliance,Documentation","Modularization is a technique to divide a software system into multiple discrete and independent modules, which are expected to be capable of carrying out task(s) independently.",0
What are functional and non-functional requirements?,"Functional requirements are functional features which are expected by users from the proposed software product. Non-functional requirements are related to security, performance, look, and feel of the user interface.","A functional requirement describes what a software system should do, while non-functional requirements place constraints on how the system will do so as Accessibility Capacity, current and forecast, Compliance,Documentation",1
What are functional and non-functional requirements?,"Functional requirements are functional features which are expected by users from the proposed software product. Non-functional requirements are related to security, performance, look, and feel of the user interface.",Modularization is a technique which is used for dividing a software system into various discrete modules. That is expected to carry out the tasks independently.,0
What is modularization?,Modularization is a technique which is used for dividing a software system into various discrete modules. That is expected to carry out the tasks independently.,"Modularization is a technique to divide a software system into multiple discrete and independent modules, which are expected to be capable of carrying out task(s) independently.",1
What is modularization?,"Modularization is a technique to divide a software system into multiple discrete and independent modules, which are expected to be capable of carrying out task(s) independently.",Cohesion is a measure that defines the intra-dependability among the elements of the module.,0
What is modularization?,Modularization is a technique which is used for dividing a software system into various discrete modules. That is expected to carry out the tasks independently.,Modularization concerns the logical partitioning of a software design so that the design becomes easy to understand and maintain and doing each job alone,1
What is modularization?,Modularization is a technique which is used for dividing a software system into various discrete modules. That is expected to carry out the tasks independently.,Cohesion: Cohesion is a measure of the degree to which the elements of the module are functionally related. It is the degree to which all elements directed towards performing a single task are contained in the component. A good software design will have high cohesion.,0
What is modularization?,Modularization is a technique which is used for dividing a software system into various discrete modules. That is expected to carry out the tasks independently.,Modularization: Modularization is the process of dividing a software system into multiple independent modules where each module works independently.,1
What is modularization?,Modularization: Modularization is the process of dividing a software system into multiple independent modules where each module works independently.,Cohesion is a measure that defines the intra-dependability among the elements of the module.,0
What is modularization?,Modularization is a technique which is used for dividing a software system into various discrete modules. That is expected to carry out the tasks independently.,"Modular programming is a software design technique that emphasizes separating the functionality of a program into independent, interchangeable modules.",1
What is modularization?,"Modularization is a technique to divide a software system into multiple discrete and independent modules, which are expected to be capable of carrying out task(s) independently.",Modularization concerns the logical partitioning of a software design so that the design becomes easy to understand and maintain and doing each job alone,1
What is modularization?,Modularization concerns the logical partitioning of a software design so that the design becomes easy to understand and maintain and doing each job alone,Cohesion is a measure that defines the intra-dependability among the elements of the module.,0
What is modularization?,"Modularization is a technique to divide a software system into multiple discrete and independent modules, which are expected to be capable of carrying out task(s) independently.",Modularization: Modularization is the process of dividing a software system into multiple independent modules where each module works independently.,1
What is modularization?,"Modularization is a technique to divide a software system into multiple discrete and independent modules, which are expected to be capable of carrying out task(s) independently.",Cohesion: Cohesion is a measure of the degree to which the elements of the module are functionally related. It is the degree to which all elements directed towards performing a single task are contained in the component. A good software design will have high cohesion.,0
What is modularization?,"Modularization is a technique to divide a software system into multiple discrete and independent modules, which are expected to be capable of carrying out task(s) independently.","Modular programming is a software design technique that emphasizes separating the functionality of a program into independent, interchangeable modules.",1
What is modularization?,"Modular programming is a software design technique that emphasizes separating the functionality of a program into independent, interchangeable modules.",Cohesion is a measure that defines the intra-dependability among the elements of the module.,0
What is modularization?,Modularization concerns the logical partitioning of a software design so that the design becomes easy to understand and maintain and doing each job alone,Modularization: Modularization is the process of dividing a software system into multiple independent modules where each module works independently.,1
What is modularization?,Modularization concerns the logical partitioning of a software design so that the design becomes easy to understand and maintain and doing each job alone,Cohesion: Cohesion is a measure of the degree to which the elements of the module are functionally related. It is the degree to which all elements directed towards performing a single task are contained in the component. A good software design will have high cohesion.,0
What is modularization?,Modularization concerns the logical partitioning of a software design so that the design becomes easy to understand and maintain and doing each job alone,"Modular programming is a software design technique that emphasizes separating the functionality of a program into independent, interchangeable modules.",1
What is modularization?,Modularization: Modularization is the process of dividing a software system into multiple independent modules where each module works independently.,"Modular programming is a software design technique that emphasizes separating the functionality of a program into independent, interchangeable modules.",1
What is modularization?,Modularization: Modularization is the process of dividing a software system into multiple independent modules where each module works independently.,Cohesion: Cohesion is a measure of the degree to which the elements of the module are functionally related. It is the degree to which all elements directed towards performing a single task are contained in the component. A good software design will have high cohesion.,0
What is cohesion?,Cohesion: Cohesion is a measure of the degree to which the elements of the module are functionally related. It is the degree to which all elements directed towards performing a single task are contained in the component. A good software design will have high cohesion.,Cohesion is a measure that defines the intra-dependability among the elements of the module.,1
What is cohesion?,Cohesion is a measure that defines the intra-dependability among the elements of the module.,"Cohesion refers to the degree to which the elements inside a module belong together.[1] In one sense, it is a measure of the strength of relationship between the methods",0
What is cohesion?,Cohesion: Cohesion is a measure of the degree to which the elements of the module are functionally related. It is the degree to which all elements directed towards performing a single task are contained in the component. A good software design will have high cohesion.,"Cohesion refers to the degree to which the elements inside a module belong together.[1] In one sense, it is a measure of the strength of relationship between the methods",1
What is cohesion?,Cohesion: Cohesion is a measure of the degree to which the elements of the module are functionally related. It is the degree to which all elements directed towards performing a single task are contained in the component. A good software design will have high cohesion.,"It is a programming method, which uses the concepts of a mathematical function. It provides means of computation as mathematical functions, which also produces results irrespective of program state.",0
What is cohesion?,Cohesion: Cohesion is a measure of the degree to which the elements of the module are functionally related. It is the degree to which all elements directed towards performing a single task are contained in the component. A good software design will have high cohesion.,"cohesion defines to the degree to which the elements of a module belong together. Thus, cohesion measures the strength of relationships between pieces of functionality within a given module",1
What is cohesion?,"cohesion defines to the degree to which the elements of a module belong together. Thus, cohesion measures the strength of relationships between pieces of functionality within a given module",Functional programming languages are specially designed to handle symbolic computation and list processing applications. Functional programming is based on mathematical functions.,0
What is cohesion?,Cohesion: Cohesion is a measure of the degree to which the elements of the module are functionally related. It is the degree to which all elements directed towards performing a single task are contained in the component. A good software design will have high cohesion.,Cohesion is the indication of the relationship within a module.,1
What is cohesion?,"Cohesion refers to the degree to which the elements inside a module belong together.[1] In one sense, it is a measure of the strength of relationship between the methods","cohesion defines to the degree to which the elements of a module belong together. Thus, cohesion measures the strength of relationships between pieces of functionality within a given module",1
What is cohesion?,"Cohesion refers to the degree to which the elements inside a module belong together.[1] In one sense, it is a measure of the strength of relationship between the methods",Cohesion is the indication of the relationship within a module.,1
What is cohesion?,"Cohesion refers to the degree to which the elements inside a module belong together.[1] In one sense, it is a measure of the strength of relationship between the methods","It is a programming method, which uses the concepts of a mathematical function. It provides means of computation as mathematical functions, which also produces results irrespective of program state.",0
What is cohesion?,"cohesion defines to the degree to which the elements of a module belong together. Thus, cohesion measures the strength of relationships between pieces of functionality within a given module",Cohesion is the indication of the relationship within a module.,1
What is cohesion?,Cohesion is the indication of the relationship within a module.,Functional programming languages are specially designed to handle symbolic computation and list processing applications. Functional programming is based on mathematical functions.,0
What is functional programming?,"It is a programming method, which uses the concepts of a mathematical function. It provides means of computation as mathematical functions, which also produces results irrespective of program state.",Functional programming languages are specially designed to handle symbolic computation and list processing applications. Functional programming is based on mathematical functions.,1
What is functional programming?,"It is a programming method, which uses the concepts of a mathematical function. It provides means of computation as mathematical functions, which also produces results irrespective of program state.",Quality Assurance checks if proper process is followed while developing the software while Quality Control deals with maintaining the quality of software product.,0
What is functional programming?,"It is a programming method, which uses the concepts of a mathematical function. It provides means of computation as mathematical functions, which also produces results irrespective of program state.","Functional programs are written using pure functions, which are designed to not affect other parts of the program. It is based on abstract math concepts,",1
What is functional programming?,"Functional programs are written using pure functions, which are designed to not affect other parts of the program. It is based on abstract math concepts,",quality assurance defined as an activity to ensure that an organization is providing the best possible product while Quality Control in Software Testing is a systematic set of processes used to ensure the quality of software products or services.,0
What is functional programming?,Functional programming languages are specially designed to handle symbolic computation and list processing applications. Functional programming is based on mathematical functions.,"Functional programs are written using pure functions, which are designed to not affect other parts of the program. It is based on abstract math concepts,",1
What is functional programming?,Functional programming languages are specially designed to handle symbolic computation and list processing applications. Functional programming is based on mathematical functions.,Quality Assurance checks if proper process is followed while developing the software while Quality Control deals with maintaining the quality of software product.,0
What is Quality Assurance vs. Quality Control?,Quality Assurance checks if proper process is followed while developing the software while Quality Control deals with maintaining the quality of software product.,quality assurance defined as an activity to ensure that an organization is providing the best possible product while Quality Control in Software Testing is a systematic set of processes used to ensure the quality of software products or services.,1
What is Quality Assurance vs. Quality Control?,quality assurance defined as an activity to ensure that an organization is providing the best possible product while Quality Control in Software Testing is a systematic set of processes used to ensure the quality of software products or services.,CASE stands for Computer Aided Software Engineering which are used to automate SDLC activities.,0
What are CASE tools?,"CASE means Computer Aided Software Engineering. They are set of automated software application programs, which are used to support, enhance and strengthen the SDLC activities.",CASE stands for Computer Aided Software Engineering which are used to automate SDLC activities.,1
What are CASE tools?,"CASE means Computer Aided Software Engineering. They are set of automated software application programs, which are used to support, enhance and strengthen the SDLC activities.",Process means any program is in execution and Thread is the segment of a process means a process can have multiple threads and these multiple threads are contained within a process.,0
What are CASE tools?,"CASE means Computer Aided Software Engineering. They are set of automated software application programs, which are used to support, enhance and strengthen the SDLC activities.",Computer-Aided Software Engineering (CASE) technologies are tools that provide automated assistance for software development . The goal of introducing CASE is the enhancement of the quality of the systems,1
What are CASE tools?,Computer-Aided Software Engineering (CASE) technologies are tools that provide automated assistance for software development . The goal of introducing CASE is the enhancement of the quality of the systems,process provides the resources needed to execute a program and A thread is an entity within a process.,0
What are CASE tools?,CASE stands for Computer Aided Software Engineering which are used to automate SDLC activities.,Computer-Aided Software Engineering (CASE) technologies are tools that provide automated assistance for software development . The goal of introducing CASE is the enhancement of the quality of the systems,1
What are CASE tools?,CASE stands for Computer Aided Software Engineering which are used to automate SDLC activities.,Process means any program is in execution and Thread is the segment of a process means a process can have multiple threads and these multiple threads are contained within a process.,0
Explain the differences between a Thread and a Process?,Process means any program is in execution and Thread is the segment of a process means a process can have multiple threads and these multiple threads are contained within a process.,process provides the resources needed to execute a program and A thread is an entity within a process.,1
Explain the differences between a Thread and a Process?,process provides the resources needed to execute a program and A thread is an entity within a process.,DLL file is a dynamic link library which can be used in exe files and other dll files. EXE file is a executable file which runs in a separate process which is managed by OS.,0
Explain the differences between a Thread and a Process?,Process means any program is in execution and Thread is the segment of a process means a process can have multiple threads and these multiple threads are contained within a process.,A program in execution is often referred as process. A thread is a part of the process.,1
Explain the differences between a Thread and a Process?,Process means any program is in execution and Thread is the segment of a process means a process can have multiple threads and these multiple threads are contained within a process.,An exe is an executable program while a DLL is a file that can be loaded and executed by programs dynamically.,0
Explain the differences between a Thread and a Process?,Process means any program is in execution and Thread is the segment of a process means a process can have multiple threads and these multiple threads are contained within a process.,An executing instance of a program is called a process. A thread is a subset of the process.,1
Explain the differences between a Thread and a Process?,An executing instance of a program is called a process. A thread is a subset of the process.,DLL file is a dynamic link library which can be used in exe files and other dll files. EXE file is a executable file which runs in a separate process which is managed by OS.,0
Explain the differences between a Thread and a Process?,process provides the resources needed to execute a program and A thread is an entity within a process.,A program in execution is often referred as process. A thread is a part of the process.,1
Explain the differences between a Thread and a Process?,process provides the resources needed to execute a program and A thread is an entity within a process.,An exe is an executable program while a DLL is a file that can be loaded and executed by programs dynamically.,0
Explain the differences between a Thread and a Process?,process provides the resources needed to execute a program and A thread is an entity within a process.,An executing instance of a program is called a process. A thread is a subset of the process.,1
Explain the differences between a Thread and a Process?,A program in execution is often referred as process. A thread is a part of the process.,An executing instance of a program is called a process. A thread is a subset of the process.,1
Explain the differences between a Thread and a Process?,A program in execution is often referred as process. A thread is a part of the process.,An exe is an executable program while a DLL is a file that can be loaded and executed by programs dynamically.,0
what is the difference between an EXE and a DLL?,An exe is an executable program while a DLL is a file that can be loaded and executed by programs dynamically.,DLL file is a dynamic link library which can be used in exe files and other dll files. EXE file is a executable file which runs in a separate process which is managed by OS.,1
what is the difference between an EXE and a DLL?,DLL file is a dynamic link library which can be used in exe files and other dll files. EXE file is a executable file which runs in a separate process which is managed by OS.,Polymorphism is overriding the functions of parent class in the child class during inheritance class.,0
When do you use polymorphism?,Polymorphism is used when there is a need for override functionality when inheriting class. It is about shared classes,Polymorphism is overriding the functions of parent class in the child class during inheritance class.,1
When do you use polymorphism?,Polymorphism is used when there is a need for override functionality when inheriting class. It is about shared classes,two classes overriding the shared functions between them after inheritance,1
When do you use polymorphism?,Polymorphism is overriding the functions of parent class in the child class during inheritance class.,two classes overriding the shared functions between them after inheritance,1
When do you use polymorphism?,Polymorphism is used when there is a need for override functionality when inheriting class. It is about shared classes,Polymorphism is not used when there is a need for override functionality when inheriting class. It is about shared classes,0
When do you use polymorphism?,Polymorphism is overriding the functions of parent class in the child class during inheritance class.,Polymorphism is not overriding the functions of parent class in the child class during inheritance class.,0
When do you use polymorphism?,two classes overriding the shared functions between them after inheritance,Cohesion is a measure that defines the intra-dependability among the elements of the module.,0
