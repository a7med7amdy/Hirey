{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Answers_similarity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5caf89c043e140a389d6dcb682a8bc08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2fb19063860341eaa08504327fa10935",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c0479a27079c491182ce94ba68499c0b",
              "IPY_MODEL_8b54228f16f649869842de3025a854a9"
            ]
          }
        },
        "2fb19063860341eaa08504327fa10935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0479a27079c491182ce94ba68499c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_30dcfe12197242ec8369142cf4eb457e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ba865ebfb5c41238653ad8f40465a0d"
          }
        },
        "8b54228f16f649869842de3025a854a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_53047963746b4f44a951b69bda57907f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 42.7B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9bd31e415d7148c798b4275619ca8c6e"
          }
        },
        "30dcfe12197242ec8369142cf4eb457e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ba865ebfb5c41238653ad8f40465a0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53047963746b4f44a951b69bda57907f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9bd31e415d7148c798b4275619ca8c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ceb2137d31a43689d5ea9be941476c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e164a45ea60f48e0893e538c4fccf70d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_08c07aff95c04095a1500266ad0249bf",
              "IPY_MODEL_f1d78aab00f3471badce3633527a9a7b"
            ]
          }
        },
        "e164a45ea60f48e0893e538c4fccf70d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08c07aff95c04095a1500266ad0249bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a44c8ec324404277ad12dbc00e032dcb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e67513444dfa463fa9b78d55e5ef008a"
          }
        },
        "f1d78aab00f3471badce3633527a9a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f37145b30229420e88f6f09d6c56b98b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:39&lt;00:00, 14.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_063b695458ac49d68a7e7ca47c8f5d6c"
          }
        },
        "a44c8ec324404277ad12dbc00e032dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e67513444dfa463fa9b78d55e5ef008a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f37145b30229420e88f6f09d6c56b98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "063b695458ac49d68a7e7ca47c8f5d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5570172d5c24d97a15c129461f82737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9b5aff0649c64ccb96f3a1f698b293c3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_90f218249a584e6eaa0c4b394e5c2a19",
              "IPY_MODEL_5f871ead71f24fe9bacfd1dc4d3d4a5b"
            ]
          }
        },
        "9b5aff0649c64ccb96f3a1f698b293c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90f218249a584e6eaa0c4b394e5c2a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4554c62465f543b39e11e4bccbb79d4b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ead636b73e5d4d8c83ebbd179f7c6f75"
          }
        },
        "5f871ead71f24fe9bacfd1dc4d3d4a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bb5b3889ece14f0db92ebd7b4751a2eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 269kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83d710aeeeb6487a8cb0273a3c460b4f"
          }
        },
        "4554c62465f543b39e11e4bccbb79d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ead636b73e5d4d8c83ebbd179f7c6f75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb5b3889ece14f0db92ebd7b4751a2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83d710aeeeb6487a8cb0273a3c460b4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58f40c2daa95435b9553b1abd90a83e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5509d5e52e9440788be5c60b6e569556",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eb19598854504930af3556d22eafd1fc",
              "IPY_MODEL_b5e4769edaa94b1a9ed8226399a996dd"
            ]
          }
        },
        "5509d5e52e9440788be5c60b6e569556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb19598854504930af3556d22eafd1fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_94cef286ec0b4dad82cd0642c71dd2c7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b83816e0e63b425c88afe07603d169ac"
          }
        },
        "b5e4769edaa94b1a9ed8226399a996dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_89f708af42d34678a3b71bce54c01180",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:37&lt;00:00, 12.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f8fff6bf543412fb208de1414d7321b"
          }
        },
        "94cef286ec0b4dad82cd0642c71dd2c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b83816e0e63b425c88afe07603d169ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89f708af42d34678a3b71bce54c01180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f8fff6bf543412fb208de1414d7321b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t2Oqtn5jhgd"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import re\n",
        "import string\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwieW9oajoP0",
        "outputId": "ceb7a24b-fc4f-45d3-f16a-707548fb95d9"
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import AutoTokenizer, AutoModel, AdamW\n",
        "!pip install pytorch-pretrained-bert\n",
        "from pytorch_pretrained_bert import BertModel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.18.4)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.4 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.21.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.4->boto3->pytorch-pretrained-bert) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.4->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.4->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKw0xxDFjqIL",
        "outputId": "4edc0739-a42d-4d6f-8b66-e8516a3b3436"
      },
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, set our device to GPU. use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uEuLZhQjsaD",
        "outputId": "34319a67-8235-4a28-da59-8c610731bfd4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "W84OH690jvQu",
        "outputId": "93d0a87c-53de-40bc-8c5d-cac3d980747b"
      },
      "source": [
        "# data1 = pd.read_csv('/content/drive/My Drive/train_snli.txt', sep=\"\\t\", header=None)\n",
        "# data1.columns = [\"ans1\", \"ans2\", \"class\"]\n",
        "data = pd.read_csv('/content/drive/My Drive/Clean_train_data.csv')\n",
        "# frames = [data1, data2]\n",
        "# data = pd.concat(frames)\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "data.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>ans1</th>\n",
              "      <th>ans2</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2809</th>\n",
              "      <td>What do you understand by Perceptron?</td>\n",
              "      <td>Perceptron is a machine learning algorithm tha...</td>\n",
              "      <td>A Perceptron is an algorithm for supervised le...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2435</th>\n",
              "      <td>What is an RNN?</td>\n",
              "      <td>RNN) are the state of the art algorithm for se...</td>\n",
              "      <td>RNNs are designed to recognize the sequential ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>861</th>\n",
              "      <td>what do you know about output layer?</td>\n",
              "      <td>The output layer is the simplest, usually cons...</td>\n",
              "      <td>Autoencoder is an artificial neural network. I...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2776</th>\n",
              "      <td>What do you understand by Perceptron?</td>\n",
              "      <td>A Perceptron is an algorithm used for supervis...</td>\n",
              "      <td>Perceptron is a machine learning algorithm tha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3255</th>\n",
              "      <td>What are stop words?</td>\n",
              "      <td>Stop words are said to be useless data for a s...</td>\n",
              "      <td>Latent Semantic Indexing (LSI) tries to overco...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1943</th>\n",
              "      <td>Explain the following variant of Gradient Desc...</td>\n",
              "      <td>Mini-batch gradient descent is a variation of ...</td>\n",
              "      <td>a compromise between batch GD and SGD. In MB-G...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3607</th>\n",
              "      <td>Why is NLP so hard?</td>\n",
              "      <td>There are several factors that make the proces...</td>\n",
              "      <td>Information extraction (IE) is the automated r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>784</th>\n",
              "      <td>Explain Data Normalization.</td>\n",
              "      <td>The hidden layer after the input layer and bef...</td>\n",
              "      <td>change the values of numeric columns in the da...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1145</th>\n",
              "      <td>What is Model Capacity?</td>\n",
              "      <td>The Rectified Linear Unit is the most commonly...</td>\n",
              "      <td>The capacity of a deep learning neural network...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>What is the meaning of term weight initializat...</td>\n",
              "      <td>n neural networking, weight initialization is ...</td>\n",
              "      <td>This is a type of gradient descent which proce...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Questions  ... class\n",
              "2809              What do you understand by Perceptron?  ...     1\n",
              "2435                                    What is an RNN?  ...     1\n",
              "861                what do you know about output layer?  ...     0\n",
              "2776              What do you understand by Perceptron?  ...     1\n",
              "3255                               What are stop words?  ...     0\n",
              "1943  Explain the following variant of Gradient Desc...  ...     1\n",
              "3607                                Why is NLP so hard?  ...     0\n",
              "784                         Explain Data Normalization.  ...     0\n",
              "1145                            What is Model Capacity?  ...     0\n",
              "510   What is the meaning of term weight initializat...  ...     0\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_S3u2K5j9DH",
        "outputId": "55bb5ff3-d078-40a1-eaf6-cd4c2d0d8a67"
      },
      "source": [
        "# sentences_pairs = data[[\"sentence1\", \"sentence2\"]].values.astype(\"str\")\n",
        "sents_pairs = data[[\"ans1\", \"ans2\"]].values.astype(\"str\")\n",
        "labels = data[\"class\"].values\n",
        "print(sents_pairs.shape, labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4274, 2) (4274,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An5gKQdqkOb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "5caf89c043e140a389d6dcb682a8bc08",
            "2fb19063860341eaa08504327fa10935",
            "c0479a27079c491182ce94ba68499c0b",
            "8b54228f16f649869842de3025a854a9",
            "30dcfe12197242ec8369142cf4eb457e",
            "4ba865ebfb5c41238653ad8f40465a0d",
            "53047963746b4f44a951b69bda57907f",
            "9bd31e415d7148c798b4275619ca8c6e",
            "1ceb2137d31a43689d5ea9be941476c9",
            "e164a45ea60f48e0893e538c4fccf70d",
            "08c07aff95c04095a1500266ad0249bf",
            "f1d78aab00f3471badce3633527a9a7b",
            "a44c8ec324404277ad12dbc00e032dcb",
            "e67513444dfa463fa9b78d55e5ef008a",
            "f37145b30229420e88f6f09d6c56b98b",
            "063b695458ac49d68a7e7ca47c8f5d6c",
            "a5570172d5c24d97a15c129461f82737",
            "9b5aff0649c64ccb96f3a1f698b293c3",
            "90f218249a584e6eaa0c4b394e5c2a19",
            "5f871ead71f24fe9bacfd1dc4d3d4a5b",
            "4554c62465f543b39e11e4bccbb79d4b",
            "ead636b73e5d4d8c83ebbd179f7c6f75",
            "bb5b3889ece14f0db92ebd7b4751a2eb",
            "83d710aeeeb6487a8cb0273a3c460b4f",
            "58f40c2daa95435b9553b1abd90a83e7",
            "5509d5e52e9440788be5c60b6e569556",
            "eb19598854504930af3556d22eafd1fc",
            "b5e4769edaa94b1a9ed8226399a996dd",
            "94cef286ec0b4dad82cd0642c71dd2c7",
            "b83816e0e63b425c88afe07603d169ac",
            "89f708af42d34678a3b71bce54c01180",
            "3f8fff6bf543412fb208de1414d7321b"
          ]
        },
        "outputId": "d6caafb9-7d7c-4b56-ba0c-8d64f123b834"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5caf89c043e140a389d6dcb682a8bc08",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ceb2137d31a43689d5ea9be941476c9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5570172d5c24d97a15c129461f82737",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58f40c2daa95435b9553b1abd90a83e7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s80G1UeQkQ1E",
        "outputId": "08c29d54-810c-4949-e75c-0b38490054f3"
      },
      "source": [
        "sents_pairs[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Deep learning is a part of machine learning with an algorithm inspired by the structure and function of the brain, which is called an artificial neural network.Deep learning is suited over a range of fields such as computer vision, speech recognition, natural language processing, etc.',\n",
              "       'Deep learning is a subset of machine learning in artificial intelligence that has networks capable of learning unsupervised from data that is unstructured or unlabeled. Also known as deep neural learning or deep neural network.'],\n",
              "      dtype='<U1005')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qUAoVFLnYut"
      },
      "source": [
        "def clean_text(text):\n",
        "    #Make text lowercase, remove text in square brackets,remove links,remove punctuation and remove words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    return text\n",
        "\n",
        "def clean2_text(text):\n",
        "  #remove some of stopwords as 'a, an, the'\n",
        "  txt = clean_text(text)\n",
        "  words = txt.split(' ')\n",
        "  aft_remove = [w for w in words if w not in ['a', 'an', 'the','of', 'that', 'which','in', 'at', 'for', 'where', 'when', 'to', 'from']]\n",
        "  return ' '.join(aft_remove)\n",
        "\n",
        "# p = clean_text(sents_pairs[0][0])\n",
        "# print(sents_pairs[0][0])\n",
        "# print(p)\n",
        "\n",
        "# cl_tx = clean2_text(p)\n",
        "# print(cl_tx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPYmWNMaTrrR",
        "outputId": "4c628769-05c3-4388-feb5-963fb8560bb1"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_text(sentence):\n",
        "  doc = nlp(sentence)\n",
        "  # Analyze syntax\n",
        "  nouns = [chunk.text for chunk in doc.noun_chunks]\n",
        "  # print(\"Noun phrases:\", nouns)\n",
        "\n",
        "  #remove the nouns from sentence\n",
        "  tmp = sentence\n",
        "  for x in nouns:\n",
        "    tmp = tmp.replace(x, '')\n",
        "  # print(tmp)\n",
        "\n",
        "  #analyze the verbs\n",
        "  doc2 = nlp(tmp)\n",
        "  verbs = [token.text for token in doc2 if token.dep_ == \"VERB\" or token.dep_ == \"ROOT\" or token.dep_ == \"auxpass\"]\n",
        "  # print(\"Verbs:\", verbs)\n",
        "  # objects = [token.text for token in doc if token.dep_ == \"iobj\" or token.dep_ == \"dobj\" or token.dep_ == \"obj\" or token.dep_ == \"nsubj\"]\n",
        "\n",
        "  tmp2 = tmp\n",
        "  for x in verbs:\n",
        "    # print(x)\n",
        "    tmp2 = tmp2.replace(x, '')\n",
        "  # print(tmp2)\n",
        "\n",
        "  # print(len((' '.join(nouns)).split(' ')))\n",
        "  if ( len( (' '.join(nouns)).split(' ') ) + len( (' '.join(tmp2)).split(' ') ) ) >= 2 and len(verbs) >= 1 :\n",
        "    return True\n",
        "  else:  \n",
        "    return False\n",
        "\n",
        "result = parse_text(\"data is made available output layer\")\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R81wk1kWad9g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87da77d2-6cad-4772-cdf0-d2c9e005227e"
      },
      "source": [
        "sentences_pairs = sents_pairs\n",
        "for i, sent in enumerate(sents_pairs):\n",
        "    tmp1 = str(sent[0])\n",
        "    tmp2 = str(sent[1])\n",
        "    if parse_text(tmp1) and parse_text(tmp2):\n",
        "        sentences_pairs[i][0] = clean2_text(sent[0])\n",
        "        sentences_pairs[i][1] = clean2_text(sent[1])\n",
        "    else:\n",
        "        print(tmp1)\n",
        "        print(tmp2)\n",
        "        print(False)\n",
        "        sentences_pairs = np.delete(sentences_pairs, i)\n",
        "        labels = np.delete(labels, i)\n",
        "        # labels.pop(i)   \n",
        "\n",
        "print(sentences_pairs.shape, labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4274, 2) (4274,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-XQCCaTqBQZ"
      },
      "source": [
        "#know the maximum length of all sentences\n",
        "def get_maximum(sent_pairs):\n",
        "  max_len = 0\n",
        "  # For every sentence...\n",
        "  for sent in sent_pairs:\n",
        "      # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "      input_ids = tokenizer.encode(sent[0], add_special_tokens=True)\n",
        "      input_ids2 = tokenizer.encode(sent[1], add_special_tokens=True)\n",
        "     \n",
        "      max_len = max(max_len, len(input_ids) , len(input_ids2))\n",
        "  return max_len\n",
        "\n",
        "max_length = get_maximum(sentences_pairs)\n",
        "print('Max sentence length: ', max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2b4IGP7rGkq",
        "outputId": "54112af0-3c3d-4fb5-987f-50e2cdffb2dd"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "\n",
        "def encoding_sentences(sentences_pairs, labels, max_length = 200):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  token_type_ids = []\n",
        "\n",
        "  # For every sentence...\n",
        "  for sent_pair in sentences_pairs:\n",
        "\n",
        "      encoded_pair = tokenizer(  sent_pair[0], sent_pair[1], \n",
        "                                padding= 'max_length',  # Pad to max_length\n",
        "                                truncation= True,  # Truncate to max_length\n",
        "                                max_length= max_length,  \n",
        "                                return_tensors='pt'  \n",
        "      )\n",
        "      \n",
        "       \n",
        "      input_ids.append(encoded_pair['input_ids'])\n",
        "      \n",
        "      # And its attention mask that simply differentiates padding from non-padding.\n",
        "      attention_masks.append(encoded_pair['attention_mask'])\n",
        "\n",
        "      # Add its token type id to the list\n",
        "      token_type_ids.append(encoded_pair['token_type_ids'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  token_type_ids = torch.cat(token_type_ids, dim=0)\n",
        "  labels = torch.tensor(labels)\n",
        "\n",
        "  return input_ids, attention_masks, token_type_ids, labels\n",
        "\n",
        "\n",
        "input_ids, attention_masks, token_type_ids, labels = encoding_sentences(sentences_pairs, labels, 128)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences_pairs[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  ['deep learning is part machine learning with algorithm inspired by structure and function brain is called artificial neural networkdeep learning is suited over range fields such as computer vision speech recognition natural language processing etc'\n",
            " 'deep learning is subset machine learning artificial intelligence has networks capable learning unsupervised data is unstructured or unlabeled also known as deep neural learning or deep neural network']\n",
            "Token IDs: tensor([  101,  2784,  4083,  2003,  2112,  3698,  4083,  2007,  9896,  4427,\n",
            "         2011,  3252,  1998,  3853,  4167,  2003,  2170,  7976, 15756,  2897,\n",
            "        26095,  2361,  4083,  2003, 10897,  2058,  2846,  4249,  2107,  2004,\n",
            "         3274,  4432,  4613,  5038,  3019,  2653,  6364,  4385,   102,  2784,\n",
            "         4083,  2003, 16745,  3698,  4083,  7976,  4454,  2038,  6125,  5214,\n",
            "         4083,  4895,  6342,  4842, 11365,  2098,  2951,  2003,  4895,  3367,\n",
            "        26134,  2030,  4895, 20470, 12260,  2094,  2036,  2124,  2004,  2784,\n",
            "        15756,  4083,  2030,  2784, 15756,  2897,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OxLsBT0rNIT",
        "outputId": "238bb3d3-ff19-475b-eae8-fa7ed9b785b3"
      },
      "source": [
        "print(input_ids.shape, attention_masks.shape, labels.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4274, 128]) torch.Size([4274, 128]) torch.Size([4274])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Yr52pMPrQVH",
        "outputId": "6c7b8977-3a67-4281-d65c-43b60864da69"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, token_type_ids, labels)\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3,419 training samples\n",
            "  427 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImhthsCOE8M3"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "# take training samples in random order and Select batches randomly. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), \n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter and  get batches sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size \n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97KalDv3FBJA"
      },
      "source": [
        "class Similarity_Model(nn.Module):\n",
        "    def __init__(self, output_dim, n_layers, hidden_dim, freeze_bert):\n",
        "        super(Similarity_Model,self).__init__()\n",
        " \n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.no_layers = no_layers\n",
        "        \n",
        "        #bert Model and Freeze the BERT model\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "        if freeze_bert:\n",
        "            for p in self.bert_model.parameters():\n",
        "                p.requires_grad = False\n",
        "\n",
        "        #LSTM layers\n",
        "        # self.lstm = nn.LSTM(768, hidden_dim, n_layers, batch_first=True)\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        # linear layer\n",
        "        self.fc = nn.Linear(768, output_dim)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input_ids, attention_masks, token_type_ids, hidden):\n",
        "        batch_size = input_ids.size(0)\n",
        "\n",
        "        # print(\"batch\" , batch_size)\n",
        "\n",
        "        sequence_output, pooled_output = self.bert_model(input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids) \n",
        "\n",
        "        # print(\"seq  \" , len(sequence_output))\n",
        "        \n",
        "        # lstm_out, hidden = self.lstm(sequence_output[0], hidden)\n",
        "        \n",
        "        # # print(\"lstm_out  \" , lstm_out.shape)\n",
        "\n",
        "        # lstm_out = lstm_out.permute(0,2,1)\n",
        "\n",
        "        # # print(\"lstm_out  \" , lstm_out.shape)\n",
        "\n",
        "        \n",
        "        # out_max = F.max_pool1d(lstm_out, kernel_size=lstm_out.shape[2])\n",
        "        # out_avg = F.avg_pool1d(lstm_out, kernel_size=lstm_out.shape[2])\n",
        "        \n",
        "        # out = torch.cat((out_avg, out_max), dim=1)\n",
        "\n",
        "        # # print(\"out  \" , out.shape)\n",
        "\n",
        "        # out = out.permute(0,2,1)\n",
        "\n",
        "        # dropout and fully connected layer\n",
        "        out = self.dropout(pooled_output)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        out = sig_out.view(batch_size, -1)\n",
        "\n",
        "        out = out[:, -1]\n",
        "\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # initialize hidden states with sizes n_layers x batch_size x hidden_dim\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        hidden = (h0,c0)\n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfGLNYXoFDww",
        "outputId": "ce1ef67b-45cb-4e82-d898-edd29424395c"
      },
      "source": [
        "no_layers = 1\n",
        "output_dim = 1\n",
        "hidden_dim = 128\n",
        "Freeze_bert = False\n",
        "model = Similarity_Model(output_dim, no_layers, hidden_dim, Freeze_bert)\n",
        "\n",
        "#moving to gpu\n",
        "model.to(device)\n",
        "\n",
        "# model_save_name = 'Snli_TechSimilarity.pt'\n",
        "# path = F\"/content/drive/My Drive/{model_save_name}\"\n",
        "# model.load_state_dict(torch.load(path))\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity_Model(\n",
            "  (bert_model): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): BertLayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=768, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zeo_UD8FGtN"
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=3e-5\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# function to predict accuracy\n",
        "def acc(pred,label):\n",
        "    pred = torch.round(pred.squeeze())\n",
        "    return torch.sum(pred == label.squeeze()).item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8c-N3SnFKDD"
      },
      "source": [
        "def forward_back_prop(model, optimizer, criterion, batch, hidden):\n",
        "    clip = 5\n",
        "    # input_ids, attention_masks, token_type_ids = np.array(input_ids, dtype=\"int32\"), np.array(attention_masks, dtype=\"int32\"), np.array(token_type_ids, dtype=\"int32\")\n",
        "    # move data to GPU, if available\n",
        "    input_ids, attention_masks, token_type_ids = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
        "    target = batch[3].to(device)\n",
        "    h = tuple([each.data for each in hidden])\n",
        "\n",
        "    optimizer.zero_grad()    \n",
        "    output, hidden = model.forward(input_ids, attention_masks, token_type_ids, h)\n",
        "\n",
        "    # calculate the loss and perform backprop\n",
        "    loss = criterion(output.squeeze(), target.float())\n",
        "    loss.backward()\n",
        "    \n",
        "    # calculating accuracy\n",
        "    accuracy = acc(output,target)\n",
        "    \n",
        "    # clip_grad_norm prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "\n",
        "    # return the loss over a batch and the hidden state produced by our model and accuracy\n",
        "    return loss.item(), hidden, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nhRXE2hFMp3"
      },
      "source": [
        "# model_save_name = 'Snli_TechSimilarity.pt'\n",
        "# path = F\"/content/drive/My Drive/{model_save_name}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkFEUcpZFQrr",
        "outputId": "4b5de6ff-5524-4cb9-ac25-2fbfb23ed036"
      },
      "source": [
        "epochs = 5\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "# train for some number of epochs\n",
        "epoch_tr_loss,epoch_vl_loss = [],[]\n",
        "epoch_tr_acc,epoch_vl_acc = [],[]\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    train_losses = []\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    # initialize hidden state\n",
        "    hidden = model.init_hidden(batch_size)\n",
        "\n",
        "    for batch_i, batch in enumerate(train_dataloader, 1):\n",
        "\n",
        "        # make sure iterate over completely full batches, only\n",
        "        n_batches = len(train_indices)//batch_size\n",
        "        if(batch_i > n_batches):\n",
        "            break\n",
        "\n",
        "        # forward, back prop\n",
        "        loss, hidden, accuracy = forward_back_prop(model, optimizer, criterion, batch, hidden)  \n",
        "\n",
        "        train_losses.append(loss)\n",
        "        train_acc += accuracy\n",
        "        \n",
        "       \n",
        "    val_h = model.init_hidden(batch_size)\n",
        "    val_losses = []\n",
        "    val_acc = 0.0\n",
        "    model.eval()\n",
        "    for batch_i, (input_ids, attention_masks,token_type_ids, labels) in enumerate(validation_dataloader, 1):  \n",
        "        # make sure iterate over completely full batches, only\n",
        "        n_batches = len(validation_dataloader.dataset)//batch_size\n",
        "        if(batch_i > n_batches):\n",
        "            break\n",
        "\n",
        "        val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "        input_ids, labels = input_ids.to(device), labels.to(device)\n",
        "        attention_masks,token_type_ids = attention_masks.to(device), token_type_ids.to(device)\n",
        "        output, val_h = model(input_ids, attention_masks, token_type_ids, val_h)\n",
        "\n",
        "        val_loss = criterion(output.squeeze(), labels.float())\n",
        "        val_losses.append(val_loss.item())\n",
        "        \n",
        "        accuracy = acc(output,labels)\n",
        "        val_acc += accuracy\n",
        "            \n",
        "    epoch_train_loss = np.mean(train_losses)\n",
        "    epoch_val_loss = np.mean(val_losses)    \n",
        "    epoch_train_acc = train_acc/len(train_dataloader.dataset)\n",
        "    epoch_val_acc = val_acc/len(validation_dataloader.dataset)\n",
        "    epoch_tr_loss.append(epoch_train_loss)\n",
        "    epoch_vl_loss.append(epoch_val_loss)\n",
        "    epoch_tr_acc.append(epoch_train_acc)\n",
        "    epoch_vl_acc.append(epoch_val_acc)\n",
        "    print(f'Epoch {epoch}') \n",
        "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
        "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
        "    if epoch_val_loss <= valid_loss_min:\n",
        "        # torch.save(model.state_dict(), path)\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
        "        valid_loss_min = epoch_val_loss\n",
        "    print(25*'==')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "train_loss : 0.2545150618929908 val_loss : 0.11424766036753471\n",
            "train_accuracy : 89.29511553085698 val_accuracy : 93.6768149882904\n",
            "Validation loss decreased (inf --> 0.114248).  Saving model ...\n",
            "==================================================\n",
            "Epoch 2\n",
            "train_loss : 0.11356116897198108 val_loss : 0.11334346535687263\n",
            "train_accuracy : 95.9344837671834 val_accuracy : 93.20843091334895\n",
            "Validation loss decreased (0.114248 --> 0.113343).  Saving model ...\n",
            "==================================================\n",
            "Epoch 3\n",
            "train_loss : 0.04866131750497756 val_loss : 0.10086795073360778\n",
            "train_accuracy : 97.86487276981573 val_accuracy : 94.84777517564403\n",
            "Validation loss decreased (0.113343 --> 0.100868).  Saving model ...\n",
            "==================================================\n",
            "Epoch 4\n",
            "train_loss : 0.02996311304796452 val_loss : 0.11726185109000653\n",
            "train_accuracy : 98.39134249780638 val_accuracy : 95.08196721311475\n",
            "==================================================\n",
            "Epoch 5\n",
            "train_loss : 0.018662216824936278 val_loss : 0.14645663416908625\n",
            "train_accuracy : 98.71307399824511 val_accuracy : 94.14519906323186\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDpDYiP1FS0j"
      },
      "source": [
        "# model.load_state_dict(torch.load(path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju-fNOyCK-rs"
      },
      "source": [
        "# predict the label given text\n",
        "def predict_similrity(text, attention, token_ids):\n",
        "        text, attention, token_ids = text.expand(1,-1), attention.expand(1,-1), token_ids.expand(1,-1)\n",
        "        # print(text.shape, attention.shape, token_ids.shape, test_dataset[i][3].shape)\n",
        "\n",
        "        inputs, attention, token_ids = text.to(device), attention.to(device), token_ids.to(device)\n",
        "        batch_size = 1\n",
        "        h = model.init_hidden(batch_size)\n",
        "        h = tuple([each.data for each in h])\n",
        "        output, h = model(inputs, attention, token_ids, h)\n",
        "        return(output.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQp8Pr6mLAz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db27328-c1eb-4ec1-fa58-58b93eec4772"
      },
      "source": [
        "#calculate test accuracy\n",
        "sum = 0.0\n",
        "for i in range(len(test_dataset)):\n",
        "        # print(test_dataset[i][0].shape, test_dataset[i][1].shape, test_dataset[i][2].shape, test_dataset[i][3].shape)\n",
        "        output = predict_similrity(test_dataset[i][0], test_dataset[i][1], test_dataset[i][2])\n",
        "        if np.round(output) == test_dataset[i][3]:\n",
        "            sum += 1\n",
        "\n",
        "accuracy = sum/len(test_dataset)\n",
        "print(f'test_accuracy : {accuracy*100}')    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_accuracy : 97.66355140186917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2Ae48S5LU7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b9f0aa-c7f2-49cc-e078-2e98fd4fb2df"
      },
      "source": [
        "sentence1 = \"First, Exploding gradient and this Solved by gradient clipping. Second, Dying ReLu — No learning if the activation is 0 (Solved by parametric relu). Third, Mean and variance of activations is not 0 and 1.(Partially solved by subtracting around 0.5 from activation. Better explained in fastai videos). \"\n",
        "sentence2 = \"ReLU units can be fragile during training and can 'die'. For example, a large gradient flowing through a ReLU neuron could cause the weights to update in such a way that the neuron will never activate on any datapoint again. If this happens, then the gradient flowing through the unit will forever be zero from that point on. That is, the ReLU units can irreversibly die during training since they can get knocked off the data manifold.\"\n",
        "\n",
        "\n",
        "encoded_pair = tokenizer(  sentence1, sentence2, \n",
        "                               padding= 'max_length',  # Pad to max_length\n",
        "                               truncation= True,  # Truncate to max_length\n",
        "                               max_length= 195,  \n",
        "                               return_tensors='pt'  \n",
        "    )\n",
        "\n",
        "output = predict_similrity(encoded_pair['input_ids'], encoded_pair['attention_mask'], encoded_pair['token_type_ids'])\n",
        "\n",
        "print(output)\n",
        "print(np.round(output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9980547428131104\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSHwyUQDuCAt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}