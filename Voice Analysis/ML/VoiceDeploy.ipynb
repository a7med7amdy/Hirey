{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "VoiceDeploy.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTYMIkgUSOAq",
        "outputId": "fcfb29b9-841a-4608-c0fa-e41791767673"
      },
      "source": [
        "pip install pydub"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (0.25.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ayi-pv9Urqy"
      },
      "source": [
        "import numpy as np\n",
        "from flask import Flask, request, jsonify, render_template\n",
        "import pickle\n",
        "import librosa\n",
        "import soundfile\n",
        "import os, glob, pickle\n",
        "import shutil\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from pydub import AudioSegment\n",
        "import wave\n",
        "import contextlib"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYGNyOowSOAv"
      },
      "source": [
        "#DataFlair - Extract features (mfcc, chroma, mel) from a sound file\n",
        "def extract_feature(X, mfcc, chroma, mel,sample_rate):   \n",
        "    result=np.array([])\n",
        "    if mfcc:\n",
        "        mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "        result=np.hstack((result, mfccs))\n",
        "    if chroma:\n",
        "        stft=np.abs(librosa.stft(X))\n",
        "        chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "        result=np.hstack((result, chroma))\n",
        "    if mel:\n",
        "        mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "        result=np.hstack((result, mel))\n",
        "    return result"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_rairS_SOAw"
      },
      "source": [
        "def predict_voice(file):\n",
        "    x=[]\n",
        "    y=[]\n",
        "    y, s = librosa.load(file) # Downsample 44.1kHz to 8kHz\n",
        "    feature=extract_feature(X=y, mfcc=True, chroma=True, mel=True,sample_rate=s)\n",
        "    x.append(feature)\n",
        "    y_pred=model.predict(x)\n",
        "    emotion = y_pred[0]\n",
        "    return emotion"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8m9iqdgSOAw",
        "outputId": "0d79d49c-abb4-45b7-aef9-57b34d7be485"
      },
      "source": [
        "#load the model \n",
        "model = pickle.load(open('voice_model.pkl', 'rb'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neural_network.multilayer_perceptron module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neural_network. Anything that cannot be imported from sklearn.neural_network is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.preprocessing.label module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.21.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.21.2 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJaP1Q9MVI3Z"
      },
      "source": [
        "## **Split Audio**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS9bn3GhSvXK"
      },
      "source": [
        "def get_duration(fname):\n",
        "    with contextlib.closing(wave.open(fname,'r')) as f:\n",
        "        frames = f.getnframes()\n",
        "        rate = f.getframerate()\n",
        "        duration = frames / float(rate)\n",
        "        return duration"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcq3gjpmZwBT"
      },
      "source": [
        "def get_emotion_dic(fname):\n",
        "  duration = get_duration(fname) \n",
        "  # frames/ is the directory to stores audio frames\n",
        "  dir='frames'\n",
        "  if not os.path.exists(dir):\n",
        "    os.makedirs(dir)\n",
        "  else:\n",
        "    shutil.rmtree(dir)           \n",
        "    os.makedirs(dir)  \n",
        "  emotion_dic={'bad':0,'medium':0,'good':0}\n",
        "  originalAudio = AudioSegment.from_wav(fname)\n",
        "  for i in range(0,int(duration),3):\n",
        "      #newAudio = AudioSegment.from_wav(\"ted2.wav\")\n",
        "      newAudio = originalAudio[i*1000:(i+3)*1000]\n",
        "      newAudio.export('frames/'+str(i)+'.wav', format=\"wav\") #Exports to a wav file in the current path.\n",
        "      emotion = predict_voice('frames/'+str(i)+'.wav') \n",
        "      emotion_dic[emotion]+=1\n",
        "  return emotion_dic"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In-vLm2EhgMD",
        "outputId": "b9724b87-cacb-4e75-bdb2-965c6fd95634"
      },
      "source": [
        "get_emotion_dic('neutral.wav')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bad': 0, 'good': 0, 'medium': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aB6dmwZSOAx"
      },
      "source": [
        "# Deploy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q17NWiuiSOAx"
      },
      "source": [
        "app = Flask(__name__)\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/predict',methods=['POST'])\n",
        "def predict():\n",
        "    audio = request.files[\"audio\"]\n",
        "    print(audio)\n",
        "    audiofile=audio.filename\n",
        "    #dir of audio is in the current directory \n",
        "    emotion = predict_voice(audiofile)\n",
        "    return emotion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA3diLSfSOAx",
        "outputId": "8f9d8f76-4942-4daf-a041-8658aa527580"
      },
      "source": [
        "app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKDJKCTtSOAy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}